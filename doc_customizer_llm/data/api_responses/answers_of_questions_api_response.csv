,question_id,response
0,63014913,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1595355398, 'answer_id': 63020688, 'question_id': 63014913, 'body': '<p>This was kind of tricky but here is something that works (assumes 2D sparse tensor, although I think should work the same for more outer dimensions). The idea is to first sort the whole sparse tensor (without making it dense) and then slice the first columns. To do that, I needed something like <a href=""https://numpy.org/doc/stable/reference/generated/numpy.lexsort.html"" rel=""nofollow noreferrer""><code>np.lexsort</code></a>, which as far as I know is not provided in TensorFlow as such - however, <a href=""https://www.tensorflow.org/api_docs/python/tf/sparse/reorder"" rel=""nofollow noreferrer""><code>tf.sparse.reorder</code></a> actually does something like a lexsort, so I made another intermediate sparse tensor to take advantage of that.</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\n\nnp.random.seed(0)\n# Input data\nk = 3\nr = np.random.randint(10, size=(6, 8))\nr[np.random.rand(*r.shape) &lt; .5] = 0\nsp = tf.sparse.from_dense(r)\nprint(tf.sparse.to_dense(sp).numpy())\n# [[0 0 0 0 0 0 3 0]\n#  [2 4 0 6 8 0 0 6]\n#  [7 0 0 1 5 9 8 9]\n#  [4 0 0 3 0 0 0 3]\n#  [8 1 0 3 3 7 0 1]\n#  [0 0 0 0 7 0 0 7]]\n\n# List of value indices\nn = tf.size(sp.values, out_type=sp.indices.dtype)\nr = tf.range(n)\n# Sort values\ns = tf.dtypes.cast(tf.argsort(sp.values, direction=\'DESCENDING\'), sp.indices.dtype)\n# Find destination index of each sorted value\nsi = tf.scatter_nd(tf.expand_dims(s, 1), r, [n])\n# Abuse sparse tensor functionality to do lexsort with column and destination index\nsp2 = tf.sparse.SparseTensor(indices=tf.stack([sp.indices[:, 0], si], axis=1),\n                             values=r,\n                             dense_shape=[sp.dense_shape[0], n])\nsp2 = tf.sparse.reorder(sp2)\n# Build top-k result\nrow = sp.indices[:, 0]\n# Make column indices\nd = tf.dtypes.cast(row[1:] - row[:-1] &gt; 0, r.dtype)\nm = tf.pad(r[1:] * d, [[1, 0]])\ncol = r - tf.scan(tf.math.maximum, m)\n# Get only up to k elements per row\nm = col &lt; k\nrow_m = tf.boolean_mask(row, m)\ncol_m = tf.boolean_mask(col, m)\nidx_m = tf.boolean_mask(sp2.values, m)\n# Make result\nscatter_idx = tf.stack([row_m, col_m], axis=-1)\nscatter_shape = [sp.dense_shape[0], k]\n# Use -1 for rows with less than k values\n# (0 is ambiguous)\nvalues = tf.tensor_scatter_nd_update(-tf.ones(scatter_shape, sp.values.dtype),\n                                     scatter_idx, tf.gather(sp.values, idx_m))\nindices = tf.tensor_scatter_nd_update(-tf.ones(scatter_shape, sp.indices.dtype),\n                                      scatter_idx, tf.gather(sp.indices[:, 1], idx_m))\nprint(values.numpy())\n# [[ 3 -1 -1]\n#  [ 8  6  6]\n#  [ 9  9  8]\n#  [ 4  3  3]\n#  [ 8  7  3]\n#  [ 7  7 -1]]\nprint(indices.numpy())\n# [[ 6 -1 -1]\n#  [ 4  3  7]\n#  [ 5  7  6]\n#  [ 0  3  7]\n#  [ 0  5  3]\n#  [ 4  7 -1]]\n</code></pre>\n<hr />\n<p>EDIT: Here is an alternative possibility, which may work well if your tensor is very sparse in all rows. The idea is to &quot;condense&quot; all the sparse tensor values into the first columns (like the previous snippet already did for <code>sp3</code>) and then make that into a dense tensor and apply top-k as usual. The caveat is that the indices would be referred to the condensed tensor, so you have to take yet another step if you want to get the right indices with respect to initial sparse tensor.</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\n\nnp.random.seed(0)\n# Input data\nk = 3\nr = np.random.randint(10, size=(6, 8))\nr[np.random.rand(*r.shape) &lt; .8] = 0\nsp = tf.sparse.from_dense(r)\nprint(tf.sparse.to_dense(sp).numpy())\n# [[0 0 0 0 0 0 3 0]\n#  [0 4 0 6 0 0 0 0]\n#  [0 0 0 0 5 0 0 9]\n#  [0 0 0 0 0 0 0 0]\n#  [8 0 0 0 0 7 0 0]\n#  [0 0 0 0 7 0 0 0]]\n\n# Build &quot;condensed&quot; sparse tensor\nn = tf.size(sp.values, out_type=sp.indices.dtype)\nr = tf.range(n)\n# Make indices\nrow = sp.indices[:, 0]\nd = tf.dtypes.cast(row[1:] - row[:-1] &gt; 0, r.dtype)\nm = tf.pad(r[1:] * d, [[1, 0]])\ncol = r - tf.scan(tf.math.maximum, m)\n# At least as many columns as k\nncols = tf.maximum(tf.math.reduce_max(col) + 1, k)\nsp2 = tf.sparse.SparseTensor(indices=tf.stack([row, col], axis=1),\n                             values=sp.values,\n                             dense_shape=[sp.dense_shape[0], ncols])\n# Get in dense form\ncondensed = tf.sparse.to_dense(sp2)\n# Top-k (indices do not correspond to initial sparse matrix)\nvalues, indices = tf.math.top_k(condensed, k)\nprint(values.numpy())\n# [[3 0 0]\n#  [6 4 0]\n#  [9 5 0]\n#  [0 0 0]\n#  [8 7 0]\n#  [7 0 0]]\n\n# Now get the right indices\nsp3 = tf.sparse.SparseTensor(indices=tf.stack([row, col], axis=1),\n                             values=sp.indices[:, 1],\n                             dense_shape=[sp.dense_shape[0], ncols])\ncondensed_idx = tf.sparse.to_dense(sp3)\nactual_indices = tf.gather_nd(condensed_idx, tf.expand_dims(indices, axis=-1),\n                              batch_dims=1)\nprint(actual_indices.numpy())\n# [[6 0 0]\n#  [3 1 0]\n#  [7 4 0]\n#  [0 0 0]\n#  [0 5 0]\n#  [4 0 0]]\n</code></pre>\n<p>Not sure whether this would be faster or not though.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9983}"
1,62611459,"{'items': [{'owner': {'reputation': 137, 'user_id': 11640695}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1594799559, 'answer_id': 62910060, 'question_id': 62611459, 'body': '<p><a href=""https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s91029-automated-mixed-precision-tools-for-tensorflow-training-v2.pdf"" rel=""nofollow noreferrer"">This</a> guide (slide 13-14) from nvidia mentions custom layers for mixed precision training.</p>\n<p>You have to implement the method <code>cast_input()</code>. In this example the layer is casted to float16 when mixed precision is enabled:</p>\n<pre class=""lang-py prettyprint-override""><code>class CustomBiasLayer(tf.keras.layers.Layer):\n\n def build(self, _):\n   self.v = self.add_weight(\'v\', ())\n   self.built = True\n  \n def call(self, inputs):\n   return inputs + self.v\n\n def cast_inputs(self, inputs):\n   # Casts to float16, the policy\'s lowest-precision dtype\n   return self._mixed_precision_policy.cast_to_lowest(inputs)\n</code></pre>\n<p>I have not tried this myself, so please let me know if this works for you.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9983}"
2,64847875,"{'items': [{'owner': {'reputation': 7656, 'user_id': 17328}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1636694455, 'answer_id': 69938301, 'question_id': 64847875, 'body': ""<p>I just fixed a model where I had defined a loss function and optimizer separate from the model class (used by a <code>tf.function</code> that was exported). I got this error until I moved the loss &amp; optimizer onto the model class.</p>\n<p>I didn't need to implement <code>get_config</code>, as they were hard-coded.</p>\n""}, {'owner': {'reputation': 6124, 'user_id': 5561472}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1605464597, 'answer_id': 64848178, 'question_id': 64847875, 'body': '<p>In order to save/load a model with custom-defined layers, or a subclassed model, you should overwrite the get_config and optionally from_config methods. Additionally, you should use register the custom object so that Keras is aware of it.</p>\n<p>See here: <a href=""https://www.tensorflow.org/guide/keras/save_and_serialize"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/keras/save_and_serialize</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9983}"
3,56213510,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9983}"
4,49899526,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1524062897, 'answer_id': 49902781, 'question_id': 49899526, 'body': '<p>You can express the entire pipeline using <code>tf.data.Dataset</code> objects, which might make things slightly easier:</p>\n\n<pre><code>dataset = tf.data.TextLineDataset(filename)\n\n# Skip the header line.\ndataset = dataset.skip(1)\n\n# Combine 10 lines into a single observation.   \ndataset = dataset.batch(rows_per_ob)\n\ndef parse_observation(line_batch):\n  record_defaults = [[0.0], [0.0], [0.0], [0.0]]\n  a, b, c, d = tf.decode_csv(value, record_defaults=record_defaults)\n  features = tf.stack([a, b, c])\n  label = d[-1]  # Take the label from the last row.\n  return features, label\n\n# Parse each observation into a `row_per_ob X 2` matrix of features and a\n# scalar label.\ndataset = dataset.map(parse_observation)\n\n# Batch multiple observations.\ndataset = dataset.batch(batch_size)\n\n# Optionally add a prefetch for performance.\ndataset = dataset.prefetch(1)\n</code></pre>\n\n<p>To use the values from the dataset, you can make a <code>tf.data.Iterator</code> to get the next element as a pair of <code>tf.Tensor</code> objects, then use these as the input to your model.</p>\n\n<pre><code>iterator = dataset.make_one_shot_iterator()\n\nfeatures_batch, label_batch = iterator.get_next()\n\n# Use the `features_batch` and `label_batch` tensors as the inputs to\n# the model, rather than fetching them and feeding them via the `Session`\n# interface.\ntrain_op = build_model(features_batch, label_batch)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9979}"
5,68984841,"{'items': [{'owner': {'reputation': 1637, 'user_id': 5523920}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1630422953, 'answer_id': 69001257, 'question_id': 68984841, 'body': '<p>Yes, your understanding is correct.</p>\n<p>To achieve what you want, you need to define a custom keras layer. Let\'s suppose the input to the layer is of shape (batch_size, d0, i0). Most part of the layer will be similar to the original <code>Dense</code> layer (link: <a href=""https://github.com/tensorflow/tensorflow/blob/22ffec3a9c44133cba2182d60678d49bb372f020/tensorflow/python/keras/layers/core.py#L1077"" rel=""nofollow noreferrer"">github</a>), except that</p>\n<ol>\n<li>In the <code>build</code> function, the shape of <code>self.kernel</code> is (d0, i0, units) instead. You can get the value of <code>d0</code> as well as <code>i0</code> from <code>input_shape</code>.</li>\n<li>In the <code>call</code> function, to do the specified tensor multiplication between <code>inputs</code> and <code>self.kernel</code>, use <code>tf.einsum</code> with this equation: <code>tf.einsum(\'abc,bcg-&gt;abg\', inputs, self.kernel)</code></li>\n</ol>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9979}"
6,65413136,"{'items': [{'owner': {'reputation': 3693, 'user_id': 6078821}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1608661488, 'answer_id': 65413924, 'question_id': 65413136, 'body': '<p>This is a bug in TF version 2.3, and was fixed in 2.4. I got a response on <a href=""https://github.com/tensorflow/tensorflow/issues/40366"" rel=""nofollow noreferrer"">an issue I filed with TF</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9979}"
7,53164055,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9979}"
8,47327256,"{'items': [{'owner': {'reputation': 1094, 'user_id': 5712507}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1510830847, 'answer_id': 47328227, 'question_id': 47327256, 'body': '<p>That is because of the shape of the output of the tf.nn.dynamic_rnn. From its documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn</a>:</p>\n\n<p>outputs: The RNN output Tensor.</p>\n\n<p>If time_major == False (default), this will be a Tensor shaped: [batch_size, max_time, cell.output_size].</p>\n\n<p>If time_major == True, this will be a Tensor shaped: [max_time, batch_size, cell.output_size].</p>\n\n<p>you are in the default case, so your <code>outputs</code> gas shape <code>[batch_size, max_time, output_size]</code>, and when performing <code>outputs[-1]</code> you obtain a tensor with shape <code>[max_time, output_size]</code>. Probably slicing with <code>outputs[:, -1]</code> should fix it.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9975}"
9,45090843,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9975}"
10,58843164,"{'items': [{'owner': {'reputation': 74, 'user_id': 4911718}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1625313934, 'answer_id': 68236102, 'question_id': 58843164, 'body': '<p>Here\'s a working example with tensorflow 1.13.1 :</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport pandas as pd \nimport numpy as np\n\n\nprod_export_dir = \'my_model_dir\'\ndata =  pd.read_csv(\'my_data.csv\')\n\npredictor = tf.contrib.predictor.from_saved_model(prod_export_dir)\n\nmodel_input = {}\nfor k, v in predictor.feed_tensors.items():\n    model_input[k] = np.array(data[k].tolist(), dtype=v.dtype.as_numpy_dtype)\n\nprediction = predictor(model_input)\n</code></pre>\n'}, {'owner': {'reputation': 7337, 'user_id': 1585523}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1573697458, 'answer_id': 58848371, 'question_id': 58843164, 'body': '<pre class=""lang-py prettyprint-override""><code>predictor({""inputs"":[model_input1, model_input2]})\n</code></pre>\n\n<p>works but that requires enumerating the data manually into multiple <code>tf.train.Example</code> instances</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9975}"
11,57970717,"{'items': [{'owner': {'reputation': 354, 'user_id': 12076271}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1568714408, 'answer_id': 57971850, 'question_id': 57970717, 'body': '<p>Here is a way to achieve the building of a partly-pretrained-and-frozen model:</p>\n\n<pre class=""lang-py prettyprint-override""><code># Load the pre-trained model and freeze it.\npre_trained = tf.keras.applications.InceptionV3(\n    weights=\'imagenet\', include_top=False\n)\npre_trained.trainable = False  # mark all weights as non-trainable\n# Define a Sequential model, adding trainable layers on top of the previous.\nmodel = tf.keras.Sequential([pre_trained])\n# ADD TOP LAYERS HERE, just as you would in your example code\n# You can check that the proper parameters are frozen or learnable with:\nmodel.summary()\n</code></pre>\n\n<p>I do not think you need to alter the loss function compared to the one you gave as an example.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9975}"
12,75640862,"{'items': [{'owner': {'reputation': 19782, 'user_id': 4281353}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1678138502, 'answer_id': 75656060, 'question_id': 75640862, 'body': '<p><code>tf.py_function</code> is traced into a tf.Graph node and tf.Graph execution runs it eagerly using Python interpreter. Hence, while TenforFlow is executing in Graph mode, it can also execute a node eagerly.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9971}"
13,54183967,"{'items': [{'owner': {'reputation': 1836, 'user_id': 1097517}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1547488560, 'answer_id': 54186789, 'question_id': 54183967, 'body': '<p>What you are trying to do can be accomplished by batch matmul. Consider the following changes:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy\nimport time\nimport numpy as np\n\nrc = 1000\n\nsess = tf.Session()\n\n#compute on cpu for comparison later\nvals = np.random.uniform(size=[rc,rc,4]).astype(np.float32)\nmat1 = tf.identity(vals)\nmat2 = tf.transpose(vals, [2, 0, 1])\n\n#store mul in array so all are fetched in run call\nmuls = []\n#I only have one GPU.\nfor deviceName in [\'/cpu:0\', \'/device:GPU:0\']:\n    with tf.device(deviceName):\n\n        def mult(i):\n                product = tf.matmul(mat1[:,:,i],mat1[:,:,i+1])\n                return product\n\n        mul = tf.zeros([rc,rc,3], dtype = tf.float32)\n    mul = tf.map_fn(mult, numpy.array([0,1,2]), dtype = tf.float32, parallel_iterations = 10)\n    muls.append(mul)\n\n#use transposed mat with a shift to matmul in one go\nmul = tf.matmul(mat2[:-1], mat2[1:])\n\nprint(muls)\nprint(mul)\n\nstart = time.time()\nm1 = sess.run(muls)\nend = time.time()\n\nprint(""muls:"", end - start)\n\nstart = time.time()\nm2 = sess.run(mul)\nend = time.time()\n\nprint(""mul:"", end - start)\n\nprint(np.allclose(m1[0],m1[1]))\nprint(np.allclose(m1[0],m2))\nprint(np.allclose(m1[1],m2))\n</code></pre>\n\n<p>The results on my PC are:</p>\n\n<pre><code>[&lt;tf.Tensor \'map/TensorArrayStack/TensorArrayGatherV3:0\' shape=(3, 1000, 1000) dtype=float32&gt;, &lt;tf.Tensor \'map_1/TensorArrayStack/TensorArrayGatherV3:0\' shape=(3, 1000, 1000) dtype=float32&gt;]\nTensor(""MatMul:0"", shape=(3, 1000, 1000), dtype=float32)\nmuls: 0.4262731075286865\nmul: 0.3794088363647461\nTrue\nTrue\nTrue\n</code></pre>\n\n<p>You rarely want to use the CPU synchronously with the GPU as it\'s going to be the bottleneck. The GPUs will be waiting for the CPU to finish. If you do anything with the CPU it should be asynchronous to the GPU so they can run full tilt.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9971}"
14,40742947,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1479835671, 'answer_id': 40748057, 'question_id': 40742947, 'body': '<p>Convert it in a tuple</p>\n\n<pre><code>output = tuple(tf.cond(sw_c, lambda: (a,b), lambda: (c,d)))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9971}"
15,42940451,"{'items': [{'owner': {'reputation': 5186, 'user_id': 992489}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1490203152, 'answer_id': 42958557, 'question_id': 42940451, 'body': ""<p>There is no way to get the filename as it's built on the other side of the C++/python interface.</p>\n\n<p>That said, listing the logdir after writing will let you see what is there.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9971}"
16,56606757,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9967}"
17,42022950,"{'items': [{'owner': {'reputation': 1269, 'user_id': 9828197}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1571214794, 'answer_id': 58409022, 'question_id': 42022950, 'body': '<p>The best solution which works as of today with GPU is to install tensorflow-determinism with the following:</p>\n<pre><code>pip install tensorflow-determinism\n</code></pre>\n<p>Then include the following code to your code</p>\n<pre><code>import tensorflow as tf\nimport os\nos.environ[\'TF_DETERMINISTIC_OPS\'] = \'1\'\n</code></pre>\n<p>source: <a href=""https://github.com/NVIDIA/tensorflow-determinism"" rel=""nofollow noreferrer"">https://github.com/NVIDIA/tensorflow-determinism</a></p>\n'}, {'owner': {'reputation': 16941, 'user_id': 8143158}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1666874506, 'answer_id': 74222227, 'question_id': 42022950, 'body': ""<pre><code>SEED = 42\nimport os\nimport random\n\nos.environ[&quot;TF_DETERMINISTIC_OPS&quot;] = &quot;1&quot;\nkeras.utils.set_random_seed(SEED)\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n</code></pre>\n""}, {'owner': {'reputation': 4524, 'user_id': 5049813}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1616309527, 'answer_id': 66729612, 'question_id': 42022950, 'body': '<p>What has worked for me is following <a href=""https://stackoverflow.com/a/52897216/5049813"">this answer</a> with a few modifications:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport random\n\n# Setting seed value\n# from https://stackoverflow.com/a/52897216\n# generated randomly by running `random.randint(0, 100)` once\nSEED = 75\n# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\nos.environ[\'PYTHONHASHSEED\'] = str(SEED)\n# 2. Set the `python` built-in pseudo-random generator at a fixed value\nrandom.seed(SEED)\n# 3. Set the `numpy` pseudo-random generator at a fixed value\nnp.random.seed(SEED)\n# 4. Set the `tensorflow` pseudo-random generator at a fixed value\ntf.random.set_seed(SEED)\n</code></pre>\n<p>I was not able to figure out how to set the <a href=""https://stackoverflow.com/questions/55142951/tensorflow-2-0-attributeerror-module-tensorflow-has-no-attribute-session"">session seed</a> (step 5), but it didn\'t seem like it was necessary.</p>\n<p>I am running Google Colab Pro on a high-RAM TPU, and my training results (the graph of the loss function) have been exactly the same three times in a row with this method.</p>\n'}, {'owner': {'reputation': 377, 'user_id': 3531215}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1486121394, 'answer_id': 42023225, 'question_id': 42022950, 'body': '<p>One possible reason is that when constructing the model, there are some code using numpy.random module. So maybe you can try to set the seed for numpy, too. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9967}"
18,66916390,"{'items': [{'owner': {'reputation': 49, 'user_id': 12721031}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1638922974, 'answer_id': 70268544, 'question_id': 66916390, 'body': '<p>I faced exactly this problem. In my case, I update the data after every epoch (the number increases). I notice that the number of batches in each epoch  stays the same (although it should depend on the number of samples). My guess is that it is called once during initialization and not updated during each epoch.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9967}"
19,70686756,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1642067583, 'answer_id': 70694530, 'question_id': 70686756, 'body': '<p>Just a small observation using Google Colab. According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#cache"" rel=""nofollow noreferrer"">docs</a>:</p>\n<blockquote>\n<p>Note: For the cache to be finalized, the input dataset must be iterated through in its entirety. Otherwise, subsequent iterations will not use cached data.</p>\n</blockquote>\n<p>And</p>\n<blockquote>\n<p>Note: cache will produce exactly the same elements during each\niteration through the dataset. If you wish to randomize the iteration\norder, make sure to call shuffle after calling cache.</p>\n</blockquote>\n<p>I did notice a few differences when using caching and iterating over the dataset beforehand. Here is an example.</p>\n<p><strong>Prepare data</strong>:</p>\n<pre><code>import random\nimport struct\nimport tensorflow as tf\nimport numpy as np\n\nRAW_N = 2 + 20*20 + 1\n\nbytess = random.sample(range(1, 5000), RAW_N*4)\nwith open(\'mydata.bin\', \'wb\') as f:\n  f.write(struct.pack(\'1612i\', *bytess))\ndef decode_and_prepare(register):\n  register = tf.io.decode_raw(register, out_type=tf.float32)\n  inputs = register[2:402]\n  label = tf.random.uniform(()) + register[402:]\n  return inputs, label\n\nraw_dataset = tf.data.FixedLengthRecordDataset(filenames=[\'/content/mydata.bin\']*7000, record_bytes=RAW_N*4)\nraw_dataset = raw_dataset.map(decode_and_prepare)\n</code></pre>\n<p><strong>Train model <em>without</em> caching and iterating beforehand</strong>:</p>\n<pre class=""lang-py prettyprint-override""><code>total_data_entries = len(list(raw_dataset.map(lambda x, y: (x, y))))\ntrain_ds = raw_dataset.shuffle(buffer_size=total_data_entries).batch(32).prefetch(tf.data.AUTOTUNE)\ninputs = tf.keras.layers.Input((400,))\nx = tf.keras.layers.Dense(200, activation=\'relu\', kernel_initializer=\'normal\')(inputs)\nx = tf.keras.layers.Dense(100, activation=\'relu\', kernel_initializer=\'normal\')(x)\noutputs = tf.keras.layers.Dense(1, kernel_initializer=\'normal\')(x)\nmodel = tf.keras.Model(inputs, outputs)\nmodel.compile(optimizer=\'adam\', loss=\'mse\')\nmodel.fit(train_ds, epochs=5)\n</code></pre>\n<pre><code>Epoch 1/5\n875/875 [==============================] - 4s 3ms/step - loss: 0.1425\nEpoch 2/5\n875/875 [==============================] - 4s 3ms/step - loss: 0.0841\nEpoch 3/5\n875/875 [==============================] - 4s 3ms/step - loss: 0.0840\nEpoch 4/5\n875/875 [==============================] - 4s 3ms/step - loss: 0.0840\nEpoch 5/5\n875/875 [==============================] - 4s 3ms/step - loss: 0.0840\n&lt;keras.callbacks.History at 0x7fc41be037d0&gt;\n</code></pre>\n<p><strong>Training model <em>with</em> caching but <em>no</em> iterating</strong>:</p>\n<pre class=""lang-py prettyprint-override""><code>total_data_entries = len(list(raw_dataset.map(lambda x, y: (x, y))))\ntrain_ds = raw_dataset.shuffle(buffer_size=total_data_entries).cache().batch(32).prefetch(tf.data.AUTOTUNE)\ninputs = tf.keras.layers.Input((400,))\nx = tf.keras.layers.Dense(200, activation=\'relu\', kernel_initializer=\'normal\')(inputs)\nx = tf.keras.layers.Dense(100, activation=\'relu\', kernel_initializer=\'normal\')(x)\noutputs = tf.keras.layers.Dense(1, kernel_initializer=\'normal\')(x)\nmodel = tf.keras.Model(inputs, outputs)\nmodel.compile(optimizer=\'adam\', loss=\'mse\')\nmodel.fit(train_ds, epochs=5)\n</code></pre>\n<pre><code>Epoch 1/5\n875/875 [==============================] - 4s 2ms/step - loss: 0.1428\nEpoch 2/5\n875/875 [==============================] - 2s 2ms/step - loss: 0.0841\nEpoch 3/5\n875/875 [==============================] - 2s 2ms/step - loss: 0.0840\nEpoch 4/5\n875/875 [==============================] - 2s 2ms/step - loss: 0.0840\nEpoch 5/5\n875/875 [==============================] - 2s 3ms/step - loss: 0.0840\n&lt;keras.callbacks.History at 0x7fc41fa87810&gt;\n</code></pre>\n<p><strong>Training model <em>with</em> caching and iterating</strong>:</p>\n<pre class=""lang-py prettyprint-override""><code>total_data_entries = len(list(raw_dataset.map(lambda x, y: (x, y))))\ntrain_ds = raw_dataset.shuffle(buffer_size=total_data_entries).cache().batch(32).prefetch(tf.data.AUTOTUNE)\n_ = list(train_ds.as_numpy_iterator()) # iterate dataset beforehand\ninputs = tf.keras.layers.Input((400,))\nx = tf.keras.layers.Dense(200, activation=\'relu\', kernel_initializer=\'normal\')(inputs)\nx = tf.keras.layers.Dense(100, activation=\'relu\', kernel_initializer=\'normal\')(x)\noutputs = tf.keras.layers.Dense(1, kernel_initializer=\'normal\')(x)\nmodel = tf.keras.Model(inputs, outputs)\nmodel.compile(optimizer=\'adam\', loss=\'mse\')\nmodel.fit(train_ds, epochs=5)\n</code></pre>\n<pre><code>Epoch 1/5\n875/875 [==============================] - 3s 3ms/step - loss: 0.1427\nEpoch 2/5\n875/875 [==============================] - 2s 2ms/step - loss: 0.0841\nEpoch 3/5\n875/875 [==============================] - 2s 2ms/step - loss: 0.0840\nEpoch 4/5\n875/875 [==============================] - 2s 2ms/step - loss: 0.0840\nEpoch 5/5\n875/875 [==============================] - 2s 2ms/step - loss: 0.0840\n&lt;keras.callbacks.History at 0x7fc41ac9c850&gt;\n</code></pre>\n<p>Conclusion: The caching and the prior iteration of the dataset seem to have an effect on training, but in this example only 7000 files were used.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9967}"
20,49346599,"{'items': [{'owner': {'reputation': 11, 'user_id': 4148062}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1521385313, 'answer_id': 49349379, 'question_id': 49346599, 'body': '<p>Okay stupid me - there was actually no issue. It happened that my batch size was exactly the same as the number of features I had, so I got confused and assumed the shape was wrong!</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9963}"
21,63158314,"{'items': [{'owner': {'reputation': 51, 'user_id': 10547657}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1597534501, 'answer_id': 63431733, 'question_id': 63158314, 'body': ""<p>You can ignore this warning in 2.3. This is here to let you know that one of the libraries you're using is calling a method that TensorFlow plans on removing in a future release. For your current usage it'll work fine.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9962}"
22,63383594,"{'items': [{'owner': {'reputation': 17612, 'user_id': 5666087}, 'down_vote_count': 0, 'up_vote_count': 15, 'is_accepted': True, 'score': 15, 'creation_date': 1597280631, 'answer_id': 63386626, 'question_id': 63383594, 'body': '<p>The <code>Layer.build()</code> method is typically used to instantiate the weights of the layer. See the <a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/layers/core.py#L1159-L1190"" rel=""noreferrer"">source code for <code>tf.keras.layers.Dense</code></a> for an example, and note that the weight and bias tensors are created in that function. The <code>Layer.build()</code> method takes an <code>input_shape</code> argument, and the shape of the weights and biases often depend on the shape of the input.</p>\n<p>The <code>Layer.call()</code> method, on the other hand, implements the forward-pass of the layer. You do not want to overwrite <code>__call__</code>, because that is implemented in the base class <code>tf.keras.layers.Layer</code>. In a custom layer, you should implement <code>call()</code>.</p>\n<p><code>Layer.call()</code> does not call <code>Layer.build()</code>. However, <code>Layer().__call__()</code> <em>does</em> call it if the layer has not been built yet (<a href=""https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/keras/engine/base_layer.py#L981-L982"" rel=""noreferrer"">source</a>), and that will set an attribute <code>self.built = True</code> to prevent <code>Layer.build()</code> from being called again. In other words, <code>Layer.__call__()</code> only calls <code>Layer.build()</code> the first time it is called.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9962}"
23,58499116,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9962}"
24,44357675,"{'items': [{'owner': {'reputation': 805, 'user_id': 1269950}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1506453812, 'answer_id': 46434300, 'question_id': 44357675, 'body': '<p>You should return a <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec"" rel=""nofollow noreferrer""><code>tf.estimator.EstimatorSpec</code></a> object. Something to the effect of:</p>\n\n<pre><code>def model_fn(features, labels, mode, params):\n    /*\n    Your marvelous model\n    */\n    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels_onehot, logits=logits)\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())  \n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n</code></pre>\n\n<p>There\'s more to it, so for a better walkthrough, see <a href=""https://www.tensorflow.org/extend/estimators"" rel=""nofollow noreferrer"">here</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9962}"
25,70328363,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1640235410, 'answer_id': 70457811, 'question_id': 70328363, 'body': '<p>As commented by @xdurch0, tf.keras.layers.InputLayer does not take Batch_size.</p>\n<blockquote>\n<p>input_shape:  Shape tuple (not including the batch axis), or TensorShape\ninstance (not including the batch axis).</p>\n</blockquote>\n<p>For information refer this <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer"" rel=""nofollow noreferrer"">link</a></p>\n<p><strong>Working sample code</strong></p>\n<pre><code>import tensorflow as tf\ninput_shape = (4, 1)\nx = tf.random.normal(input_shape)\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.InputLayer(input_shape=input_shape))\nmodel.add(tf.keras.layers.Conv1D(filters=32,\n                  kernel_size=3,\n                  activation=\'tanh\',\n                  padding=\'same\',\n                  strides=1),)\nmodel.add(tf.keras.layers.MaxPool1D(pool_size=2,\n                     padding=\'same\'))\n\noutput = model(x)\n</code></pre>\n<p><strong>Output</strong></p>\n<pre><code>&lt;tf.Tensor: shape=(4, 1, 32), dtype=float32, numpy=\narray([[[ 0.4607179 ,  0.15637583, -0.5004345 , -0.07796285,\n          0.30203223,  0.45201266,  0.01206997,  0.49042067,\n          0.190878  , -0.06044334,  0.35961443, -0.2021137 ,\n         -0.49953443, -0.03703883,  0.31947324,  0.10558284,\n         -0.4071377 , -0.17169577,  0.41974816,  0.35714787,\n         -0.1540432 ,  0.16283943, -0.38012537,  0.08710621,\n          0.5129782 , -0.38887107,  0.06570872,  0.12256396,\n         -0.2707871 ,  0.31438676,  0.08643996,  0.02944363]],\n\n       [[ 0.15212363,  0.04848025, -0.16761488, -0.024035  ,\n          0.09564026,  0.1488167 ,  0.00371435,  0.16364299,\n          0.05939662, -0.01862026,  0.11532419, -0.06297952,\n         -0.16725594, -0.01140236,  0.10152339,  0.03260009,\n         -0.13221109, -0.05331242,  0.13680711,  0.11446481,\n         -0.04774643,  0.05051624, -0.12253318,  0.02686608,\n          0.17265812, -0.12564273,  0.02024639,  0.03788798,\n         -0.08525081,  0.09980103,  0.02665966,  0.00906281]],\n\n       [[-0.15694636, -0.05004002,  0.17290986,  0.02480924,\n         -0.09870265, -0.15353796, -0.00383405, -0.16881739,\n         -0.06130603,  0.01922018, -0.11900602,  0.06500347,\n          0.17254004,  0.01176979, -0.1047715 , -0.03364989,\n          0.13641952,  0.05502706, -0.14115801, -0.11811972,\n          0.04928267, -0.05214129,  0.1264404 , -0.02773144,\n         -0.17810565,  0.12964691, -0.02089867, -0.03910775,\n          0.08798415, -0.1029948 , -0.02751837, -0.00935485]],\n\n       [[ 0.25630587,  0.08277144, -0.281522  , -0.04108214,\n          0.16258071,  0.25089246,  0.0063511 ,  0.27507976,\n          0.10133278, -0.03183164,  0.19552334, -0.10741517,\n         -0.28094047, -0.01949524,  0.17245385,  0.05570482,\n         -0.22355829, -0.09099286,  0.2311481 ,  0.19409074,\n         -0.08152226,  0.0862364 , -0.20751894,  0.04591698,\n          0.28967807, -0.21268068,  0.03461014,  0.06472494,\n         -0.14509352,  0.16956565,  0.04556449,  0.01549565]]],\n      dtype=float32)&gt;\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9958}"
26,63905839,"{'items': [{'owner': {'reputation': 3, 'user_id': 8343298}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1600222911, 'answer_id': 63912228, 'question_id': 63905839, 'body': '<p>The error has been resolved. The problem was with the strides. Someone here already reported this issue and it really helped me to solve this problem <a href=""https://stackoverflow.com/q/37444951/8343298"">Detail description of this problem</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9958}"
27,65863738,"{'items': [{'owner': {'reputation': 112017, 'user_id': 1714410}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1611732301, 'answer_id': 65914563, 'question_id': 65863738, 'body': '<p>Although your data seems to be isotropic, it might not be the case <a href=""https://www.med.upenn.edu/cbica/brats2020/data.html"" rel=""nofollow noreferrer""><sup>1</sup></a>:</p>\n<blockquote>\n<p>The provided data are distributed after their pre-processing, i.e., co-registered to the same anatomical template, interpolated to the same resolution (1 mm^3) and skull-stripped.</p>\n</blockquote>\n<p>It might be the case that the underlying source data was not isotropic, and what you are seeing is the effect of interpolation (some dimensions are &quot;smoother&quot; than the others).</p>\n<p>Have you considered taking advantage of this &quot;isotropic&quot; property and use &quot;across dimensions&quot; augmentations as proposed by</p>\n<p><em>Liad Pollak Zuckerman, Eyal Naor, George Pisha, Shai Bagon, Michal Irani</em> <a href=""http://www.wisdom.weizmann.ac.il/%7Evision/DeepTemporalSR/index.html"" rel=""nofollow noreferrer""><strong>Across Scales &amp; Across Dimensions:\nTemporal Super-Resolution using Deep Internal Learning</strong></a> (ECCV 2020).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9958}"
28,55109696,"{'items': [{'owner': {'reputation': 1878, 'user_id': 8793975}, 'down_vote_count': 0, 'up_vote_count': 26, 'is_accepted': True, 'score': 26, 'creation_date': 1557532025, 'answer_id': 56086070, 'question_id': 55109696, 'body': '<p>In the documentation:</p>\n\n<blockquote>\n  <p>The Model class has the same API as Layer, with the following\n  differences: - It exposes built-in training, evaluation, and\n  prediction loops (model.fit(), model.evaluate(), model.predict()). -\n  It exposes the list of its inner layers, via the model.layers\n  property. - It exposes saving and serialization APIs.</p>\n  \n  <p>Effectively, the ""Layer"" class corresponds to what we refer to in the\n  literature as a ""layer"" (as in ""convolution layer"" or ""recurrent\n  layer"") or as a ""block"" (as in ""ResNet block"" or ""Inception block"").</p>\n  \n  <p>Meanwhile, the ""Model"" class corresponds to what is referred to in the\n  literature as a ""model"" (as in ""deep learning model"") or as a\n  ""network"" (as in ""deep neural network"").</p>\n</blockquote>\n\n<p>So if you want to be able to call <code>.fit()</code>, <code>.evaluate()</code>, or <code>.predict()</code> on those blocks or you want to be able to save and load those blocks separately or something you should use the Model class. The Layer class is leaner so you won\'t bloat the layers with unnecessary functionality...but I would guess that that generally wouldn\'t be a big problem.  </p>\n'}, {'owner': {'reputation': 16316, 'user_id': 423926}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1552335950, 'answer_id': 55109850, 'question_id': 55109696, 'body': '<ul>\n<li>A layer takes in a tensor and give out a tensor which is a result of\nsome tensor operations</li>\n<li>A model is a composition of multiple layers. </li>\n</ul>\n\n<p>If you are building a new model architecture using existing keras/tf layers then build a custom model. </p>\n\n<p>If you are implementing your own custom tensor operations with in a layer, then build a custom layer. If you are using non tensor operation inside your custom layer, then you have to code how the layer will forward propagate and backward propagate. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9958}"
29,48222274,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9958}"
30,75851842,"{'items': [{'owner': {'reputation': 16941, 'user_id': 8143158}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1679940364, 'answer_id': 75859000, 'question_id': 75851842, 'body': ""<p>Couple of mistakes-\nFirst you need to use the <code>einops tensorflow layer</code> for <code>rearrange</code>. The below changes should work:</p>\n<pre><code>from einops.layers.tensorflow import Rearrange\n\na = tf.random.uniform(shape=(1, 196, 196))\nq, k, v = tf.map_fn(fn= Rearrange('b (h n) d -&gt; b h n d', h=14), elems=tf.stack([a, a, a]))\nprint(q.shape, k.shape, v.shape)\n# (1, 14, 14, 196) (1, 14, 14, 196) (1, 14, 14, 196)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9953}"
31,57481282,"{'items': [{'owner': {'reputation': 152, 'user_id': 4615962}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1565715009, 'answer_id': 57482158, 'question_id': 57481282, 'body': '<p>You need to distribute your dataset aslo, for details please refer to this URL.\n - <a href=""https://www.tensorflow.org/beta/tutorials/distribute/training_loops"" rel=""nofollow noreferrer"">https://www.tensorflow.org/beta/tutorials/distribute/training_loops</a></p>\n\n<pre><code>train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n</code></pre>\n\n<p>every part of your model creates under strategy scope like optimizer also.</p>\n\n<pre><code>with strategy.scope():\n  optimizer = tf.keras.optimizers.Adam()\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9953}"
32,58398790,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1571161203, 'answer_id': 58399997, 'question_id': 58398790, 'body': '<p>Here is how you can do the equivalent to <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.ravel_multi_index.html"" rel=""nofollow noreferrer""><code>np.ravel_multi_index</code></a> in TensorFlow:</p>\n\n<pre><code>import tensorflow as tf\n\n# multi_index is 2D (num dimensions x num indices), dims is 1D\n# Does not check for out of bounds indices\ndef tf_ravel_multi_index(multi_index, dims):\n    strides = tf.cumprod(dims, exclusive=True, reverse=True)\n    return tf.reduce_sum(multi_index * tf.expand_dims(strides, 1), axis=0)\n\n# Test\nwith tf.Graph().as_default(), tf.Session() as sess:\n    # Shape tensor\n    shape = tf.constant([4, 5, 6])\n    # Some flat indices\n    idx = tf.constant([23, 56, 4, 17])\n    # Unravel indices\n    unravel = tf.unravel_index(idx, shape)\n    # Ravel indices again\n    idx2 = tf_ravel_multi_index(unravel, shape)\n    # Check result\n    print(*sess.run((unravel, idx2)), sep=\'\\n\')\n    # [[0 1 0 0]\n    #  [3 4 0 2]\n    #  [5 2 4 5]]\n    # [23 56  4 17]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9953}"
33,62877768,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1594650483, 'answer_id': 62878030, 'question_id': 62877768, 'body': '<p>When you pass a dataset to <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""noreferrer""><code>fit</code></a>, it is expected that it will directly generate batches, not individual examples. You just need to batch your dataset before training.</p>\n<pre class=""lang-py prettyprint-override""><code>dataset = dataset.batch(batch_size)\nmodel.fit(x=dataset)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9953}"
34,57929803,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9949}"
35,45869131,"{'items': [{'owner': {'reputation': 2569, 'user_id': 7847518}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1503605983, 'answer_id': 45870240, 'question_id': 45869131, 'body': '<p>If you print the values of <code>A</code>, <code>W</code>, and <code>b</code> for each iteration, you will see that they are alternating (i.e. positive and negative values following each other). This is often due to a large learning rate. In your example, you should be able to fix this behaviour by reducing the learning rate to about <code>0.001</code>:</p>\n\n<pre><code>optimizer = tf.train.GradientDescentOptimizer(0.001)\n</code></pre>\n\n<p>With this learning rate, I achieved a decreasing loss, while <code>A</code> tended to 1 and <code>W</code> and <code>b</code> tended to zero, as expected. </p>\n\n<pre><code>A: [ 0.7536] W: [ 0.42800003] b: [-0.26100001] loss: 7.86113\nA: [ 0.8581112] W: [ 0.45682004] b: [-0.252166] loss: 0.584708\nA: [ 0.88233441] W: [ 0.46283191] b: [-0.25026742] loss: 0.199126\n...\nA: [ 0.96852171] W: [ 0.1454313] b: [-0.11387932] loss: 0.0183883\nA: [ 0.96855479] W: [ 0.14527865] b: [-0.11376046] loss: 0.0183499\nA: [ 0.96858788] W: [ 0.14512616] b: [-0.11364172] loss: 0.0183113\nA: [ 0.9686209] W: [ 0.14497384] b: [-0.1135231] loss: 0.0182731\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9949}"
36,74201166,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9949}"
37,57403472,"{'items': [{'owner': {'reputation': 399, 'user_id': 7508594}, 'down_vote_count': 0, 'up_vote_count': 15, 'is_accepted': False, 'score': 15, 'creation_date': 1565223333, 'answer_id': 57403695, 'question_id': 57403472, 'body': '<p>Wow, this is embarassing, but I have found the solution and it\'s simplicity literally makes me feel like an idiot for asking this. But I will leave the answer up just in case anyone else is ever facing this issue.</p>\n\n<p>You first create a new tf.data.Dataset object using any function that returns a Dataset, such as "".map"".</p>\n\n<p>Then you create a new Dataset by zipping the original and the one with the new data:</p>\n\n<pre><code>dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9949}"
38,51392594,"{'items': [{'owner': {'reputation': 1043, 'user_id': 9063971}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': False, 'score': 0, 'creation_date': 1606230992, 'answer_id': 64989420, 'question_id': 51392594, 'body': '<p>I had the dim error too, but got fixed by passing the right loss function in <code>model.compile</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9945}"
39,34877523,"{'items': [{'owner': {'reputation': 20463, 'user_id': 1179925}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1555940465, 'answer_id': 55795328, 'question_id': 34877523, 'body': '<p>I see this kind of hack to check assert:</p>\n\n<pre><code>assertion = tf.assert_equal(tf.shape(image)[-1], 3, message=""image must have 3 color channels"")\nwith tf.control_dependencies([assertion]):\n    image = tf.identity(image)\n</code></pre>\n\n<p>Also it\'s used just to give a name:</p>\n\n<pre><code>image = tf.identity(image, name=\'my_image\')\n</code></pre>\n'}, {'owner': {'reputation': 833, 'user_id': 8755319}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1518129445, 'answer_id': 48695926, 'question_id': 34877523, 'body': ""<p>When our input data is serialized in bytes, and we want to extract features from this dataset. We can do so in key-value format and then get a placeholder for it. Its benefits are more realised when there are multiple features and each feature has to be read in different format.</p>\n\n<pre><code>  #read the entire file in this placeholder      \n  serialized_tf_example = tf.placeholder(tf.string, name='tf_example')\n\n  #Create a pattern in which data is to be extracted from input files\n  feature_configs = {'image': tf.FixedLenFeature(shape=[256], dtype=tf.float32),/\n                     'text': tf.FixedLenFeature(shape=[128], dtype=tf.string),/\n                     'label': tf.FixedLenFeature(shape=[128], dtype=tf.string),}\n\n  #parse the example in key: tensor dictionary\n  tf_example = tf.parse_example(serialized_tf_example, feature_configs)\n\n  #Create seperate placeholders operation and tensor for each feature\n  image = tf.identity(tf_example['image'], name='image')\n  text  = tf.identity(tf_example['text'], name='text')\n  label = tf.identity(tf_example['text'], name='label')\n</code></pre>\n""}, {'owner': {'reputation': 76, 'user_id': 2017102}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1514212180, 'answer_id': 47969514, 'question_id': 34877523, 'body': '<p>In distribution training, we should use tf.identity or the workers will hang at waiting for initialization of the chief worker:</p>\n\n<pre><code>vec = tf.identity(tf.nn.embedding_lookup(embedding_tbl, id)) * mask\nwith tf.variable_scope(""BiRNN"", reuse=None):\n    out, _ = tf.nn.bidirectional_dynamic_rnn(fw, bw, vec, sequence_length=id_sz, dtype=tf.float32)\n</code></pre>\n\n<p>For details, without identity, the chief worker would treat some variables as local variables inappropriately and the other workers wait for an initialization operation that can not end</p>\n'}, {'owner': {'reputation': 1129, 'user_id': 5307226}, 'down_vote_count': 0, 'up_vote_count': 17, 'is_accepted': False, 'score': 17, 'creation_date': 1514095664, 'answer_id': 47958446, 'question_id': 34877523, 'body': '<p>In addition to the above, I simply use it when I need to assign a name to ops that do not have a name argument, just like when initializing a state in RNN\'s:</p>\n\n<pre><code>rnn_cell = tf.contrib.rnn.MultiRNNCell([cells])\n# no name arg\ninitial_state = rnn_cell.zero_state(batch_size,tf.float32)\n# give it a name with tf.identity()\ninitial_state = tf.identity(input=initial_state,name=""initial_state"")\n</code></pre>\n'}, {'owner': {'reputation': 81, 'user_id': 3333803}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1498213516, 'answer_id': 44719124, 'question_id': 34877523, 'body': '<p>I found another application of tf.identity in Tensorboard.\nIf you use tf.shuffle_batch, it returns multiple tensors at once, so you see messy picture when visualizing the graph, you can\'t split tensor creation pipeline from actiual input tensors: <a href=""https://i.stack.imgur.com/UwAaH.png"" rel=""nofollow noreferrer"">messy</a></p>\n\n<p>But with tf.identity you can create duplicate nodes, which don\'t affect computation flow: <a href=""https://i.stack.imgur.com/LJs84.png"" rel=""nofollow noreferrer"">nice</a></p>\n'}, {'owner': {'reputation': 606, 'user_id': 3312142}, 'down_vote_count': 1, 'up_vote_count': 6, 'is_accepted': False, 'score': 5, 'creation_date': 1472117602, 'answer_id': 39141615, 'question_id': 34877523, 'body': '<p>I came across another use case that is not completely covered by the other answers.</p>\n\n<pre><code>def conv_layer(input_tensor, kernel_shape, output_dim, layer_name, decay=None, act=tf.nn.relu):\n    """"""Reusable code for making a simple convolutional layer.\n    """"""\n    # Adding a name scope ensures logical grouping of the layers in the graph.\n    with tf.name_scope(layer_name):\n        # This Variable will hold the state of the weights for the layer\n        with tf.name_scope(\'weights\'):\n            weights = weight_variable(kernel_shape, decay)\n            variable_summaries(weights, layer_name + \'/weights\')\n        with tf.name_scope(\'biases\'):\n            biases = bias_variable([output_dim])\n            variable_summaries(biases, layer_name + \'/biases\')\n        with tf.name_scope(\'convolution\'):\n            preactivate = tf.nn.conv2d(input_tensor, weights, strides=[1, 1, 1, 1], padding=\'SAME\')\n            biased = tf.nn.bias_add(preactivate, biases)\n            tf.histogram_summary(layer_name + \'/pre_activations\', biased)\n        activations = act(biased, \'activation\')\n        tf.histogram_summary(layer_name + \'/activations\', activations)\n        return activations\n</code></pre>\n\n<p>Most of the time when constructing a convolutional layer, you just want the activations returned so you can feed those into the next layer. Sometimes, however - for example when building an auto-encoder - you want the pre-activation values.</p>\n\n<p>In this situation an elegant solution is to pass <code>tf.identity</code> as the activation function, effectively not activating the layer.</p>\n'}, {'owner': {'reputation': 3056, 'user_id': 1441121}, 'down_vote_count': 1, 'up_vote_count': 69, 'is_accepted': True, 'score': 68, 'creation_date': 1453218432, 'answer_id': 34881060, 'question_id': 34877523, 'body': ""<p>After some stumbling I think I've noticed a single use case that fits all the examples I've seen. If there are other use cases, please elaborate with an example.</p>\n\n<p>Use case:</p>\n\n<p>Suppose you'd like to run an operator every time a particular Variable is evaluated. For example, say you'd like to add one to <code>x</code> every time the variable <code>y</code> is evaluated. It might seem like this will work:</p>\n\n<pre><code>x = tf.Variable(0.0)\nx_plus_1 = tf.assign_add(x, 1)\n\nwith tf.control_dependencies([x_plus_1]):\n    y = x\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as session:\n    init.run()\n    for i in xrange(5):\n        print(y.eval())\n</code></pre>\n\n<p>It doesn't: it'll print 0, 0, 0, 0, 0. Instead, it seems that we need to add a new node to the graph within the <code>control_dependencies</code> block. So we use this trick:</p>\n\n<pre><code>x = tf.Variable(0.0)\nx_plus_1 = tf.assign_add(x, 1)\n\nwith tf.control_dependencies([x_plus_1]):\n    y = tf.identity(x)\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as session:\n    init.run()\n    for i in xrange(5):\n        print(y.eval())\n</code></pre>\n\n<p>This works: it prints 1, 2, 3, 4, 5.</p>\n\n<p>If in the CIFAR-10 tutorial we dropped <code>tf.identity</code>, then <code>loss_averages_op</code> would never run.</p>\n""}, {'owner': {'reputation': 6215, 'user_id': 5543198}, 'down_vote_count': 1, 'up_vote_count': 38, 'is_accepted': False, 'score': 37, 'creation_date': 1453209311, 'answer_id': 34877802, 'question_id': 34877523, 'body': '<p><code>tf.identity</code> is useful when you want to explicitly transport tensor between devices (like, from GPU to a CPU).\nThe op adds send/recv nodes to the graph, which make a copy when the devices of the input and the output are different.</p>\n\n<p>A default behavior is that the send/recv nodes are added implicitly when the operation happens on a different device but you can imagine some situations (especially in a multi-threaded/distributed settings) when it might be useful to fetch the value of the variable multiple times within a single execution of the <code>session.run</code>. <code>tf.identity</code> allows for more control with regard to when the value should be read from the source device. Possibly a more appropriate name for this op would be <code>read</code>.</p>\n\n<p>Also, please note that in the implementation of <code>tf.Variable</code> <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/variables.py#L205"" rel=""noreferrer"">link</a>, the identity op is added in the constructor, which makes sure that all the accesses to the variable copy the data from the source only once. Multiple copies can be expensive in cases when the variable lives on a GPU but it is read by multiple CPU ops (or the other way around). Users can change the behavior with multiple calls to <code>tf.identity</code> when desired.</p>\n\n<p>EDIT: Updated answer after the question was edited.</p>\n\n<p>In addition, <code>tf.identity</code> can be used used as a dummy node to update a reference to the tensor. This is useful with various control flow ops. In the CIFAR case we want to enforce that the ExponentialMovingAverageOp will update relevant variables before retrieving the value of the loss. This can be implemented as:</p>\n\n<pre><code>with tf.control_dependencies([loss_averages_op]):\n  total_loss = tf.identity(total_loss)\n</code></pre>\n\n<p>Here, the <code>tf.identity</code> doesn\'t do anything useful aside of marking the <code>total_loss</code> tensor to be ran after evaluating <code>loss_averages_op</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9945}"
40,73726034,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1663220868, 'answer_id': 73726162, 'question_id': 73726034, 'body': '<p>Use <code>tf.data.Dataset.elementspec</code>:</p>\n<pre><code>import numpy as np\nimport tensorflow as tf\n\nx, y = np.array([1, 2, 3, 4]), np.array([5, 6, 7, 8])\nd = tf.data.Dataset.from_tensors((x,y))\nd.element_spec\n</code></pre>\n<pre><code>(TensorSpec(shape=(4,), dtype=tf.int64, name=None),\n TensorSpec(shape=(4,), dtype=tf.int64, name=None))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9943}"
41,64737363,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9943}"
42,56385622,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9941}"
43,57651287,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9941}"
44,60237912,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9941}"
45,57835609,"{'items': [{'owner': {'reputation': 7846, 'user_id': 2787185}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1568023100, 'answer_id': 57851715, 'question_id': 57835609, 'body': '<p>Which <code>tensorflow</code> version do you use? There is a known issue with 2.0.0 <a href=""https://youtrack.jetbrains.com/issue/PY-37589"" rel=""nofollow noreferrer"">https://youtrack.jetbrains.com/issue/PY-37589</a></p>\n'}, {'owner': {'reputation': 341, 'user_id': 8302848}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1567874388, 'answer_id': 57835631, 'question_id': 57835609, 'body': ""<p>You have to set your projects' python interpreter to the one that you are using.</p>\n\n<p>Try to change it in <code>File-&gt;settings-&gt;Project-&gt;project interpreter</code> and then select the python from the environment where you have tensorflow installed</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9941}"
46,66146394,"{'items': [{'owner': {'reputation': 187, 'user_id': 16681242}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1650641563, 'answer_id': 71971239, 'question_id': 66146394, 'body': ""<p>Here is a way to do this. A few relevant notes:</p>\n<ol>\n<li><p>I'm using the California housing dataset from scikit-learn, I haven't included that portion of the code, but train_ds is already split into X, y and the dataset is already set up.</p>\n</li>\n<li><p>I setup up this particular feature_layer using feature_columns, which I know is deprecated in favor of preprocessing layers in keras.  It was instantiated using:</p>\n</li>\n</ol>\n<pre><code>feature_layer = tf.keras.layers.DenseFeatures(                                                                                                                            \n      dictionary_of_all_feature_columns.values())\n</code></pre>\n<p>I don't believe this should affect the use of the function below in other contexts, but I'll test it as I get to preprocessing layers in Keras. It also only handles numeric, one-hot encoded, and bucketized feature columns. I'm at the beginning of my study of feature engineering, so have not experienced too much diversity on variable types.  Will update here as I make progress over there.</p>\n<pre><code>import pandas as pd\n\n# Get one batch of what we're going to process\n[(X, y)] = train_ds.take(1)                                                                                                                                                 \n                                                                                                                                                                            \n                                                                                                                                                                            \ndef get_feature_names(feature_layer):\n    &quot;&quot;&quot;\n    Takes as input a preprocessing layer of type \n    keras.feature_column.dense_features_v2.DenseFeatures\n    and returns as output a list containing variable names in the order that \n    they are processed by the layer.  Only deals with numeric and categorical \n    variables. The one-hot encoded variable names match how scikit-learn \n    names them, namely variable_name + _ + category_in_vocabulary_list and similarly with bucket ranges.\n    &quot;&quot;&quot;                                                                                                                                        \n    feature_list = []                                                                                                                                                       \n    feature_layer_dictionary = feature_layer.get_config()                                                                                                                   \n    list_of_encoded_features = feature_layer_dictionary[&quot;feature_columns&quot;]                                                                                                  \n    for encoded_feature in list_of_encoded_features:                                                                                                                        \n        class_name = encoded_feature[&quot;class_name&quot;]                                                                                                                          \n        if class_name == 'NumericColumn':                                                                                                                                   \n            feature_list.append(encoded_feature['config']['key'])                                                                                                           \n        elif class_name == 'IndicatorColumn':                                                                                                                               \n            variable_name = encoded_feature['config'][                                                                                                                      \n                'categorical_column']['config']['key']                                                                                                                      \n            category_list = list(                                                                                                                                           \n                encoded_feature['config']                                                                                                                                   \n                ['categorical_column']['config']                                                                                                                            \n                ['vocabulary_list'])                                                                                                                                        \n            for category in category_list:                                                                                                                                  \n                feature_list.append(variable_name + &quot;_&quot; + category)                                                                                                         \n        elif class_name == 'BucketizedColumn':                                                                                                                              \n            variable_name = encoded_feature['config'][                                                                                                                      \n                'source_column']['config']['key']                                                                                                                           \n            boundary_list = list(encoded_feature['config']['boundaries'])                                                                                                   \n            boundary_list.insert(0, -np.inf)                                                                                                                                \n            boundary_list.append(np.inf)                                                                                                                                    \n            for i in range(len(boundary_list) - 1):                                                                                                                         \n                begin_bucket = str(boundary_list[i])                                                                                                                        \n                end_bucket = str(boundary_list[i+1])                                                                                                                        \n                both_sides_bucket = begin_bucket + &quot;_&quot; + end_bucket                                                                                                         \n                encoded_variable_name = variable_name + &quot;_&quot; + both_sides_bucket                                                                                             \n                feature_list.append(encoded_variable_name)                                                                                                                  \n                                                                                                                                                                            \n        else:                                                                                                                                                               \n            pass                                                                                                                                                            \n    return feature_list \n                                                                                                                                                                            \npreprocessed_df = pd.DataFrame(X, columns=list(X.keys()))                                                                                                                   \npostprocessed_df = pd.DataFrame(                                                                                                                                            \n    feature_layer(X),                                                                                                                                                       \n    columns=get_feature_names(feature_layer))\n\n[ins] In [344]: preprocessed_df.iloc[0]                                                                                                                                     \nOut[344]:                                                                                                                                                                   \nlongitude                -119.3                                                                                                                                             \nlatitude                  36.34                                                                                                                                             \nhousing_median_age         45.0                                                                                                                                             \ntotal_rooms              3723.0                                                                                                                                             \ntotal_bedrooms            831.0                                                                                                                                             \npopulation               2256.0                                                                                                                                             \nhouseholds                770.0                                                                                                                                             \nmedian_income            1.8299                                                                                                                                             \nocean_proximity       b'INLAND'                                                                                                                                             \nName: 0, dtype: object                                                                                                                                                      \n                                                                                                                                                                            \n[ins] In [345]: postprocessed_df.iloc[0]                                                                                                                                    \nOut[345]:                                                                                                                                                                   \nhouseholds                    0.707083                                                                                                                                      \nhousing_median_age_-inf_2     0.000000                                                                                                                                      \nhousing_median_age_2_5        0.000000                                                                                                                                      \nhousing_median_age_5_10       0.000000                                                                                                                                      \nhousing_median_age_10_15      0.000000                                                                                                                                      \nhousing_median_age_15_20      0.000000                                                                                                                                      \nhousing_median_age_20_30      0.000000                                                                                                                                      \nhousing_median_age_30_40      0.000000                                                                                                                                      \nhousing_median_age_40_inf     1.000000                                                                                                                                      \nlatitude                      0.334551                                                                                                                                      \nlongitude                     0.132462                                                                                                                                      \nmedian_income                -1.066948                                                                                                                                      \nocean_proximity_&lt;1H OCEAN     0.000000                                                                                                                                      \nocean_proximity_INLAND        1.000000                                                                                                                                      \nocean_proximity_NEAR OCEAN    0.000000                                                                                                                                      \nocean_proximity_NEAR BAY      0.000000                                                                                                                                      \nocean_proximity_ISLAND        0.000000                                                                                                                                      \npopulation                    0.724704                                                                                                                                      \ntotal_bedrooms                0.697491                                                                                                                                      \ntotal_rooms                   0.501156                                                                                                                                      \nName: 0, dtype: float32                \n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9941}"
47,45774938,"{'items': [{'owner': {'reputation': 1738, 'user_id': 8429154}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1503171346, 'answer_id': 45775635, 'question_id': 45774938, 'body': ""<blockquote>\n  <p>By documenation this should be axis...but that can't be, right? </p>\n</blockquote>\n\n<p>From tensorflow 1.0 onwards, the first argument of <code>tf.split</code> is not the axis, but I assume that the code was written using an older version where the first argument is indeed the axis. </p>\n\n<blockquote>\n  <p>Isn't x one dimensional?</p>\n</blockquote>\n\n<p><code>x</code> is not one dimensional. Right before the call to <code>tf.split</code>, <code>x</code> is reshaped from 3 to 2 dimensions with this statement:</p>\n\n<pre><code>x = tf.reshape(x, [-1, chunk_size])\n</code></pre>\n\n<p>The statement reshapes <code>x</code> into a tensor with two dimensions: the size of the second dimension is <code>chunk_size</code> and the size of the first dimension is inferred (that is what the <code>-1</code> denotes here).</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9936}"
48,53569622,"{'items': [{'owner': {'reputation': 16217, 'user_id': 1462770}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': True, 'score': 0, 'creation_date': 1543731187, 'answer_id': 53577894, 'question_id': 53569622, 'body': '<p>According to Tensorflow <a href=""https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint"" rel=""nofollow noreferrer"">docs</a>:</p>\n\n<blockquote>\n  <p><code>Checkpoint.save</code> and <code>Checkpoint.restore</code> write and read object-based\n  checkpoints, in contrast to <code>tf.train.Saver</code> which writes and reads\n  variable.name based checkpoints. Object-based checkpointing saves a\n  graph of dependencies between Python objects (Layers, Optimizers,\n  Variables, etc.) with named edges, and this graph is used to match\n  variables when restoring a checkpoint. It can be more robust to\n  changes in the Python program, and helps to support restore-on-create\n  for variables when executing eagerly. <strong>Prefer <code>tf.train.Checkpoint</code> over\n  <code>tf.train.Saver</code> for new code</strong>.</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9936}"
49,47380573,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9936}"
50,40347742,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1477936767, 'answer_id': 40347828, 'question_id': 40347742, 'body': ""<p>The <code>fifo.close()</code> call in your code doesn't actually close the queue: instead it returns a <code>tf.Operation</code> that, when run, will close the queue. If you replace it with the following code, you should see the exception as expected:</p>\n\n<pre><code>close_op = fifo.close()\nsess.run(close_op)\n\n# Now `sess.run(data)` will return values until all of the elements in the queue\n# have been dequeued.\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9936}"
51,57878623,"{'items': [{'owner': {'reputation': 1630, 'user_id': 10025506}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1568197366, 'answer_id': 57887051, 'question_id': 57878623, 'body': ""<blockquote>\n  <p>I don't understand how having a shape [50,1] is not the same as being 1D.</p>\n</blockquote>\n\n<p>While you can reshape a [50, 1] 2D matrix into a [50] 1D matrix just with a simple squeeze, Tensorflow will never do that automatically. </p>\n\n<p>The only heuristic the <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> uses to check if the input shape is correct is to check the number of dimensions it has. If it's not 1D, it fails without trying other heuristics like checking if the input could be squeezed. This is a security feature.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9936}"
52,38045785,"{'items': [{'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1540006124, 'answer_id': 52902150, 'question_id': 38045785, 'body': '<p>In addition to Olivier\'s answer, the global step is incremented also in <a href=""https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer#apply_gradients"" rel=""nofollow noreferrer"">apply_gradients</a> (which is one of the steps in <a href=""https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer#minimize"" rel=""nofollow noreferrer"">minimize</a>). </p>\n\n<blockquote>\n  <p>If global_step was not None, that operation also increments\n  global_step</p>\n</blockquote>\n\n<p>So no matter how you do optimization (with just minimize or modifying the gradients), the global step is incremented.</p>\n'}, {'owner': {'reputation': 28028, 'user_id': 5098368}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1467008127, 'answer_id': 38046989, 'question_id': 38045785, 'body': '<p>The variable <code>global_step</code> is passed to the <code>minimize</code> function and will be incremented each time the training operation <code>learning_step</code> is run. </p>\n\n<p>It is even written in the commentary of your code:</p>\n\n<blockquote>\n  <p><code># Passing global_step to minimize() will increment it at each step.</code></p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9931}"
53,50606178,"{'items': [{'owner': {'reputation': 16941, 'user_id': 8143158}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1527694139, 'answer_id': 50608469, 'question_id': 50606178, 'body': '<p>Various <code>bucketing</code> use cases using <code>Dataset API</code> are explained well <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/kernel_tests/bucketing_test.py"" rel=""nofollow noreferrer"">here</a>.</p>\n\n<p><strong><code>bucket_by_sequence_length()</code> example:</strong></p>\n\n<pre><code>def elements_gen():\n   text = [[1, 2, 3], [3, 4, 5, 6, 7], [1, 2], [8, 9, 0, 2]]\n   label = [1, 2, 1, 2]\n   for x, y in zip(text, label):\n       yield (x, y)\n\ndef element_length_fn(x, y):\n   return tf.shape(x)[0]\n\ndataset = tf.data.Dataset.from_generator(generator=elements_gen,\n                                     output_shapes=([None],[]),\n                                     output_types=(tf.int32, tf.int32))\n\ndataset =   dataset.apply(tf.contrib.data.bucket_by_sequence_length(element_length_func=element_length_fn,\n                                                              bucket_batch_sizes=[2, 2, 2],\n                                                              bucket_boundaries=[0, 8]))\n\nbatch = dataset.make_one_shot_iterator().get_next()\n\nwith tf.Session() as sess:\n\n   for _ in range(2):\n      print(\'Get_next:\')\n      print(sess.run(batch))\n</code></pre>\n\n<p><strong>Output:</strong></p>\n\n<pre><code>Get_next:\n(array([[1, 2, 3, 0, 0],\n   [3, 4, 5, 6, 7]], dtype=int32), array([1, 2], dtype=int32))\nGet_next:\n(array([[1, 2, 0, 0],\n   [8, 9, 0, 2]], dtype=int32), array([1, 2], dtype=int32))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9931}"
54,59074659,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1590047623, 'answer_id': 61929802, 'question_id': 59074659, 'body': '<p>Many TensorFlow operations are accelerated using the GPU for computation. Without any annotations, TensorFlow automatically decides whether to use the GPU or CPU for an operationcopying the tensor between CPU and GPU memory, if necessary. Tensors produced by an operation are typically backed by the memory of the device on which the operation executed.</p>\n\n<p>Tensorflow will only allocate memory and place operations on visible physical devices, as otherwise no LogicalDevice will be created on them. By default all discovered devices are marked as visible. </p>\n\n<p>Also GPU utilization depends on the <code>batch_size</code>. The utilization may change with varying <code>batch_size</code>. </p>\n\n<p>You can also compare your current results(time taken and utilization) with model using the <code>Example 3</code> from <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/multi_gpu_model"" rel=""nofollow noreferrer"">multi_gpu_model</a>.</p>\n\n<p>Also if you go into the link, it states -</p>\n\n<blockquote>\n  <p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2020-04-01. Instructions for updating: Use tf.distribute.MirroredStrategy instead.</p>\n</blockquote>\n\n<p>There should be performance improvement and GPU Utilization using <code>tf.distribute.MirroredStrategy</code>. This strategy is typically used for training on one machine with multiple GPUs. The <code>tf.distribute.Strategy</code> API provides an abstraction for distributing your training across multiple processing units. The goal is to allow users to enable distributed training using existing models and training code, with minimal changes.</p>\n\n<p>For example, a variable created under a <code>MirroredStrategy</code> is a <code>MirroredVariable</code>. If no devices are specified in the constructor argument of the strategy then it will use all the available <code>GPUs</code>. If no <code>GPUs</code> are found, it will use the available <code>CPUs</code>. Note that TensorFlow treats all <code>CPUs</code> on a machine as a single device, and uses threads internally for parallelism.</p>\n\n<p>Would recommend to go through <a href=""https://www.tensorflow.org/tutorials/distribute/custom_training"" rel=""nofollow noreferrer"">Custom training with tf.distribute.Strategy</a> tutorial that demonstrates on how to use tf.distribute.Strategy with custom training loops. They will train a simple CNN model on the fashion MNIST dataset.</p>\n\n<p>Hope this answers your question. Happy Learning.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9931}"
55,69941348,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1636719303, 'answer_id': 69942797, 'question_id': 69941348, 'body': '<p>If I understood your question correctly, yes, the order of examples is preserved when using <code>tf.data.Dataset.from_tensor_slices</code> with <code>tfrecord</code>. Here is a simple example:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\nwith tf.io.TFRecordWriter(&quot;sample1.tfrecord&quot;) as w:\n    w.write(b&quot;Record A&quot;)\n    w.write(b&quot;Record B&quot;)\n\nwith tf.io.TFRecordWriter(&quot;sample2.tfrecord&quot;) as w:\n    w.write(b&quot;Record C&quot;)\n    w.write(b&quot;Record D&quot;)\n    w.write(b&quot;Record E&quot;)\n    w.write(b&quot;Record F&quot;)\n\nwith tf.io.TFRecordWriter(&quot;sample3.tfrecord&quot;) as w:\n    w.write(b&quot;Record G&quot;)\n    w.write(b&quot;Record H&quot;)\n    w.write(b&quot;Record I&quot;)\n    w.write(b&quot;Record J&quot;)\n    w.write(b&quot;Record K&quot;)\n    w.write(b&quot;Record L&quot;)\n\ndataset = tf.data.Dataset.from_tensor_slices([&quot;sample1.tfrecord&quot;,\n                                              &quot;sample2.tfrecord&quot;,\n                                              &quot;sample3.tfrecord&quot;])\nfor record in dataset:\n   for item in tf.data.TFRecordDataset(record):\n     tf.print(\'Record:\', record, \'Item --&gt;\', item)\n</code></pre>\n<pre><code>Record: &quot;sample1.tfrecord&quot; Item --&gt; &quot;Record A&quot;\nRecord: &quot;sample1.tfrecord&quot; Item --&gt; &quot;Record B&quot;\nRecord: &quot;sample2.tfrecord&quot; Item --&gt; &quot;Record C&quot;\nRecord: &quot;sample2.tfrecord&quot; Item --&gt; &quot;Record D&quot;\nRecord: &quot;sample2.tfrecord&quot; Item --&gt; &quot;Record E&quot;\nRecord: &quot;sample2.tfrecord&quot; Item --&gt; &quot;Record F&quot;\nRecord: &quot;sample3.tfrecord&quot; Item --&gt; &quot;Record G&quot;\nRecord: &quot;sample3.tfrecord&quot; Item --&gt; &quot;Record H&quot;\nRecord: &quot;sample3.tfrecord&quot; Item --&gt; &quot;Record I&quot;\nRecord: &quot;sample3.tfrecord&quot; Item --&gt; &quot;Record J&quot;\nRecord: &quot;sample3.tfrecord&quot; Item --&gt; &quot;Record K&quot;\nRecord: &quot;sample3.tfrecord&quot; Item --&gt; &quot;Record L&quot;\n</code></pre>\n<p>Or:</p>\n<pre class=""lang-py prettyprint-override""><code>dataset = tf.data.Dataset.from_tensor_slices([&quot;sample1.tfrecord&quot;,\n                                              &quot;sample2.tfrecord&quot;,\n                                              &quot;sample3.tfrecord&quot;])\nfor item in tf.data.TFRecordDataset(dataset):\n  tf.print(\'Item --&gt;\', item)\n</code></pre>\n<pre><code>Item --&gt; &quot;Record A&quot;\nItem --&gt; &quot;Record B&quot;\nItem --&gt; &quot;Record C&quot;\nItem --&gt; &quot;Record D&quot;\nItem --&gt; &quot;Record E&quot;\nItem --&gt; &quot;Record F&quot;\nItem --&gt; &quot;Record G&quot;\nItem --&gt; &quot;Record H&quot;\nItem --&gt; &quot;Record I&quot;\nItem --&gt; &quot;Record J&quot;\nItem --&gt; &quot;Record K&quot;\nItem --&gt; &quot;Record L&quot;\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9931}"
56,61522019,"{'items': [{'owner': {'reputation': 1, 'user_id': 19711131}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1659874334, 'answer_id': 73267307, 'question_id': 61522019, 'body': '<p>I think it may be that when you use input_shape in the build method of your layer, it means it is a dynamic layer</p>\n'}, {'owner': {}, 'down_vote_count': 0, 'up_vote_count': 9, 'is_accepted': True, 'score': 9, 'creation_date': 1591953646, 'answer_id': 62341280, 'question_id': 61522019, 'body': '<p>It is not mentioned in the Tensorflow Documentation but in <strong>Chapter 12</strong>,  <strong>Custom Models and Training with TensorFlow</strong> of the book, <strong>Hands-on Machine Learning using Scikit-Learn and Tensorflow (2nd Edition Updated for Tensorflow 2)</strong> of O\'REILLY Publications, written by Aurelien Geron, it is mentioned as shown in the screenshot below:</p>\n<p><a href=""https://i.stack.imgur.com/OqSfX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OqSfX.png"" alt=""enter image description here"" /></a></p>\n<p>To answer your question, yes, it is safe to say <code>compute_output_shape</code> is not needed unless the Layer is Dynamic.</p>\n<p>This is evident from this <a href=""https://www.tensorflow.org/tutorials/customization/custom_layers#implementing_custom_layers"" rel=""nofollow noreferrer"">Tensorflow Tutorial on Custom Layer</a> where <code>compute_output_shape</code> is not used.</p>\n<p>Hope this helps. Happy Learning!</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9927}"
57,47568998,"{'items': [{'owner': {'reputation': 18649, 'user_id': 3214872}, 'down_vote_count': 0, 'up_vote_count': 12, 'is_accepted': True, 'score': 12, 'creation_date': 1513176353, 'answer_id': 47795795, 'question_id': 47568998, 'body': '<p>Assuming you\'re using the latest Tensorflow (1.4 at the time of this writing), you can keep the generator and use the <a href=""https://www.tensorflow.org/api_docs/python/tf/data"" rel=""noreferrer""><code>tf.data.*</code></a> API as follows (I chose arbitrary values for the thread number, prefetch buffer size, batch size and output data types):</p>\n\n<pre><code>NUM_THREADS = 5\nsceneGen = SceneGenerator()\ndataset = tf.data.Dataset.from_generator(sceneGen.generate_data, output_types=(tf.float32, tf.int32))\ndataset = dataset.map(lambda x,y : (x,y), num_parallel_calls=NUM_THREADS).prefetch(buffer_size=1000)\ndataset = dataset.batch(42)\nX, y = dataset.make_one_shot_iterator().get_next()\n</code></pre>\n\n<p>To show that it\'s actually multiple threads extracting from the generator, I modified your class as follows:</p>\n\n<pre><code>import threading    \nclass SceneGenerator(object):\n  def __init__(self):\n    # some inits\n    pass\n\n  def generate_data(self):\n    """"""\n    Generator. Yield data X and labels y after some preprocessing\n    """"""\n    while True:\n      # opening files, selecting data\n      X,y = threading.get_ident(), 2 #self.preprocess(some_params, filenames, ...)            \n      yield X, y\n</code></pre>\n\n<p>This way, creating a Tensorflow session and getting one batch shows the thread IDs of the threads getting the data. On my pc, running:</p>\n\n<pre><code>sess = tf.Session()\nprint(sess.run([X, y]))\n</code></pre>\n\n<p>prints</p>\n\n<pre><code>[array([  8460.,   8460.,   8460.,  15912.,  16200.,  16200.,   8460.,\n         15912.,  16200.,   8460.,  15912.,  16200.,  16200.,   8460.,\n         15912.,  15912.,   8460.,   8460.,   6552.,  15912.,  15912.,\n          8460.,   8460.,  15912.,   9956.,  16200.,   9956.,  16200.,\n         15912.,  15912.,   9956.,  16200.,  15912.,  16200.,  16200.,\n         16200.,   6552.,  16200.,  16200.,   9956.,   6552.,   6552.], dtype=float32),\n array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])]\n</code></pre>\n\n<p><strong>Note</strong>: You might want to experiment removing the <code>map</code> call (that we only use to have the multiple threads) and checking if the <code>prefetch</code>\'s buffer is enough to remove the bottleneck in your input pipeline (even with only one thread, often the input preprocessing is faster than the actual graph execution, so the buffer is enough to have the preprocessing go as fast as it can).</p>\n'}, {'owner': {'reputation': 52739, 'user_id': 712995}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1513011695, 'answer_id': 47757771, 'question_id': 47568998, 'body': '<p>Running a session with a <code>feed_dict</code> is indeed <a href=""https://github.com/tensorflow/tensorflow/issues/2919"" rel=""nofollow noreferrer"">pretty slow</a>:</p>\n\n<blockquote>\n  <p>Feed_dict does a single-threaded memcpy of contents from Python runtime into TensorFlow runtime.</p>\n</blockquote>\n\n<p>A faster way to feed the data is by using <a href=""https://www.tensorflow.org/api_docs/python/tf/train/string_input_producer"" rel=""nofollow noreferrer""><code>tf.train.string_input_producer</code></a> + <a href=""https://www.tensorflow.org/api_docs/python/tf/ReaderBase"" rel=""nofollow noreferrer""><code>*Reader</code></a> + <a href=""https://www.tensorflow.org/api_docs/python/tf/train/Coordinator"" rel=""nofollow noreferrer""><code>tf.train.Coordinator</code></a>, which will batch the data in multiple threads. For that, you read the data directly into tensors, e.g., here\'s a way to read and process a <code>csv</code> file:</p>\n\n\n\n<pre class=""lang-py prettyprint-override""><code>def batch_generator(filenames):\n  filename_queue = tf.train.string_input_producer(filenames)\n  reader = tf.TextLineReader(skip_header_lines=1)\n  _, value = reader.read(filename_queue)\n\n  content = tf.decode_csv(value, record_defaults=record_defaults)\n  content[4] = tf.cond(tf.equal(content[4], tf.constant(\'Present\')),\n                       lambda: tf.constant(1.0),\n                       lambda: tf.constant(0.0))\n\n  features = tf.stack(content[:N_FEATURES])\n  label = content[-1]\n\n  data_batch, label_batch = tf.train.shuffle_batch([features, label],\n                                                   batch_size=BATCH_SIZE,\n                                                   capacity=20*BATCH_SIZE,\n                                                   min_after_dequeue=10*BATCH_SIZE)\n  return data_batch, label_batch\n</code></pre>\n\n<p>This function gets the list of input files, creates the reader and data transformations and outputs the <em>tensors</em>, which are evaluated to the contents of these files. Your scene generator is likely to do different transformations, but the idea is the same.</p>\n\n<p>Next, you start a <code>tf.train.Coordinator</code> to parallelize this:</p>\n\n<pre class=""lang-py prettyprint-override""><code>with tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord)\n    for _ in range(10):  # generate 10 batches\n        features, labels = sess.run([data_batch, label_batch])\n        print(features)\n    coord.request_stop()\n    coord.join(threads)\n</code></pre>\n\n<p>In my experience, this way feeds the data much faster and allows to utilize the whole available GPU power. Complete working example can be found <a href=""https://github.com/chiphuyen/stanford-tensorflow-tutorials/blob/master/examples/05_csv_reader.py"" rel=""nofollow noreferrer"">here</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9927}"
58,44640357,"{'items': [{'owner': {'reputation': 352, 'user_id': 1779549}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1510644595, 'answer_id': 47279999, 'question_id': 44640357, 'body': '<p>You can.</p>\n\n<p>according to this <a href=""https://github.com/tensorflow/tensorflow/issues/1984"" rel=""nofollow noreferrer"">issue</a>, ops will run in parallel once all their inputs nodes are computed:</p>\n\n<blockquote>\n  <p>while_loop implements non-strict semantics. An iteration can start as soon as one of the ops for this iteration is ready (i.e., all its inputs are available.) for execution. So a while_loop can easily have multiple iterations running in parallel. For example, for scan, even if the accumulated value is not available in a step, the step can still start and execute any ops that don\'t depend on the accumulated value. </p>\n</blockquote>\n\n<p>so you shouldn\'t encounter any issues.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9927}"
59,57888872,"{'items': [{'owner': {'reputation': 106, 'user_id': 2063526}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1624272985, 'answer_id': 68066690, 'question_id': 57888872, 'body': ""<p>I had a similar issue when using <code>tf.range()</code> instead of python's <code>range()</code> for a list comprehension inside a tensorflow graph function. I was training a 3D segmentation neural net and had to use <code>range()</code> for the code to work.</p>\n<p>Check the pseudo code below:-</p>\n<pre><code>Y         = # [Batch,Height,Width,Depth,Channels]\ny_predict = # [B,H,W,D,C,MC_Runs] ; MC_Runs=Monte Carlo Runs\n\n@tf.function\ndef train_loss(Y,y_predict):\n    # calulate loss and return scalar value\n\n@tf.function\ndef train_step():\n    loss = [train_loss(Y, y_predict[:,:,:,:,:,id_])) for id_ in range(MC_RUNS)]\n    loss = tf.math.reduce_mean(loss)\n</code></pre>\n""}, {'owner': {'reputation': 3631, 'user_id': 5931672}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1592558860, 'answer_id': 62467248, 'question_id': 57888872, 'body': '<p>In case it helps someone.</p>\n\n<p>I had the same problem with a code that did:</p>\n\n<pre><code>for index, image in enumerate(inputs):\n    ... My code ...\n</code></pre>\n\n<p>The solution was just to do:</p>\n\n<pre><code>index = 0\nfor image in inputs:\n    .... My code ...\n    index += 1\n</code></pre>\n'}, {'owner': {}, 'down_vote_count': 1, 'up_vote_count': 5, 'is_accepted': False, 'score': 4, 'creation_date': 1583772534, 'answer_id': 60605029, 'question_id': 57888872, 'body': '<p>The root cause is that autograph doesn\'t yet support list comprehensions (primarily because it\'s difficult to determine the dtype of the result in all cases)</p>\n\n<p>As a workaround, you can use tf.map_fn for the comprehension:</p>\n\n<pre><code>return tf.map_fn(lambda i: i ** 2 if i &gt; 0 else i, x)\n</code></pre>\n\n<p>For more information please take a look at this <a href=""https://github.com/tensorflow/tensorflow/issues/32546#issuecomment-538549035"" rel=""nofollow noreferrer"">issue</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9927}"
60,49633383,"{'items': [{'owner': {'reputation': 365, 'user_id': 4311598}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1522776945, 'answer_id': 49636067, 'question_id': 49633383, 'body': '<p>Its like nodes in the hidden layers of a feed forward network</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9923}"
61,55347304,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9923}"
62,56553579,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1561006877, 'answer_id': 56679248, 'question_id': 56553579, 'body': '<p>Can you try the code shown below:</p>\n\n<pre><code>def serving_input_receiver_fn():\n    """"""\n    This is used to define inputs to serve the model.\n    :return: ServingInputReciever\n    """"""\n    reciever_tensors = {\n        # The size of input image is flexible.\n        \'image\': tf.placeholder(tf.float32, [None, None, None, 1]),\n    }\n\n    # Convert give inputs to adjust to the model.\n    features = {\n        # Resize given images.\n        \'image\': tf.reshape(reciever_tensors[INPUT_FEATURE], [-1, INPUT_SHAPE])\n    }\n    return tf.estimator.export.ServingInputReceiver(receiver_tensors=reciever_tensors,\n                                                    features=features)\n</code></pre>\n\n<p>Then use <code>tf.estimator.BestExporter</code> as shown below:</p>\n\n<pre><code>best_exporter = tf.estimator.BestExporter(\n        serving_input_receiver_fn=serving_input_receiver_fn,\n        exports_to_keep=1)\n    exporters = [best_exporter]\n    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n        x={input_name: eval_data},\n        y=eval_labels,\n        num_epochs=1,\n        shuffle=False)\n    eval_spec = tf.estimator.EvalSpec(\n        input_fn=eval_input_fn,\n        throttle_secs=10,\n        start_delay_secs=10,\n        steps=None,\n        exporters=exporters)\n\n    # Train and evaluate the model.\n    tf.estimator.train_and_evaluate(classifier, train_spec=train_spec, eval_spec=eval_spec)\n</code></pre>\n\n<p>For more info, refer the link:\n<a href=""https://github.com/yu-iskw/tensorflow-serving-example/blob/master/python/train/mnist_keras_estimator.py"" rel=""nofollow noreferrer"">https://github.com/yu-iskw/tensorflow-serving-example/blob/master/python/train/mnist_keras_estimator.py</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9921}"
63,52035692,"{'items': [{'owner': {'reputation': 4958, 'user_id': 5623899}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1535378338, 'answer_id': 52041027, 'question_id': 52035692, 'body': '<p><strong>Note</strong>: this is not an answer to the question (whether Example or SequenceExample is better and whether or not a sequence should be broken down into channels or as a byte string)</p>\n\n<p>Rather, it occurred to me whilst looking at TensorFlow Records tutorials, posts, videos, etc that most examples (that I encountered) focused on constructing the (Sequence)Example with concrete data and did not show how one could be made more dynamically. Thus I encapsulated the four methods above for converting data of the described type in the example. </p>\n\n<p>While still tied to the data we are trying to create an (Sequence)Example around, hopefully for those who are still somewhat confused about the format - in addition to the concrete examples above - this might be of use.</p>\n\n<p>Here is some code to play around with.  Feedback is welcome.</p>\n\n<h1>Update</h1>\n\n<p>This has been condensed into a package named <a href=""https://pypi.org/project/fio/"" rel=""nofollow noreferrer"">Feature Input / Output (FIO)</a>.</p>\n\n<p>Here is a <a href=""https://colab.research.google.com/drive/1HrSYF1I7rBGaNQ7388Ss3epWPLTloEC6"" rel=""nofollow noreferrer"">Colab</a> demonstrating how to use it.</p>\n\n<p>Namely, it introduces the concept of a <code>""schema""</code>:</p>\n\n<pre><code>SCHEMA = {\n    \'my-feature\': {\'length\': \'fixed\', \'dtype\': tf.string,  \'shape\': []},\n    \'seq\': {\n        \'length\': \'fixed\',\n        \'dtype\': tf.int64,\n        \'shape\': [4, 3],\n        \'encode\': \'channels\',\n        \'channel_names\': [\'A\', \'B\', \'C\'],\n        \'data_format\': \'channels_last\'\n    }\n}\n</code></pre>\n\n<p>which allows you to define your data <em>_once_</em> rather than twice (once to encode into example, and once to extract from a record).</p>\n\n<hr>\n\n<h1>Original</h1>\n\n<h2>Setup</h2>\n\n<pre><code>import os, sys, json\nsys.path.insert(0, \'../\')\nimport tensorflow as tf\nimport numpy as np\n</code></pre>\n\n<h2>Some light helper functions</h2>\n\n<pre><code>def list_like_q(value) -&gt; bool:\n    \'\'\'\n    TensorFlow tf.train.Feature requires a list of feature values.\n    Many values used in practice are either python lists or numpy.ndarrays.\n    We often have features which consist of a singular value.\n    For brevity, we define some light helper functions to wrap a list as a\n    tf.train.Feature. This lets us test if we need to wrap the value.\n    \'\'\'\n    # import numpy as np\n    return (type(value) is list or type(value) is np.ndarray)\n\n\ndef take_all() -&gt; slice: return slice(None, None, None)\ndef take_channel(sequence, channel:int, data_format:str=\'channels_last\'):\n    slices = [channel, take_all()]\n    if data_format != \'channels_last\': slices.reverse()\n    return sequence[tuple(slices)]\n\ndef number_of_channels(sequence, data_format:str=\'channels_last\') -&gt; int:\n    return sequence.shape[-1] if data_format == \'channels_last\' else sequence.shape[0]\n\ndef feature_int64(value):\n    \'\'\'Takes value and wraps into tf.train.Feature(Int64List)\'\'\'\n    if not list_like_q(value): value = [value]\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef feature_float(value):\n    \'\'\'Takes value and wraps into tf.train.Feature(FloatList)\'\'\'\n    if not list_like_q(value): value = [value]\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\ndef feature_bytes(value):\n    \'\'\'Takes value and wraps is into tf.train.Feature(BytesList).\'\'\'\n    if type(value) is np.ndarray: value = value.tostring()\n    if type(value) is not bytes:  value = str(value).encode(\'utf-8\')\n    if type(value) is not list:   value = [value]\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n\ndef feature_function(dtype):\n    \'\'\'\n    Given &lt;dtype&gt; returns the function for wrapping a value into the\n    corresponding tf.train.Feature\n    \'\'\'\n    return feature_int64 if dtype == ""int64"" else \\\n           feature_float if dtype == ""float"" else \\\n           feature_bytes\n\ndef feature_list(iterable, dtype:str=\'float\'):\n    \'\'\'Given an iterable, returns the feature list of corresponding &lt;dtype&gt;.\'\'\'\n    return tf.train.FeatureList([feature_function(dtype)(item) for item in iterable])\n\n\n# the next three for completeness\ndef feature_list_int64(value):\n    return tf.train.FeatureList(feature=feature_list(value, \'int64\'))\n\ndef feature_list_float(value):\n    return tf.train.FeatureList(feature=feature_list(value, \'float\'))\n\ndef feature_list_bytes(value):\n    return tf.train.FeatureList(feature=feature_list(value, \'bytes\'))\n\n\n\ndef dict_to_features(values:dict, types:dict) -&gt; dict:\n    \'\'\'\n    Given &lt;types&gt;, maps over name:dtype pairs and wraps &lt;values&gt;[name] in the\n    corresponding  feature type.\n    \'\'\'\n    return {name: feature_function(dtype)(values[name]) for name, dtype in types.items()}\n\ndef features_from_dict(values:dict, types:dict):\n    return tf.train.Features(feature=dict_to_features(values, types))\n\ndef default_channel_names(sequence, data_format:str=\'channels_last\') -&gt; list:\n    \'\'\'Ensures a naming scheme as required for channel based Example\'\'\'\n    return [f\'Channel {i}\' for i in range(number_of_channels(sequence, data_format))]\n\ndef channels_to_features(sequence, dtype:str=\'float\', data_format:str=\'channels_last\', channel_names:list=None) -&gt; dict:\n    \'\'\'\n    Given a &lt;sequence&gt; of corresponding &lt;dtype&gt; and &lt;data_format&gt;, with optional &lt;channel_names&gt;\n    returns the dictionary of each channel:tf.train.Feature pair.\n    \'\'\'\n    if channel_names is None: channel_names = default_channel_names(sequence, data_format)\n    return {\n        channel: feature_function(dtype)(take_channel(sequence, i, data_format))\n        for i, channel in enumerate(channel_names)\n    }\n\ndef channels_to_feature_list(sequence, dtype:str=\'float\', data_format:str=\'channels_last\'):\n    \'\'\'\n    Given a &lt;sequence&gt; of &lt;dtype&gt; and &lt;data_format&gt; returns the FeatureList\n    where each element corresponds to a channel of &lt;sequence&gt;\n    \'\'\'\n    return tf.train.FeatureList(feature=list(channels_to_features(sequence, dtype, data_format).values()))\n</code></pre>\n\n<h1>SequenceRecords</h1>\n\n<pre><code>class SequenceRecord:\n    \'\'\'\n    SequenceRecord is a supporting class built on top of the functions found in\n    /model/utils/features.py with the purpose of converting our data consisting\n    of:\n\n        - a sequence of length n,\n        - n vectors of class probability vectors (refered to as pclasses), and\n        - metadata (name of sequence, start site, stop site, etc)\n\n    and converting it into a TensorFlow (Sequence)Example which can\n    subsequentially be written as a TensorFlow Record.\n\n    For both Example and SequenceExample options, the channels / classes of the\n    sequence / pclasses can be stored as numeric features (int64 / float) or as\n    a byte string. For each of these options, the encoding can be done per\n    channel / class, or the entire sequence / pclasses matrix.\n\n    Overwrite the following class variables to suit your needs:\n\n    _class_var           || description\n    ---------------------------------------------------------------------------\n    _metadata_types:dict || a dictionary of &lt;feature-name&gt;:&lt;dtype&gt; pairs which\n                         || is refered to when the  metadata is converted into\n                         || tf.train.Feature (only \'int64\', \'float\', \'bytes\' are\n                         || supported for &lt;dtype&gt;)\n    _sequence_data_format|| a string specifying where the channels are. By\n                         || default, this is set to \'channels_last\'\n    _pclasses_data_format|| a string specifying where the channels are (by\n                         || default, this is set to \'channels_last\')\n    _sequence_data_type  || a string specifying what dtype channels should be\n                         || encoded as (by default \'int64\')\n    _pclasses_data_type  || a string specifying what dtype channels should be\n                         || encoded as (by default \'float\')\n    _channel_names       || a list of strings specifying the name and order\n                         || channels appear in &lt;sequence&gt; (by default set to\n                         || None)\n    _classes_names       || a list of strings specifying the name and order\n                         || classes appear as channels in &lt;pclasses&gt; (by default\n                         || set to None)\n\n    \'\'\'\n    _metadata_types = {}\n    _sequence_data_format = \'channels_last\'\n    _pclasses_data_format = \'channels_last\'\n    _sequence_data_type = \'int64\'\n    _pclasses_data_type = \'float\'\n\n    _channel_names = None\n    _classes_names = None\n\n\n    def make_example(self, sequence, pclasses, metadata:dict={}, form:str=\'example\', by:str=\'channels\'):\n        \'\'\'\n        The core function of SequenceRecord. Given &lt;sequence&gt;, &lt;pclasses&gt; and &lt;metadata&gt;\n        converts them to the corresponing &lt;form&gt; and &lt;by&gt; the specified encoding schema.\n\n        form: either \'example\' (default) or \'sequence\' and yields either a\n              a Example or SequenceExample.\n        by:   either \'channels\' (default) or \'bstrings\' or \'bdstring\' and\n              encodes the sequence / pclasses by channel / class as a numeric,\n              or a byte string (options \'channels\' and \'bstrings\'), or dumps the\n              entire numpy.ndarray a byte string (option \'bdstring\')\n\n        \'\'\'\n        wrap = self.example if form == \'example\' else self.sequence_example\n        return wrap(sequence, pclasses, metadata, by)\n\n    def example(self, sequence, pclasses, metadata, by=\'channels\'):\n        wrap = self.example_as_channels if by == \'channels\' else \\\n               self.example_as_bdstring if by == \'bdstring\' else \\\n               self.example_as_bstrings\n        return wrap(sequence, pclasses, metadata)\n\n    def sequence_example(self, sequence, pclasses, metadata, by=\'channels\'):\n        wrap = self.sequence_example_as_channels if by == \'channels\' else \\\n               self.sequence_example_as_bdstring if by == \'bdstring\' else \\\n               self.sequence_example_as_bstrings\n        return wrap(sequence, pclasses, metadata)\n\n\n    def example_as_channels(self, sequence, pclasses, metadata):\n        \'\'\'\n        Encoded each channel (or class) as its own feature with specified dtype\n        (e.g. _sequence_data_type) and wraps in tf.train.Example\n        \'\'\'\n        features = {\n            **dict_to_features(metadata, self._metadata_types),\n            **channels_to_features(sequence, self._sequence_data_type, self._sequence_data_format, self._channel_names),\n            **channels_to_features(pclasses, self._pclasses_data_type, self._pclasses_data_format, self._classes_names),\n        }\n        return tf.train.Example(features=tf.train.Features(feature=features))\n\n    def example_as_bstrings(self, sequence, pclasses, metadata):\n        \'\'\'\n        Encoded each channel (or class) as its own feature but dumps ndarrays\n        as byte strings (&lt;np.ndarray.tostring()&gt;) and wraps in tf.train.Example.\n        \'\'\'\n        features = {\n            **dict_to_features(metadata, self._metadata_types),\n            **channels_to_features(sequence, \'bytes\', self._sequence_data_format, self._channel_names),\n            **channels_to_features(pclasses, \'bytes\', self._pclasses_data_format, self._classes_names),\n        }\n        return tf.train.Example(features=tf.train.Features(feature=features))\n\n    def example_as_bdstring(self, sequence, pclasses, metadata):\n        \'\'\'\n        Encodes sequence and probability classes as a byte \'dump\' string\n        i.e. dump the sequence to a string and encode to bytes\n        ( equivalent to np.ndarray.tostring() )\n        \'\'\'\n        features = {\n            **dict_to_features(metadata, self._metadata_types),\n            \'sequence\': feature_bytes(sequence),\n            \'pclasses\': feature_bytes(pclasses)\n        }\n        return tf.train.Example(features=tf.train.Features(feature=features))\n\n\n    def sequence_example_as_channels(self, sequence, pclasses, metadata):\n        \'\'\'\n        Encoded each channel (or class) as its own feature with specified dtype\n        (e.g. _sequence_data_type) and wraps in tf.train.SequenceExample\n        \'\'\'\n        context = features_from_dict(metadata, self._metadata_types)\n        feat_list = tf.train.FeatureLists(feature_list={\n            \'sequence\': channels_to_feature_list(sequence, self._sequence_data_type, self._sequence_data_format),\n            \'pclasses\': channels_to_feature_list(pclasses, self._pclasses_data_type, self._pclasses_data_format)\n        })\n        return tf.train.SequenceExample(context=context, feature_lists=feat_list)\n\n    def sequence_example_as_bstrings(self, sequence, pclasses, metadata):\n        \'\'\'\n        Encoded each channel (or class) as its own feature but dumps ndarrays\n        as byte strings (&lt;np.ndarray.tostring()&gt;) and wraps in\n        tf.train.SequenceExample.\n        \'\'\'\n        context = features_from_dict(metadata, self._metadata_types)\n        feat_list = tf.train.FeatureLists(feature_list={\n            \'sequence\': channels_to_feature_list(sequence, \'bytes\', self._sequence_data_format),\n            \'pclasses\': channels_to_feature_list(pclasses, \'bytes\', self._pclasses_data_format)\n        })\n        return tf.train.SequenceExample(context=context, feature_lists=feat_list)\n\n    def sequence_example_as_bdstring(self, sequence, pclasses, metadata):\n        \'\'\'\n        Encodes sequence and probability classes as a byte \'dump\' string\n        i.e. dump the sequence to a string and encode to bytes\n        ( equivalent to np.ndarray.tostring() )\n        \'\'\'\n        context = features_from_dict(metadata, self._metadata_types)\n        feat_list = tf.train.FeatureLists(feature_list={\n            \'sequence\': tf.train.FeatureList(feature=[feature_bytes(sequence)]),\n            \'pclasses\': tf.train.FeatureList(feature=[feature_bytes(pclasses)])\n        })\n        return tf.train.SequenceExample(context=context, feature_lists=feat_list)\n\n    def write(self, example, to:str):\n        \'\'\'\n        After calling corresponding method to construct (Sequence)Example,\n        writes the passed (Sequence)Example to specified location (full path name).\n        \'\'\'\n        with tf.python_io.TFRecordWriter(to) as writer:\n            writer.write(example.SerializeToString())\n</code></pre>\n\n<h1>Dummy data</h1>\n\n<pre><code>sequences = np.array([\n    # sequence 1\n    [\n        # el1, el2, el3\n        [   1,   1,  1], # channel 1\n        [   2,   2,  2], # channel 2\n        [   3,   3,  3], # channel 3\n    ],\n    #sequence 2\n    [\n        [  10,  10, 10], # channel 1\n        [  20,  20, 20], # channel 2\n        [  30,  30, 30], # channel 3\n    ]\n])\n\npclasses = np.array([\n    # sequence 1\n    [\n        # cls1, cls2, cls3\n        [    0,  0.9, 0.1], # class probabilities element 1\n        [    0,  0.1, 0.9], # class probabilities element 2\n        [  0.8,  0.1, 0.1]  # class probabilities element 3\n    ],\n    # sequence 2\n    [\n        # cls1, cls2, cls3\n        [  0.8,  0.1, 0.1], # class probabilities element 3    \n        [    0,  0.1, 0.9], # class probabilities element 2\n        [    0,  0.9, 0.1]  # class probabilities element 1\n    ]\n])\n\n\nmetadata = [\n    {\'Name\': \'sequence 1\', \'Val_1\': 100, \'Val_2\': 10},\n    {\'Name\': \'sequence 2\', \'Val_1\':  10, \'Val_2\': 100}\n]\n\nmetatypes = {\'Name\': \'bytes\', \'Val_1\': \'float\', \'Val_2\': \'float\'}\n</code></pre>\n\n<h1>Initiate and go</h1>\n\n<pre><code>SequenceRecord._channel_names = [\'Channel 1\', \'Channel 2\', \'Channel 3\']\nSequenceRecord._classes_names = [\'Class A\', \'Class B\', \'Class C\']\nSequenceRecord._metadata_types = metatypes\nSR = SequenceRecord()  \n\n\nSR.make_example(sequences[0], pclasses[0], metadata[0], form=\'example\',  by=\'channels\')\nSR.make_example(sequences[0], pclasses[0], metadata[0], form=\'example\',  by=\'bstrings\')\nSR.make_example(sequences[0], pclasses[0], metadata[0], form=\'example\',  by=\'bdstring\')\nSR.make_example(sequences[0], pclasses[0], metadata[0], form=\'sequence\', by=\'channels\')\nSR.make_example(sequences[0], pclasses[0], metadata[0], form=\'sequence\', by=\'bstrings\')\nSR.make_example(sequences[0], pclasses[0], metadata[0], form=\'sequence\', by=\'bdstring\')\n</code></pre>\n'}, {'owner': {'reputation': 4958, 'user_id': 5623899}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1536152115, 'answer_id': 52185682, 'question_id': 52035692, 'body': '<p>This is an extension to my first answer which some may find useful.</p>\n\n<p>Rather than considering the encoding, I here consider the opposite, e.g. how one retrieves the data from a TFRecord.</p>\n\n<p>The colab can be found <a href=""https://colab.research.google.com/drive/1M10tbHih5eJ8LiApJSKKpNM79IconYJX"" rel=""nofollow noreferrer"">here</a>.</p>\n\n<p>In essence I survey 10 ways of encoding an array / array of arrays.</p>\n\n<ol>\n<li>Example: Int64 feature (int array)</li>\n<li>Example: Float feature (float array)</li>\n<li>Example: Bytes feature (int array dumped to byte string)</li>\n<li>SequenceExample: Int64 feature list (array of int arrays)</li>\n<li>SequenceExample: Float feature list (array of float arrays)</li>\n<li>SequenceExample: Bytes feature list (array of int arrays dumped to byte strings)</li>\n<li>Example: Bytes feature (array of int arrays all of which is dumped to byte string)</li>\n<li>SequenceExample: Bytes feature list (array of int arrays dumped to byte strings)</li>\n<li>SequenceExample: Bytes feature list (array of int arrays all of which is dumped to byte string)</li>\n<li>SequenceExample: Bytes feature list (array of int arrays, where each int is dumped to byte string)</li>\n</ol>\n\n<p>There are more ways to do this.</p>\n\n<p>In short, with the exception of 8, I was able to \'recover\' (write to tf.record and read back the data). </p>\n\n<p>However, it should be noted that for methods 7 and 10, the retrieved array is flattened.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9921}"
64,55904359,"{'items': [{'owner': {'reputation': 55, 'user_id': 9092979}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1556644104, 'answer_id': 55925748, 'question_id': 55904359, 'body': '\n\n<p><strong>EDIT</strong>: Below, I report how I computed the <code>tf.hessians</code> of my output w.r.t the inputs.</p>\n\n<p>I succeeded in computing the gradients using the function <code>tf.gradients</code>. However, according to the documentation this function uses <em>symbolic derivation</em> whereas <code>GradientTape.gradient</code> uses <em>automatic differentiation</em>. In the papers I am reading, they talk about <em>automatic differentiation</em>, so I don\'t know if I\'ll encounter some problems later on, but at least my code runs.  </p>\n\n<p>Below, I post a MWE with the RNN code I already used.</p>\n\n<pre><code>import tensorflow as tf\nfrom tensorflow.keras.layers import RNN, GRUCell, Dense\n\n# Define size of variable. TODO: adapt to data\ninp_dim = 2\nnum_units = 50\nbatch_size = 100\ntimesteps = 10\n\n# Reset the graph, so as to avoid errors\ntf.reset_default_graph()\n\ninputs = tf.ones(shape=(timesteps, batch_size, inp_dim))\n\n### Building the model\ncells = [GRUCell(num_units), GRUCell(num_units)]\nrnn = RNN(cells, time_major=True, return_sequences=True)\nfinal_layer = Dense(1, input_shape=(num_units,))\n\n# Apply to inputs\nlast_state = rnn(inputs)\nf = final_layer(last_state)\n\n[derivs] = tf.gradients(f, inputs)\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    grads = sess.run(derivs)\n</code></pre>\n\n<p>Just to warn any interested bystander that would like to compute <strong>second order derivatives</strong>, using <code>tf.gradients(tf.gradients(func, vars))</code> is not supported. There is a function called <code>tf.hessian</code> too, but replacing <code>tf.gradients</code> by <code>tf.hessian</code> in the code above did not work, and led to an error so long that I will not include it here. I will most likely do an <strong>issue</strong> on Github, that I will link here for anyone interested. For the moment, as I encountered a unsatisfying workaround, I will mark my own response as solving my problem.</p>\n\n<h1>Computing second-order derivatives</h1>\n\n<p>See this <a href=""https://github.com/tensorflow/tensorflow/issues/28310"" rel=""nofollow noreferrer"">issue</a> on Github.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9921}"
65,52471921,"{'items': [{'owner': {'reputation': 1146, 'user_id': 9865225}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1537772545, 'answer_id': 52474148, 'question_id': 52471921, 'body': ""<p>As I answered in your another post, I will post it again, In <code>tensorflow</code>, anything that is created using <code>tf.Variable()</code>, will get updated during training in back-propagation, for example, a weight matrix.</p>\n\n<p>Ideally, by default, every <code>tf.Variable()</code> becomes trainable unless you specify it <code>non-trainable</code> explicitly.</p>\n\n<p>If you do this <code>initial = tf.truncated_normal([5,10], mean=0, stddev=0.1)</code>, then tensorflow will not know that it's a trainable variable and hence it will not be trained. It will stay constant throughout the training.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9921}"
66,64100466,"{'items': [{'owner': {'reputation': 425, 'user_id': 11010255}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1627591696, 'answer_id': 68582621, 'question_id': 64100466, 'body': ""<p>In TensorFlow 2.4, I've got a dataset that returns a tuple of one element, ie <code>(inputs,)</code>, which is training just fine. The only caveat is of course that you cannot pass a loss or metrics to <code>model.compile</code>, but must instead use the <code>add_loss</code> and <code>add_metric</code> APIs somewhere in the model.</p>\n""}, {'owner': {'reputation': 1159, 'user_id': 5235528}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1601336398, 'answer_id': 64110994, 'question_id': 64100466, 'body': '<p>&quot;the repeated inputs double the GPU memory for my model?&quot;; Generally , the dataset pipeline run on CPU, not on GPU.</p>\n<p>For your AutoEncoder model, if you want to use a dataset that only contains the examples without labels, you can use custom training :</p>\n<pre><code>def loss(model, x):\n\n    y_ = model(x, training=True)           # use x as input\n\n   return loss_object(y_true=x, y_pred=y_) # use x as label (y_true)\n\nwith tf.GradientTape() as tape:\n   loss_value = loss(model, inputs)\n</code></pre>\n<p>If it is necessary to use the fit() method, you can subclass keras.Model and overrides the train_step() method <a href=""https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit"" rel=""nofollow noreferrer""> link </a>. (I did not verify this code ) :</p>\n<pre><code>class CustomModel(keras.Model):\ndef train_step(self, data):\n\n    x = data\n    y = data  # the same data as label ++++\n\n    with tf.GradientTape() as tape:\n        y_pred = self(x, training=True)  # Forward pass\n      \n        loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n\n    # Compute gradients\n    trainable_vars = self.trainable_variables\n    gradients = tape.gradient(loss, trainable_vars)\n    # Update weights\n    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n    # Update metrics (includes the metric that tracks the loss)\n    self.compiled_metrics.update_state(y, y_pred)\n    # Return a dict mapping metric names to current value\n    return {m.name: m.result() for m in self.metrics}\n</code></pre>\n'}, {'owner': {'reputation': 34678, 'user_id': 10908375}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1601296359, 'answer_id': 64102263, 'question_id': 64100466, 'body': ""<p>You can use <code>map()</code> to return your input twice:</p>\n<pre><code>import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Conv2DTranspose, Reshape\nfrom functools import partial\n\n(xtrain, _), (xtest, _) = tf.keras.datasets.mnist.load_data()\n\nds = tf.data.Dataset.from_tensor_slices(\n    tf.expand_dims(tf.concat([xtrain, xtest], axis=0), axis=-1))\n\nds = ds.take(int(1e4)).batch(4).map(lambda x: (x/255, x/255))\n\ncustom_convolution = partial(Conv2D, kernel_size=(3, 3),\n                             strides=(1, 1),\n                             activation='relu',\n                             padding='same')\ncustom_pooling = partial(MaxPool2D, pool_size=(2, 2))\n\nconv_encoder = Sequential([\n    custom_convolution(filters=16, input_shape=(28, 28, 1)),\n    custom_pooling(),\n    custom_convolution(filters=32),\n    custom_pooling(),\n    custom_convolution(filters=64),\n    custom_pooling()\n    ])\n\n# conv_encoder(next(iter(ds))[0].numpy().astype(float)).shape\ncustom_transpose = partial(Conv2DTranspose,\n                           padding='same',\n                           kernel_size=(3, 3),\n                           activation='relu',\n                           strides=(2, 2))\n\nconv_decoder = Sequential([\n    custom_transpose(filters=32, input_shape=(3, 3, 64), padding='valid'),\n    custom_transpose(filters=16),\n    custom_transpose(filters=1, activation='sigmoid'),\n    Reshape(target_shape=[28, 28, 1])\n    ])\n\nconv_autoencoder = Sequential([\n    conv_encoder,\n    conv_decoder\n    ])\n\nconv_autoencoder.compile(loss='binary_crossentropy', optimizer='adam')\n\nhistory = conv_autoencoder.fit(ds)\n</code></pre>\n<pre><code>2436/2500 [============================&gt;.] - ETA: 0s - loss: 0.1282\n2446/2500 [============================&gt;.] - ETA: 0s - loss: 0.1280\n2456/2500 [============================&gt;.] - ETA: 0s - loss: 0.1279\n2466/2500 [============================&gt;.] - ETA: 0s - loss: 0.1278\n2476/2500 [============================&gt;.] - ETA: 0s - loss: 0.1277\n2487/2500 [============================&gt;.] - ETA: 0s - loss: 0.1275\n2497/2500 [============================&gt;.] - ETA: 0s - loss: 0.1274\n2500/2500 [==============================] - 14s 6ms/step - loss: 0.1273\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9917}"
67,67811443,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9917}"
68,52572275,"{'items': [{'owner': {'reputation': 1452, 'user_id': 4259243}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1538331866, 'answer_id': 52580832, 'question_id': 52572275, 'body': '<p>Some moderators might have regarded my question as a duplicate of <a href=""https://stackoverflow.com/questions/42207554/swapping-elements-within-a-matrix-rows-and-columns-tensorflow-scatter-nd"">this one</a>, not because the questions are the same, but only because the answers contain parts one can use to answer this question -- i.e. specifying every index combination by hand. </p>\n\n<p>A totally different method would be to multiply by a permutation matrix as shown in <a href=""https://stackoverflow.com/questions/20265229/rearrange-columns-of-numpy-2d-array"">the last answer to this question</a>.  Since my original question was about scatter_nd, I\'m going to post this solution but wait to see what other answers come in... (Alternatively, I or someone could edit the question to make it about reordering columns, not specific to scatter_nd <strong>--EDIT: I have just edited the question title to reflect this</strong>).</p>\n\n<p>Here, we concatenate the two different arrays/tensors...</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\n\nsess = tf.Session()\n\n# the ultimate application is for merging variables which should be in groups,\n#   e.g. in this example, [1,2,10] is a group of 3, and there are 3 groups of 3\nn_groups = 3\nvars_per_group = 3    # once the single value from arr2 (below) is included\n\narr1 = 10+tf.range(n_groups, dtype=float)\narr1 = tf.stack((arr1,arr1,arr1),0)\narr2 = 1+tf.range(n_groups * (vars_per_group-1), dtype=float)\narr2 = tf.stack((arr2,arr2,arr2),0)\n\ncatted = tf.concat((arr1,arr2),1)        # concatenate the two arrays together\nprint(""arr1 = \\n"",sess.run(arr1))\nprint(""arr2 = \\n"",sess.run(arr2))\nprint(""catted = \\n"",sess.run(catted))\n</code></pre>\n\n<p>Which gives output </p>\n\n<pre><code>arr1 = \n [[10. 11. 12.]\n [10. 11. 12.]\n [10. 11. 12.]]\narr2 = \n [[1. 2. 3. 4. 5. 6.]\n [1. 2. 3. 4. 5. 6.]\n [1. 2. 3. 4. 5. 6.]]\ncatted = \n [[10. 11. 12.  1.  2.  3.  4.  5.  6.]\n [10. 11. 12.  1.  2.  3.  4.  5.  6.]\n [10. 11. 12.  1.  2.  3.  4.  5.  6.]]\n</code></pre>\n\n<p>Now we build the permutation matrix and multiply...</p>\n\n<pre><code>start_index = 2               # location of where the interleaving begins\n\n# cml = ""column map list"" is the list of where each column will get mapped to\ncml = [start_index + x*(vars_per_group) for x in range(n_groups)]  # first array  \nfor i in range(n_groups):                                       # second array \n    cml += [x + i*(vars_per_group) for x in range(start_index)] # vars before start_index\n    cml += [1 + x + i*(vars_per_group) + start_index \\\n        for x in range(vars_per_group-start_index-1)]           # vars after start_index\nprint(""\\n cml = "",cml,""\\n"")\n\n# Create a permutation matrix using p\nnp_perm_mat = np.zeros((len(cml), len(cml)))\nfor idx, i in enumerate(cml):\n    np_perm_mat[idx, i] = 1\nperm_mat = tf.constant(np_perm_mat,dtype=float)\n\nresult = tf.matmul(catted, perm_mat)\nprint(""result = \\n"",sess.run(result))\n</code></pre>\n\n<p>Which gives output</p>\n\n<pre><code>cml =  [2, 5, 8, 0, 1, 3, 4, 6, 7] \n\nresult = \n [[ 1.  2. 10.  3.  4. 11.  5.  6. 12.]\n [ 1.  2. 10.  3.  4. 11.  5.  6. 12.]\n [ 1.  2. 10.  3.  4. 11.  5.  6. 12.]]\n</code></pre>\n\n<p>Even though this doesn\'t use scatter_nd as the original question asked, one thing I like about this is, you can allocate the <code>perm_mat</code> once in some <code>__init__()</code> method, and hang on to it, and after that initial overhead it\'s just matrix-matrix multiplication by a sparse, constant matrix, which should be pretty fast. (?)</p>\n\n<p>Still happy to wait and see what other answers might come in.</p>\n'}, {'owner': {'reputation': 3062, 'user_id': 1234909}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1538285113, 'answer_id': 52574910, 'question_id': 52572275, 'body': ""<p>This is pure slicing but I didn't know that syntax like <code>arr1[0:,:][:,:2]</code> actually works. It seems it does but not sure if it is better.</p>\n\n<p>This may be the <em>wildcard</em> slicing mechanism you are looking for.</p>\n\n<pre><code>arr1 = tf.constant([[1,2,3,4,5,6],[1,2,3,4,5,7],[1,2,3,4,5,8]])\narr2 = tf.constant([[10, 11, 12], [10, 11, 12], [10, 11, 12]])\n\nwith tf.Session() as sess :\n    sess.run( tf.global_variables_initializer() )\n    print(sess.run(tf.concat([arr1[0:,:][:,:2], arr2[0:,:] [:,:1],\n                              arr1[0:,:][:,2:4],arr2[0:, :][:, 1:2],\n                              arr1[0:,:][:,4:6],arr2[0:, :][:, 2:3]],axis=1)))\n</code></pre>\n\n<p>Output is</p>\n\n<pre><code>[[ 1  2 10  3  4 11  5  6 12]\n [ 1  2 10  3  4 11  5  7 12]\n [ 1  2 10  3  4 11  5  8 12]]\n</code></pre>\n\n<p>So, for example,</p>\n\n<p><code>arr1[0:,:]</code> returns</p>\n\n<pre><code>[[1 2 3 4 5 6]\n [1 2 3 4 5 7]\n [1 2 3 4 5 8]]\n</code></pre>\n\n<p>and <code>arr1[0:,:][:,:2]</code> returns the first two columns</p>\n\n<pre><code>[[1 2]\n [1 2]\n [1 2]]\n</code></pre>\n\n<p>axis is 1.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9917}"
69,56754293,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1561968877, 'answer_id': 56832145, 'question_id': 56754293, 'body': '<p>If you want to use Tensorflow Serving, in my opinion, it will be difficult to do it using Native Keras. </p>\n\n<p>If you want to Prepare the Data ready for <code>Training</code> and <code>Serving</code>, you can perform the respective transformations using <code>Tensorflow Transform</code>.</p>\n\n<p>But if you want to Prepare the Data only for <code>Serving</code>, The best way is the one mentioned by you, ""<em>It seems that the only way it to create it from a tf.keras model (and not a native keras model like I have), and to train it directly with the estimator.</em>"" </p>\n\n<p>And you rightly said that it can\'t be done using <code>tf.saved_model.simple_save</code> function.</p>\n\n<p>Example Code for creating Keras Model is shown below and converting it to <code>Estimator</code> is shown below:</p>\n\n<pre><code>import tensorflow as tf\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras import layers\nfrom tensorflow.python.keras import models\n\ndef get_keras_model():\n    inputs = layers.Input(shape=(INPUT_SHAPE,), name=INPUT_FEATURE)\n    dense256 = layers.Dense(256, activation=\'relu\')(inputs)\n    dense32 = layers.Dense(32, activation=\'relu\')(dense256)\n    outputs = layers.Dense(NUM_CLASSES, activation=\'softmax\')(dense32)\n    model = models.Model(inputs, outputs)\n    return model\n</code></pre>\n\n<p>Then convert the Keras Model to Estimator using the below code:</p>\n\n<pre><code>classifier = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir=FLAGS.model_dir)\n</code></pre>\n\n<p>For more information, refer the link,\n<a href=""https://github.com/yu-iskw/tensorflow-serving-example/blob/master/python/train/mnist_keras_estimator.py"" rel=""nofollow noreferrer"">https://github.com/yu-iskw/tensorflow-serving-example/blob/master/python/train/mnist_keras_estimator.py</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9917}"
70,58818679,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1573565649, 'answer_id': 58819890, 'question_id': 58818679, 'body': '<p>In general, TensorFlow graphs contain a description of operations to be performed on tensors. When you do, for example, <code>tf.add(a, b)</code>, a new node is added to the graph indicating that an addition operation should be computed on the tensors <code>a</code> and <code>b</code>.</p>\n\n<p>When you use <code>tf.py_function</code>, TensorFlow has to execute some arbitrary Python code that you are giving as a function. Unfortunately, <code>tf.py_function</code> is not able to ""translate"" arbitrary functions into graph nodes, so there is no way that the operations can be incorporated as such into the graph. One could consider the option of just embedding the Python code itself into the graph, but since TensorFlow works on multiple languages it would not make sense to have nodes with code specialized for one particular language.</p>\n\n<p>In TensorFlow 2.x, where eager execution is enabled by default, there is <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""nofollow noreferrer""><code>tf.function</code></a> to convert particular functions into graphs, for faster execution (<a href=""https://www.tensorflow.org/tutorials/customization/performance"" rel=""nofollow noreferrer"">see guide</a>), but there is no direct integration of this functionality with <code>tf.py_function</code> as such.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9917}"
71,66582647,"{'items': [{'owner': {'reputation': 121, 'user_id': 9598527}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1616509241, 'answer_id': 66765049, 'question_id': 66582647, 'body': '<p>It was due to older version of Ubuntu. I was using 14. After upgrading to 18, the issue got resolved</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9912}"
72,61767803,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1589363767, 'answer_id': 61771538, 'question_id': 61767803, 'body': '<p>You can just average the result (which is what <code>tf.losses.softmax_cross_entropy</code> did anyway through <code>tf.losses.compute_weighted_loss</code>):</p>\n\n<pre class=""lang-py prettyprint-override""><code>loss = tf.math.reduce_mean(\n    tf.nn.softmax_cross_entropy_with_logits(one_hot_labels, logits))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9912}"
73,62249084,"{'items': [{'owner': {'reputation': 281, 'user_id': 10899915}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': True, 'score': 11, 'creation_date': 1591553470, 'answer_id': 62249676, 'question_id': 62249084, 'body': '<p><strong>Using Tensorflow</strong></p>\n\n<pre><code>initializer = tf.initializers.GlorotUniform(seed=0)\ntf.Variable(initializer(shape=[2,2],dtype=tf.float32))\n&lt;tf.Variable \'Variable:0\' shape=(2, 2) dtype=float32, numpy=\narray([[-0.7078647 ,  0.50461936],\n       [ 0.73500216,  0.6633029 ]], dtype=float32)&gt;\n</code></pre>\n\n<p><strong>Same logic in Numpy</strong></p>\n\n<pre><code>import math\nnp.random.seed(0)\nscale = 1/max(1., (2+2)/2.)\nlimit = math.sqrt(3.0 * scale)\nweights = np.random.uniform(-limit, limit, size=(2,2))\nprint(weights)\narray([[0.11956818, 0.52710415],\n       [0.25171784, 0.1099409 ]])\n</code></pre>\n\n<p>If you observe, the above two are not the same because of random number generators. Internally tensorflow uses the stateless random generator as below and if you observe, we got the same output. </p>\n\n<pre><code>tf.random.stateless_uniform(shape=(2,2),seed=[0, 0], minval=-limit, maxval=limit)\n&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[-0.7078647 ,  0.50461936],\n       [ 0.73500216,  0.6633029 ]], dtype=float32)&gt;\n</code></pre>\n\n<p>If you need to know more about internal implementation, you can check <a href=""https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/init_ops_v2.py#L525"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/init_ops_v2.py#L525</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9912}"
74,51247229,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9912}"
75,68550779,"{'items': [{'owner': {'reputation': 1637, 'user_id': 5523920}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1627437041, 'answer_id': 68553450, 'question_id': 68550779, 'body': '<p>To slice a nxn 2D array with a 1D tensor of length d that results in a dxd 2D array with the specified indices, it can be done by using <code>tf.repeat</code>, <code>tf.tile</code> and then <code>tf.stack</code>:</p>\n<pre><code>n = 5\na = tf.constant(np.arange(n * n).reshape(n, n)) # 2D nxn array\nidx = [1,2,4] # 1D tensor with length d\nd = tf.shape(idx)[0]\nix_ = tf.reshape(tf.stack([tf.repeat(idx,d),tf.tile(idx,[d])],1),[d,d,2])\ntarget = tf.gather_nd(a,ix_) # 2D dxd array\nprint(a)\nprint(target)\n</code></pre>\n<p>Expected outputs:</p>\n<pre><code>tf.Tensor(\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]\n [15 16 17 18 19]\n [20 21 22 23 24]], shape=(5, 5), dtype=int64)\ntf.Tensor(\n[[ 6  7  9]\n [11 12 14]\n [21 22 24]], shape=(3, 3), dtype=int64)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9912}"
76,59998335,"{'items': [{'owner': {'reputation': 1387, 'user_id': 9618246}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1580452071, 'answer_id': 59998922, 'question_id': 59998335, 'body': ""<p>You can make a placeholder for <code>foo</code> and feed it's value while running the session. Modified code:</p>\n\n<pre><code>import tensorflow as tf\n\ndef funa():\n    return tf.constant(32)\n\ndef funb():\n    return tf.constant(25)\n\nfoo = True\nfoo_p = tf.placeholder(tf.bool)\n\nsess = tf.Session()\n\nx = tf.cond(foo_p, lambda: funa(), lambda: funb())\nfor i in range(20):\n    if i &gt; 10:\n        foo = False\n    print(sess.run(x, {foo_p:foo}))\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9907}"
77,39133312,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1472075379, 'answer_id': 39133562, 'question_id': 39133312, 'body': '<p>This error arises because <code>tf.Variable(0, ...)</code> defines a variable of element type <code>tf.int32</code>, and there is no kernel that implements <code>int32</code> variables on GPU in the standard TensorFlow distribution. When you use <code>tf.Variable(tf.zeros([1]))</code>, you\'re defining a variable of element type <code>tf.float32</code>, which <em>is</em> supported on GPU.</p>\n\n<p>The story of <code>tf.int32</code> on GPUs in TensorFlow is a long one. While it\'s technically easy to support integer operations running on a GPU, our experience has been that most integer operations actually take place on the <strong>metadata</strong> of tensors, and this metadata lives on the CPU, so it\'s more efficient to operate on it there. As a short-term workaround, several kernel registrations for <code>int32</code> on GPUs were removed. However, if these would be useful for your models, it would be possible to <a href=""https://www.tensorflow.org/versions/r0.10/how_tos/adding_an_op/index.html"" rel=""noreferrer"">add them as custom ops</a>.</p>\n\n<hr>\n\n<p><strong>Source:</strong> In TensorFlow 0.10, the Variable-related kernels are <a href=""https://github.com/tensorflow/tensorflow/blob/854146110b5ec6b087fc6f2e18f35cc3b98e7186/tensorflow/core/kernels/variable_ops.cc#L55"" rel=""noreferrer"">registered</a> using the <a href=""https://github.com/tensorflow/tensorflow/blob/854146110b5ec6b087fc6f2e18f35cc3b98e7186/tensorflow/core/framework/register_types.h#L162"" rel=""noreferrer""><code>TF_CALL_GPU_NUMBER_TYPES()</code></a> macro. The current ""GPU number types"" are <code>tf.float16</code>, <code>tf.float32</code>, and <code>tf.float64</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9907}"
78,61720708,"{'items': [{'owner': {'reputation': 1148, 'user_id': 714004}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1667665601, 'answer_id': 74329500, 'question_id': 61720708, 'body': '<p>Tensorflow 2.10 moved the <a href=""https://www.tensorflow.org/versions/r2.10/api_docs/python/tf/data/Dataset#save"" rel=""noreferrer"">save</a> method from <code>tf.data.experimental</code> to <code>tf.data.Dataset</code>.  Used with the <a href=""https://www.tensorflow.org/versions/r2.10/api_docs/python/tf/data/Dataset#load"" rel=""noreferrer"">load</a> method, this is the easiest way to, well, save and load a model.</p>\n<p>Tensorflow 2.6 introduced the <a href=""https://www.tensorflow.org/versions/r2.6/api_docs/python/tf/data/Dataset#snapshot"" rel=""noreferrer"">snapshot</a> method (previously an &quot;experimental&quot; feature).  <a href=""https://github.com/tensorflow/community/blob/master/rfcs/20200107-tf-data-snapshot.md"" rel=""noreferrer"">Tensorflow RFC-193</a> goes into detail on the motivation and details of the feature.</p>\n<p>From the docs:</p>\n<blockquote>\n<p>The snapshot API allows users to transparently persist the output of their preprocessing pipeline to disk, and materialize the pre-processed data on a different training run.</p>\n<p>This API enables repeated preprocessing steps to be consolidated, and allows re-use of already processed data, trading off disk storage and network bandwidth for freeing up more valuable CPU resources and accelerator compute time.</p>\n</blockquote>\n'}, {'owner': {'reputation': 3631, 'user_id': 5931672}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1656947162, 'answer_id': 72858773, 'question_id': 61720708, 'body': '<p>You can use <a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/save"" rel=""nofollow noreferrer"">tf.data.experimental.save</a> and  <a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/load"" rel=""nofollow noreferrer"">tf.data.experimental.load</a> like this:</p>\n<p>Code to save it:</p>\n<pre><code>tf_dataset = get_dataset()    # returns a tf.data.Dataset() file\ntf.data.experimental.save(dataset=tf_dataset, path=&quot;path/to/desired/save/file_name&quot;)\nwith open(&quot;path/to/desired/save/file_name&quot; + &quot;.pickle&quot;)), \'wb\') as file:\n    pickle.dump(tf_dataset.element_spec, file)   # I need this for opening it later\n</code></pre>\n<p>Code to open:</p>\n<pre><code>element_spec = pickle.load(&quot;path/to/desired/save/file_name&quot; + &quot;.pickle&quot;, \'rb\'))\ntensor_data = tf.data.experimental.load(&quot;path/to/desired/save/file_name&quot;, element_spec=element_spec)\n</code></pre>\n'}, {'owner': {'reputation': 138, 'user_id': 5047095}, 'down_vote_count': 2, 'up_vote_count': 8, 'is_accepted': False, 'score': 6, 'creation_date': 1622513974, 'answer_id': 67781967, 'question_id': 61720708, 'body': ""<p>To add on Yoan's answer:</p>\n<p>the tf.experimental.save() and load() API works well. You also need to MANUALLY save the ds.element_spec to disk to be able to load() later / within a different context.</p>\n<p>Pickling works well for me:</p>\n<p>1- Saving:</p>\n<pre><code>tf.data.experimental.save(\n    ds, tf_data_path, compression='GZIP'\n)\nwith open(tf_data_path + '/element_spec', 'wb') as out_:  # also save the element_spec to disk for future loading\n    pickle.dump(ds.element_spec, out_)\n</code></pre>\n<p>2- For loading, you need both the folder path with the tf shards and the element_spec that we manually pickled</p>\n<pre><code>with open(tf_data_path + '/element_spec', 'rb') as in_:\n    es = pickle.load(in_)\n\nloaded = tf.data.experimental.load(\n    tf_data_path, es, compression='GZIP'\n)\n</code></pre>\n""}, {'owner': {'reputation': 1485, 'user_id': 12054590}, 'down_vote_count': 1, 'up_vote_count': 11, 'is_accepted': False, 'score': 10, 'creation_date': 1596217888, 'answer_id': 63196757, 'question_id': 61720708, 'body': '<p>An incident was open on GitHUb and it appears there\'s a new feature available in TF 2.3 to write to disk :</p>\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/save"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/experimental/save</a>\n<a href=""https://www.tensorflow.org/api_docs/python/tf/data/experimental/load"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/experimental/load</a></p>\n<p>I haven\'t tested this features yet but it seems to be doing what you want.</p>\n'}, {'owner': {'reputation': 4914, 'user_id': 4444546}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1592916668, 'answer_id': 62535155, 'question_id': 61720708, 'body': '<p>I have been working on this issus as well and so far I have written the following util (as to be found <a href=""https://github.com/few-shot-learning/Keras-FewShotLearning/blob/master/keras_fsl/utils/datasets.py"" rel=""nofollow noreferrer"">in my repo as well</a>)</p>\n<pre class=""lang-py prettyprint-override""><code>def cache_with_tf_record(filename: Union[str, pathlib.Path]) -&gt; Callable[[tf.data.Dataset], tf.data.TFRecordDataset]:\n    &quot;&quot;&quot;\n    Similar to tf.data.Dataset.cache but writes a tf record file instead. Compared to base .cache method, it also insures that the whole\n    dataset is cached\n    &quot;&quot;&quot;\n\n    def _cache(dataset):\n        if not isinstance(dataset.element_spec, dict):\n            raise ValueError(f&quot;dataset.element_spec should be a dict but is {type(dataset.element_spec)} instead&quot;)\n        Path(filename).parent.mkdir(parents=True, exist_ok=True)\n        with tf.io.TFRecordWriter(str(filename)) as writer:\n            for sample in dataset.map(transform(**{name: tf.io.serialize_tensor for name in dataset.element_spec.keys()})):\n                writer.write(\n                    tf.train.Example(\n                        features=tf.train.Features(\n                            feature={\n                                key: tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.numpy()]))\n                                for key, value in sample.items()\n                            }\n                        )\n                    ).SerializeToString()\n                )\n        return (\n            tf.data.TFRecordDataset(str(filename), num_parallel_reads=tf.data.experimental.AUTOTUNE)\n            .map(\n                partial(\n                    tf.io.parse_single_example,\n                    features={name: tf.io.FixedLenFeature((), tf.string) for name in dataset.element_spec.keys()},\n                ),\n                num_parallel_calls=tf.data.experimental.AUTOTUNE,\n            )\n            .map(\n                transform(\n                    **{name: partial(tf.io.parse_tensor, out_type=spec.dtype) for name, spec in dataset.element_spec.items()}\n                )\n            )\n            .map(\n                transform(**{name: partial(tf.ensure_shape, shape=spec.shape) for name, spec in dataset.element_spec.items()})\n            )\n        )\n\n    return _cache\n</code></pre>\n<p>With this util, I can do:</p>\n<pre class=""lang-py prettyprint-override""><code>dataset.apply(cache_with_tf_record(&quot;filename&quot;)).map(...)\n</code></pre>\n<p>and also load directly the dataset for later use with only the second part of the util.</p>\n<p>I am still working on it so it may change later on, especially to serialize with the correct types instead of all bytes to save space (I guess).</p>\n'}, {'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 10, 'is_accepted': True, 'score': 10, 'creation_date': 1589191291, 'answer_id': 61727034, 'question_id': 61720708, 'body': '<p><code>TFRecordWriter</code> seems to be the most convenient option, but unfortunately it can only write datasets with a single tensor per element. Here are a couple of workarounds you can use. First, since all your tensors have the same type and similar shape, you can concatenate them all into one, and split them back later on load:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\n# Write\na = tf.zeros((100, 512), tf.int32)\nds = tf.data.Dataset.from_tensor_slices((a, a, a, a[:, 0]))\nprint(ds)\n# &lt;TensorSliceDataset shapes: ((512,), (512,), (512,), ()), types: (tf.int32, tf.int32, tf.int32, tf.int32)&gt;\ndef write_map_fn(x1, x2, x3, x4):\n    return tf.io.serialize_tensor(tf.concat([x1, x2, x3, tf.expand_dims(x4, -1)], -1))\nds = ds.map(write_map_fn)\nwriter = tf.data.experimental.TFRecordWriter(\'mydata.tfrecord\')\nwriter.write(ds)\n\n# Read\ndef read_map_fn(x):\n    xp = tf.io.parse_tensor(x, tf.int32)\n    # Optionally set shape\n    xp.set_shape([1537])  # Do `xp.set_shape([None, 1537])` if using batches\n    # Use `x[:, :512], ...` if using batches\n    return xp[:512], xp[512:1024], xp[1024:1536], xp[-1]\nds = tf.data.TFRecordDataset(\'mydata.tfrecord\').map(read_map_fn)\nprint(ds)\n# &lt;MapDataset shapes: ((512,), (512,), (512,), ()), types: (tf.int32, tf.int32, tf.int32, tf.int32)&gt;\n</code></pre>\n\n<p>But, more generally, you can simply have a separate file per tensor and then read them all:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\n# Write\na = tf.zeros((100, 512), tf.int32)\nds = tf.data.Dataset.from_tensor_slices((a, a, a, a[:, 0]))\nfor i, _ in enumerate(ds.element_spec):\n    ds_i = ds.map(lambda *args: args[i]).map(tf.io.serialize_tensor)\n    writer = tf.data.experimental.TFRecordWriter(f\'mydata.{i}.tfrecord\')\n    writer.write(ds_i)\n\n# Read\nNUM_PARTS = 4\nparts = []\ndef read_map_fn(x):\n    return tf.io.parse_tensor(x, tf.int32)\nfor i in range(NUM_PARTS):\n    parts.append(tf.data.TFRecordDataset(f\'mydata.{i}.tfrecord\').map(read_map_fn))\nds = tf.data.Dataset.zip(tuple(parts))\nprint(ds)\n# &lt;ZipDataset shapes: (&lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;), types: (tf.int32, tf.int32, tf.int32, tf.int32)&gt;\n</code></pre>\n\n<p>It is possible to have the whole dataset in a single file with multiple separate tensors per element, namely as a file of TFRecords containing <code>tf.train.Example</code>s, but I don\'t know if there is a way to create those within TensorFlow, that is, without having to get the data out of the dataset into Python and then write it to the records file.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9907}"
79,55740550,"{'items': [{'owner': {'reputation': 953, 'user_id': 1803124}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1555585261, 'answer_id': 55744637, 'question_id': 55740550, 'body': ""<p>You can eliminate the loops in your <code>loss</code> function. This is done by vectorising everything. For example you iterate through <code>i</code> and <code>j</code> to calculate <code>phi[i]*phi[j]</code> But this is the ij'th element of <code>tf.matmul(phi[:, None], phi[None, :])</code>. Doing this should be faster than the implementation with loops.</p>\n\n<p>Also, because tensorflow builds the graph statically, your function could take a loooong time to even build the graph. You should generally avoid big nested for loops in tensorflow for this reason.</p>\n\n<p>I have made an example with part of your loss function vectorised, it should be easy to do the other parts.</p>\n\n<pre><code>import tensorflow as tf\nfrom numpy import pi as PI\nfrom time import time\n\n\n# some random vectors\nsize = 10\nphi = tf.random.uniform([size])\nmu = tf.random.uniform([size])\nsigma = tf.random.uniform([size])\n\n\n####################################\n# Your original loss\n####################################\n\ndef pdf(x, m, s):\n    return tf.exp(-0.5*(x-m)**2/s**2) / ((2*PI*s**2)**0.5)\n\n\ndef loss():\n    _loss = 0.0\n    for i in range(phi.shape[0]):\n        for j in range(phi.shape[0]):\n            _loss += phi[i] * phi[j] * pdf(mu[i], mu[j], tf.sqrt(sigma[i]**2 + sigma[j]**2))\n    return tf.sqrt(_loss)\n\n\n####################################\n# vectorised loss\n####################################\n\ndef vector_pdf(x, s):\n    return tf.exp(-0.5*x**2/s**2) / ((2*PI*s**2)**0.5)\n\n\ndef vectorised_loss():\n    phi_ij = tf.matmul(phi[:, None], phi[None, :])\n    difference = mu[:, None] - mu[None, :]\n    sigma_squared = sigma**2\n    sigma_sum = tf.sqrt(sigma_squared[:, None] + sigma_squared[None, :])\n\n    loss_array = phi_ij*vector_pdf(difference, sigma_sum)\n    return tf.sqrt(tf.reduce_sum(loss_array))\n\n\n#######################################\n# Time the functions and show they are the same\n#######################################\n\nwith tf.Session() as sess:\n    loop_loss = loss()\n    vector_loss = vectorised_loss()\n    # init = tf.global_variables_initializer()\n    # sess.run(init)\n\n    t = 0.\n    for _ in range(100):\n        st = time()\n        loop_loss_val = sess.run(loop_loss)\n        t += time() - st\n    print('loop took {}'.format(t/100))\n\n    t = 0.\n    for _ in range(100):\n        st = time()\n        vector_val = sess.run(vector_loss)\n        t += time() - st\n    print('vector took {}'.format(t / 100))\n\n    l_val, v_val = sess.run([loop_loss, vector_loss])\n    print(l_val, v_val)\n</code></pre>\n\n<p>This prints</p>\n\n<pre><code>loop took 0.01740453243255615\nvector took 0.004280190467834472\n4.6466274 4.6466274\n</code></pre>\n\n<p>By vectorising the loss function, your reduce function should be straightforward to vectorise as well. Now you will want to batch matmul, and slightly change the indices of the subtractions. For example:</p>\n\n<pre><code>mu[:, None] - mu[None, :]\n# becomes\nmu[: ,:, None] - mu[:, None, :]\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9904}"
80,65099915,"{'items': [{'owner': {'reputation': 1000, 'user_id': 11878567}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1606881612, 'answer_id': 65102019, 'question_id': 65099915, 'body': '<p>You can simply call <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L1042-L1067"" rel=""nofollow noreferrer""><strong><code>.numpy()</code></strong></a> on the Tensor object.</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\na = tf.Variable(4.0)\nb = tf.Variable([4.0])\nc = tf.Variable([[1, 2], [3, 4]])\n\na.numpy()\n# 4.0\n\nb.numpy()\n# array([4.], dtype=float32)\n\nc.numpy()\n# array([[1, 2],\n       [3, 4]], dtype=int32)\n</code></pre>\n<p>See <a href=""https://www.tensorflow.org/tutorials/customization/basics"" rel=""nofollow noreferrer"">Customization basics: tensors and operations</a> for more. Also as stated in the docs</p>\n<blockquote>\n<p>Numpy array may share memory with the Tensor object. Any changes to one may be reflected in the other.</p>\n</blockquote>\n<hr />\n<p>If Eager Execution is disabled, you can build a graph and then run it through <code>tf.compat.v1.Session</code>:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\na = tf.Variable(4.0)\nb = tf.Variable([4.0])\nc = tf.Variable([[1, 2], [3, 4]])\n\na.eval(session=tf.compat.v1.Session())\n# 4.0\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9903}"
81,46534796,"{'items': [{'owner': {'reputation': 2034, 'user_id': 2805070}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1507081168, 'answer_id': 46555783, 'question_id': 46534796, 'body': '<p>The problem that you encounter for inception network may be resolved by using padding in convolutional layers to keep the size same. For inception blocks, instead of using ""VALID"" padding, change it to ""SAME"" one. So, without requiring any resizing, you can concatenate the outputs. </p>\n\n<p>Alternatively, you can append padding to the feature maps that are going to be concatenated. You can do that by using tf.pad(). </p>\n\n<p>If you don\'t prefer to do this one, you can use tf.image.resize_images function to resize them to same values. However, this is a dirty and computationally expensive approach. </p>\n'}, {'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1507014204, 'answer_id': 46538857, 'question_id': 46534796, 'body': ""<p>It's impossible and meaningless to concatenate features maps with different sizes.</p>\n\n<p>If you want to concatenate 2 tensors, every dimension except the concatenation one must be equal.</p>\n\n<p>From the image you posted, in fact, you can see that every feature map that gets concatenated, has the same spatial extent (but different depth) of the other one.\nIf you can't concatenate in that way, probabily that's something wrong in your code, and probably the problem is the lack of padding = valid in the convolution operation.</p>\n""}, {'owner': {'reputation': 767, 'user_id': 8015346}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1506987990, 'answer_id': 46535229, 'question_id': 46534796, 'body': '<p>Tensors can only be concatenated along one axis. If you need to concatenate feature maps of different sizes, you must somehow manipulate the sizes of the original tensors.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9903}"
82,68939916,"{'items': [{'owner': {'reputation': 1258, 'user_id': 4794555}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1629991496, 'answer_id': 68941327, 'question_id': 68939916, 'body': ""<p>I reproduced this error through the code below</p>\n<pre><code>import tensorflow as tf\n\n#there are same values in the tensor\nskip_ids = tf.constant([[0], [0]], dtype=tf.int64)\n\nsparse_mask = tf.SparseTensor(\n    # Put a -inf at each bad index.\n    values=[-float('inf')] * len(skip_ids),\n    indices=skip_ids,\n    # Match the shape to the vocabulary\n    dense_shape=[76])\nprint(sparse_mask)\n\nprediction_mask = tf.sparse.to_dense(sparse_mask)\n</code></pre>\n<p>Your indices has same value, it does not allow to assign values in the same position. Just get unique values in indices tensor before:</p>\n<pre><code>import tensorflow as tf\n\nskip_ids = tf.constant([[0], [0]], dtype=tf.int64)\n\n# get unique indices\ntmp1 = tf.reshape(skip_ids, shape=(-1,))\nuniques, idx, counts = tf.unique_with_counts(tmp1)\nuniques_ids = tf.expand_dims(uniques, axis=1)\n\n\nsparse_mask = tf.SparseTensor(\n    # Put a -inf at each bad index.\n    values=[-float('inf')] * len(uniques_ids),\n    indices=uniques_ids,\n    # Match the shape to the vocabulary\n    dense_shape=[76])\nprint(sparse_mask)\n\nprediction_mask = tf.sparse.to_dense(sparse_mask)\n\nprint(prediction_mask)\n</code></pre>\n<p>My tensorflow version is 2.1.0</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9903}"
83,57731214,"{'items': [{'owner': {'reputation': 860, 'user_id': 7331631}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1567193998, 'answer_id': 57732427, 'question_id': 57731214, 'body': '<p>There are two main concepts in TensorFlow 1.0 <strong>Graphs</strong> and <strong>Sessions</strong>.</p>\n<ul>\n<li><p>Graph - It is a set of connected operations and placeholders which doesn\'t hold any tensor(numpy array) or values without a session. As an analogy, you can consider a food processing assembly line without any ingredients, but process and recipes are defined.</p>\n</li>\n<li><p>Session - It takes the graph and initializes the variable with initial values and ready to take some to feed in the placeholder to start implementing the operations defined the graph to the feed values in placeholders, at last, it will deliver you the final output from you desired operation node (in neural network nodes of the last layer.)(like feeding tomatoes and getting ketchup as output.)</p>\n<p>coming back to your real question.</p>\n</li>\n<li><p>If you use the <code>tf.keras.backend.clear_session</code> it will discard the values resides in the variable defined in the graph, leaving an empty vessel. (It will free up your RAM space.), now you can load weights from some other files.</p>\n</li>\n<li><p>If you use the <code>tf.reset_default_graph()</code> it will reset the graph and it will remove all the defined operations and their inter-connection with corresponding weights. Now you have to load both models architecture and weights for the execution.</p>\n</li>\n</ul>\n<p>practically it seems it is doing same stuff cause it is tf.reset_default_graph() will be called internally while calling k.clear_session() but clear_session will also intiate the fresh graph for the new operation you can check the source code <a href=""https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/backend.py#L217-L242"" rel=""nofollow noreferrer"">here</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9900}"
84,63953040,"{'items': [{'owner': {'reputation': 1931, 'user_id': 383053}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1603235057, 'answer_id': 64454490, 'question_id': 63953040, 'body': ""<p>I don't know if this is the best way of going about this but for TF 2.x you can do something like:</p>\n<pre><code>import tensorflow as tf\n\ndef make_serving_input_fn():\n    # your feature spec\n    feature_spec = {\n        'chunk': tf.io.FixedLenFeature([128, 2, 3], tf.float32),  \n        'class': tf.io.FixedLenFeature([2], tf.int64),\n    }\n\n    serialized_tf_examples = tf.keras.Input(\n        shape=[], name='input_example_tensor', dtype=tf.string)\n\n    examples = tf.io.parse_example(serialized_tf_examples, feature_spec)\n\n    # any processing \n    processed_chunks = tf.map_fn(\n        &lt;PROCESSING_FN&gt;, \n        examples['chunk'], # ?\n        dtype=tf.float32)\n\n    return tf.estimator.export.ServingInputReceiver(\n        features={&lt;MODEL_FIRST_LAYER_NAME&gt;: processed_chunks},\n        receiver_tensors={&quot;input_example_tensor&quot;: serialized_tf_examples}\n    )\n\n\nestimator = tf.keras.estimator.model_to_estimator(\n    keras_model=model,\n    model_dir=&lt;ESTIMATOR_SAVE_DIR&gt;)\n\nestimator.export_saved_model(\n    export_dir_base=&lt;WORKING_DIR&gt;,\n    serving_input_receiver_fn=make_serving_input_fn)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9900}"
85,55363728,"{'items': [{'owner': {'reputation': 992, 'user_id': 10111931}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1553698345, 'answer_id': 55380205, 'question_id': 55363728, 'body': '<p>Here is an example of how you can wrap the function with the help of <a href=""https://www.tensorflow.org/api_docs/python/tf/py_func"" rel=""nofollow noreferrer"">py_func</a>. Do note that this is deprecated in TF V2. You can follow the documentation for further details.</p>\n\n<pre><code>def parse_function_wrapper(filename):\n   # Assuming your data and labels are float32\n   # Your input is parse_function, who arg is filename, and you get X and y as output\n   # whose datatypes are indicated by the tuple argument  \n   features, labels = tf.py_func(\n       parse_function, [filename], (tf.float32, tf.float32)) \n   return features, labels\n\n# Create dataset of filenames.\ndataset = tf.data.Dataset.from_tensor_slices(flist)\ndataset = dataset.shuffle(len(flist))\ndataset = dataset.map(parse_function_wrapper)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9900}"
86,51499154,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9897}"
87,42127505,"{'items': [{'owner': {'reputation': 397, 'user_id': 7930290}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1532368779, 'answer_id': 51484756, 'question_id': 42127505, 'body': '<p>tf.contrib.layers.dense_to_sparse does dense tensor to sparse conversion. termination is detected by presence of zeros in the end of array. Please visit <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/layers/dense_to_sparse"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/contrib/layers/dense_to_sparse</a> for more details.</p>\n'}, {'owner': {'reputation': 1583, 'user_id': 3159795}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': True, 'score': 11, 'creation_date': 1486611536, 'answer_id': 42127784, 'question_id': 42127505, 'body': '<p><a href=""https://stackoverflow.com/questions/39838234/sparse-matrix-from-a-dense-one-tensorflow"">according to this question:</a> </p>\n\n<p>you can do it with this:</p>\n\n<p>You can use tf.where and tf.gather_nd to do that:</p>\n\n<pre><code>a = np.reshape(np.arange(24), (3, 4, 2))\nwith tf.Session() as sess:\n    a_t = tf.constant(a)\n    idx = tf.where(tf.not_equal(a_t, 0))\n    # Use tf.shape(a_t, out_type=tf.int64) instead of a_t.get_shape() if tensor shape is dynamic\n    sparse = tf.SparseTensor(idx, tf.gather_nd(a_t, idx), a_t.get_shape())\n    dense = tf.sparse_tensor_to_dense(sparse)\n    b = sess.run(dense)\nnp.all(a == b)\n&gt;&gt;&gt; True\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9897}"
88,41109652,"{'items': [{'owner': {'reputation': 169, 'user_id': 9011148}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1629554682, 'answer_id': 68873708, 'question_id': 41109652, 'body': '<p>For the latest versions of tensorflow, All audio related utilities have been moved/added to tensorflow_io (<a href=""https://www.tensorflow.org/io/api_docs/python/tfio/audio"" rel=""nofollow noreferrer"">here</a>). To install run <code>pip install tensorflow.io</code></p>\n<pre><code>import tensorflow_io as tfio\nimport tensorflow as tf\n\nfp = \'path/to/mp3\'\naudio  = tfio.audio.decode_mp3(tf.io.read_file(fp))\n</code></pre>\n'}, {'owner': {'reputation': 66044, 'user_id': 133374}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1584723273, 'answer_id': 60778416, 'question_id': 41109652, 'body': '<p>Such a function has recently been added to <a href=""https://github.com/tensorflow/io"" rel=""nofollow noreferrer""><code>tensorflow_io</code></a> (<a href=""https://github.com/tensorflow/io/pull/857"" rel=""nofollow noreferrer"">here</a>).\nYou can use it like this:</p>\n\n<pre><code>content = tf.io.read_file(path)\naudio = tfio.experimental.audio.decode_ogg(content)\n</code></pre>\n'}, {'owner': {'reputation': 2937, 'user_id': 4958717}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1583416910, 'answer_id': 60547112, 'question_id': 41109652, 'body': '<p>The answer from @sygi is unfortunately not supported in TensorFlow 2.x. An alternative solution would be to use some external library (e.g. <a href=""https://github.com/jiaaro/pydub/blob/master/API.markdown"" rel=""noreferrer"">pydub</a> or <a href=""https://librosa.github.io/librosa/generated/librosa.core.load.html"" rel=""noreferrer"">librosa</a>) to implement the mp3 decoding step, and integrate it in the pipeline through the use of <code>tf.py_function</code>. So you can do something along the lines of:</p>\n\n<pre><code>from pydub import AudioSegment\nimport tensorflow as tf\n\ndataset = tf.data.Dataset.list_files(\'path/to/mp3s/*\')\n\ndef decode_mp3(mp3_path):\n    mp3_path = mp3_path.numpy().decode(""utf-8"")\n    mp3_audio = AudioSegment.from_file(mp3_path, format=""mp3"")\n    return mp3_audio.get_array_of_samples()\n\ndataset = dataset.map(lambda path:\n    tf.py_function(func=decode_mp3, inp=[path], Tout=tf.float32))\n\nfor features in dataset.take(3):\n    data = features.numpy()\n    plt.plot(data)\n    plt.show()\n</code></pre>\n\n<p><a href=""https://i.stack.imgur.com/to46j.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/to46j.png"" alt=""enter image description here""></a></p>\n'}, {'owner': {'reputation': 4577, 'user_id': 1951176}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': False, 'score': 6, 'creation_date': 1481580906, 'answer_id': 41110613, 'question_id': 41109652, 'body': '<p>Yes, there are special decoders, in the package <a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/contrib.ffmpeg.html#ffmpeg-contrib"" rel=""nofollow noreferrer"">tensorflow.contrib.ffmpeg</a>. To use it, you need to install <a href=""https://ffmpeg.org/download.html"" rel=""nofollow noreferrer"">ffmpeg</a> first.</p>\n\n<p>Example:</p>\n\n<pre><code>audio_binary = tf.read_file(\'song.mp3\')\nwaveform = tf.contrib.ffmpeg.decode_audio(audio_binary, file_format=\'mp3\', samples_per_second=44100, channel_count=2)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9897}"
89,47822996,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9897}"
90,49746064,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9897}"
91,52447384,"{'items': [{'owner': {'reputation': 1630, 'user_id': 10025506}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1537546048, 'answer_id': 52447502, 'question_id': 52447384, 'body': ""<blockquote>\n  <p>However, when I try the loss function with randomly generated arrays, it works fine and yields normal values.</p>\n</blockquote>\n\n<p>It seems that you have an issue with your input_fn. Are you sure that it is correctly implemented ? </p>\n\n<blockquote>\n  <p>Also, is there any way I could print the loss returned by the loss function.</p>\n</blockquote>\n\n<p>Estimator prints the value of the loss function automatically in the console every global_step % 'save_summary_steps'. You can also track the loss function using a scalar summary like so :</p>\n\n<pre><code>tf.summary.scalar('loss', loss)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9892}"
92,57809049,"{'items': [{'owner': {'reputation': 351, 'user_id': 11427310}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1567780517, 'answer_id': 57824035, 'question_id': 57809049, 'body': '<p>I changed my strategy and come with this working :</p>\n\n<pre><code>total_loss, i = list(), tf.constant(0)\ndef sampled_softmax_body(i):\n    loss = tf.nn.sampled_softmax_loss(weights=logits_weights, biases=logits_biases, labels=target, inputs=h2_decoder_outputs[:,i,:], num_sampled=n_sampled_softmax, num_classes=n_fra_words, partition_strategy=""div"")     \n    total_loss.append(loss)\n    return tf.add(i, 1)\ndef condition(i):\n    return i &lt; max_words_per_sentence[""fra""]\ntf.while_loop(condition, sampled_softmax_body, [i])\n</code></pre>\n\n<p>but how I am supposed to get the content of <code>total_list</code> ? \nbecause it is transform buy the loop. I have not the appended list I created.</p>\n\n<pre><code>In [8]: total_loss\nOut[8]: [&lt;tf.Tensor \'while/softmax_cross_entropy_with_logits/Reshape_2:0\' shape=(?,) dtype=float32&gt;]\n</code></pre>\n\n<p>My goal is to use backpropagation using <code>total_loss</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9892}"
93,61829273,"{'items': [{'owner': {'reputation': 41, 'user_id': 9763431}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1589653542, 'answer_id': 61841641, 'question_id': 61829273, 'body': '<p>Solution to the specific problem of the question was to .batch() the dataset:</p>\n\n<pre><code>ds = tf.data.Dataset.zip((X_ds, y_ds)).batch(32) # eg, batch size 32\n</code></pre>\n\n<p>My understanding (<a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">docs</a>) is that the \'batch\' presented to the model effectively restores the data outer dimension that was removed via the tf.data.Data.from_tensor_slices method.  That is, the data is restored to the shape that worked with the original numpy arrays.  </p>\n'}, {'owner': {'reputation': 633, 'user_id': 12915531}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1589583108, 'answer_id': 61829577, 'question_id': 61829273, 'body': '<p>According to the <code>tf.data.Dataset</code> <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices"" rel=""nofollow noreferrer"">documentation</a></p>\n\n<p><code>from_tensors</code> combines the input and returns a single element containing the dataset.</p>\n\n<pre><code>dataset = tf.data.Dataset.from_tensors([[1, 2], [3, 4]])\nlist(dataset.as_numpy_iterator())\n\n[array([[1, 2], [3, 4]], dtype=int32)]\n</code></pre>\n\n<p><code>from_tensor_slices</code> slices the dataset along its first dimension and creates a dataset with a separate element for each row of the input tensor</p>\n\n<pre><code>dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\nlist(dataset.as_numpy_iterator())\n\n[array([1, 2], dtype=int32), array([3, 4], dtype=int32)]\n</code></pre>\n\n<p>You are getting Value Error because the shape of <code>from_tensors</code> is different from <code>from_tensor_slices</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9892}"
94,66711706,"{'items': [{'owner': {'reputation': 4691, 'user_id': 4360557}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1638297366, 'answer_id': 70174417, 'question_id': 66711706, 'body': '<p><strong>Currently, you can\'t</strong> (<em>as discussed here</em>)</p>\n<p>This is not a limitation of JAX jit vs TensorFlow, but a limitation of XLA or rather how the two compile.</p>\n<p>JAX uses simply XLA to compile the function. XLA <em>needs to know</em> the static shape. That\'s an inherent design choice <em>within XLA</em>.</p>\n<p>TensorFlow uses the <code>function</code>: this creates a graph which can have shapes that are not statically known. This is not as efficient as using XLA, but still fine. However, <code>tf.function</code> offers an option <a href=""https://www.tensorflow.org/xla/tutorials/jit_compile"" rel=""nofollow noreferrer""><code>jit_compile</code></a>, which will compile the graph inside the function with XLA. While this offers often a decent speedup (for free), it comes with restrictions: shapes need to be statically known (surprise, surprise,...)</p>\n<p>This is overall not too surprising behavior: computations in computers are in general faster (given a decent optimizer went over it) <em>the more is previously known</em> as more parameters (memory layout,...) can be optimally scheduled. The less is known, the slower the code (on this end is normal Python).</p>\n'}, {'owner': {'reputation': 1551, 'user_id': 6084245}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1620226869, 'answer_id': 67403861, 'question_id': 66711706, 'body': '<p>I don\'t think JAX isn\'t more incapable of doing this than TensorFlow. Nothing forbid you to do this in JAX:</p>\n<pre><code>new_array = my_array[mask]\n</code></pre>\n<p>However, <code>mask</code> should be indices (integers) and not booleans. This way, JAX is aware of the shape of <code>new_array</code> (the same as <code>mask</code>). In that sens, I\'m pretty sure that <code>tf.boolean_mask</code> is not differentiable i.e. it will raise an error if you try to compute its gradient at some point.</p>\n<p>More generally, if you need to mask an array, whatever library you are using, there are two approaches:</p>\n<ol>\n<li>if you know in advance what indices need to be selected and you need to provide these indices such that the library can compute the shape before compilation;</li>\n<li>if you can\'t define these indices, for whatever reason, then you need to design your code in order to avoid the prevent the padding to affect your result.</li>\n</ol>\n<p><strong>Examples for each situation</strong></p>\n<ol>\n<li><p>Let say you\'re writing a simple embedding layer in JAX. The <code>input</code> is a batch of token indices corresponding to several sentences. To get word embeddings corresponding to these indices, I will simply write <code>word_embeddings = embeddings[input]</code>. Since I don\'t know the length of the sentences in advance, I need to pad all token sequences to the same length beforehand, such that <code>input</code> is of shape <code>(number_of_sentences, sentence_max_length)</code>. Now, JAX will compile the masking operation every time this shape changes. To minimize the number of compilations, you can provide the same number of sentences (also called batch size) and you can set the <code>sentence_max_length</code> to the maximum sentence length in the entire corpus. This way, there will be only one compilation during training. Of course, you need to reserve one row in <code>word_embeddings</code> that corresponds to the pad index. But still, the masking works.</p>\n</li>\n<li><p>Later in the model, let say you want to express each word of each sentence as a weighted average of all other words in the sentence (like a self-attention mechanism). The weights are computed in parallel for the entire batch and are stored in the matrix <code>A</code> of dimension <code>(number_of_sentences, sentence_max_length, sentence_max_length)</code>. The weighted averages are computed with the formula <code>A @ word_embeddings</code>. Now, you need to make sure the pad tokens don\'t affect this previous formula. To do so, you can zero out the entries of A corresponding to the pad indices to remove their influence in the averaging. If the pad token index is 0, you would do:</p>\n</li>\n</ol>\n<pre class=""lang-py prettyprint-override""><code>    mask = jnp.array(input &gt; 0, dtype=jnp.float32)\n    A = A * mask[:, jnp.newaxis, :]\n    weighted_mean = A @ word_embeddings \n</code></pre>\n<p>So here we used a boolean mask, but the masking is somehow differentiable since we multiply the mask with another matrix instead of using it as an index. Note that we should proceed the same way to remove the rows of <code>weighted_mean</code> that also correspond to pad tokens.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9892}"
95,47558813,"{'items': [{'owner': {'reputation': 31, 'user_id': 11730933}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1579488003, 'answer_id': 59816366, 'question_id': 47558813, 'body': '<p>For those who are still looking here, starting in TensorFlow 2.x <code>tf.contrib</code> is deprecated, and so <code>tf.contrib.image.rotate</code> will no longer work. </p>\n\n<p>Instead you can use <strong><code>tfa.image.rotate</code></strong> from the <code>tensorflow_addons</code> library. This function rotates an image counterclockwise and takes an angle in radians as an input.</p>\n\n<pre><code>img = ... #insert image(s) here\nangle = 60 #in degrees\nangle_radians = angle * math.pi / 180\nrotated_img = tfa.image.rotate(img, angle_radians)\n</code></pre>\n'}, {'owner': {'reputation': 5966, 'user_id': 1190882}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1511981823, 'answer_id': 47559863, 'question_id': 47558813, 'body': '<p>You are mixing two separate tensorflow functions.</p>\n\n<p><strong><code>tf.contrib.image.rotate</code></strong>: This function is used for rotating images at any degree of your choice.</p>\n\n<pre><code>X_img =  # Your image or batch of images\ndegree_angle = 45 # In degrees\nradian = degree_angle * math.pi / 180\ntf_img = tf.contrib.image.rotate(X_img, radian)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    rotated_img = sess.run(tf_img)\n</code></pre>\n\n<p><strong><code>tf.cast</code></strong>: Used to cast the dtype of tensor from one form to another. Example of converting to float32 format.</p>\n\n<pre><code>casted_tensor = tf.cast(input_tensor, tf.float32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9888}"
96,58126494,"{'items': [{'owner': {'reputation': 2457, 'user_id': 8842694}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1569570460, 'answer_id': 58130094, 'question_id': 58126494, 'body': '<blockquote>\n<p>For starters, I need to know what type a TFRecord file can take, when using CSV types are removed.</p>\n</blockquote>\n<p>TFRecord accepts following datatypes-\nstring, byte, float32, float 64, bool, enum, int32, int64, uint32, uint64\nTalked <a href=""https://www.tensorflow.org/beta/tutorials/load_data/tf_records#data_types_for_tfexample"" rel=""nofollow noreferrer"">here</a>.</p>\n<blockquote>\n<p>Secondly, How can I convert data type:object into a type that a TFRecord can take?</p>\n</blockquote>\n<p><a href=""https://www.tensorflow.org/beta/tutorials/load_data/tf_records#creating_a_tfexample_message"" rel=""nofollow noreferrer"">Here</a> is an example from TF, it is a bit complicated to digest it at once but if you read it carefully it is easy.</p>\n<blockquote>\n<p>have two columns (will post example below) of two objects types that are strings, How can I convert that data to the correct type for TFRecords?</p>\n</blockquote>\n<p>For string type data, you require <code>tf.train.BytesList</code> which returns a bytes_list from a string.</p>\n<blockquote>\n<p>When importing Im hoping to append data from each row at a time into the TFRecord file, any advice or documentation would be great, I have been looking for some time at this problem and it seems there can only be ints,floats inputted into a TFRecord but what about a list/array of Integers?</p>\n<p>Quick Note, I am using PANDAS to create a dataframe of the CSV file</p>\n</blockquote>\n<p>Instead of reading csv file using Pandas, I would recommend you to use <code>tf.data.experimental.make_csv_dataset</code> defined <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/make_csv_dataset"" rel=""nofollow noreferrer"">here</a>. This will make this conversion process very faster than Pandas and will give you less compatibility issues to work with TF classes. If you use this function, then you will not need to read the csv file row by row but all at once using <code>map()</code> which uses <code>eager execution</code>. <a href=""https://www.tensorflow.org/beta/tutorials/load_data/tf_records#tfrecord_files_using_tfdata"" rel=""nofollow noreferrer"">This</a> is a good tutorial to get started.</p>\n<p>Accidentally edited wrong section of the post</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9888}"
97,40394910,"{'items': [{'owner': {'reputation': 748, 'user_id': 2197248}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': False, 'score': 7, 'creation_date': 1478154034, 'answer_id': 40395017, 'question_id': 40394910, 'body': ""<p>QueueRunner:\nWhen TensorFlow is reading the input, it needs to maintain multiple queues for it.  The queue serves all the workers that are responsible for executing the training step.  We use a queue because we want to have the inputs ready for the workers to operate on.  If you don't have a queue, you will be blocked on I/O and performance will degrade.</p>\n\n<p>Coordindator:\nThis is part of tf.train.Supervisor. It's necessary because you need a controller to maintain the set of threads (know when main thread should terminate, request stopping of sub-threads, etc). </p>\n\n<p>Hope this helps.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9888}"
98,65745053,"{'items': [{'owner': {'reputation': 83, 'user_id': 6455795}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1628741843, 'answer_id': 68751545, 'question_id': 65745053, 'body': '<p>Feel free to correct me if I\'m wrong. I think we have an easy way to do it.</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\nimport math\n\n# create padded zeros and change two valid entries.\ninputs = tf.constant([0., 0.5, 0.1, 0., 0.])\nmask = tf.not_equal(inputs, 0.)\nwith_masking = tf.keras.layers.Softmax()(inputs, mask=mask)\nwithout_masking = tf.keras.layers.Softmax()(inputs)\n\nprint(with_masking)\nprint(without_masking)\n</code></pre>\n<p>And output is,</p>\n<pre class=""lang-sh prettyprint-override""><code>tf.Tensor([0.         0.59868765 0.40131232 0.         0.        ], shape=(5,), dtype=float32)\ntf.Tensor([0.1737954  0.28654018 0.19207363 0.1737954  0.1737954 ], shape=(5,), dtype=float32)\n</code></pre>\n'}, {'owner': {'reputation': 18926, 'user_id': 4755954}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': True, 'score': 7, 'creation_date': 1610757131, 'answer_id': 65745327, 'question_id': 65745053, 'body': '<p>I think this is already explained well in the <a href=""https://github.com/tensorflow/tensorflow/issues/27010"" rel=""noreferrer"">Github issue</a> you have linked. Underlying problem is that irrespective of whether an array is masked or not, <code>softmax()</code> still operates on <code>0.0</code> values and returns a <code>non-zero</code> value as mathematically expected (<a href=""https://en.wikipedia.org/wiki/Softmax_function"" rel=""noreferrer"">link</a>).</p>\n<p>The only way to get a zero output from a <code>softmax()</code> is to pass a <strong>very small float value</strong>. If you set the masked values to the minimum possible machine limit for <code>float64</code>, <code>Softmax()</code> of this value will be zero.</p>\n<p>To get machine limit on float64 you need <code>tf.float64.min</code> which is equal to <code>-1.7976931348623157e+308</code>. More info about machine limits on this <a href=""https://stackoverflow.com/questions/65657086/how-can-i-express-this-custom-loss-function-in-tensorflow/65658222#65658222"">post</a>.</p>\n<p>Here is an implementation for your reference on <code>tf.boolean_mask</code> only, and the correct method of using <code>tf.where</code> for creating the mask and passing it to <code>softmax()</code> -</p>\n<pre><code>import tensorflow as tf\n\ninputs = np.zeros([1,5])\ninputs[0,1] = 0.5\ninputs[0,2] = 0.1\ninputs = tf.Variable(inputs)\n\n#Returns only the elements that are not masked (2,)\nwith_boolmask = tf.boolean_mask(inputs, inputs!=0)\nwith_boolmask = tf.keras.layers.Softmax()(with_boolmask)\n\n#Correct way to do it!\nmasked_inp = tf.where(inputs!=0, inputs, tf.float64.min) #&lt;----\nwith_where = tf.keras.layers.Softmax()(masked_inp)\n\nprint(\'BOOLEAN MASK (NOT EXPECTED)\')\nprint(with_boolmask)\n\nprint(\'\')\nprint(\'MASKED INPUT - \')\nprint(masked_inp)\nprint(\'\')\nprint(\'SOFTMAX OUTPUT\')\nprint(with_where)\n</code></pre>\n<pre><code>BOOLEAN MASK (NOT EXPECTED)\ntf.Tensor([0.59868765 0.40131232], shape=(2,), dtype=float32)\n\nMASKED INPUT - \ntf.Tensor(\n[[-1.79769313e+308  5.00000000e-001  1.00000000e-001 -1.79769313e+308\n  -1.79769313e+308]], shape=(1, 5), dtype=float64)\n\nSOFTMAX OUTPUT\ntf.Tensor([[0.         0.59868765 0.40131232 0.         0.        ]], shape=(1, 5), dtype=float32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9888}"
99,42133661,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1501759517, 'answer_id': 45482821, 'question_id': 42133661, 'body': ""<p>You are basically there, just need to update <code>state</code> with <code>curr_state</code>:</p>\n\n<pre><code>state_update = tf.assign(state, curr_state)\n</code></pre>\n\n<p>Then, make sure you either call <code>run</code> on <code>state_update</code> itself or an operation that has <code>state_update</code> as a dependency, or the assignment will not actually happen. For example:</p>\n\n<pre><code>with tf.control_dependencies([state_update]):\n    model_output = ...\n</code></pre>\n\n<p>As suggested in the comments, the typical case for RNNs is that you have a batch where the first dimension (0) is the number of sequences and the second dimension (1) is the maximum length of each sequence (if you pass <code>time_major=True</code> when you build the RNN these two are swapped). Ideally, in order to get good performance, you stack multiple sequences into one batch, and then split that batch time-wise. But that's all a different topic really.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9884}"
100,47665314,"{'items': [{'owner': {'reputation': 26, 'user_id': 7056204}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1527030515, 'answer_id': 50477640, 'question_id': 47665314, 'body': '<p>First of all, how come dataset is 204GB for only 2million images? I think your image is way too large. Try to resize the image. After all, you would probably need to resize it to 224 x 224 in the end.</p>\n\n<p>Second, try to reduce the size of your model. your model could be either too deep or not efficient enough.</p>\n\n<p>Third, try to parallelize your input reading process. It could the bottleneck.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9883}"
101,54929570,"{'items': [{'owner': {'reputation': 171, 'user_id': 6633679}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1551413661, 'answer_id': 54937852, 'question_id': 54929570, 'body': '<p>You used <code>tf.stop_gradient</code> correctly. However, TensorFlow stops the gradients at <code>inter</code> by removing all graph connections leading to <code>loss</code>. As a result, it will return <code>None</code> if you calculate <code>dLoss/dw2</code> using <code>tf.gradients</code> or <code>opt.compute_gradients</code> because <a href=""https://github.com/tensorflow/tensorflow/issues/783"" rel=""nofollow noreferrer"">[1]</a></p>\n\n<blockquote>\n  <p>Returning <code>None</code> makes it explicit that there is no graph connection between the two.</p>\n</blockquote>\n\n<p>That\'s how the <code>TypeError</code> appears (<code>dLoss/dw1</code> does not have this problem).\nMany users (including myself) thought this kind of gradient should be <code>0</code> instead of <code>None</code>, but TensorFlow engineers insist that this is intended behavior.</p>\n\n<p>Fortunately there\'re workarounds, try the codes below:</p>\n\n<pre><code>import tensorflow as tf\n\nw1 = tf.get_variable(name=\'w1\', initializer=tf.constant(10, dtype=tf.float32))\nw2 = tf.get_variable(name=\'w2\', initializer=tf.constant(3, dtype=tf.float32))\ninter = w1 * w2\ninter = tf.stop_gradient(inter)\nloss = w1*w1 - inter - 10\ndL_dW = tf.gradients(loss, [w1, w2])\n# Replace None gradient with 0 manully\ndL_dW = [tf.constant(0) if grad is None else grad for grad in dL_dW]\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    print(sess.run(dL_dW))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9883}"
102,45955241,"{'items': [{'owner': {'reputation': 17, 'user_id': 7141994}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1596818808, 'answer_id': 63306068, 'question_id': 45955241, 'body': '<p>Beware of not passing a tuple of tuples. That gives a very vague error of &quot;cannot convert value None to type Nonetype&quot;.</p>\n<p>So correct:\n<code>padded_shapes = ([None, None], [None])</code></p>\n<p>INCORRECT:\n<code>padded_shapes = ((None, None), (None))</code></p>\n'}, {'owner': {'reputation': 733, 'user_id': 2913884}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1583781963, 'answer_id': 60607130, 'question_id': 45955241, 'body': '<p>You may need to get help from the dataset output shapes: </p>\n\n<pre><code>padded_shapes = dataset.output_shapes\n</code></pre>\n'}, {'owner': {'reputation': 5525, 'user_id': 3831845}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1514850081, 'answer_id': 48054169, 'question_id': 45955241, 'body': '<p>If your current <code>Dataset</code> object contains a tuple, you can also to specify the shape of each padded element. </p>\n\n<p>For example, I have a <code>(same_sized_images, Labels)</code> dataset and each label has different length but same rank. </p>\n\n<pre><code>def process_label(resized_img, label):\n    # Perfrom some tensor transformations\n    # ......\n\n    return resized_img, label\n\ndataset = dataset.map(process_label)\ndataset = dataset.padded_batch(batch_size, \n                               padded_shapes=([None, None, 3], \n                                              [None, None]))  # my label has rank 2\n</code></pre>\n'}, {'owner': {'reputation': 156, 'user_id': 8350832}, 'down_vote_count': 0, 'up_vote_count': 14, 'is_accepted': True, 'score': 14, 'creation_date': 1504085529, 'answer_id': 45956801, 'question_id': 45955241, 'body': '<p>You need to pass a tuple of shapes.\nIn your case you should pass </p>\n\n<pre><code>dataset = dataset.padded_batch(4, padded_shapes=([vectorSize],[None]))\n</code></pre>\n\n<p>or try </p>\n\n<pre><code>dataset = dataset.padded_batch(4, padded_shapes=([None],[None]))\n</code></pre>\n\n<p>Check this <a href=""https://github.com/tensorflow/tensorflow/blob/d236d19f7753ae23f91d794701efa70ace1629da/tensorflow/python/util/nest.py#L427"" rel=""noreferrer"">code</a> for more details. I had to debug this method to figure out why it wasn\'t working for me.  </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9883}"
103,48048297,"{'items': [{'owner': {'reputation': 52739, 'user_id': 712995}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1514801555, 'answer_id': 48048786, 'question_id': 48048297, 'body': '<p>The reason to place the embedding matrix on a CPU is that <code>tf.nn.embedding_lookup</code> <a href=""https://github.com/tensorflow/tensorflow/issues/2502"" rel=""nofollow noreferrer"">isn\'t supported</a> on a GPU yet:</p>\n\n<blockquote>\n  <p>So, given the basic word2vec example being bound to CPU (#514), we can\n  see that <code>tf.nn.embedding_lookup</code> doesn\'t work on GPU. Therefore, ops\n  that use <code>embedding_lookup</code> internally doesn\'t support GPU either (for\n  example, <code>nce_loss</code>).</p>\n</blockquote>\n\n<p>This means that GPU placement of <code>embedding</code> variable will only lead to unnecessary transfer of data from the main memory to the GPU memory and vice versa. Hence, it would be more efficient to explicitly place the variable on a CPU.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9880}"
104,69195950,"{'items': [{'owner': {'reputation': 2316, 'user_id': 10349960}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1662635472, 'answer_id': 73648123, 'question_id': 69195950, 'body': '<p>This is how to use <code>tf.py_function</code> correctly to create a model that takes string as an input:</p>\n<pre class=""lang-py prettyprint-override""><code>model_name = &quot;dbmdz/bert-base-italian-xxl-cased&quot;\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nbert = TFBertModel.from_pretrained(model_name)\n\ndef build_model():\n    \n    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\'text\')\n\n    def encode_text(text):\n        inputs = [tf.compat.as_str(x) for x in text.numpy().tolist()]\n        tokenized = tokenizer(\n            inputs,\n            return_tensors=\'tf\',\n            add_special_tokens=True,\n            max_length=110,\n            padding=\'max_length\',\n            truncation=True)\n        return tokenized[\'input_ids\'], tokenized[\'attention_mask\']\n        \n    input_ids, attention_mask = tf.py_function(encode_text, inp=[text_input], Tout=[tf.int32, tf.int32])\n    \n    input_ids = tf.ensure_shape(input_ids, [None, 110])\n    attention_mask = tf.ensure_shape(attention_mask, [None, 110])\n    \n    outputs = bert(input_ids, attention_mask)\n    \n    net = outputs[\'last_hidden_state\']\n\n    # Some other layers, this part is not important\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(net)\n    x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, name=\'classifier\'))(x)\n\n    return tf.keras.Model(inputs=text_input, outputs=x)\n</code></pre>\n<p>I use <code>last_hidden_state</code> instead of <code>pooler_output</code>, that\'s where outputs for each token in the sequence are located. (See discussion <a href=""https://github.com/huggingface/transformers/issues/7540#issuecomment-704155218"" rel=""nofollow noreferrer"">here</a> on difference between <code>last_hidden_state</code> and <code>pooler_output</code>). We usually use <code>last_hidden_state</code> when doing token level classification (e.g. <em>named entity recognition</em>).</p>\n<p>To use <code>pooler_output</code> would be even simpler, e.g:</p>\n<pre class=""lang-py prettyprint-override""><code>net = outputs[\'pooler_output\']\nx = tf.keras.layers.Dense(1, name=\'classifier\')(net)\nreturn tf.keras.Model(inputs=text_input, outputs=x)\n</code></pre>\n<p><code>pooler_output</code> can be used in simpler classification problems (like irony detection), but of course it\'s still possible to use <code>last_hidden_state</code> to create more powerful models. (When you use <code>bert(input_ids_in, attention_mask=input_masks_in)[0]</code> in your solution, it actually returns <code>last_hidden_state</code>.)</p>\n<p>Making sure the model works:</p>\n<pre class=""lang-py prettyprint-override""><code>model = build_model()\nmy_phrase = &quot;Ciao, come va?&quot;\nmodel(tf.constant([my_phrase]))\n\n&gt;&gt;&gt; &lt;tf.Tensor: shape=(1, 110, 1), dtype=float32, numpy=...&gt;, \n</code></pre>\n<p>Making sure HuggingFace part of the model is trainable:</p>\n<pre class=""lang-py prettyprint-override""><code>model.summary(show_trainable=True)\n</code></pre>\n'}, {'owner': {'reputation': 23, 'user_id': 13963563}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1662622512, 'answer_id': 73645287, 'question_id': 69195950, 'body': '<p>Found this <a href=""https://stackoverflow.com/questions/71411065/use-sentence-transformers-inside-of-a-keras-model"">Use `sentence-transformers` inside of a keras model</a> and this amazing articles <a href=""https://www.philschmid.de/tensorflow-sentence-transformers"" rel=""nofollow noreferrer"">https://www.philschmid.de/tensorflow-sentence-transformers</a>, which explain you how to do what you\'re trying to achieve.</p>\n<p>The first one is using the py_function approach, the second uses tf.Model to wrap everything into model classes.</p>\n<p>Hope this helps anyone arriving here in the future.</p>\n'}, {'owner': {'reputation': 1632, 'user_id': 11579184}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1632667914, 'answer_id': 69336070, 'question_id': 69195950, 'body': '<p>For now I solved by taking the tokenization step out of the model:</p>\n<pre class=""lang-py prettyprint-override""><code>def tokenize(sentences, tokenizer):\n    input_ids, input_masks, input_segments = [],[],[]\n    for sentence in sentences:\n        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=128, pad_to_max_length=True, return_attention_mask=True, return_token_type_ids=True)\n        input_ids.append(inputs[\'input_ids\'])\n        input_masks.append(inputs[\'attention_mask\'])\n        input_segments.append(inputs[\'token_type_ids\'])        \n        \n    return np.asarray(input_ids, dtype=\'int32\'), np.asarray(input_masks, dtype=\'int32\'), np.asarray(input_segments, dtype=\'int32\')\n</code></pre>\n<p>The model takes two inputs which are the first two values returned by the tokenize funciton.</p>\n<pre class=""lang-py prettyprint-override""><code>def build_classifier_model():\n   input_ids_in = tf.keras.layers.Input(shape=(128,), name=\'input_token\', dtype=\'int32\')\n   input_masks_in = tf.keras.layers.Input(shape=(128,), name=\'masked_token\', dtype=\'int32\') \n\n   embedding_layer = bert(input_ids_in, attention_mask=input_masks_in)[0]\n...\n   model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)\n\n   for layer in model.layers[:3]:\n     layer.trainable = False\n   return model\n</code></pre>\n<p>I\'d still like to know if someone has a solution which integrates the tokenization step inside the model-building context so that an user of the model can simply feed phrases to it to get a prediction or to train the model.</p>\n'}, {'owner': {'reputation': 6287, 'user_id': 997378}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1632402409, 'answer_id': 69300653, 'question_id': 69195950, 'body': ""<p>Yeah, my first answer was wrong.</p>\n<p>The problem is that tensorflow has two types of tensors. Eager tensors (these have a value). And &quot;symbolic tensors&quot; or &quot;graph tensors&quot; that don't have a value, and are just used to build up a calculation.</p>\n<p>Your <code>tokenize_tensor</code> function expects an  eager tensor. Only eager tensors have a <code>.numpy()</code> method.</p>\n<pre><code>def tokenize_tensor(tensor):\n  t = tensor.numpy()\n  t = np.array([str(s, 'utf-8') for s in t])\n  return tokenizer(t.tolist(), return_tensors='tf', add_special_tokens=True, max_length=110, padding='max_length', truncation=True)\n</code></pre>\n<p>But keras <code>Input</code> is a symbolic tensor.</p>\n<pre><code>text_input = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='text')  \nencoder_inputs = tf.keras.layers.Lambda(tokenize_tensor, name='tokenize')(text_input)\n\n</code></pre>\n<p>To fix this, you can use <code>tf.py_function</code>. It works in graph mode, and will call the wrapped function with eager tensors when the graph is executed, instead of passing it the graph-tensors while the graph is being constructed.</p>\n<pre><code>def py_func_tokenize_tensor(tensor):\n  return tf.py_function(tokenize_tensor, [tensor])\n\n...\n\nencoder_inputs = tf.keras.layers.Lambda(py_func_tokenize_tensor, name='tokenize')(text_input)\n</code></pre>\n""}, {'owner': {'reputation': 6287, 'user_id': 997378}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1631968924, 'answer_id': 69234761, 'question_id': 69195950, 'body': '<p>It looks like this is not TensorFlow compatible.</p>\n<p><a href=""https://huggingface.co/dbmdz/bert-base-italian-xxl-cased#model-weights"" rel=""nofollow noreferrer"">https://huggingface.co/dbmdz/bert-base-italian-xxl-cased#model-weights</a></p>\n<pre><code>Currently only PyTorch-Transformers compatible weights are available. If you need access to TensorFlow checkpoints, please raise an issue!\n</code></pre>\n<p>But remember that some things are easier if you don\'t use keras\'s functional-model-api. That\'s what <code>got &lt;class \'keras.engine.keras_tensor.KerasTensor\'&gt;</code> is complaining about.</p>\n<p>Try passing a <code>tf.Tensor</code> to see if that works.\nWhat happens when you try:</p>\n<pre><code>text_input = tf.constant(\'text\')\n</code></pre>\n<p>Try writing your model as a subclass of model.</p>\n'}, {'owner': {'reputation': 1296, 'user_id': 3306097}, 'down_vote_count': 2, 'up_vote_count': 2, 'is_accepted': False, 'score': 0, 'creation_date': 1631822022, 'answer_id': 69214413, 'question_id': 69195950, 'body': ""<blockquote>\n<p>text input must of type str (single example), List[str] (batch or single pretokenized example) or List[List[str]] (batch of pretokenized examples).</p>\n</blockquote>\n<p>Solution to the above error:</p>\n<p>Just use <code>text_input = 'text'</code></p>\n<p>instead of</p>\n<p><code> text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')</code></p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9880}"
105,53424304,"{'items': [{'owner': {'reputation': 354, 'user_id': 11980301}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1668365914, 'answer_id': 74423865, 'question_id': 53424304, 'body': '<p>When comparing two tensors it is returning a <code>bool tensor</code> like this <code>&lt;tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])&gt;</code>  which is useless if you want to find an answer to the question &quot;Is this tensor equal to another tensor?&quot;. Adding <code>tf.reduce_all</code> to it will return a tensor like this <code>&lt;tf.Tensor: shape=(), dtype=bool, numpy=True&gt;</code> and now it should work.</p>\n<p><code>dataset = dataset.filter(lambda inputs, label: tf.reduce_all(tf.equal(label,15)))</code></p>\n'}, {'owner': {'reputation': 670, 'user_id': 5811400}, 'down_vote_count': 2, 'up_vote_count': 1, 'is_accepted': False, 'score': -1, 'creation_date': 1604070951, 'answer_id': 64611084, 'question_id': 53424304, 'body': '<p>I faced the same problem in a different situation, and it turns out, as suggested in the comments, that the issue was caused by batching before filtering.</p>\n<p>You can reproduce this using this example:</p>\n<pre><code>import pprint\nimport tensorflow as tf\n\ndataset = tf.data.Dataset.zip((\n    tf.data.Dataset.range(0, 5),\n    tf.data.Dataset.from_tensor_slices([0, 10, 15, 20, 15])\n))\npprint.pprint(list(dataset.as_numpy_iterator()))\n# [(0, 0), (1, 10), (2, 15), (3, 20), (4, 15)]\n\nfiltered = dataset.filter(lambda x, y: y == 15)\npprint.pprint(list(filtered.as_numpy_iterator()))\n# [(2, 15), (4, 15)]\n\nBATCH_SIZE = 2\nbatched = dataset.batch(BATCH_SIZE)\nbatched_filtered = batched.filter(lambda x, y: y == 15)\n# ValueError: `predicate` return type must be convertible to a scalar boolean tensor. Was [...]\n</code></pre>\n<p>One simple solution for this problem is to <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#unbatch"" rel=""nofollow noreferrer"">unbatch</a> your dataset, then filter, and finally batch again:</p>\n<pre><code>BATCH_SIZE = 2\nbatched = dataset.batch(BATCH_SIZE)\nbatched_filtered = batched.unbatch().filter(lambda x, y: y == 15).batch(BATCH_SIZE)\npprint.pprint(list(batched_filtered.as_numpy_iterator()))\n# [(array([1, 2]), array([15, 15], dtype=int32)),\n#  (array([4]), array([15], dtype=int32))]\n</code></pre>\n<p>If you don\'t know or don\'t want to keep track of the value of <code>BATCH_SIZE</code>, you can adapt <a href=""https://stackoverflow.com/a/64610658/5811400"">this solution</a> to calculate the batch size on demand.</p>\n<p>I ended up combining those two solutions like this:</p>\n<pre><code>def calculate_batch_size(dataset):\n    return next(iter(dataset))[0].shape[0]\n\ndef filter_batch(dataset, pred_fn):\n    batch_size = calculate_batch_size(dataset)\n    return dataset.unbatch().filter(pred_fn).batch(batch_size)\n\nBATCH_SIZE = 2\nbatched = dataset.batch(BATCH_SIZE)\nbatched_filtered = filter_batch(batched, lambda x, y: y == 15)\npprint.pprint(list(batched_filtered.as_numpy_iterator()))\n# [(array([1, 2]), array([15, 15], dtype=int32)),\n#  (array([4]), array([15], dtype=int32))]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9880}"
106,36223157,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 21, 'is_accepted': True, 'score': 21, 'creation_date': 1458922003, 'answer_id': 36223553, 'question_id': 36223157, 'body': '<p>If you have the weights and biases in a NumPy array, it should be easy to connect them into your TensorFlow network:</p>\n\n<pre><code>weights_1_array = ...  # ndarray of weights for layer 1\nbiases_1_array = ...  # ndarray of biases for layer 1\n\nconv_kernel_1 = tf.nn.conv2d(input, weights_1_array, [1, 4, 4, 1], padding=\'SAME\')\nbias_layer_1 = tf.nn.bias_add(conv_kernel_1, biases_1_array)\n</code></pre>\n\n<p>Note that you must ensure that <code>weights_1_array</code> and <code>biases_1_array</code> are in the correct data format. See the documentation for <a href=""https://www.tensorflow.org/versions/master/api_docs/python/nn.html#conv2d"" rel=""noreferrer""><code>tf.nn.conv2d()</code></a> for an explanation of the required filter shape.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9880}"
107,54509752,"{'items': [{'owner': {'reputation': 1081, 'user_id': 7906266}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1549250893, 'answer_id': 54509824, 'question_id': 54509752, 'body': '<p>Here is the translation, which prints exactly the same to standard output.</p>\n\n<pre><code>#!/usr/bin/env python3\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport shutil\n\nif not os.path.exists(\'example\'):\n    shutil.rmTree(\'example\');\n    os.mkdir(\'example\');\n\nbatch_sz = 10; epochs = 2; buffer_sz = 30; samples = 0;\nfor i in range(50):\n    _x = np.random.randint(0, 256, (10, 10, 3), np.uint8);\n    plt.imsave(""example/image_{}.jpg"".format(i), _x);\nfname_data = tf.data.Dataset.list_files(\'example/*.jpg\')\\\n        .shuffle(buffer_sz).repeat(epochs);\nimg_batch = fname_data.map(lambda fname: \\\n        tf.image.decode_image(tf.read_file(fname),3))\\\n        .batch(batch_sz).make_initializable_iterator();\n\nwith tf.Session() as sess:\n    sess.run([img_batch.initializer,\n        tf.global_variables_initializer(),\n        tf.local_variables_initializer()]);\n    next_element = img_batch.get_next();\n    try:\n        while True:\n            sess.run(next_element);\n            samples += batch_sz\n            print(samples, ""samples have been seen"");\n    except tf.errors.OutOfRangeError:\n        pass;\n    print(\'Done training -- epoch limit reached\');\n</code></pre>\n\n<p>The main issues are: </p>\n\n<ol>\n<li>Use of <code>tf.data.Dataset.list_files()</code> to load filenames as a dataset, instead of generating a queue with deprecated <code>tf.tran.string_input_producer()</code> for consuming filenames.</li>\n<li>Use of iterators to process datasets, which require initialization too, instead of sequent reads to a deprecated <code>tf.WholeFileReader</code>, batched with a deprecated <code>tf.train.batch()</code> function.</li>\n<li>A Coordinator is not needed because threads for queues (<code>tf.train.QueueRunners</code> created by <code>tf.train.string_input_producer()</code>) are not used anymore, but it should be checked when dataset iterator has ended.</li>\n</ol>\n\n<p>I hope this will be useful for many, as was for me after achieving it.</p>\n\n<p>Ref:</p>\n\n<ul>\n<li>Importing data: <a href=""https://www.tensorflow.org/guide/datasets"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/datasets</a></li>\n<li>Medium Datasets Tutorial: <a href=""https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428"" rel=""nofollow noreferrer"">https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428</a></li>\n</ul>\n\n<hr>\n\n<p><strong>BONUS:</strong> Dataset + Estimator</p>\n\n<pre><code>#!/usr/bin/env python3\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport shutil\n\nif not os.path.exists(\'example\'):\n    shutil.rmTree(\'example\');\n    os.mkdir(\'example\');\n\nbatch_sz = 10; epochs = 2; buffer_sz = 10000; samples = 0;\nfor i in range(50):\n    _x = np.random.randint(0, 256, (10, 10, 3), np.uint8);\n    plt.imsave(""example/image_{}.jpg"".format(i), _x);\ndef model(features,labels,mode,params):\n    return tf.estimator.EstimatorSpec(\n            tf.estimator.ModeKeys.PREDICT,{\'images\': features});\nestimator = tf.estimator.Estimator(model,\'model_dir\',params={});\ndef input_dataset():\n    return tf.data.Dataset.list_files(\'example/*.jpg\')\\\n        .shuffle(buffer_sz).repeat(epochs).map(lambda fname: \\\n            tf.image.decode_image(tf.read_file(fname),3))\\\n        .batch(batch_sz);\n\npredictions = estimator.predict(input_dataset,\n        yield_single_examples=False);\nfor p_dict in predictions:\n    samples += batch_sz;\n    print(samples, ""samples have been seen"");\nprint(\'Done training -- epoch limit reached\');\n</code></pre>\n\n<p>The main issues are: </p>\n\n<ol>\n<li>Definition of a <code>model</code> function for a custom <code>estimator</code> for processing images, which in this case does nothing because we are just passing them by.</li>\n<li>Definition of an <code>input_dataset</code> function for retriving the dataset to be used (for prediction in this case) by the estimator.</li>\n<li>Use of <code>tf.estimator.Estimator.predict()</code> on estimator instead of using <code>tf.Session()</code> directly, plus <code>yield_single_example=False</code> to retrieve batch of elements instead of single in predictions list of dictionaries.</li>\n</ol>\n\n<p>It seems to me like more modular and reusable code.</p>\n\n<p>Ref:</p>\n\n<ul>\n<li>Datasets for estimators: <a href=""https://www.tensorflow.org/guide/datasets_for_estimators"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/datasets_for_estimators</a>, </li>\n<li>Custom estimators: <a href=""https://www.tensorflow.org/guide/custom_estimators"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/custom_estimators</a></li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9880}"
108,58699961,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9875}"
109,70381758,"{'items': [{'owner': {'reputation': 955, 'user_id': 15948240}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1656394337, 'answer_id': 72781170, 'question_id': 70381758, 'body': '<p>There is also <code>torch.diagonal</code>, see <a href=""https://discuss.pytorch.org/t/matrix-diagonal-part/47446/2"" rel=""nofollow noreferrer"">https://discuss.pytorch.org/t/matrix-diagonal-part/47446/2</a> :</p>\n<pre><code>import torch \nimport tensorflow as tf\nimport numpy as np\nr = np.array([[[0.1000, 0.0000, 0.0000, 0.0000],\n               [0.0000, 0.0000, 0.0000, 0.0000],\n               [0.0000, 0.0000, 0.0000, 0.0000],\n               [0.1000, 0.1000, 0.1000, 0.1000]],\n\n              [[0.0000, 0.0000, 0.0000, 0.0000],\n               [0.3000, 0.2000, 0.2000, 0.2000],\n               [0.0400, 0.5000, 0.5000, 0.5000],\n               [0.0000, 0.0000, 0.0000, 0.0000]]])\n\ntf.linalg.diag_part(r)\n#returns\n#&lt;tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n#array([[0.1, 0. , 0. , 0.1],\n#       [0. , 0.2, 0.5, 0. ]], dtype=float32)&gt;\n\n\ntorch.diagonal(torch.tensor(r), dim1=-2, dim2=-1)\n\n#returns\n#tensor([[0.1000, 0.0000, 0.0000, 0.1000],\n#        [0.0000, 0.2000, 0.5000, 0.0000]])\n</code></pre>\n'}, {'owner': {'reputation': 35511, 'user_id': 6331369}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1639671700, 'answer_id': 70382365, 'question_id': 70381758, 'body': '<p>I don\'t believe there\'s a direct equivalent. However, you can get away using <a href=""https://pytorch.org/docs/stable/generated/torch.diag.html"" rel=""nofollow noreferrer""><code>torch.diag</code></a>:</p>\n<pre><code>&gt;&gt;&gt; x = torch.tensor([[1, 2, 3, 4],\n                      [5, 6, 7, 8]])\n\n&gt;&gt;&gt; torch.diag(x.flatten()).reshape(-1, 4, 2, 4).sum(-2)\ntensor([[[1, 0, 0, 0],\n         [0, 2, 0, 0],\n         [0, 0, 3, 0],\n         [0, 0, 0, 4]],\n\n        [[5, 0, 0, 0],\n         [0, 6, 0, 0],\n         [0, 0, 7, 0],\n         [0, 0, 0, 8]]])\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9875}"
110,42569921,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1488570041, 'answer_id': 42587133, 'question_id': 42569921, 'body': '<p>The problem here seems to be that your graph is emptyi.e. it does not contain any variables. You create a new graph on the line <code>with tf.Session(graph=tf.Graph()):</code>, and none of the following lines creates a <code>tf.Variable</code> object.</p>\n\n<p>To restore a pre-trained TensorFlow model, you need to do one of three things:</p>\n\n<ol>\n<li>Rebuild the model graph, by executing the same Python graph building code that was used to train the model in the first place.</li>\n<li>Load a ""MetaGraph"" that contains information about how to reconstruct the graph structure and model variables. See <a href=""https://www.tensorflow.org/programmers_guide/meta_graph"" rel=""nofollow noreferrer"">this tutorial</a> for more details on how to create and use a MetaGraph. MetaGraphs are often created alongside checkpoint files, and typically have the extension <code>.meta</code>.</li>\n<li>Load a ""SavedModel"", which contains a ""MetaGraph"". See the documentation <a href=""https://github.com/tensorflow/tensorflow/blob/1f09d0c1ee7648288b3454d64e72e8760b9acc9c/tensorflow/python/saved_model/README.md"" rel=""nofollow noreferrer"">here</a> for more details.</li>\n</ol>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9875}"
111,57155780,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9875}"
112,55916743,"{'items': [{'owner': {'reputation': 2669, 'user_id': 262432}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1556615597, 'answer_id': 55917615, 'question_id': 55916743, 'body': '<p><code>tf.GradientTape.gradients</code> can only differentiate wrt to a watched tensor. Variables are automatically watched on first access. In order to differentiate wrt an arbitrary tensor, you have to explicitly <code>watch</code> it:</p>\n\n<pre><code>&gt;&gt;&gt; x = tf.constant([4.0])\n&gt;&gt;&gt; y = tf.constant([2.0])\n&gt;&gt;&gt; with tf.GradientTape() as tape:\n...     tape.watch([x, y])\n...     z = x * y\n...     \n&gt;&gt;&gt; tape.gradient(z, [x, y])\n[&lt;tf.Tensor: id=9, shape=(1,), dtype=float32, numpy=array([ 2.], dtype=float32)&gt;, \n &lt;tf.Tensor: id=10, shape=(1,), dtype=float32, numpy=array([ 4.], dtype=float32)&gt;]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9875}"
113,48101576,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1517962629, 'answer_id': 48654046, 'question_id': 48101576, 'body': '<p>Encoding each frame as a separate feature makes it difficult to select frames dynamically, because the signature of <code>tf.parse_example()</code> (and <code>tf.parse_single_example()</code>) requires that the set of parsed feature names be fixed at graph construction time. However, you could try encoding the frames as a <em>single</em> feature that contains a list of JPEG-encoded strings:</p>\n\n<pre><code>def _bytes_list_feature(values):\n    """"""Wrapper for inserting bytes features into Example proto.""""""\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=values))\n\nwith tf.python_io.TFRecordWriter(output_file) as writer:\n\n  # Read and resize all video frames, np.uint8 of size [N,H,W,3]\n  frames = ... \n\n  features = {}\n  features[\'num_frames\']  = _int64_feature(frames.shape[0])\n  features[\'height\']      = _int64_feature(frames.shape[1])\n  features[\'width\']       = _int64_feature(frames.shape[2])\n  features[\'channels\']    = _int64_feature(frames.shape[3])\n  features[\'class_label\'] = _int64_feature(example[\'class_id\'])\n  features[\'class_text\']  = _bytes_feature(tf.compat.as_bytes(example[\'class_label\']))\n  features[\'filename\']    = _bytes_feature(tf.compat.as_bytes(example[\'video_id\']))\n\n  # Compress the frames using JPG and store in as a list of strings in \'frames\'\n  encoded_frames = [tf.compat.as_bytes(cv2.imencode("".jpg"", frame)[1].tobytes())\n                    for frame in frames]\n  features[\'frames\'] = _bytes_list_feature(encoded_frames)\n\n  tfrecord_example = tf.train.Example(features=tf.train.Features(feature=features))\n  writer.write(tfrecord_example.SerializeToString())\n</code></pre>\n\n<p>Once you have done this, it will be possible to slice the <code>frames</code> feature dynamically, using a modified version of <a href=""https://gist.github.com/tomrunia/7ef5d40639f2ae41fb71d3352a701e4a"" rel=""nofollow noreferrer"">your parsing code</a>:</p>\n\n<pre><code>def decode(serialized_example, sess):\n  # Prepare feature list; read encoded JPG images as bytes\n  features = dict()\n  features[""class_label""] = tf.FixedLenFeature((), tf.int64)\n  features[""frames""] = tf.VarLenFeature(tf.string)\n  features[""num_frames""] = tf.FixedLenFeature((), tf.int64)\n\n  # Parse into tensors\n  parsed_features = tf.parse_single_example(serialized_example, features)\n\n  # Randomly sample offset from the valid range.\n  random_offset = tf.random_uniform(\n      shape=(), minval=0,\n      maxval=parsed_features[""num_frames""] - SEQ_NUM_FRAMES, dtype=tf.int64)\n\n  offsets = tf.range(random_offset, random_offset + SEQ_NUM_FRAMES)\n\n  # Decode the encoded JPG images\n  images = tf.map_fn(lambda i: tf.image.decode_jpeg(parsed_features[""frames""].values[i]),\n                     offsets)\n\n  label  = tf.cast(parsed_features[""class_label""], tf.int64)\n\n  return images, label\n</code></pre>\n\n<p>(Note that I haven\'t been able to run your code, so there may be some small errors, but hopefully it is enough to get you started.)</p>\n'}, {'owner': {'reputation': 10590, 'user_id': 7353970}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1518471957, 'answer_id': 48756030, 'question_id': 48101576, 'body': '<p>Since you\'re using very similar dependencies, I suggest to take a look at the following Python package as it addresses your exact problem setting:</p>\n\n<pre><code>pip install video2tfrecord\n</code></pre>\n\n<p>or refer to <a href=""https://github.com/ferreirafabio/video2tfrecord"" rel=""noreferrer"">https://github.com/ferreirafabio/video2tfrecord</a>.\nIt should also be adaptable enough to use <code>tf.data.Dataset</code>.</p>\n\n<p>disclaimer: I am one of the authors of the package.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9870}"
114,70363340,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1639569993, 'answer_id': 70363424, 'question_id': 70363340, 'body': '<p>It is literally creating a new tensor by repeating the input across the third dimension 5 times resulting in 5 x 5 rows x 5 columns:</p>\n<pre class=""lang-py prettyprint-override""><code>x = tf.random.uniform(((1,1,5,5)))\nx = x[:,:,tf.newaxis]\nprint(\'Before tile --&gt;\', x)\nx = tf.tile(x, (1, 1, 5, 1, 1))\nprint(\'After tile --&gt;\', x)\n</code></pre>\n<pre><code>Before tile --&gt; tf.Tensor(\n[[[[[0.86033905 0.91900826 0.39433706 0.9772172  0.32149637]\n    [0.01335323 0.03711665 0.664286   0.11703181 0.7997707 ]\n    [0.7063314  0.01817334 0.685941   0.6407242  0.59115565]\n    [0.819417   0.46511436 0.00940382 0.12464321 0.9256897 ]\n    [0.45731974 0.8999344  0.3199395  0.41329288 0.05623758]]]]], shape=(1, 1, 1, 5, 5), dtype=float32)\nAfter tile --&gt; tf.Tensor(\n[[[[[0.86033905 0.91900826 0.39433706 0.9772172  0.32149637]\n    [0.01335323 0.03711665 0.664286   0.11703181 0.7997707 ]\n    [0.7063314  0.01817334 0.685941   0.6407242  0.59115565]\n    [0.819417   0.46511436 0.00940382 0.12464321 0.9256897 ]\n    [0.45731974 0.8999344  0.3199395  0.41329288 0.05623758]]\n\n   [[0.86033905 0.91900826 0.39433706 0.9772172  0.32149637]\n    [0.01335323 0.03711665 0.664286   0.11703181 0.7997707 ]\n    [0.7063314  0.01817334 0.685941   0.6407242  0.59115565]\n    [0.819417   0.46511436 0.00940382 0.12464321 0.9256897 ]\n    [0.45731974 0.8999344  0.3199395  0.41329288 0.05623758]]\n\n   [[0.86033905 0.91900826 0.39433706 0.9772172  0.32149637]\n    [0.01335323 0.03711665 0.664286   0.11703181 0.7997707 ]\n    [0.7063314  0.01817334 0.685941   0.6407242  0.59115565]\n    [0.819417   0.46511436 0.00940382 0.12464321 0.9256897 ]\n    [0.45731974 0.8999344  0.3199395  0.41329288 0.05623758]]\n\n   [[0.86033905 0.91900826 0.39433706 0.9772172  0.32149637]\n    [0.01335323 0.03711665 0.664286   0.11703181 0.7997707 ]\n    [0.7063314  0.01817334 0.685941   0.6407242  0.59115565]\n    [0.819417   0.46511436 0.00940382 0.12464321 0.9256897 ]\n    [0.45731974 0.8999344  0.3199395  0.41329288 0.05623758]]\n\n   [[0.86033905 0.91900826 0.39433706 0.9772172  0.32149637]\n    [0.01335323 0.03711665 0.664286   0.11703181 0.7997707 ]\n    [0.7063314  0.01817334 0.685941   0.6407242  0.59115565]\n    [0.819417   0.46511436 0.00940382 0.12464321 0.9256897 ]\n    [0.45731974 0.8999344  0.3199395  0.41329288 0.05623758]]]]], shape=(1, 1, 5, 5, 5), dtype=float32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9870}"
115,45217998,"{'items': [{'owner': {'reputation': 52739, 'user_id': 712995}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1510412596, 'answer_id': 47239309, 'question_id': 45217998, 'body': '<p>Your guess is correct, the <code>weights</code> parameter in <a href=""https://www.tensorflow.org/api_docs/python/tf/losses/softmax_cross_entropy"" rel=""nofollow noreferrer""><code>tf.losses.softmax_cross_entropy</code></a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy"" rel=""nofollow noreferrer""><code>tf.losses.sparse_softmax_cross_entropy</code></a> means the weights across the <em>batch</em>, i.e. make some input <em>examples</em> more important than others. There\'s no out-of-the-box way to weight the loss across <em>classes</em>.</p>\n\n<p>What you can do as a workaround, is specially pick the weights according to the current labels and use them as batch weights. This means that the weights vector will be different for each batch, but will try to make occasional rare classes more important. See the sample code in <a href=""https://stackoverflow.com/q/44560549/712995"">this question</a>.</p>\n\n<p>Note: since the batches not necessarily contain uniform class distribution, this trick works poorly with small batch size and gets better with the larger batch size. When the batch size is 1, it\'s completely useless. So make the batches as big as possible.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9870}"
116,53053649,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9870}"
117,66144466,"{'items': [{'owner': {'reputation': 43, 'user_id': 10263591}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1613084062, 'answer_id': 66164168, 'question_id': 66144466, 'body': '<p>The right documentation for defining the Signatures can be found here.</p>\n<p><a href=""https://www.tensorflow.org/tfx/serving/serving_basic?hl=en"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tfx/serving/serving_basic?hl=en</a></p>\n<pre><code>builder.add_meta_graph_and_variables(\n    sess, [tf.compat.v1.saved_model.tag_constants.SERVING],\n    signature_def_map={\n        \'predict_images\':\n            prediction_signature,\n        tf.compat.v1.saved_model.signature_constants\n            .DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n            classification_signature,\n    },\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9870}"
118,42754259,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9865}"
119,56905939,"{'items': [{'owner': {'reputation': 303, 'user_id': 7590649}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1562342287, 'answer_id': 56906199, 'question_id': 56905939, 'body': '<p>One way to do this is simply load those 2 files into variables and use <code>tf.data.Dataset.from_tensor_slices</code> (see <a href=""https://www.tensorflow.org/guide/datasets#consuming_numpy_arrays"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/datasets#consuming_numpy_arrays</a>)</p>\n\n<p>Another way is to map the file path into dataset and do data pipelining to read and return it as (img, label) \nHere is the sample code from <a href=""https://www.tensorflow.org/tutorials/load_data/images"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/load_data/images</a></p>\n\n<pre class=""lang-py prettyprint-override""><code>def load_and_preprocess_image(path):\n  image = tf.read_file(path)\n  return preprocess_image(image)\n\nds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n\n# The tuples are unpacked into the positional arguments of the mapped function\ndef load_and_preprocess_from_path_label(path, label):\n  return load_and_preprocess_image(path), label\n\nimage_label_ds = ds.map(load_and_preprocess_from_path_label)\n</code></pre>\n\n<p>Myself would prefer the second way if the data is too big for the memory, but the first one is handy for small data</p>\n'}, {'owner': {'reputation': 311, 'user_id': 11744541}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1562342151, 'answer_id': 56906170, 'question_id': 56905939, 'body': '<p>This tutorial should be a good place to start: <a href=""https://www.tensorflow.org/tutorials/load_data/images"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/load_data/images</a></p>\n\n<p>As explained in the link, load in your image paths and their labels. Create a dataset with from_tensor_slices of the paths and their labels, then map the paths (which are strings) with a preprocessing function to image Tensors.</p>\n\n<pre><code>ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n\n# The tuples are unpacked into the positional arguments of the mapped function\ndef load_and_preprocess_from_path_label(path, label):\n  return load_and_preprocess_image(path), label\n\nimage_label_ds = ds.map(load_and_preprocess_from_path_label)\nimage_label_ds\n</code></pre>\n\n<p>Follow the tutorial for step-by-step details. If your images are saved as numpy arrays rather than jpg files, you\'ll have to change some of the preprocessing but the overall flow should be very similar.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9865}"
120,63598808,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9863}"
121,54155481,"{'items': [{'owner': {'reputation': 1837, 'user_id': 9277245}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1547317926, 'answer_id': 54162664, 'question_id': 54155481, 'body': '<p>In StandardScaler, we do feature-wise normalization. In case of images, we can do pixel-wise normalization, by considering the entire data-distribution, but that is not helpful, because of variability in the distribution. So <strong>per_image_standardization</strong> is preferred, which normalize the entire image to mean zero and std 1. <strong>It also make learning fast.</strong></p>\n\n<p>Further <a href=""https://stats.stackexchange.com/questions/211436/why-normalize-images-by-subtracting-datasets-image-mean-instead-of-the-current"">this-link</a> can be helpful. There is <a href=""https://becominghuman.ai/image-data-pre-processing-for-neural-networks-498289068258"" rel=""nofollow noreferrer"">another-link</a>, where author has explained this by taking an example.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9863}"
122,49959130,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9861}"
123,55627995,"{'items': [{'owner': {'reputation': 14062, 'user_id': 6117017}, 'down_vote_count': 0, 'up_vote_count': 16, 'is_accepted': False, 'score': 16, 'creation_date': 1570172435, 'answer_id': 58231402, 'question_id': 55627995, 'body': ""<p>Alongside custom defined Python generators, you can wrap the <code>ImageDataGenerator</code> from Keras inside <code>tf.data</code>.</p>\n<p><code>TensorFlow &gt;= 2.10</code> (it's all about <code>tf.data.Dataset()</code>)</p>\n<pre><code>   # Treat it as a normal tf.data.Dataset()\n   dataset = tf.keras.utils.image_dataset_from_directory (...)\n   # Or any other augmentation\n   normalization_layer = tf.keras.layers.Rescaling(1./255)\n   normalized_dataset = dataset.map(lambda x, y: (normalization_layer(x), y))\n</code></pre>\n<p><code>TensorFlow &lt;= 2.9</code> (deprecation warnings may already appear in those)\nThe following snippets are taken from the TensorFlow 2.0 documentation.</p>\n<pre><code>img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=20)\nds = tf.data.Dataset.from_generator(\n    img_gen.flow_from_directory, args=[flowers], \n    output_types=(tf.float32, tf.float32), \n    output_shapes = ([32,256,256,3],[32,5])\n)\n</code></pre>\n<p>Therefore, one can still use the typical Keras <code>ImageDataGenerator</code>, you just need to wrap it into a <code>tf.data.Dataset</code> like above.</p>\n""}, {'owner': {'reputation': 445, 'user_id': 5302813}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1667623762, 'answer_id': 74325178, 'question_id': 55627995, 'body': '<h3>Update 2022</h3>\n<p>On visiting the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"" rel=""nofollow noreferrer""><code>ImageDataGenerator</code> documentation</a>, there is now a deprecation message that says the following:</p>\n<blockquote>\n<p><strong>Deprecated:</strong> <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"" rel=""nofollow noreferrer""><code>tf.keras.preprocessing.image.ImageDataGenerator</code></a> is not recommended for new code. Prefer loading images with <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory"" rel=""nofollow noreferrer""><code>tf.keras.utils.image_dataset_from_directory</code></a> and transforming the output <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer""><code>tf.data.Dataset</code></a> with preprocessing layers. For more information, see the tutorials for <a href=""https://www.tensorflow.org/tutorials/load_data/images"" rel=""nofollow noreferrer"">loading images</a> and <a href=""https://www.tensorflow.org/tutorials/images/data_augmentation"" rel=""nofollow noreferrer"">augmenting images</a>, as well as the <a href=""https://www.tensorflow.org/guide/keras/preprocessing_layers"" rel=""nofollow noreferrer"">preprocessing layer guide</a>.</p>\n</blockquote>\n'}, {'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 10, 'is_accepted': False, 'score': 10, 'creation_date': 1554972237, 'answer_id': 55628241, 'question_id': 55627995, 'body': '<p>Since its release, TensorFlow Dataset API is a default recommended way to construct input pipeline for any model build on TensorFlow backend, both Keras and low-level TensorFlow. \nIn later versions of TF 1.xx it can be directly used in <code>tf.keras.Model.fit</code> method as </p>\n\n<pre><code>model.fit(dataset, epochs)\n</code></pre>\n\n<p>It\'s good both for rapid prototyping,</p>\n\n<pre><code>dataset = tf.data.Dataset.from_tensor_slices((train, test))\ndataset = dataset.shuffle().repeat().batch()\n</code></pre>\n\n<p>And for building complex, high performance ETL pipelines \n4. Upgrade your data input pipelines, more on this here <a href=""https://www.tensorflow.org/guide/performance/datasets"" rel=""noreferrer"">https://www.tensorflow.org/guide/performance/datasets</a></p>\n\n<p>As per official docs, in TF 2.0 it\'ll also be the default way to input data to the model. <a href=""https://www.tensorflow.org/alpha/guide/migration_guide"" rel=""noreferrer"">https://www.tensorflow.org/alpha/guide/migration_guide</a></p>\n\n<p>As by default, upcoming TensorFlow version will be executed eagerly, dataset object will become iterable and will be even easier to use. </p>\n'}, {'owner': {'reputation': 143, 'user_id': 9457030}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1554973941, 'answer_id': 55628807, 'question_id': 55627995, 'body': ""<p>For me, I prefer to build a generator with <code>yield</code>:</p>\n\n<pre><code>def generator(batch_size=4,path):\nimgs=glob(path+'*.jpg')\nwhile True:\n    batch=[]\n    for i in range(batch_size):\n        idx=np.random.randint(0,len(imgs))\n        img=cv.resize(cv.imread(imgs[idx]),(256,256))/255\n        batch.append(img)\n    batch=np.array(batch)\n    yield batch\n</code></pre>\n\n<p>Then create the generator and input it to <code>model.fit_generator</code>, it will work. </p>\n\n<p>You can choose data randomly like this or use some recurrent methods. </p>\n\n<p>Though the code is rough, it is easy to change so that it can generate complex batch.</p>\n\n<p>Note that this is a way to generate for TF 1.X with Keras2 and not with TensorFlow 2.0. </p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9861}"
124,49711324,"{'items': [{'owner': {'reputation': 6711, 'user_id': 6708503}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1523172959, 'answer_id': 49715567, 'question_id': 49711324, 'body': '<p>I believe you are mistaken. <strong>All</strong> the summary methods in <code>tf.contrib.summary</code> are supported for both eager execution and graph construction. For example, something like this seems to work:</p>\n\n<pre><code>import tensorflow as tf\n\ntf.enable_eager_execution()\n\nwith tf.contrib.summary.create_file_writer(\'/tmp/logdir\').as_default(), tf.contrib.summary.always_record_summaries():\n  for step in range(3):\n    tf.contrib.summary.generic(""generic"", tf.pow(10., step), step=step)\n    tf.contrib.summary.histogram(""histogram"", tf.random_uniform([10]), step=step)\n  tf.contrib.summary.flush()\n</code></pre>\n\n<p>With <code>tensorboard --logdir /tmp/logdir --inspect</code> you can see that 3 events each are written, and of course the histogram can be visualized in <code>tensorboard</code>.</p>\n\n<p>Hope that helps.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9861}"
125,38641887,"{'items': [{'owner': {'reputation': 853, 'user_id': 3301620}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1508194961, 'answer_id': 46780232, 'question_id': 38641887, 'body': '<h2>Saving Graph in Tensorflow:</h2>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\n# Create some placeholder variables\nx_pl = tf.placeholder(..., name=""x"")\ny_pl = tf.placeholder(..., name=""y"")\n\n# Add some operation to the Graph\nadd_op = tf.add(x, y)\n\nwith tf.Session() as sess:\n\n    # Add variable initializer\n    init = tf.global_variables_initializer()\n\n    # Add ops to save variables to checkpoints\n    # Unless var_list is specified Saver will save ALL named variables\n    # in Graph\n    # Optionally set maximum of 3 latest models to be saved\n    saver = tf.train.Saver(max_to_keep=3)\n\n    # Run variable initializer\n    sess.run(init)\n\n    for i in range(no_steps):\n        # Feed placeholders with some data and run operation\n        sess.run(add_op, feed_dict={x_pl: i+1, y_pl: i+5})\n        saver.save(sess, ""path/to/checkpoint/model.ckpt"", global_step=i)\n</code></pre>\n\n<p>This will save the following files:</p>\n\n<p><strong>1) Meta Graph</strong></p>\n\n<p><code>.meta</code> file:</p>\n\n<ul>\n<li><p>MetaGraphDef protocol buffer representation of MetaGraph which saves the complete Tf Graph structure i.e. the GraphDef that describes the dataflow and all metadata associated with it e.g. all variables, operations, collections, etc.</p></li>\n<li><p>importing the graph structure will recreate the Graph and all its variables, then the corresponding values for these variables can be restored from the checkpoint file </p></li>\n<li><p>if you don\'t want to restore the Graph however you can reconstruct all of the information in the MetaGraphDef by re-executing the Python code that builds the model n.b. you must recreate the EXACT SAME variables first before restoring their values from the checkpoint </p></li>\n<li><p>since Meta Graph file is not always needed, you can switch off writing the file in <code>saver.save</code> using <code>write_meta_graph=False</code></p></li>\n</ul>\n\n<p><strong>2) Checkpoint files</strong></p>\n\n<p><code>.data</code> file:</p>\n\n<ul>\n<li>binary file containing VALUES of all saved variables outlined in <code>tf.train.Saver()</code> (default is all variables)</li>\n</ul>\n\n<p><code>.index</code> file:</p>\n\n<ul>\n<li><p>immutable table describing all tensors and their metadata checkpoint file:</p></li>\n<li><p>keeps a record of latest checkpoint files saved</p></li>\n</ul>\n\n<h2>Restoring Graph in Tensorflow:</h2>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\nlatest_checkpoint = tf.train.latest_checkpoint(""path/to/checkpoint"")\n\n# Load latest checkpoint Graph via import_meta_graph:\n#   - construct protocol buffer from file content\n#   - add all nodes to current graph and recreate collections\n#   - return Saver\nsaver = tf.train.import_meta_graph(latest_checkpoint + \'.meta\')\n\n# Start session\nwith tf.Session() as sess:\n\n    # Restore previously trained variables from disk\n    print(""Restoring Model: {}"".format(""path/to/checkpoint""))\n    saver.restore(sess, latest_checkpoint)\n\n    # Retrieve protobuf graph definition\n    graph = tf.get_default_graph()\n\n    print(""Restored Operations from MetaGraph:"")\n    for op in graph.get_operations():\n       print(op.name)\n\n    # Access restored placeholder variables\n    x_pl = graph.get_tensor_by_name(""x_pl:0"")\n    y_pl = graph.get_tensor_by_name(""y_pl:0"")\n\n    # Access restored operation to re run\n    accuracy_op = graph.get_tensor_by_name(""accuracy_op:0"")\n</code></pre>\n\n<p>This is just a quick example with the basics, for a working implementation see <a href=""https://github.com/sophdaly/znist-playground/tree/master/src/models"" rel=""noreferrer"">here</a>.</p>\n'}, {'owner': {'reputation': 38, 'user_id': 6473011}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1499340632, 'answer_id': 44947672, 'question_id': 38641887, 'body': '<p>In order to save the graph, you need to freeze the graph.\nHere is the python script for freezing the graph : <strong><a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py</a></strong></p>\n\n<p>Here is a code snippet for freezing graph:</p>\n\n<pre class=""lang-py prettyprint-override""><code>from tensorflow.python.tools import freeze_graph\nfreeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n                            input_binary, checkpoint_path,  output_node\n                            restore_op_name, filename_tensor_name,\n                            output_frozen_graph_name, True, """")\n</code></pre>\n\n<p>where output node corresponds to output tensor variable.</p>\n\n<pre class=""lang-py prettyprint-override""><code>output = tf.nn.softmax(outer_layer_name,name=""output"")\n</code></pre>\n'}, {'owner': {'reputation': 16962, 'user_id': 5046896}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': False, 'score': 7, 'creation_date': 1482370137, 'answer_id': 41274507, 'question_id': 38641887, 'body': '<p>From the <a href=""https://stackoverflow.com/questions/41265035/tensorflow-why-there-are-3-files-after-saving-the-model"">docs</a>, try this:</p>\n\n<pre class=""lang-py prettyprint-override""><code># Create some variables.\nv1 = tf.Variable(..., name=""v1"")\nv2 = tf.Variable(..., name=""v2"")\n...\n# Add an op to initialize the variables.\ninit_op = tf.global_variables_initializer()\n\n# Add ops to save and restore all the variables.\nsaver = tf.train.Saver()\n\n# Later, launch the model, initialize the variables, do some work, save the\n# variables to disk.\nwith tf.Session() as sess:\n  sess.run(init_op)\n  # Do some work with the model.\n  ..\n  # Save the variables to disk.\n  save_path = saver.save(sess, ""/tmp/model.ckpt"")\n  print(""Model saved in file: %s"" % save_path)\n</code></pre>\n\n<p>You can specify the path.</p>\n\n<p>And if you want to restore the model, try:</p>\n\n<pre class=""lang-py prettyprint-override""><code>with tf.Session() as sess:\n    saver = tf.train.import_meta_graph(\'/tmp/model.ckpt.meta\')\n    saver.restore(sess, ""/tmp/model.ckpt"")\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9861}"
126,56312032,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9857}"
127,63008991,"{'items': [{'owner': {'reputation': 1717, 'user_id': 9061899}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1595323864, 'answer_id': 63011508, 'question_id': 63008991, 'body': '<pre><code>from keras.models import Model\nimport inspect\n\ninspect.getmro(Model)\n# (keras.engine.training.Model, keras.engine.network.Network, keras.engine.layer._Layer)\n</code></pre>\n<p><code>inspect.getmro(CLS)</code> returns a tuple of class CLS\'s base classes, including CLS, in method resolution order.</p>\n<p>The <code>__call__</code> method inside <code>Model</code> infact comes from <code>keras.engine.layer._Layer</code> class. You can refer the code <a href=""https://github.com/tensorflow/tensorflow/blob/4343d75c5153470198d970166497fb5b9c4961f5/tensorflow/python/keras/engine/base_layer.py#L103"" rel=""nofollow noreferrer"">here</a></p>\n<p>On line <a href=""https://github.com/tensorflow/tensorflow/blob/4343d75c5153470198d970166497fb5b9c4961f5/tensorflow/python/keras/engine/base_layer.py#L1107"" rel=""nofollow noreferrer"">996</a>, inside <code>__call__</code> method <code>call_fn</code> is assigned as <code>call</code> &amp; is indeed called on line <a href=""https://github.com/tensorflow/tensorflow/blob/4343d75c5153470198d970166497fb5b9c4961f5/tensorflow/python/keras/engine/base_layer.py#L979"" rel=""nofollow noreferrer"">979</a>.</p>\n<p>So, essentially, in a way I guess, the following holds true -</p>\n<pre><code>def __call__(self, input):\n    return self.call(input)\n</code></pre>\n<p>Let\'s discuss further!</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9857}"
128,53539040,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9857}"
129,50997477,"{'items': [{'owner': {'reputation': 55360, 'user_id': 349130}, 'down_vote_count': 1, 'up_vote_count': 4, 'is_accepted': True, 'score': 3, 'creation_date': 1529741554, 'answer_id': 50999294, 'question_id': 50997477, 'body': ""<p>Of course its possible to save Model, all your examples have an empty Model, whcih makes no sense to save. Keras' author simply did not implement that case.</p>\n\n<p>If you test with a non-empty Model you will see that saving works perfectly. We use it every day.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9857}"
130,43460838,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9853}"
131,50825446,"{'items': [{'owner': {'reputation': 21, 'user_id': 8818388}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1588344368, 'answer_id': 61544714, 'question_id': 50825446, 'body': '<p>You could try something like</p>\n\n<pre><code>generator = Generator()\ncheckpoint = tf.train.Checkpoint(generator=generator)\ncheckpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n</code></pre>\n\n<p>where the Generator() constructor is the same as the one you used in the training.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9853}"
132,73437417,"{'items': [{'owner': {'reputation': 321, 'user_id': 19121443}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1661110122, 'answer_id': 73437610, 'question_id': 73437417, 'body': ""<p>In this case you could use keras.preprocessing.image.ImageDataGenerator() class and then use flow_from_directory() or flow_from_dataframe() as it's functions depend on the case you are working on.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9853}"
133,53690602,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9853}"
134,65794527,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9849}"
135,47984876,"{'items': [{'owner': {'reputation': 3247, 'user_id': 3165451}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1528114142, 'answer_id': 50680270, 'question_id': 47984876, 'body': '<p>A probably prettier solution is to specify the <code>dtype</code> argument (see <a href=""https://www.tensorflow.org/api_docs/python/tf/map_fn"" rel=""nofollow noreferrer"">documentation</a>) of <code>map_fn</code>, e.g.:</p>\n\n<pre><code>tf.map_fn(lambda x: fn(*x), elements, dtype=tf.float32)\n</code></pre>\n\n<p>if <code>fn</code> returns only one float32 value.</p>\n'}, {'owner': {'reputation': 511, 'user_id': 1519665}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1514474650, 'answer_id': 48010033, 'question_id': 47984876, 'body': ""<p>Turns out tf.map_fn's error messages are horribly misleading; the documentation does not mention this in detail but you need the exact number of returns on your function as arguments if you pass a tuple/list of tensors. Easiest way to do this is to return junk and then only grab the first return value.</p>\n\n<pre><code>print(a.shape) #[batch, 784, 2]\nprint(b.shape) #[batch, 28, 28]\nlambdaData = (a, b)\ntestFunc = lambda x: return &lt;somethingUseful&gt;, 0\nreturnValues, _ = tf.map_fn(testFunc, lambdaData)\n</code></pre>\n\n<p>works as expected.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9849}"
136,52134130,"{'items': [{'owner': {'reputation': 31, 'user_id': 1337994}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1539843616, 'answer_id': 52868060, 'question_id': 52134130, 'body': '<p>Now I use this, it works well.</p>\n\n<pre><code>grads=[tf.IndexedSlices(tf.clip_by_value(g.values, -max_grad_value, max_grad_value), g.indices, g.dense_shape) if isinstance(g, tf.IndexedSlices) else tf.clip_by_value(g, -max_grad_value, max_grad_value) for g in grads]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9849}"
137,68217076,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9849}"
138,51069173,"{'items': [{'owner': {'reputation': 3824, 'user_id': 252370}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1530125092, 'answer_id': 51069529, 'question_id': 51069173, 'body': '<p><a href=""https://www.tensorflow.org/programmers_guide/tensors"" rel=""nofollow noreferrer"">https://www.tensorflow.org/programmers_guide/tensors</a></p>\n\n<blockquote>\n  <p>TensorFlow, as the name indicates, is a framework to define and run\n  computations involving tensors. A tensor is a generalization of\n  vectors and matrices to potentially higher dimensions. Internally,\n  TensorFlow represents tensors as n-dimensional arrays of base\n  datatypes.</p>\n</blockquote>\n\n<p>What you are observing commes from the fact that tensorflow operations (like reshape) can be built from various python types using the function tf.convert_to_tensor:</p>\n\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor</a></p>\n\n<blockquote>\n  <p>All standard Python op constructors apply this function to each of\n  their Tensor-valued inputs, which allows those ops to accept numpy\n  arrays, Python lists, and scalars in addition to Tensor objects</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9845}"
139,71813366,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9845}"
140,50368759,"{'items': [{'owner': {'reputation': 16941, 'user_id': 8143158}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1526468438, 'answer_id': 50369132, 'question_id': 50368759, 'body': '<p>You can do:</p>\n\n<pre><code>shape = tf.shape(t1)\nt2 = tf.reshape(t1, [-1, shape[2]*shape[3]])\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9843}"
141,53922040,"{'items': [{'owner': {'reputation': 36, 'user_id': 9071001}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1552214258, 'answer_id': 55086800, 'question_id': 53922040, 'body': '<p>Conv2DTranspose is often used as upsampling for an image/feature map. The code below use 1X1 filter kernel to show how the input is padded with zero. the code is for tensorflow 2.0, add enable_eager_execution() with tensorflow1.x</p>\n\n<pre><code>data = tf.ones([2,2],tf.float32,""input_data"")\ninput_layer = tf.reshape(data, [-1, 2, 2, 1])\ntranspose2d = layers.Conv2DTranspose(1, (1, 1), kernel_initializer=\'ones\', strides=(2, 2), padding=\'valid\', use_bias=False)\nx = transpose2d(input_layer)\nprint(x)\n</code></pre>\n\n<p>The input is </p>\n\n<ul>\n<li>1,1</li>\n<li>1,1</li>\n</ul>\n\n<p>The x is</p>\n\n<ul>\n<li>1,0,1,0</li>\n<li>0,0,0,0</li>\n<li>1,0,1,0</li>\n<li>0,0,0,0</li>\n</ul>\n\n<p>you can change the stride value to see the diffrence </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9843}"
142,58630393,"{'items': [{'owner': {'reputation': 11, 'user_id': 10449989}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1654709024, 'answer_id': 72549848, 'question_id': 58630393, 'body': '<p>AUC can have a higher score than accuracy.\nAdditionally, you can use AUC to decide the cutoff threshold for a binary classifier(this cutoff is by default 0.5). Though there are more technical ways to decide this cutoff, you could simply simply increase it from 0 to 1 to find the value which maximizes your accuracy(this is a naive solution and 1 recommend you to read this <a href=""https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/One_ROC_Curve_and_Cutoff_Analysis.pdf"" rel=""nofollow noreferrer"">https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/One_ROC_Curve_and_Cutoff_Analysis.pdf</a> for an in depth explanation on cutoff analysis )</p>\n'}, {'owner': {'reputation': 149, 'user_id': 13410687}, 'down_vote_count': 1, 'up_vote_count': 5, 'is_accepted': False, 'score': 4, 'creation_date': 1587901175, 'answer_id': 61440077, 'question_id': 58630393, 'body': '<p>There is the argument <code>multi_label</code> which is a boolean inside your <code>tf.keras.metrics.AUC</code> call.</p>\n\n<p>If <code>True</code> (<em>not</em> the default), multi-label data will be treated as such, and so AUC is computed separately for each label and then averaged across labels.</p>\n\n<p>When <code>False</code> (the default), the data will be flattened into a single label before AUC computation. In the latter case, when multi-label data is passed to AUC, each label-prediction pair is treated as an individual data point. </p>\n\n<p>The documentation recommends to set it to <code>False</code> for multi-class data.</p>\n\n<p>e.g.: <code>tf.keras.metrics.AUC(multi_label = True)</code></p>\n\n<p>See the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC"" rel=""nofollow noreferrer"">AUC Documentation</a> for more details.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9843}"
143,56344827,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1559058976, 'answer_id': 56346038, 'question_id': 56344827, 'body': '<p>You can do it in a similar way you are used to in Tensorflow 1.x - by using a checkpoint object and, news introduced in Tensorflow 2.0, a checkpoint manager.</p>\n\n<pre class=""lang-py prettyprint-override""><code>ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net)\nmanager = tf.train.CheckpointManager(ckpt, \'./tf_ckpts\', max_to_keep=3)\nckpt.restore(manager.latest_checkpoint)\nif manager.latest_checkpoint:\n  print(""Restored from {}"".format(manager.latest_checkpoint))\nelse:\n  print(""Initializing from scratch."")\n\nfor example in toy_dataset():\n  loss = train_step(net, example, opt)\n</code></pre>\n\n<p>You can give a look at the <a href=""https://www.tensorflow.org/alpha/guide/checkpoints"" rel=""nofollow noreferrer"">Training checkpoints guide</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9843}"
144,55841019,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9843}"
145,60590333,"{'items': [{'owner': {'reputation': 9939, 'user_id': 2050}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1584083751, 'answer_id': 60666326, 'question_id': 60590333, 'body': '<p>Here is an answer that just provides some information, and a naive solution to fix the code---not the actual problem (please refer below for the why).</p>\n\n<p>First of, the <code>TypeError</code> is a problem of incompatible types in the tensors of your early attempt. Some tensors contain floating point numbers (double), some contain integers. It would have helped to show the <em>full</em> error message:</p>\n\n<pre><code>TypeError: Input \'y\' of \'Mul\' Op has type int32 that does not match type float64 of argument \'x\'.\n</code></pre>\n\n<p>Which happens to put on the right track (despite the gory details of the stack trace).</p>\n\n<p>Here is a naive fix to get the code to work (with caveats against the target problem):</p>\n\n<pre><code>import tensorflow as tf\n\n@tf.function\ndef vectorize_predec(t, p):\n    _p = tf.transpose(\n        tf.convert_to_tensor(\n            [p * t[...,idx] for idx in range(t.shape[-1] - 1)],\n            dtype=tf.float64))\n    _p = tf.concat([\n        tf.zeroes((_p.shape[0], 1), dtype=tf.float64),\n        _p\n    ], axis=1)\n    return t + _p\n\np = tf.Variable(0.5, dtype=\'double\')\n\nm = tf.constant([[0, 1, 2, 3, 4],\n          [1, 3, 5, 7, 10],\n          [1, 1, 1, -1, 0]], dtype=tf.float64)\n\nn = tf.constant([[0.0, 1.0, 2.5, 4.0, 5.5],\n          [1.0, 3.5, 6.5, 9.5, 13.5],\n          [1.0, 1.5, 1.5, -0.5, -0.5]], dtype=tf.float64)\nprint(f\'Expected: {n}\')\n\nresult = vectorize_predec(m, p)\nprint(f\'Result: {result}\')\n\ntf.test.TestCase().assertAllEqual(n, result)\n</code></pre>\n\n<p>The main changes:</p>\n\n<ul>\n<li>The <code>m</code> tensor gets a <code>dtype=tf.float64</code> to match the orignal <code>double</code>, so the type error vanishes.</li>\n<li>The function is basically a complete rewrite. The naive idea is to exploit the problem definition, which does <em>not</em> state whether the values in <code>N</code> are calculated before or after updates. Here is a version before update, way easier. Solving what seems to be the ""real"" problem requires working a bit more on the function (see other answers, and I may work more here).</li>\n</ul>\n\n<p>How the function works:</p>\n\n<ul>\n<li>It calculates the expected increments <code>p * x1</code>, <code>p * x2</code>, etc into a standard Python array. Note it stops before the last element of the last dimension, as we will shift the array.</li>\n<li>It converts the array to a tensor with <code>tf.convert_to_tensor</code>, so adding the array to the computation graph. The transpose is necessary to match the original tensor shape (we could avoid it).</li>\n<li>It appends zeroes at the beginning of each dimension along the last axis.</li>\n<li>The result is the sum of the original tensor and the constructed one.</li>\n</ul>\n\n<p>The values become <code>x1 + 0.0 * p</code>, then <code>x2 + x1 * p</code>, etc. This illustrates a few functions and issues to look at (types, shapes), but I admit it cheats and does not solve the actual problem.</p>\n\n<p>Also, this code is not efficient on any hardware. It is just illustrative, and would need to (1) eliminate the Python array, (2) eliminate the transpose, (3) eliminate the concatenate operation. Hopefully great training :-)</p>\n\n<hr>\n\n<p>Extra notes:</p>\n\n<ul>\n<li>The problem asks for a solution on tensors of shape (a, b, c). The code you share works on tensors of shape (a, b), so fixing the code will still not solve the problem.</li>\n<li>The problem requires rational numbers. Not sure what the intent\nis, and this answer leaves this requirement aside.</li>\n<li>The shape of <code>T = [x1, x2, x3, x4]</code> is actually <code>(4,)</code>, assuming <code>xi</code> are scalars.</li>\n<li>Why <code>tf.float64</code>? By default, we get <code>tf.float32</code>, and removing the <code>double</code> would make the code works. But the example would lose the point that types matter, so the choice for an explicit non-default type (and uglier code).</li>\n</ul>\n'}, {'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1583927943, 'answer_id': 60635516, 'question_id': 60590333, 'body': '<p>I\'ll give you a couple of different methods to implement that. I think the most obvious solution is to use <a href=""https://www.tensorflow.org/api_docs/python/tf/scan"" rel=""noreferrer""><code>tf.scan</code></a>:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\ndef apply_momentum_scan(m, p, axis=0):\n    # Put axis first\n    axis = tf.convert_to_tensor(axis, dtype=tf.int32)\n    perm = tf.concat([[axis], tf.range(axis), tf.range(axis + 1, tf.rank(m))], axis=0)\n    m_t = tf.transpose(m, perm)\n    # Do computation\n    res_t = tf.scan(lambda a, x: a * p + x, m_t)\n    # Undo transpose\n    perm_t = tf.concat([tf.range(1, axis + 1), [0], tf.range(axis + 1, tf.rank(m))], axis=0)\n    return tf.transpose(res_t, perm_t)\n</code></pre>\n\n<p>However, you can also implement this as a particular matrix product, if you build a matrix of exponential factors:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\ndef apply_momentum_matmul(m, p, axis=0):\n    # Put axis first and reshape\n    m = tf.convert_to_tensor(m)\n    p = tf.convert_to_tensor(p)\n    axis = tf.convert_to_tensor(axis, dtype=tf.int32)\n    perm = tf.concat([[axis], tf.range(axis), tf.range(axis + 1, tf.rank(m))], axis=0)\n    m_t = tf.transpose(m, perm)\n    shape_t = tf.shape(m_t)\n    m_tr = tf.reshape(m_t, [shape_t[0], -1])\n    # Build factors matrix\n    r = tf.range(tf.shape(m_tr)[0])\n    p_tr = tf.linalg.band_part(p ** tf.dtypes.cast(tf.expand_dims(r, 1) - r, p.dtype), -1, 0)\n    # Do computation\n    res_tr = p_tr @ m_tr\n    # Reshape back and undo transpose\n    res_t = tf.reshape(res_tr, shape_t)\n    perm_t = tf.concat([tf.range(1, axis + 1), [0], tf.range(axis + 1, tf.rank(m))], axis=0)\n    return tf.transpose(res_t, perm_t)\n</code></pre>\n\n<p>This can also be rewritten to avoid the first transposing (which in TensorFlow is expensive) with <a href=""https://www.tensorflow.org/api_docs/python/tf/tensordot"" rel=""noreferrer""><code>tf.tensordot</code></a>:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\ndef apply_momentum_tensordot(m, p, axis=0):\n    # Put axis first and reshape\n    m = tf.convert_to_tensor(m)\n    # Build factors matrix\n    r = tf.range(tf.shape(m)[axis])\n    p_mat = tf.linalg.band_part(p ** tf.dtypes.cast(tf.expand_dims(r, 1) - r, p.dtype), -1, 0)\n    # Do computation\n    res_t = tf.linalg.tensordot(m, p_mat, axes=[[axis], [1]])\n    # Transpose\n    last_dim = tf.rank(res_t) - 1\n    perm_t = tf.concat([tf.range(axis), [last_dim], tf.range(axis, last_dim)], axis=0)\n    return tf.transpose(res_t, perm_t)\n</code></pre>\n\n<p>The three functions would be used in a similar way:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\np = tf.Variable(0.5, dtype=tf.float32)\nm = tf.constant([[0, 1, 2, 3, 4],\n                 [1, 3, 5, 7, 10],\n                 [1, 1, 1, -1, 0]], tf.float32)\n# apply_momentum is one of the functions above\nprint(apply_momentum(m, p, axis=0).numpy())\n# [[ 0.    1.    2.    3.    4.  ]\n#  [ 1.    3.5   6.    8.5  12.  ]\n#  [ 1.5   2.75  4.    3.25  6.  ]]\nprint(apply_momentum(m, p, axis=1).numpy())\n# [[ 0.      1.      2.5     4.25    6.125 ]\n#  [ 1.      3.5     6.75   10.375  15.1875]\n#  [ 1.      1.5     1.75   -0.125  -0.0625]]\n</code></pre>\n\n<p>Using a matrix product is more asymptotically complex, but it can be faster than scanning. Here is a small benchmark:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\n\n# Make test data\ntf.random.set_seed(0)\np = tf.constant(0.5, dtype=tf.float32)\nm = tf.random.uniform([100, 30, 50], dtype=tf.float32)\n\n# Axis 0\nprint(np.allclose(apply_momentum_scan(m, p, 0).numpy(), apply_momentum_matmul(m, p, 0).numpy()))\n# True\nprint(np.allclose(apply_momentum_scan(m, p, 0).numpy(), apply_momentum_tensordot(m, p, 0).numpy()))\n# True\n%timeit apply_momentum_scan(m, p, 0)\n# 11.5 ms  610 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n%timeit apply_momentum_matmul(m, p, 0)\n# 1.36 ms  18.3 s per loop (mean  std. dev. of 7 runs, 1000 loops each)\n%timeit apply_momentum_tensordot(m, p, 0)\n# 1.62 ms  7.39 s per loop (mean  std. dev. of 7 runs, 1000 loops each)\n\n# Axis 1\nprint(np.allclose(apply_momentum_scan(m, p, 1).numpy(), apply_momentum_matmul(m, p, 1).numpy()))\n# True\nprint(np.allclose(apply_momentum_scan(m, p, 1).numpy(), apply_momentum_tensordot(m, p, 1).numpy()))\n# True\n%timeit apply_momentum_scan(m, p, 1)\n# 4.27 ms  60.4 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n%timeit apply_momentum_matmul(m, p, 1)\n# 1.27 ms  36.4 s per loop (mean  std. dev. of 7 runs, 1000 loops each)\n%timeit apply_momentum_tensordot(m, p, 1)\n# 1.2 ms  11.6 s per loop (mean  std. dev. of 7 runs, 1000 loops each)\n\n# Axis 2\nprint(np.allclose(apply_momentum_scan(m, p, 2).numpy(), apply_momentum_matmul(m, p, 2).numpy()))\n# True\nprint(np.allclose(apply_momentum_scan(m, p, 2).numpy(), apply_momentum_tensordot(m, p, 2).numpy()))\n# True\n%timeit apply_momentum_scan(m, p, 2)\n# 6.29 ms  64.6 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n%timeit apply_momentum_matmul(m, p, 2)\n# 1.41 ms  21.8 s per loop (mean  std. dev. of 7 runs, 1000 loops each)\n%timeit apply_momentum_tensordot(m, p, 2)\n# 1.05 ms  26 s per loop (mean  std. dev. of 7 runs, 1000 loops each)\n</code></pre>\n\n<p>So, matrix product seems to win. Let\'s see if this scales:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\n\n# Make test data\ntf.random.set_seed(0)\np = tf.constant(0.5, dtype=tf.float32)\nm = tf.random.uniform([1000, 300, 500], dtype=tf.float32)\n\n# Axis 0\nprint(np.allclose(apply_momentum_scan(m, p, 0).numpy(), apply_momentum_matmul(m, p, 0).numpy()))\n# True\nprint(np.allclose(apply_momentum_scan(m, p, 0).numpy(), apply_momentum_tensordot(m, p, 0).numpy()))\n# True\n%timeit apply_momentum_scan(m, p, 0)\n# 784 ms  6.78 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n%timeit apply_momentum_matmul(m, p, 0)\n# 1.13 s  76.9 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n%timeit apply_momentum_tensordot(m, p, 0)\n# 1.3 s  27 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n\n# Axis 1\nprint(np.allclose(apply_momentum_scan(m, p, 1).numpy(), apply_momentum_matmul(m, p, 1).numpy()))\n# True\nprint(np.allclose(apply_momentum_scan(m, p, 1).numpy(), apply_momentum_tensordot(m, p, 1).numpy()))\n# True\n%timeit apply_momentum_scan(m, p, 1)\n# 852 ms  12.7 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n%timeit apply_momentum_matmul(m, p, 1)\n# 659 ms  10.7 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n%timeit apply_momentum_tensordot(m, p, 1)\n# 741 ms  19.5 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n\n# Axis 2\nprint(np.allclose(apply_momentum_scan(m, p, 2).numpy(), apply_momentum_matmul(m, p, 2).numpy()))\n# True\nprint(np.allclose(apply_momentum_scan(m, p, 2).numpy(), apply_momentum_tensordot(m, p, 2).numpy()))\n# True\n%timeit apply_momentum_scan(m, p, 2)\n# 1.06 s  16.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n%timeit apply_momentum_matmul(m, p, 2)\n# 924 ms  17 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n%timeit apply_momentum_tensordot(m, p, 2)\n# 483 ms  10.1 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n</code></pre>\n\n<p>Well, now it\'s not so clear anymore. Scanning is still not super fast, but matrix products are sometimes slower. As you can imagine if you go to even bigger tensors the complexity of matrix products will dominate the timings.</p>\n\n<p>So, if you want the fastest solution and know your tensors are not going to get huge, use one of the matrix product implementations. If you\'re fine with okay speed but want to make sure you don\'t run out of memory (matrix solution also takes much more) and timing is predictable, you can use the scanning solution.</p>\n\n<p>Note: Benchmarks above were carried out on CPU, results may vary significantly on GPU.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9838}"
146,50329855,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 10, 'is_accepted': True, 'score': 10, 'creation_date': 1526324895, 'answer_id': 50337385, 'question_id': 50329855, 'body': '<p>As you have noticed, <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices"" rel=""noreferrer""><code>tf.data.Dataset.from_tensor_slices()</code></a> only works on objects that can be converted to a (dense) <code>tf.Tensor</code> or a <code>tf.SparseTensor</code>. The easiest way to get variable-length NumPy data into a <code>Dataset</code> is to use <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""noreferrer""><code>tf.data.Dataset.from_generator()</code></a>, as follows:</p>\n\n<pre><code>dataset = tf.data.Dataset.from_generator(lambda: dataset_list, \n                                         tf.as_dtype(dataset_list[0].dtype),\n                                         tf.TensorShape([None, 32, 2]))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9838}"
147,49987839,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1524509812, 'answer_id': 49988099, 'question_id': 49987839, 'body': ""<p>There's a small problem in your code: you're assigning the return value of <code>tf.clip_by_global_norm</code> to a single variable, when this function returns a pair of values.</p>\n\n<p>The documentation says:</p>\n\n<blockquote>\n  <p>Returns:</p>\n  \n  <p>list_clipped: A list of Tensors of the same type as list_t.</p>\n  \n  <p>global_norm: A 0-D (scalar) Tensor representing the global norm.</p>\n</blockquote>\n\n<p>Hence, the problem arises when you try to apply the gradients to the variables, in the next line.</p>\n\n<p>You can easily fix your code ignoring the global_norm returned value.</p>\n\n<pre><code>gradients, _ = tf.clip_by_global_norm(gradients, 2.5)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9838}"
148,45115650,"{'items': [{'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1500115556, 'answer_id': 45117293, 'question_id': 45115650, 'body': '<p><a href=""https://www.tensorflow.org/api_docs/python/tf/argmax"" rel=""noreferrer"">tf.argmax</a> does not return the first maximum. In case of tie anything can be returned: </p>\n\n<blockquote>\n  <p>Note that in case of ties the identity of the return value is not\n  guaranteed.</p>\n</blockquote>\n\n<p>So the answers like reverse and argmax are wrong.</p>\n\n<p>One option which I can see is:</p>\n\n<pre><code>import tensorflow as tf\na = tf.constant([5, 3, 3, 5, 4, 2, 5, 1])\nb = tf.argmax(tf.multiply(\n    tf.cast(tf.equal(a, tf.reduce_max(a)), tf.int32),\n    tf.range(1, a.get_shape()[0] + 1)\n))\nwith tf.Session() as sess:\n    print sess.run(b)\n</code></pre>\n\n<p>If your starting vector is does not consist of integers, you need to change the type.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9838}"
149,42785026,"{'items': [{'owner': {'reputation': 517, 'user_id': 9686324}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': False, 'score': 8, 'creation_date': 1544279589, 'answer_id': 53683545, 'question_id': 42785026, 'body': '<p>All of these other replies talk about how the parameters are different, but actually, the main difference of tf.nn and tf.layers conv2d is that for tf.nn, you need to create your own filter tensor and pass it in. This filter needs to have the size of: <code>[kernel_height, kernel_width, in_channels, num_filters]</code></p>\n\n<p>Essentially, tf.nn is lower level than tf.layers. Unfortunately, this answer is not applicable anymore is tf.layers is obselete</p>\n'}, {'owner': {'reputation': 71, 'user_id': 11582320}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1559903088, 'answer_id': 56492538, 'question_id': 42785026, 'body': '<p>DIFFERENCES IN PARAMETER: </p>\n\n<p>Using tf.layer* in a code:  </p>\n\n<pre><code># Convolution Layer with 32 filters and a kernel size of 5\nconv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu) \n# Max Pooling (down-sampling) with strides of 2 and kernel size of 2\nconv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n</code></pre>\n\n<p>Using tf.nn* in a code: \n( Notice we need to pass weights and biases <strong>additionally</strong> as parameters )</p>\n\n<pre><code>strides = 1\n# Weights matrix looks like: [kernel_size(=5), kernel_size(=5), input_channels (=3), filters (= 32)]\n# Similarly bias = looks like [filters (=32)]\nout = tf.nn.conv2d(input, weights, padding=""SAME"", strides = [1, strides, strides, 1])\nout = tf.nn.bias_add(out, bias)\nout = tf.nn.relu(out)\n</code></pre>\n'}, {'owner': {'reputation': 4393, 'user_id': 6487788}, 'down_vote_count': 1, 'up_vote_count': 3, 'is_accepted': False, 'score': 2, 'creation_date': 1489492755, 'answer_id': 42785422, 'question_id': 42785026, 'body': '<p>Take a look here:<a href=""https://www.tensorflow.org/api_docs/python/tf/layers/conv2d"" rel=""nofollow noreferrer"">tensorflow >  tf.layers.conv2d</a></p>\n\n<p>and here: <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv2d"" rel=""nofollow noreferrer"">tensorflow > conv2d</a></p>\n\n<p>As you can see the arguments to the layers version are: </p>\n\n<blockquote>\n  <p>tf.layers.conv2d(inputs, filters, kernel_size, strides=(1, 1), padding=\'valid\', data_format=\'channels_last\', dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer=None, bias_initializer=tf.zeros_initializer(), kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, trainable=True, name=None, reuse=None)</p>\n</blockquote>\n\n<p>and the nn version: </p>\n\n<blockquote>\n  <p>tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)</p>\n</blockquote>\n\n<p>I think you can choose the one with the options you want/need/like!</p>\n'}, {'owner': {'reputation': 1090, 'user_id': 390292}, 'down_vote_count': 2, 'up_vote_count': 32, 'is_accepted': True, 'score': 30, 'creation_date': 1490113775, 'answer_id': 42932979, 'question_id': 42785026, 'body': '<p>For convolution, they are the same. More precisely, <code>tf.layers.conv2d</code> (actually <code>_Conv</code>) uses <code>tf.nn.convolution</code> as the backend. You can follow the calling chain of: <code>tf.layers.conv2d&gt;Conv2D&gt;Conv2D.apply()&gt;_Conv&gt;_Conv.apply()&gt;_Layer.apply()&gt;_Layer.\\__call__()&gt;_Conv.call()&gt;nn.convolution()...</code></p>\n'}, {'owner': {'reputation': 882, 'user_id': 347208}, 'down_vote_count': 0, 'up_vote_count': 13, 'is_accepted': False, 'score': 13, 'creation_date': 1510806376, 'answer_id': 47321605, 'question_id': 42785026, 'body': '<p>As others mentioned the parameters are different especially the ""filter(s)"". tf.nn.conv2d takes a tensor as a filter, which means you can specify the weight decay (or maybe other properties) like the following in <a href=""https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10.py"" rel=""noreferrer"">cifar10 code</a>. (Whether you want/need to have weight decay in conv layer is another question.)</p>\n\n<pre><code>kernel = _variable_with_weight_decay(\'weights\',\n                                     shape=[5, 5, 3, 64],\n                                     stddev=5e-2,\n                                     wd=0.0)\nconv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding=\'SAME\')\n</code></pre>\n\n<p>I\'m not quite sure how to set weight decay in tf.layers.conv2d since it only take an integer as filters. Maybe using <code>kernel_constraint</code>?</p>\n\n<p>On the other hand, tf.layers.conv2d handles activation and bias automatically while you have to write additional codes for these if you use tf.nn.conv2d.</p>\n'}, {'owner': {'reputation': 992, 'user_id': 4114051}, 'down_vote_count': 1, 'up_vote_count': 44, 'is_accepted': False, 'score': 43, 'creation_date': 1500999251, 'answer_id': 45308609, 'question_id': 42785026, 'body': '<p>As GBY mentioned, they use the same implementation.</p>\n\n<p>There is a slight difference in the parameters.</p>\n\n<p>For tf.nn.conv2d:</p>\n\n<pre><code>filter: A Tensor. Must have the same type as input. A 4-D tensor of shape [filter_height, filter_width, in_channels, out_channels]\n</code></pre>\n\n<p>For tf.layers.conv2d:</p>\n\n<pre><code>filters: Integer, the dimensionality of the output space (i.e. the number of filters in the convolution).\n</code></pre>\n\n<p>I would use tf.nn.conv2d when loading a pretrained model (example code: <a href=""https://github.com/ry/tensorflow-vgg16"" rel=""noreferrer"">https://github.com/ry/tensorflow-vgg16</a>), and tf.layers.conv2d for a model trained from scratch.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9838}"
150,44093698,"{'items': [{'owner': {'reputation': 34138, 'user_id': 987185}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1495348184, 'answer_id': 44093850, 'question_id': 44093698, 'body': '<p>The formula used is slightly different from:</p>\n\n<pre><code>bn = scale * (x - mean) / (sqrt(var) + 1e-3) + offset\n</code></pre>\n\n<p>It <a href=""https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/nn_impl.py#L780"" rel=""nofollow noreferrer"">should be</a>:</p>\n\n<pre><code>bn = scale * (x - mean) / (sqrt(var + 1e-3)) + offset\n</code></pre>\n\n<p>The <code>variance_epsilon</code> variable is supposed to scale with the <code>variance</code>, not with <code>sigma</code>, which is the square-root of variance.</p>\n\n<p>After the correction, the formula yields the correct value:</p>\n\n<pre><code>1.0055743 * (-0.077417567 - -0.089603029)/((0.000436493 + 1e-3)**0.5)  + -0.016652612\n# 0.30664642276945747\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9833}"
151,66879748,"{'items': [{'owner': {'reputation': 16444, 'user_id': 9215780}, 'down_vote_count': 0, 'up_vote_count': 14, 'is_accepted': True, 'score': 14, 'creation_date': 1617153029, 'answer_id': 66880334, 'question_id': 66879748, 'body': '<p>There are two class API to define a model in <code>tf. keras</code>. According to the doc</p>\n<ul>\n<li><p><a href=""https://keras.io/api/models/sequential/"" rel=""noreferrer""><code>Sequential class</code></a>: Sequential groups a linear stack of layers into a <code>tf. keras.Model</code>.</p>\n</li>\n<li><p><a href=""https://keras.io/api/models/model/"" rel=""noreferrer""><code>Model class</code></a>: <code>Model</code> group\'s layers into an object with training and inference features.</p>\n</li>\n</ul>\n<hr />\n<p>An <code>Sequential</code> model is the simplest type of model, a linear stack of layers. But there are some flaws in using the <code>sequential</code> model API, it\'s limited in certain points. We can\'t build complex networks such as multi-input or multi-output networks using this API.</p>\n<p>But using <a href=""https://keras.io/api/models/model/"" rel=""noreferrer""><code>Model class</code></a>, we can instantiate a Model with the <strong>Functional API</strong> (and also with <strong>Subclassing the Model class</strong>) that allows us to create arbitrary graphs of layers. From this, we can get more flexibility and easily define models where each layer can connect not just with the previous and next layers but also share feature information with other layers in the model, for example, model-like <code>ResNet</code>, <code>EfficientNet</code>.</p>\n<p>In fact, most of the SOTA model that you can get from <code>tf.keras.applications</code> is basically implemented using the <strong>Functional API</strong>. However, in subclassing API, we define our layers in <code>__init__</code> and we implement the model\'s forward pass in the <code>call</code> method.</p>\n<p>Generally speaking, all the model definitions using Sequential API, can be achieved in Functional API or Model Subclassing API. And in Functional API or Model Subclassing API, we can create complex layers that not possible to achieve in Sequential API. If you wondering which one to choose, the answer is, it totally depends on your need. However, check out the following blog post where we have discussed the various model strategies in <code>tf. keras</code> with more examples. <a href=""https://towardsdatascience.com/model-sub-classing-and-custom-training-loop-from-scratch-in-tensorflow-2-cc1d4f10fb4e"" rel=""noreferrer"">Model Sub-Classing and Custom Training Loop from Scratch in TensorFlow 2</a></p>\n'}, {'owner': {'reputation': 134, 'user_id': 12317000}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': False, 'score': 0, 'creation_date': 1617147855, 'answer_id': 66879829, 'question_id': 66879748, 'body': '<p>It\'s because they are from different versions of tensorflow. According to the documentation (TensorFlow 2.0), <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Sequential"" rel=""nofollow noreferrer"">tf.keras.Sequential</a> is the most recent way of calling the function. If you go to the documentation, and click on &quot;View aliases&quot;, you can see the different aliases used in older version of Tensorflow for that function.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9833}"
152,48427269,"{'items': [{'owner': {'reputation': 6711, 'user_id': 6708503}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1516869127, 'answer_id': 48438616, 'question_id': 48427269, 'body': '<p>Yes, it is advisable to use the tensors returned by <code>get_next()</code> directly in your graph. Perhaps you missed the <a href=""https://www.tensorflow.org/programmers_guide/datasets#consuming_values_from_an_iterator"" rel=""nofollow noreferrer"">Programmer\'s Guide</a> on the <code>tf.data</code> API.</p>\n\n<p>You may also find the <a href=""https://www.tensorflow.org/versions/master/performance/datasets_performance"" rel=""nofollow noreferrer"">performance guide</a> instructive.</p>\n\n<p>Hope that helps.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9833}"
153,44339463,"{'items': [{'owner': {'reputation': 1448, 'user_id': 4333609}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1496459891, 'answer_id': 44339888, 'question_id': 44339463, 'body': ""<p>I got it now.</p>\n\n<p>To display any nodes in tensorboard, the nodes have to be used in an operation first. Being a <code>tf.constant</code> without involving in <code>add</code> or <code>multiply</code> or any other operations, won't be displayed by tensorboard.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9833}"
154,55681290,"{'items': [{'owner': {'reputation': 8315, 'user_id': 5154274}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1555317885, 'answer_id': 55685450, 'question_id': 55681290, 'body': '<p>Here\'s a full example. </p>\n\n<p><strong>Note</strong></p>\n\n<ul>\n<li>Iterator must be initialized at the beginning</li>\n<li>We can set number of epochs to perform by using <code>repeat()</code> method of number of epochs and <code>batch()</code> method for batch size. Note that I use first <code>repeat()</code> and then <code>batch()</code>.</li>\n<li>At each iteration we\'re using <code>tf.Session()</code> interface to access the next batch.</li>\n<li>We use <code>try-except</code> since when repetition of data ends it raises <code>tf.error.OutOfRangeError</code>.</li>\n</ul>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nfrom sklearn.datasets import make_blobs\n\n# generate dummy data for illustration\nx_train, y_train = make_blobs(n_samples=25,\n                              n_features=2,\n                              centers=[[1, 1], [-1, -1]],\n                              cluster_std=0.5)\nn_epochs = 2\nbatch_size = 10\n\nwith tf.name_scope(\'inputs\'):\n    x = tf.placeholder(tf.float32, shape=[None, 2])\n    y = tf.placeholder(tf.int32, shape=[None])\n\nwith tf.name_scope(\'logits\'):\n    logits = tf.layers.dense(x,\n                             units=2,\n                             name=\'logits\')\n\nwith tf.name_scope(\'loss\'):\n    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n    loss_tensor = tf.reduce_mean(xentropy)\n\nwith tf.name_scope(\'optimizer\'):\n    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss_tensor)\n\n# create dataset `from_tensor_slices` and create iterator\ndataset = tf.data.Dataset.from_tensor_slices({\'x\':x_train, \'y\':y_train})\ndataset = dataset.repeat(n_epochs).batch(10)\niterator = dataset.make_initializable_iterator()\n\nwith tf.Session() as sess:\n    sess.run([tf.global_variables_initializer(), \n              iterator.initializer]) # &lt;-- must be initialized!\n    next_batch = iterator.get_next()\n\n    while True:\n        try:\n            batch = sess.run(next_batch) # &lt;-- extract next batch\n            loss_val, _ = sess.run([loss_tensor, train_op], \n                                   feed_dict={x:batch[\'x\'], y:batch[\'y\']})\n            print(loss_val)\n        except tf.errors.OutOfRangeError:\n            break \n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9829}"
155,57717004,"{'items': [{'owner': {'reputation': 1444, 'user_id': 9988487}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1570297625, 'answer_id': 58250849, 'question_id': 57717004, 'body': '<p>While this is no real answer to the original question (i.e. ""what is the optimal way to train on large datasets""), I managed to get tfrecords and datasets to work. Of particular help was this <a href=""https://www.youtube.com/watch?v=oxrcZ9uUblI&amp;list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ&amp;index=25"" rel=""nofollow noreferrer"">tutorial on YouTube</a>. I include a minimal example with working code for anyone struggling with the same problem.</p>\n\n<pre><code># Developed using python 3.6, tensorflow 1.14.0.\n# This code writes data (pairs (label, image) where label is int64 and image is np.ndarray) into .tfrecord files and\n# uses them for training a simple neural network. It is meant as a minimal working example of how to use tfrecords. This\n# solution is likely not optimal. If you know how to improve it, please comment on\n# https://stackoverflow.com/q/57717004/9988487. Refer to links therein for further information.\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.python import keras as keras\n\n\n# Helper functions (see also https://www.tensorflow.org/tutorials/load_data/tf_records)\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\ndef write_tfrecords_file(out_path: str, images: np.ndarray, labels: np.ndarray) -&gt; None:\n    """"""Write all image-label pairs into a single .tfrecord file.\n    :param out_path: File path of the .tfrecord file to generate or overwrite.\n    :param images: array with first dimension being the image index. Every images[i].tostring() is\n        serialized and written into the file as \'image\': wrap_bytes(img_bytes)\n    :param labels: 1d array of integers. labels[i] is the label of images[i]. Written as \'label\': wrap_int64(label)""""""\n    assert len(images) == len(labels)\n    with tf.io.TFRecordWriter(out_path) as writer:  # could use writer_options parameter to enable compression\n        for i in range(len(labels)):\n            img_bytes = images[i].tostring()  # Convert the image to raw bytes.\n            label = labels[i]\n            data = {\'image\': _bytes_feature(img_bytes), \'label\': _int64_feature(label)}\n            feature = tf.train.Features(feature=data)  # Wrap the data as TensorFlow Features.\n            example = tf.train.Example(features=feature)  # Wrap again as a TensorFlow Example.\n            serialized = example.SerializeToString()  # Serialize the data.\n            writer.write(serialized)  # Write the serialized data to the TFRecords file.\n\n\ndef parse_example(serialized, shape=(256, 256, 1)):\n    features = {\'image\': tf.io.FixedLenFeature([], tf.string), \'label\': tf.io.FixedLenFeature([], tf.int64)}\n    # Parse the serialized data so we get a dict with our data.\n    parsed_example = tf.io.parse_single_example(serialized=serialized, features=features)\n    label = parsed_example[\'label\']\n    image_raw = parsed_example[\'image\']  # Get the image as raw bytes.\n    image = tf.decode_raw(image_raw, tf.float32)  # Decode the raw bytes so it becomes a tensor with type.\n    image = tf.reshape(image, shape=shape)\n    return image, label  # this function will be called once (to add it to tf graph; then parse images individually)\n\n\n# create some arbitrary data to play with: 1000 images sized 256x256 with one colour channel. Use your custom np-arrays\nIMAGE_WIDTH, NUM_OF_IMAGES, NUM_OF_CLASSES, COLOUR_CHANNELS = 256, 10_000, 10, 1\n# using float32 to save memory. Must match type in parse_example(), tf.decode_raw(image_raw, tf.float32)\nfeatures_train = np.random.sample((NUM_OF_IMAGES, IMAGE_WIDTH, IMAGE_WIDTH, COLOUR_CHANNELS)).astype(np.float32)\nlabels_train = np.random.randint(low=0, high=NUM_OF_CLASSES, size=NUM_OF_IMAGES)  # one random label for each image\nfeatures_eval = features_train[:200]  # use the first 200 images as evaluation data for simplicity.\nlabels_eval = labels_train[:200]\nwrite_tfrecords_file(""train.tfrecord"", features_train, labels_train)  # normal: split the data files of several GB each\nwrite_tfrecords_file(""eval.tfrecord"", features_eval, labels_eval)  # this may take a while. Consider a progressbar\n# The files are complete. Now define a model and use datasets to feed the data from the .tfrecord files into the model.\nmodel = keras.Sequential([keras.layers.Flatten(input_shape=(256, 256, 1)),\n                          keras.layers.Dense(128, activation=\'relu\'),\n                          keras.layers.Dense(10, activation=\'softmax\')])\nmodel.compile(optimizer=\'adam\',\n              loss=\'sparse_categorical_crossentropy\',\n              metrics=[\'accuracy\'])\n# Check docs for parameters (compression, buffer size, thread count. Also www.tensorflow.org/guide/performance/datasets\n\ntrain_dataset = tf.data.TFRecordDataset(""train.tfrecord"")  # specify a list (or dataset) of file names for large data\ntrain_dataset = train_dataset.map(parse_example)  # parse tfrecords. Parameter num_parallel_calls may help performance.\ntrain_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n\nvalidation_dataset = tf.data.TFRecordDataset(""eval.tfrecord"")\nvalidation_dataset = validation_dataset.map(parse_example).batch(64)\n\nmodel.fit(train_dataset, epochs=3)\n# evaluate the results\nresults = model.evaluate(validation_dataset)\nprint(\'\\n\\nvalidation loss, validation acc:\', results)\n\n</code></pre>\n\n<p>Note that it\'s tricky to use some_keras_model.fit(..., validation_data=some_dataset) with dataset objects. It may result in\n<code>TypeError: \'DatasetV1Adapter\' object does not support indexing</code>.\nThis seems to be a bug (see github.com/tensorflow/tensorflow/issues/28995) and is supposedly fixed as of  tf-nightly version \'1.15.0-dev20190808\'; The <a href=""https://www.tensorflow.org/guide/keras/train_and_evaluate"" rel=""nofollow noreferrer"">official tutorial</a> uses this too, although it doesn\'t work in most versions. An easy but dirty-ish fix is to use verbose=0 (which only suppresses program output) and plot the validation results using tensorboard. Also see <a href=""https://stackoverflow.com/questions/50955798/keras-model-fit-with-tf-dataset-api-validation-data#50979587"">Keras model.fit() with tf.dataset API + validation_data</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9829}"
156,69509388,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1634104190, 'answer_id': 69550342, 'question_id': 69509388, 'body': ""<p>BERT model expects specific input shape.</p>\n<p><strong>Working sample code:</strong></p>\n<pre><code>bert_preprocess = hub.KerasLayer(&quot;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&quot;)\nbert_encoder = hub.KerasLayer(&quot;https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4&quot;,trainable=True)\n\ndef get_sentence_embeding(sentences):\n    preprocessed_text = bert_preprocess(sentences)\n    return bert_encoder(preprocessed_text)['pooled_output']\n\nget_sentence_embeding([\n    &quot;How to find which version of TensorFlow is&quot;, \n    &quot;TensorFlow not found using pip&quot;]\n)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9829}"
157,41294094,"{'items': [{'owner': {'reputation': 2457, 'user_id': 2570465}, 'down_vote_count': 0, 'up_vote_count': 30, 'is_accepted': True, 'score': 30, 'creation_date': 1482458672, 'answer_id': 41294283, 'question_id': 41294094, 'body': '<h3>Placeholder</h3>\n\n<p>A placeholder is used for feeding external data into a Tensorflow computation (stuff outside the graph). Here\'s some documentation: (<a href=""https://www.tensorflow.org/versions/r0.10/how_tos/reading_data/#feeding"" rel=""noreferrer"">https://www.tensorflow.org/versions/r0.10/how_tos/reading_data/#feeding</a>)</p>\n\n<blockquote>\n  <p>TensorFlow\'s feed mechanism lets you inject data into any Tensor in a\n  computation graph. A python computation can thus feed data directly\n  into the graph.</p>\n</blockquote>\n\n<p>I personally would draw an analogy from placeholders to reading from standard input.</p>\n\n<pre><code>x = raw_input()\nX = tf.placeholder(""float"")\n</code></pre>\n\n<p>When you read from standard input, you need to ""inject data"" from an external source. Same with a placeholder. It lets you ""inject data"" that\'s external to the computation graph.</p>\n\n<p>If you\'re training a learning algorithm, the clear use case of placeholder is to feed in your training data. The training data isn\'t stored in the computation graph. How are you going to get it into the graph? By injecting it through a placeholder. A placeholder is basically you telling the graph ""I don\'t have this for you yet. But I\'ll have it for you when I ask you to run.""</p>\n\n<h3>Variable</h3>\n\n<p>A variable is used to store state in your graph. It requires an initial value. One use case could be representing weights of a neural network or something similar. Here\'s documentation: (<a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/Variable</a>)</p>\n\n<blockquote>\n  <p>A variable maintains state in the graph across calls to run(). You add\n  a variable to the graph by constructing an instance of the class\n  Variable.</p>\n  \n  <p>The Variable() constructor requires an initial value for the variable,\n  which can be a Tensor of any type and shape. The initial value defines\n  the type and shape of the variable. After construction, the type and\n  shape of the variable are fixed. The value can be changed using one of\n  the assign methods.</p>\n</blockquote>\n\n<p>I personally would draw an analogy between Tensorflow Variables and assigning a variable in Python to anything that is not dependent on external stuff. For example,</p>\n\n<pre><code># Tensorflow:\nW = tf.Variable(rng.randn(), name=""weight"")\n\n# Standard python:\nw = 5\nw = ""hello""\nw = [1, 2, 3, 4, 5]\n</code></pre>\n\n<p><code>W</code> represents some sort of result of your computation. Just like how you must initialize all your variables in Python (you can\'t just run a command <code>x</code> you have to say <code>x = ...something...</code>), you have to initialize all Variable objects in Tensorflow.</p>\n\n<h3>Variable vs. Placeholder</h3>\n\n<p>There\'s not much related between <code>tf.Variable</code> and <code>tf.placeholder</code> in my opinion. You use a <code>Variable</code> if you need to store state. You use a <code>placeholder</code> if you need to input external data.</p>\n\n<p>If you are not building a model, you should still use <code>tf.placeholder</code> if you want to insert external data that you don\'t necessarily have while you\'re defining the graph. If you are not building a model, you still need <code>tf.Variable</code> if you want to store some kind of result of your computation while the graph is being run.</p>\n\n<h3>Why have both?</h3>\n\n<p>I\'m not an expert in Tensorflow, so I can only speculate as to why the design has both. </p>\n\n<p>A big difference between placeholders and variables is that placeholders can have variable size, but the shape of a <code>tf.Variable</code> must be specified while constructing the graph.</p>\n\n<p>Variable size placeholders sense: maybe I only want to input a training batch of size 5 right now, but maybe I want to increase the batch size later on. Maybe I don\'t know ahead of time how many training examples I\'m going to get.</p>\n\n<p>Variable size variables don\'t make sense: <code>tf.Variable</code> holds the learned parameters of your model, and the number of parameters shouldn\'t change. Furthermore, Tensorflow extends to distributed computation. If you had <code>Variables</code> whose shape changed throughout the computation, it would be very difficult to keep it properly distributed among 1000 computers.</p>\n\n<p>Usually, you build a model and all parameters are known ahead of time, so that\'s what <code>tf.Variable</code> is probably used to represent. <code>tf.placeholder</code> is probably for everything else outside of your model (or computation graph) and so that can be more flexible.</p>\n'}, {'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 9, 'is_accepted': False, 'score': 9, 'creation_date': 1499660801, 'answer_id': 45003763, 'question_id': 41294094, 'body': '<p>The most obvious difference between the <a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""noreferrer"">tf.Variable</a> and the <a href=""https://www.tensorflow.org/api_docs/python/tf/placeholder"" rel=""noreferrer"">tf.placeholder</a> is that</p>\n\n<hr>\n\n<blockquote>\n  <p>you use variables to hold and update parameters. Variables are\n  in-memory buffers containing tensors. They must be explicitly\n  initialized and can be saved to disk during and after training. You\n  can later restore saved values to exercise or analyze the model.</p>\n</blockquote>\n\n<p>Initialization of the variables is done with <code>sess.run(tf.global_variables_initializer())</code>. Also while creating a variable, you need to pass a Tensor as its initial value to the Variable() constructor and when you create a variable you always know its shape.</p>\n\n<hr>\n\n<p>On the other hand you can\'t update the placeholder. They also should not be initialized, but because they are a promise to have a tensor, you need to feed the value into them <code>sess.run(&lt;op&gt;, {a: &lt;some_val&gt;})</code>. And at last, in comparison to a variable, placeholder might not know the shape. You can either provide parts of the dimensions or provide nothing at all.</p>\n\n<hr>\n\n<p><strong>There other differences:</strong></p>\n\n<ul>\n<li>the values inside the variable can be updated during optimizations</li>\n<li>variables can be <a href=""https://www.tensorflow.org/programmers_guide/variable_scope"" rel=""noreferrer"">shared</a>, and can be <a href=""https://stackoverflow.com/q/40736859/1090562"">non-trainable</a></li>\n<li>the values inside the variable can be stored after training</li>\n<li>when the variable is created, <a href=""https://www.tensorflow.org/programmers_guide/variables#creation"" rel=""noreferrer"">3 ops are added to a graph</a> (variable op, initializer op, ops for the initial value)</li>\n<li><a href=""https://stackoverflow.com/a/43536220/1090562"">placeholder is a function, Variable is a class</a> (hence an uppercase)</li>\n<li>when you use TF in a distributed environment, variables are stored in a special place (<a href=""https://www.tensorflow.org/deploy/distributed"" rel=""noreferrer"">parameter server</a>) and are shared between the workers.</li>\n</ul>\n\n<p>Interesting part is that not only placeholders can be fed. You can feed the value to a Variable and even to a constant.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9829}"
158,48021777,"{'items': [{'owner': {'reputation': 11, 'user_id': 4260223}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1523738496, 'answer_id': 49836001, 'question_id': 48021777, 'body': '<p>you can use\ntf.concat([t1, t2], 0)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9825}"
159,56201490,"{'items': [{'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1558207028, 'answer_id': 56202136, 'question_id': 56201490, 'body': '<p>Eager execution, used by default in TF 2.0, evaluates operations immediately, without building graphs. Graph on the other hand, has certain <a href=""https://www.tensorflow.org/guide/graphs#why_dataflow_graphs"" rel=""nofollow noreferrer"">advantages</a>. However, execution time will depend on particular code. The more code uses c++ backend, the less the difference will be. All the overhead comes from program in eager mode using python interpreter. For example basic matrix multiplication operation will not get as much benefit as more complex DNN applications.</p>\n'}, {'owner': {'reputation': 558, 'user_id': 5025377}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1558206880, 'answer_id': 56202116, 'question_id': 56201490, 'body': '<p>In graph mode, TensorFlow builds a computation graph representing your model and forwards it to the C++ runtime via a Session. This provides distributed training benefits and optimizes your computation graph in the process(through constant folding, etc). It also eases the process of deploying to a platform-independent server. </p>\n\n<p>The @tf.function decorator allows the user to reap the benefits of graph execution in eager mode, but do be aware that some caveats apply(for example, tf.function prefers TF ops to Python primitives). </p>\n\n<p>Sources: <a href=""https://www.tensorflow.org/guide/eager"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/eager</a>\n         <a href=""https://www.tensorflow.org/alpha/tutorials/eager/tf_function"" rel=""nofollow noreferrer"">https://www.tensorflow.org/alpha/tutorials/eager/tf_function</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9825}"
160,76153107,"{'items': [{'owner': {'reputation': 113838, 'user_id': 15239951}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': False, 'score': 0, 'creation_date': 1683017091, 'answer_id': 76153168, 'question_id': 76153107, 'body': '<p><code>tf.keras.Model</code> is an higher class to build your model. If you look the class tree, you will see the <code>tf.Module</code>:</p>\n<pre><code>import tensorflow as tf\nimport inspect\n</code></pre>\n<pre><code>&gt;&gt;&gt; inspect.getclasstree(inspect.getmro(tf.keras.Model))\n[(object, ()),\n [(keras.utils.version_utils.LayerVersionSelector, (object,)),\n  [(keras.engine.base_layer.Layer,\n    (tensorflow.python.module.module.Module,\n     keras.utils.version_utils.LayerVersionSelector)),\n   [(keras.engine.training.Model,\n     (keras.engine.base_layer.Layer,\n      keras.utils.version_utils.ModelVersionSelector))]],\n  (keras.utils.version_utils.ModelVersionSelector, (object,)),\n  [(keras.engine.training.Model,\n    (keras.engine.base_layer.Layer,\n     keras.utils.version_utils.ModelVersionSelector))],\n  (tensorflow.python.trackable.base.Trackable, (object,)),\n  [(tensorflow.python.trackable.autotrackable.AutoTrackable,\n    (tensorflow.python.trackable.base.Trackable,)),\n   [(tensorflow.python.module.module.Module,  # &lt;- HERE\n     (tensorflow.python.trackable.autotrackable.AutoTrackable,)),\n    [(keras.engine.base_layer.Layer,\n      (tensorflow.python.module.module.Module,\n       keras.utils.version_utils.LayerVersionSelector)),\n     [(keras.engine.training.Model,\n       (keras.engine.base_layer.Layer,\n        keras.utils.version_utils.ModelVersionSelector))]]]]]]\n</code></pre>\n<p>You can probably do the same thing but you will lose useful methods and I think you will find less community documentation using <code>tf.Module</code> (Opinion based)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9823}"
161,44939540,"{'items': [{'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1499316302, 'answer_id': 44939985, 'question_id': 44939540, 'body': '<p>You have not correctly read my explanation in the tutorial you linked. After a straight-forward modification of <code>no-padding, strides=1</code> you suppose to get the following code.</p>\n\n<pre><code>import tensorflow as tf\nk = tf.constant([\n    [1, 2],\n], dtype=tf.float32, name=\'k\')\ni = tf.constant([\n    [0, 1],\n    [2, 3],\n], dtype=tf.float32, name=\'i\')\nkernel = tf.reshape(k, [1, 2, 1, 1], name=\'kernel\')\nimage  = tf.reshape(i, [1, 2, 2, 1], name=\'image\')\n\nres = tf.squeeze(tf.nn.conv2d(image, kernel, [1, 1, 1, 1], ""VALID""))\n# VALID means no padding\nwith tf.Session() as sess:\n   print sess.run(res)\n</code></pre>\n\n<p>Which gives you the result you expected: <code>[2., 8.]</code>. Here I got a vector instead of the column because of squeeze operator. </p>\n\n<hr>\n\n<p>One problem I see with your code (there might be other) is that your kernel is of the shape <code>(1, 1, 1, 2)</code>, but it suppose to be <code>(1, 2, 1, 1)</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9823}"
162,38136081,"{'items': [{'owner': {'reputation': 6526, 'user_id': 4392784}, 'down_vote_count': 0, 'up_vote_count': 9, 'is_accepted': False, 'score': 9, 'creation_date': 1467339912, 'answer_id': 38136082, 'question_id': 38136081, 'body': '<p>This error is caused by not initializing local variables. To ensure local variables are initialized you should do something like the following.</p>\n\n<pre><code>init_op = tf.group(tf.global_variables_initializer(),\n                   tf.local_variables_initializer())\nsess.run(init_op)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9821}"
163,65712409,"{'items': [{'owner': {'reputation': 540, 'user_id': 10952155}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1610645558, 'answer_id': 65724008, 'question_id': 65712409, 'body': '<p>Since TF.Size is not natively supported on TFLite you can use TF Select mode which fallbacks to TF for the missing op, which during conversion is enabled using &quot;SELECT_TF_OPS&quot; that you tried.\nWhen you run inference you will need to use Interpreter which have Select ops linked.\nSee the <a href=""https://www.tensorflow.org/lite/guide/ops_select#run_inference"" rel=""nofollow noreferrer"">guide</a> on running inference.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9821}"
164,43411738,"{'items': [{'owner': {'reputation': 47089, 'user_id': 121687}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1492189664, 'answer_id': 43416019, 'question_id': 43411738, 'body': ""<p>Mostly you use them <code>tf.image.*</code> for easiness of use.</p>\n\n<p>Both <code>crop_to_bounding_box</code> and <code>pad_to_bounding_box</code> use <code>slice</code> and <code>pad</code>underneath, but also add checkings and constraints to make sure you don't spend hours trying to debug your slice/pad indices and offsets.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9821}"
165,74213661,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9821}"
166,69792031,"{'items': [{'owner': {'reputation': 20222, 'user_id': 122207}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1669138062, 'answer_id': 74536780, 'question_id': 69792031, 'body': ""<p>The simple answer here is that the explanation of multi-hot encoding that you linked to is not correct.</p>\n<p>The purpose of multi-hot encoding is to create a one-to-one correspondence between categorical labels and places in the encoded tensor such that if there are multiple applicable labels than all would be included in a single input tensor. This is very obvious from your own example as quoted below:</p>\n<blockquote>\n<p>print(mhe(lookup(tf.constant(['cat', 'dog']))).numpy())</p>\n<p>[0. 0. 1. 1. 0.]</p>\n</blockquote>\n<p>The output tensor is <code>[!UNK, !fish, Dog, Cat, !Bird]</code></p>\n<p>The description of multi-hot encoding you linked to is actually of a compact binary representation, a kind of encoding, but not one suitable for data science. Each input in the encoded tensor would have no specific meaning and it would be much more difficult for a traditional deep learning approach to derive the meaning from the input tensor.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9817}"
167,41685279,"{'items': [{'owner': {'reputation': 57117, 'user_id': 419116}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1484605597, 'answer_id': 41686009, 'question_id': 41685279, 'body': '<p>Not an answer, but some general notes how to find an answer :)</p>\n\n<p>First of all, using github\'s blame, inception_distributed was checked in on April 13, while that comment in <code>start_queue_runners</code> was added on Apr 15th, so it\'s possible that functionality was changed but didn\'t get updated in all the places that use it.</p>\n\n<p>You could comment-out that line and see if things still work. And if not, you could add <code>import pdb; pdb.set_trace()</code> in the place where queue runner gets created (ie <a href=""https://github.com/tensorflow/tensorflow/blob/dd01113c2b9efb16c3c3ea0a4aaa340a0494696f/tensorflow/python/training/queue_runner_impl.py#L47"" rel=""nofollow noreferrer"">here</a>) and see who is creating those extra unattended queue runners.</p>\n\n<p>Also, Supervisor development seems to have slowed down and things are getting moved over to FooSession (from comment <a href=""https://github.com/tensorflow/tensorflow/issues/6604#issuecomment-270950324"" rel=""nofollow noreferrer"">here</a>). Those provide a more robust training architecture (your workers won\'t crash because of temporary network error), but there are not many examples on how to use them yet.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9817}"
168,63359268,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9817}"
169,73279782,"{'items': [{'owner': {'reputation': 431, 'user_id': 13538900}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1670906239, 'answer_id': 74780026, 'question_id': 73279782, 'body': '<p>For TPU Node architecture you can also try using <code>cloud-tpu-profiler</code>:</p>\n<pre><code>pip3 install --upgrade &quot;cloud-tpu-profiler&gt;=2.3.0&quot; \n</code></pre>\n<p>Then capture the profile using</p>\n<pre><code>capture_tpu_profile --tpu=$TPU_NAME --logdir=${MODEL_DIR} --duration_ms=2000 --num_tracing_attempts=10\n</code></pre>\n<p>For details you can refer <a href=""https://cloud.google.com/tpu/docs/cloud-tpu-tools#monitor_job"" rel=""nofollow noreferrer"">here</a>.</p>\n<p><a href=""https://cloud.google.com/tpu/docs/run-calculation-tensorflow"" rel=""nofollow noreferrer"">TPU VM</a> is recommended TPU architecture and you can follow <a href=""https://cloud.google.com/tpu/docs/profile-tpu-vm"" rel=""nofollow noreferrer"">Profile TPU VM guide</a> when using TPU VMs.</p>\n'}, {'owner': {'reputation': 1220, 'user_id': 10017662}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1662986160, 'answer_id': 73689364, 'question_id': 73279782, 'body': '<ol>\n<li>Please check the trace files in your logdir. If they are too small, it\'s likely that you got some issues during tracing.</li>\n<li>Just be sure that you typed the right command. <code>$ tensorboard --logdir logs/predict</code></li>\n<li>Try another profiling method by using <code>tf.profiler.experimental.client.start(...)</code>, as indicated by <a href=""https://www.tensorflow.org/guide/profiler#profiling_use_cases"" rel=""nofollow noreferrer"">TF profiler Docs</a>.\nBelow is the code snippet.</li>\n</ol>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nfrom threading import Thread\n\ndef call_trace(tpu_resolver):  # This should be called asynchronously\n  # a profiler service has been started in the TPU worker at port 8466\n  service_addr = &quot;:&quot;.join(tpu_resolver.get_master().split(&quot;:&quot;)[:-1] +\n                          [&quot;8466&quot;])  # need to change for TPU pod\n  tf.profiler.experimental.client.trace(service_addr=service_addr,\n                                        logdir=&quot;gs://your_logdir&quot;,\n                                        duration_ms=5000)\n\ntpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(...)\n# Other initialization codes\n\nthr = Thread(target=call_trace, args=(tpu_resolver,))\nthr.start()\n# Codes you want to execute on the cloud TPU node\nthr.join()\n\n</code></pre>\n<p>Then open tensorboard for visualization.</p>\n<pre class=""lang-bash prettyprint-override""><code>$ tensorboard --logdir gs://your_logdir\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9817}"
170,69843239,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9817}"
171,53549352,"{'items': [{'owner': {'reputation': 6369, 'user_id': 5495304}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1543537534, 'answer_id': 53549555, 'question_id': 53549352, 'body': ""<p>If I understand your question correctly, you want to find the value of <code>x</code> which minimizes <code>x^2 + 2</code>. </p>\n\n<p>To do so, you need to repeatedly call <code>GradientDescentOptimizer</code> until <code>x</code> converges to the value which minimizes the function. This is because gradient descent is an iterative technique. </p>\n\n<p>Also, in tensorflow, the method  <code>minimize</code> of <code>GradientDescentOptimizer</code> does both computing the gradients and then applying them to the relevant variables (<code>x</code> in your case). So the code should look like this (Notice I commented the <code>grad</code> variable, which is not required unless you want to look at the gradient values): </p>\n\n<pre><code>x = tf.Variable(1.0, trainable=True)\ny = x**2 + 2\n\n# grad = tf.gradients(y, x)\ngrad_op = tf.train.GradientDescentOptimizer(0.2).minimize(y)\n\ninit = tf.global_variables_initializer()\n\nn_iterations = 10\nwith tf.Session() as sess:\n    sess.run(init)\n    for i in range(n_iterations):\n        _, new_x = sess.run([grad_op, x])\n        print('Iteration:', i,', x:', new_x)\n</code></pre>\n\n<p>and you get: </p>\n\n<pre><code>Iteration: 0 , x: 1.0\nIteration: 1 , x: 0.6\nIteration: 2 , x: 0.36\nIteration: 3 , x: 0.216\nIteration: 4 , x: 0.07776\nIteration: 5 , x: 0.07776\nIteration: 6 , x: 0.046656\nIteration: 7 , x: 0.01679616\nIteration: 8 , x: 0.010077696\nIteration: 9 , x: 0.010077696\n</code></pre>\n\n<p>which you see in converging to the true answer which is 0.</p>\n\n<p>If you increase the learning rate of <code>GradientDescentOptimizer</code>, from 0.2 to 0.4, it will converge to 0 much faster.</p>\n\n<p><strong>EDIT</strong></p>\n\n<p>OK, based on my new understanding of the question, to manually implement gradient descent, you cannot do <code>x = x - alpha * gradient</code> because this is python operation which simply replaces the object <code>x</code>. You need to tell tensorflow to add the op to the graph, and this can be done using <code>x.assign</code>. It will look like: </p>\n\n<pre><code>x = tf.Variable(1.0, trainable=True)\ny = x**2 + 2\n\ngrad = tf.gradients(y, x)\n# grad_op = tf.train.GradientDescentOptimizer(0.5).minimize(y)\n\nupdate_op = x.assign(x - 0.2*grad[0])\n\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n    for i in range(10):\n        new_x = sess.run([update_op, x])\n        print('Iteration:', i,', x:', new_x)\n</code></pre>\n\n<p>and we get the same answer as the native <code>GradientDescentOptimizer</code>:</p>\n\n<pre><code>Iteration: 0 , x: 1.0\nIteration: 1 , x: 0.6\nIteration: 2 , x: 0.36\nIteration: 3 , x: 0.1296\nIteration: 4 , x: 0.1296\nIteration: 5 , x: 0.077759996\nIteration: 6 , x: 0.046655998\nIteration: 7 , x: 0.027993599\nIteration: 8 , x: 0.01679616\nIteration: 9 , x: 0.010077696\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9812}"
172,48369961,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9812}"
173,41437483,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9812}"
174,45373740,"{'items': [{'owner': {'reputation': 19196, 'user_id': 7214344}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1501246967, 'answer_id': 45374285, 'question_id': 45373740, 'body': '<p><code>tf.nn.relu</code> does not normalize the data. For example, if I run</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nX = tf.placeholder(tf.float32, [2, 3])\nrelu_X=tf.nn.relu(X)\n\nsess = tf.Session()\nmat = np.array([[-1,2,3],[2,-5,1]])\nsess.run(relu_X, feed_dict={X:mat})\n</code></pre>\n\n<p>the result is</p>\n\n<pre><code>array([[ 0.,  2.,  3.],\n       [ 2.,  0.,  1.]], dtype=float32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9812}"
175,51509549,"{'items': [{'owner': {'reputation': 2924, 'user_id': 3353760}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1532773414, 'answer_id': 51570396, 'question_id': 51509549, 'body': ""<p>This is not possible at the moment using TensorFlow's Premade BoostedTreeRegressor or Classifier Estimators.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9812}"
176,64612657,"{'items': [{'owner': {'reputation': 455, 'user_id': 14548310}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1604309522, 'answer_id': 64642928, 'question_id': 64612657, 'body': '<p>Thanks Nicholas for the suggestion.</p>\n<p>I\'m not using Keras for the network modelling, I need in fact to use Tensorflow directly, in particular with <a href=""https://github.com/google-research/tf-slim"" rel=""nofollow noreferrer"">tf-slim</a> library.</p>\n<p>The solution that you proposed could work for replacing the weights, but the problem to overcome so is that I need also to change how these weights are used to compute the convolution operation. To be more concrete I want to pass to the Conv layer a vector of weights that is representative in some way of the previous weights matrix, so before making the convolution I need to reconstruct a matrix and pass it to the layer.</p>\n<p>Any suggestion to accomplish this?</p>\n<p>Thank you.</p>\n'}, {'owner': {'reputation': 34678, 'user_id': 10908375}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1604078883, 'answer_id': 64613160, 'question_id': 64612657, 'body': ""<p>Let's say you have a basic convolutional neural network like this:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), \n                           strides=(1, 1), activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), \n                           strides=(1, 1), activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(5e-1),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n</code></pre>\n<p>All the convolutional layers will, by default, have the name <code>'conv2d...'</code> something.</p>\n<pre><code>list(map(lambda x: x.name, model.layers))\n</code></pre>\n<pre><code>['conv2d_19',\n 'max_pooling2d_19',\n 'conv2d_20',\n 'max_pooling2d_20',\n 'flatten_8',\n 'dense_16',\n 'dropout_8',\n 'dense_17']\n</code></pre>\n<p>Using that, you can iterate through all the convolutional layers.</p>\n<pre><code>for layer in filter(lambda x: 'conv2d' in x.name, model.layers):\n    print(layer)\n</code></pre>\n<pre><code>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000295BE4EB048&gt;\n&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000295C1617448&gt;\n</code></pre>\n<p>For all these layers, you can obtain the weights shape, and the bias shape.</p>\n<pre><code>for layer in filter(lambda x: 'conv' in x.name, model.layers):\n    weights_shape, bias_shape = map(lambda x: x.shape, layer.get_weights())\n</code></pre>\n<p>Then you can use <code>layer.set_weights()</code> with the values you want, since you know the correct shape. Let's say <code>0.12345</code>. Let's do that with <code>np.full</code>, which fills an array of the specified shape with any value you want.</p>\n<pre><code>for layer in filter(lambda x: 'conv2d' in x.name, model.layers):\n    weights_shape, bias_shape = map(lambda x: x.shape, layer.get_weights())\n    layer.set_weights([np.full(weights_shape, 0.12345),\n                       np.full(bias_shape,    0.12345)])\n</code></pre>\n<p>The weights now:</p>\n<pre><code>[array([[[[0.12345, 0.12345, 0.12345, ..., 0.12345, 0.12345, 0.12345],\n          [0.12345, 0.12345, 0.12345, ..., 0.12345, 0.12345, 0.12345],\n          [0.12345, 0.12345, 0.12345, ..., 0.12345, 0.12345, 0.12345],\n          ...,\n          [0.12345, 0.12345, 0.12345, ..., 0.12345, 0.12345, 0.12345],\n          [0.12345, 0.12345, 0.12345, ..., 0.12345, 0.12345, 0.12345],\n          [0.12345, 0.12345, 0.12345, ..., 0.12345, 0.12345, 0.12345]]]],\n       dtype=float32),\n array([0.12345, 0.12345, 0.12345, 0.12345, 0.12345, 0.12345, 0.12345,\n        0.12345, 0.12345, 0.12345, 0.12345, 0.12345, 0.12345, 0.12345,\n        0.12345, 0.12345, 0.12345, 0.12345, 0.12345, 0.12345, 0.12345,\n        0.12345, 0.12345, 0.12345, 0.12345, 0.12345, 0.12345, 0.12345,\n        0.12345, 0.12345, 0.12345, 0.12345], dtype=float32)]\n</code></pre>\n<p>Fully copy/pastable example:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), \n                           strides=(1, 1), activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), \n                           strides=(1, 1), activation='relu'),\n    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(5e-1),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.build(input_shape=(None, 28, 28, 1))\n\nfor layer in filter(lambda x: 'conv2d' in x.name, model.layers):\n    weights_shape, bias_shape = map(lambda x: x.shape, layer.get_weights())\n    layer.set_weights([np.full(weights_shape, 0.12345),\n                       np.full(bias_shape,    0.12345)])\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9807}"
177,55253299,"{'items': [{'owner': {'reputation': 1166, 'user_id': 3595278}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1553059605, 'answer_id': 55254067, 'question_id': 55253299, 'body': '<p>In the <a href=""https://github.com/tensorflow/models/tree/master/official/resnet"" rel=""nofollow noreferrer"">tf.official ResNet implementation</a>, they use <code>tf.identity</code> for this purpose:</p>\n\n<pre><code>logits = tf.identity(logits, \'logits\')\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9807}"
178,54966581,"{'items': [{'owner': {'reputation': 553, 'user_id': 9904344}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1594204142, 'answer_id': 62792739, 'question_id': 54966581, 'body': '<p>If you remove the <code>axis</code> argument from the function , it will work .The error you are getting will be resolved.</p>\n'}, {'owner': {'reputation': 43, 'user_id': 8819252}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1559151051, 'answer_id': 56365798, 'question_id': 54966581, 'body': ""<p>As @syltruong has pointed out, check if the version of Keras you're using matches the documentation. Right now, the documentation uses version 2.2.4. </p>\n\n<p>On a side note @Ganesh and @Sushant, you don't actually need to use the axis parameter for that particular piece of code in the Deep Learning Specialization.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9807}"
179,48396599,"{'items': [{'owner': {'reputation': 7022, 'user_id': 3309610}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1516712756, 'answer_id': 48402496, 'question_id': 48396599, 'body': '<p>After some investigation, it seems that the <code>tf.while_loop</code> idiom used above is quite common. Alternatively, one can use <code>tf.scan</code>: </p>\n\n<pre><code>def body( x ):\n    return ...\n\ndef scan_body( previous_output, iteration ):\n    return body( ... )\n\nx = tf.scan( scan_body, tf.range(n), initializer = [x] )\n</code></pre>\n\n<p>although I have no idea if one is preferable from a performance point of view. Note in the above that we have to wrap the <code>body</code> function to accept the previous output.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9807}"
180,48445751,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9803}"
181,67361081,"{'items': [{'owner': {'reputation': 16444, 'user_id': 9215780}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1620014898, 'answer_id': 67363360, 'question_id': 67361081, 'body': '<p>For <code>indices</code>, the <code>index depth</code> is the size or <strong>length</strong> of the <strong>index vectors</strong>. For example:</p>\n<pre><code>indicesA = [[1], [3], [4], [7]] # index vector with 1 element: index_depth = 1\nindicesB = [[0, 1], [2, 0]]     # index vector with 2 element: index_depth = 2\n</code></pre>\n<hr />\n<p>The reason for indices is <code>2D</code> is to hold two information, one is the <strong>length of the updates (<code>num_updates</code>)</strong> and the <strong>length of the index vector</strong>. Two things need to be fulfilled:</p>\n<ul>\n<li>The <code>index depth</code> of <code>indices</code> must equal the <strong>rank</strong> of the <code>input</code> tensor</li>\n<li>The length of <code>updates</code> must equal the <strong>length</strong> of the <code>indices</code></li>\n</ul>\n<p>So, in the example code</p>\n<pre><code># tf.rank(tensor) == 1\ntensor = [0, 0, 0, 0, 0, 0, 0, 0]    \n\n# num_updates == 4, index_depth == 1 | tf.rank(indices).numpy() == 2 \nindices = [[1], [3], [4], [7]]    \n\n# num_updates == 4 | tf.rank(output).numpy() == 1  \nupdates = [9, 10, 11, 12]        \n\noutput = tf.tensor_scatter_nd_update(tensor, indices, updates)\ntf.Tensor([ 0  9  0 10 11  0  0 12], shape=(8,), dtype=int32)\n</code></pre>\n<p>Also</p>\n<pre><code># tf.rank(tensor) == 2\ntensor = [[1, 1], [1, 1], [1, 1]]    \n\n # num_updates == 2, index_depth == 2 | tf.rank(indices).numpy() == 2\nindices = [[0, 1], [2, 0]]          \n\n# num_updates == 2 | tf.rank(output).numpy() == 2\nupdates = [5, 10]       \n             \noutput = tf.tensor_scatter_nd_update(tensor, indices, updates)\ntf.Tensor(\n[[ 1  5]\n [ 1  1]\n [10  1]], shape=(3, 2), dtype=int32)\n\nnum_updates, index_depth = tf.convert_to_tensor(indices).shape.as_list()\n[num_updates, index_depth]\n[2, 2]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9802}"
182,62284095,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9802}"
183,74029376,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1665498163, 'answer_id': 74029724, 'question_id': 74029376, 'body': ""<p>It really depends on how many dimensions your tensor has, but for a 2D tensor you could just do:</p>\n<pre><code>import tensorflow as tf\n\ntensor = tf.constant(\n  [[1,  5, -3],\n   [2, -3,  1],\n   [3, -6,  2]])\n\ntf.gather(tensor, tf.argmax(tf.abs(tensor), axis=1), axis=1, batch_dims=1)\n</code></pre>\n<pre><code>&lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 5, -3, -6], dtype=int32)&gt;\n</code></pre>\n<p>3D example:</p>\n<pre><code>tensor = tf.constant(\n  [\n    [[ 1,  5, -3],\n     [ 2, -3,  1],\n     [ 3, -6,  2]],\n\n    [[-2,  3, -5],\n     [-1,  4,  2],\n     [ 4, -1,  0]]\n   ]\n)\n\n# axis = 0\nargmax = tf.argmax(tf.abs(tensor), axis=0)\ni, j = tf.meshgrid(\n    tf.range(tensor.shape[1], dtype=tf.int64), \n    tf.range(tensor.shape[2], dtype=tf.int64),\n                              indexing='ij')\ntf.gather_nd(tensor, tf.stack([argmax, i, j], axis=-1))\n</code></pre>\n<pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=int32, numpy=\narray([[-2,  5, -5],\n       [ 2,  4,  2],\n       [ 4, -6,  2]], dtype=int32)&gt;\n</code></pre>\n<pre><code># axis = 1\nargmax = tf.argmax(tf.abs(tensor), axis=1)\ni, j = tf.meshgrid(\n    tf.range(tensor.shape[0], dtype=tf.int64), \n    tf.range(tensor.shape[2], dtype=tf.int64),\n                              indexing='ij')\ntf.gather_nd(tensor, tf.stack([i, argmax, j], axis=-1))\n</code></pre>\n<pre><code>&lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy=\narray([[ 3, -6, -3],\n       [ 4,  4, -5]], dtype=int32)&gt;\n</code></pre>\n<pre><code># axis = 2\ni, j = tf.meshgrid(\n    tf.range(tensor.shape[0], dtype=tf.int64), \n    tf.range(tensor.shape[1], dtype=tf.int64),\n                              indexing='ij')\ntf.gather_nd(tensor, tf.stack([i, j, argmax], axis=-1))\n</code></pre>\n<pre><code>&lt;tf.Tensor: shape=(2, 3), dtype=int32, numpy=\narray([[ 5, -3, -6],\n       [-5,  4,  4]], dtype=int32)&gt;\n</code></pre>\n<p>For a 4D tensor just extend the <code>meshgrid</code>:</p>\n<pre><code># axis=-1\ni, j, k = tf.meshgrid(\n    tf.range(tensor.shape[0], dtype=tf.int64), \n    tf.range(tensor.shape[1], dtype=tf.int64),\n    tf.range(tensor.shape[2], dtype=tf.int64),\n                              indexing='ij')\n</code></pre>\n<p>Quick function bundling everything by @leleogere</p>\n<pre><code>def reduce_maxamplitude(tensor, axis):\n    argmax = tf.argmax(tf.abs(tensor), axis=axis)\n    mesh = tf.meshgrid(\n        *[tf.range(tensor.shape[i], dtype=tf.int64) for i in range(tensor.shape.rank) if i != axis],\n        indexing='ij'\n    )\n    return tf.gather_nd(tensor, tf.stack([*mesh[:axis], argmax, *mesh[axis:]], axis=-1))\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9802}"
184,64039233,"{'items': [{'owner': {'reputation': 14062, 'user_id': 6117017}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1600929961, 'answer_id': 64040888, 'question_id': 64039233, 'body': '<p>Yes, there is a difference between Keras and Tf.Keras.</p>\n<p>Keras is the standalone library implementation, on top of TensorFlow.</p>\n<p>TF.Keras is the Keras library implemented inside the TensorFlow (and other DL frameworks in the older versions).</p>\n<p>Everybody should choose TF.Keras, since it is better maintained, less prone to bugs, and the way to go in the future; in fact the majority of Keras developers now work on TF.Keras, including the creator Francois Chollet.</p>\n<p>Keras standalone will not release any other major versions and will be abandoned in the future.</p>\n<p>For all your projects and tasks that you have to solve, choose TF.Keras.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9802}"
185,41216322,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9798}"
186,59607363,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1578295243, 'answer_id': 59608126, 'question_id': 59607363, 'body': ""<p>You can get the desired result by setting,</p>\n\n<pre><code>train_dataset = train_dataset.batch(2, drop_remainder=True)\n</code></pre>\n\n<p><code>drop_remainder=False</code> by default. When that's the case, the first dimension <strong>must</strong> be <code>None</code> as there will (most probably) be a batch with <code>&lt; batch_size</code> elements at the end of the dataset, because the number of samples is not divisible by <code>batch_size</code>.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9798}"
187,39211332,"{'items': [{'owner': {'reputation': 11854, 'user_id': 5140223}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1472490387, 'answer_id': 39211524, 'question_id': 39211332, 'body': ""<p>You can use <code>x.initialized_value()</code> as well. For example:</p>\n\n<pre><code>import tensorflow as tf\n\nx = tf.Variable(1.0)\ny = tf.get_variable('y', initializer=x.initialized_value())\n\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n    print(sess.run(y)) #\xa0prints 1.0\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9798}"
188,67760450,"{'items': [{'owner': {'reputation': 26, 'user_id': 16075630}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1622478844, 'answer_id': 67777445, 'question_id': 67760450, 'body': '<p>I think I figured it out by accident by doing the following for something else I was trying:</p>\n<p><code>tf.compat.v1.disable_v2_behavior()</code> at the top of the script. And then <code>print(len(outputs))</code> right after getting the outputs. This gives the following error: <code>TypeError: len is not well defined for symbolic Tensors.</code>.</p>\n<p>By Googling I found out that symbolic tensors are tensors that do not directly hold values so the values are probably filled in later.</p>\n<p>This means that <code>Model() (__call__)</code> does its computation asynchronous, timing the function gives us a false value. This can be &quot;fixed&quot; by stopping the time after printing/using every output or just using the <code>predict()</code> method to avoid this completely.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9798}"
189,51859776,"{'items': [{'owner': {'reputation': 85288, 'user_id': 2097240}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1534341620, 'answer_id': 51860193, 'question_id': 51859776, 'body': '<p>If you\'re not using <code>import tensorflow</code> and its functions, there is absolutely no problem. </p>\n\n<p>The code is perfect and that\'s it. </p>\n\n<p>Just <code>import keras.backend as K</code></p>\n\n<p>Example <code>rounded = K.round(x)</code></p>\n\n<hr>\n\n<p>This is Keras independent documentation: <a href=""https://keras.io/layers/core/#lambda"" rel=""nofollow noreferrer"">https://keras.io/layers/core/#lambda</a></p>\n'}, {'owner': {'reputation': 5229, 'user_id': 9962955}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1534342867, 'answer_id': 51860536, 'question_id': 51859776, 'body': ""<p>There is no <em>requirement</em> to use <code>tf.keras.backend</code> as such. The function that you give to keras.layers.Lambda() can do anything you want with the input tensor.</p>\n\n<p>However, most 'default python packages' are simply not able to work with a Tensor object (e.g., as you noted in your comment, <code>round(x)</code> won't work on it).</p>\n\n<p>You <strong>can</strong> use most of the Python language constructs on a tensor <code>x</code> (such as <code>x*2</code>, or <code>x+y</code>, etc) - the tensor objects implement those. Likewise, you can call some 'regular' python libraries, as long as they use only operations that are supported by tensors. For everything else, you will need to use either methods of the tensor object or appropriate Keras library functions - or write your own.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9798}"
190,46885191,"{'items': [{'owner': {'reputation': 9, 'user_id': 13105109}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1592111870, 'answer_id': 62368626, 'question_id': 46885191, 'body': '<p>Just use tf.shape(X_batch)[0]  when you need train_batch_size</p>\n'}, {'owner': {'reputation': 1033, 'user_id': 4315914}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1533259798, 'answer_id': 51664153, 'question_id': 46885191, 'body': '<p>You can use the following code to calculate the output shape parameter for <strong>tf.nn.conv2d_transpose</strong> based on the input to this layer (<strong>input</strong>) and the number of outputs from this layer (<strong>num_outputs</strong>). Of course, you have the filter size, padding, stride, and data_format.</p>\n\n<pre class=""lang-py prettyprint-override""><code>def calculate_output_shape(input, filter_size_h, filter_size_w, \n    stride_h, stride_w, num_outputs, padding=\'SAME\', data_format=\'NHWC\'):\n\n    #calculation of the output_shape:\n    if data_format == ""NHWC"":\n        input_channel_size = input.get_shape().as_list()[3]\n        input_size_h = input.get_shape().as_list()[1]\n        input_size_w = input.get_shape().as_list()[2]\n        stride_shape = [1, stride_h, stride_w, 1]\n        if padding == \'VALID\':\n            output_size_h = (input_size_h - 1)*stride_h + filter_size_h\n            output_size_w = (input_size_w - 1)*stride_w + filter_size_w\n        elif padding == \'SAME\':\n            output_size_h = (input_size_h - 1)*stride_h + 1\n            output_size_w = (input_size_w - 1)*stride_w + 1\n        else:\n            raise ValueError(""unknown padding"")\n\n        output_shape = tf.stack([tf.shape(input)[0], \n                            output_size_h, output_size_w, \n                            num_outputs])\n    elif data_format == ""NCHW"":\n        input_channel_size = input.get_shape().as_list()[1]\n        input_size_h = input.get_shape().as_list()[2]\n        input_size_w = input.get_shape().as_list()[3]\n        stride_shape = [1, 1, stride_h, stride_w]\n        if padding == \'VALID\':\n            output_size_h = (input_size_h - 1)*stride_h + filter_size_h\n            output_size_w = (input_size_w - 1)*stride_w + filter_size_w\n        elif padding == \'SAME\':\n            output_size_h = (input_size_h - 1)*stride_h + 1\n            output_size_w = (input_size_w - 1)*stride_w + 1\n        else:\n            raise ValueError(""unknown padding"")\n\n        output_shape = tf.stack([tf.shape(input)[0], \n                                output_size_h, output_size_w, num_outputs])\n    else:\n        raise ValueError(""unknown data_format"")\n\n    return output_shape\n</code></pre>\n'}, {'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1508752177, 'answer_id': 46886389, 'question_id': 46885191, 'body': '<p>You can use the dynamic shape of a reference tensor, instead of the static one.</p>\n\n<p>Usually, wehn you use the <code>conv2d_transpose</code> operation, your\'re ""upsampling"" a layer in order to obtain a certain shape of another tensor in your network.</p>\n\n<p>If, for instance, you want to replicate the shape of the <code>input_tensor</code> tensor, you can do something like:</p>\n\n<pre><code>import tensorflow as tf\n\ninput_tensor = tf.placeholder(dtype=tf.float32, shape=[None, 16, 16, 3])\n# static shape\nprint(input_tensor.shape)\n\nconv_filter = tf.get_variable(\n    \'conv_filter\', shape=[2, 2, 3, 6], dtype=tf.float32)\nconv1 = tf.nn.conv2d(\n    input_tensor, conv_filter, strides=[1, 2, 2, 1], padding=\'SAME\')\n# static shape\nprint(conv1.shape)\n\ndeconv_filter = tf.get_variable(\n    \'deconv_filter\', shape=[2, 2, 6, 3], dtype=tf.float32)\n\ndeconv = tf.nn.conv2d_transpose(\n    input_tensor,\n    filter=deconv_filter,\n    # use tf.shape to get the dynamic shape of the tensor\n    # know at RUNTIME\n    output_shape=tf.shape(input_tensor),\n    strides=[1, 2, 2, 1],\n    padding=\'SAME\')\nprint(deconv.shape)\n</code></pre>\n\n<p>The program outputs:</p>\n\n<pre><code>(?, 16, 16, 3)\n(?, 8, 8, 6)\n(?, ?, ?, ?)\n</code></pre>\n\n<p>As you can see, the last shape is completely unknown at compile time, because I\'m setting the output shape of <code>conv2d_transpose</code> with the result of the <a href=""https://www.tensorflow.org/api_docs/python/tf/shape"" rel=""nofollow noreferrer""><code>tf.shape</code></a> operation, that returns and thus its values can change at runtime.</p>\n'}, {'owner': {'reputation': 5966, 'user_id': 1190882}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1508749169, 'answer_id': 46885439, 'question_id': 46885191, 'body': ""<p>You can use value of -1 to substitute the exact value of <code>batch_size</code>. Consider the below example whereby I convert variable batch sized input tensor of shape (16, 16, 3) to (32, 32, 6).</p>\n\n<pre><code>import tensorflow as tf\n\ninput_tensor = tf.placeholder(dtype = tf.float32, shape = [None, 16, 16, 3])\nprint (input_tensor.shape)\n\nmy_filter = tf.get_variable('filter', shape = [2, 2, 6, 3], dtype = tf.float32)\nconv = tf.nn.conv2d_transpose(input_tensor,\n                              filter = my_filter,\n                              output_shape = [-1, 32, 32, 6],\n                              strides = [1, 2, 2, 1],\n                              padding = 'SAME')\nprint (conv.shape)\n</code></pre>\n\n<p>Will Output you:</p>\n\n<pre><code>(?, 16, 16, 3)\n(?, 32, 32, 6)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9793}"
191,46752071,"{'items': [{'owner': {'reputation': 9284, 'user_id': 86432}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1508201006, 'answer_id': 46780877, 'question_id': 46752071, 'body': '<p>Ultimately it wasn\'t necessary to convert my text representation into sparse vectors in my <code>input_fn</code>. Instead I had to tell the model to expect an input of an array of strings, which it understands how to convert into a ""bag of words"" or n-hot vector and how to embed as dense vectors.</p>\n\n<pre><code>import tensorflow as tf\nimport tempfile\nimport os\nfrom collections import namedtuple\n\nGameRecord = namedtuple(\'GameRecord\', \'team_0 team_1 game_map winner\')\ndef parse(line):\n    parts = line.rstrip().split(""\\t"")\n    return GameRecord(\n        game_map = parts[1], \n        team_0 = parts[2].split("",""), \n        team_1 = parts[3].split("",""), \n        winner = int(parts[4]))\n\ndef conjugate(record):\n    return GameRecord(\n        team_0 = record.team_1, \n        team_1 = record.team_0, \n        game_map = record.game_map, \n        winner = 0 if record.winner == 1 else 1)\n\ndef make_input_fn(filename, batch_size=128, shuffle = True, add_conjugate_games = True, epochs=1):\n    def _fn():\n        records = []\n        with open(filename, ""r"") as raw:\n            i = 0\n            for line in raw:\n                record = parse(line)\n                records.append(record)\n                if add_conjugate_games:\n                    records.append(conjugate(record))\n\n        team_0s = tf.constant(list(map(lambda r: r.team_0, records)))\n        team_1s = tf.constant(list(map(lambda r: r.team_1, records)))\n        maps    = tf.constant(list(map(lambda r: r.game_map, records)))\n        winners = tf.constant(list(map(lambda r: [r.winner], \n\n        return {\n                    ""team_0"": team_0s,\n                    ""team_1"": team_1s,\n                    ""game_map"": maps,\n                }, winners\n\n    return _fn\n\nteam_0 = tf.feature_column.embedding_column(\n    tf.feature_column.categorical_column_with_vocabulary_list(""team_0"", source.heroes_array), dimension=len(source.heroes_array))\nteam_1 = tf.feature_column.embedding_column(\n    tf.feature_column.categorical_column_with_vocabulary_list(""team_1"", source.heroes_array), dimension=len(source.heroes_array))\ngame_map = tf.feature_column.embedding_column(\n    tf.feature_column.categorical_column_with_vocabulary_list(""game_map"", source.maps_array), dimension=len(source.maps_array))\n\nmodel_dir = ""DNNClassifierModel_00""\nos.mkdir(model_dir)\nm = tf.estimator.DNNClassifier(\n    model_dir=model_dir,\n    hidden_units = [1024, 512, 256], \n    feature_columns=[team_0, team_1, game_map])\n\ndef main():\n        m.train(input_fn=make_input_fn(""training.txt""))\n        results = m.evaluate(input_fn=make_input_fn(""validation.txt""))\n        print(""model directory = %s"" % model_dir)\n        for key in sorted(results):\n            print(""%s: %s"" % (key, results[key]))\n\nif __name__ == ""__main__"":\n    main()\n</code></pre>\n\n<p>Note that this code isn\'t perfect yet. I need to add in batching. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9793}"
192,56799561,"{'items': [{'owner': {'reputation': 479, 'user_id': 1327630}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1616672765, 'answer_id': 66798841, 'question_id': 56799561, 'body': '<p>This code snippet would do</p>\n<pre class=""lang-py prettyprint-override""><code>for k, v in tf.keras.activations.__dict__.items():\n    if not k[0].isupper() and not k[0] == &quot;_&quot;:\n        print(k)\n</code></pre>\n<pre><code>deserialize\nelu\nexponential\ngelu\nget\nhard_sigmoid\nlinear\nrelu\nselu\nserialize\nsigmoid\nsoftmax\nsoftplus\nsoftsign\nswish\ntanh\n</code></pre>\n'}, {'owner': {'reputation': 9218, 'user_id': 867889}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1561701422, 'answer_id': 56801602, 'question_id': 56799561, 'body': '<p>Sadly, this is not documented and there is no single place storage of such string constants.</p>\n\n<p>When keras receives <code>tf.keras.layers.Dense(10, activation=\'elu\')</code> it will go into the activation function module and will literally call activation function by its name if it is present there. So, <code>activation=\'elu\'</code> will be converted into  <code>tf.keras.activations.elu()</code>.</p>\n\n<p>At the same time, it means that you can use any activation function name as a string.</p>\n\n<p>You can take a look at the code <a href=""https://stackoverflow.com/questions/56176475/in-keras-is-there-documentation-describing-the-string-name-to-class-mappings-fo/56179296#56179296"">suggested here</a> to workaround this problem.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9793}"
193,60778828,"{'items': [{'owner': {'reputation': 1824, 'user_id': 13071836}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1585717999, 'answer_id': 60964083, 'question_id': 60778828, 'body': '<p>Based on the <strong>documentation</strong> of <code>tf.py_function</code> you cannot compute the higher <code>&gt;1st</code> derivative. This function allows expressing computations in a <strong>TensorFlow graph</strong> as <strong>Python functions</strong>. In particular, it wraps a Python function <code>func</code> in a <strong>once-differentiable</strong> TensorFlow operation that executes it with eager execution enabled.  Meaning you can only differentiate it <strong>once</strong>.</p>\n\n<p>If you want to get <strong>higher-order derivatives</strong>, you can just use  <strong>gradient</strong> function normally in <strong>Tensorflow 2.1.0</strong>.</p>\n\n<p><strong>Modified Code:</strong></p>\n\n<pre><code>import tensorflow as tf     # Tensorflow 2.1.0\nimport os\n\n\ndef huber(x, delta):\n  if tf.abs(x) &lt;= delta:\n    return x*x/ (2*delta)  ## x^2  / 2*delta  \n                           ## x / delta   - 1st derivative\n                           ## 1 / delta   - 2nd derivative\n  else:\n    return tf.abs(x)-delta/2.0 \n\n\nx = tf.constant ([2.0 ])         \nz = tf.constant ([1.0 ])\n\nwith tf.GradientTape (persistent=True) as g0:\n  g0.watch(x)\n\n  with tf.GradientTape (persistent=True) as g :\n    g.watch (x)\n    # y = tf.py_function(func=huber, inp=[x, 3.0] , Tout=tf.float32  )  # once-differentiable\n    y= huber(x, 3.0)\n  dy_dx = g.gradient(y, x)\n  aa = tf.reduce_sum(dy_dx *z)\n\naa_x = g0.gradient(aa, x)\n\nprint (dy_dx)  #  tf.Tensor([0.6666667], shape=(1,), dtype=float32)\nprint (aa_x)   #  tf.Tensor([0.33333334], shape=(1,), dtype=float32)\n</code></pre>\n\n<p>You can read more about <code>tf.py_wrap</code> function in this <a href=""https://www.tensorflow.org/api_docs/python/tf/py_function"" rel=""nofollow noreferrer"">link</a>. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9793}"
194,54985037,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1551710049, 'answer_id': 54985390, 'question_id': 54985037, 'body': ""<p>You simply need to convert the label to its one-hot representation (that's the representation you described):</p>\n\n<pre><code>label = tf.cast(parsed_features['label'], tf.int32)\nnum_classes = 2\nlabel = tf.one_hot(label, num_classes)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9793}"
195,62449998,"{'items': [{'owner': {'reputation': 2021, 'user_id': 6510273}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1592485068, 'answer_id': 62450533, 'question_id': 62449998, 'body': '<p>It seems that they are the same</p>\n\n<p>cudos to Mohsin hasan <a href=""https://stackoverflow.com/a/57482004/6510273"">answer</a></p>\n\n<blockquote>\n  <p>In the past, when I had to convert tf.keras model to keras model, I\n  did following:</p>\n  \n  <ol>\n  <li>Train model in <code>tf.keras</code></li>\n  <li>Save only the weights <code>tf_model.save_weights(""tf_model.hdf5"")</code></li>\n  <li>Make Keras model architecture using all layers in keras (same as the tf keras one)</li>\n  <li>load weights by layer names in keras: <code>keras_model.load_weights(by_name=True)</code></li>\n  </ol>\n  \n  <p>This seemed to work for me. Since, I was using out of box architecture\n  (DenseNet169), I had to very less work to replicate tf.keras network\n  to keras.</p>\n</blockquote>\n\n<p>And the <a href=""https://stackoverflow.com/a/55984420/6510273"">answer</a> from Alex Cohn</p>\n\n<blockquote>\n  <p>tf.keras HDF5 model and Keras HDF5 models are not different things,\n  except for inevitable software version update synchronicity. This is\n  what the official docs say:</p>\n  \n  <blockquote>\n    <p>tf.keras is TensorFlow\'s implementation of the Keras API specification. This is a high-level API to build and train models that\n    includes first-class support for TensorFlow-specific functionality</p>\n  </blockquote>\n  \n  <p>If the convertor can convert a keras model to tf.lite, it will deliver\n  same results. But tf.lite functionality is more limited than tf.keras.\n  If this feature set is not enough for you, you can still work with\n  tensorflow, and enjoy its other advantages.</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9788}"
196,49686860,"{'items': [{'owner': {'reputation': 485, 'user_id': 2697831}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1523017884, 'answer_id': 49692883, 'question_id': 49686860, 'body': ""<p>There were actually many things wrong with my first example:</p>\n\n<p>tf.Print is not executed if the operator has no side effect (ie i = tf.Print())</p>\n\n<p>If the boolean, is a scalar, it is then a rank-0 tensor, not a rank-1 tensor. ...</p>\n\n<p>Here is the code that works:</p>\n\n<pre><code>import tensorflow as tf\n\n#nb_iter = tf.constant(value=10)\n#This solution does not work at all\nnb_iter = tf.get_variable('nb_iter', shape=(), dtype=tf.int32, trainable=False,\n                          initializer=tf.zeros_initializer())\nnb_iter = tf.add(nb_iter,10)\ni = tf.get_variable('i', shape=(), trainable=False,\n                     initializer=tf.zeros_initializer(), dtype=nb_iter.dtype)\nv = tf.get_variable('v', shape=(10), trainable=False,\n                     initializer=tf.random_uniform_initializer, dtype=tf.float32)\n\nloop_condition = lambda i: tf.less(i, nb_iter)\ndef loop_body(i):\n    i = tf.Print(i, [v[i]], message='Another vector element: ')\n    return [tf.add(i, 1)]\n\ni = tf.while_loop(loop_condition, loop_body, [i])\n\ninitializer_op = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(initializer_op)\n    res = sess.run(i)\n    print('res is now {}'.format(res))\n</code></pre>\n\n<p>output:</p>\n\n<pre><code>Another vector element: [0.203766704]\nAnother vector element: [0.692927241]\nAnother vector element: [0.732221603]\nAnother vector element: [0.0556482077]\nAnother vector element: [0.422092319]\nAnother vector element: [0.597698212]\nAnother vector element: [0.92387116]\nAnother vector element: [0.590101123]\nAnother vector element: [0.741415381]\nAnother vector element: [0.514917374]\nres is now 10\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9788}"
197,51407186,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9788}"
198,45678931,"{'items': [{'owner': {'reputation': 37, 'user_id': 7580897}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1510774438, 'answer_id': 47315820, 'question_id': 45678931, 'body': '<p>There are several things you need to consider to preserve the ordering of images and labels. </p>\n\n<p>let\'s say we need a function that gives us images and labels. </p>\n\n<pre><code>def _get_test_images(_train=False):\n\n\n""""""\nGets the test images and labels as a batch\n\nInputs:\n======\n_train      : Boolean if images are from training set\nrandom_crop     : Boolean if random cropping is allowed\nrandom_flip         : Boolean if random horizontal flip is allowed\ndistortion      : Boolean if distortions are allowed\n\nOutputs:\n========\nimages_batch    : Batch of images containing BATCH_SIZE images at a time\nlabel_batch     : Batch of labels corresponding to the images in images_batch\nidx         : Batch of indexes of images\n""""""\n\n#get images and labels\n_,_img_names,_img_class,index= _get_list(_train = _train)\n\n#total number of distinct images used for train will be equal to the images\n#fed in tf.train.slice_input_producer as _img_names\n\nimg_path,label,idx = tf.train.slice_input_producer([_img_names,_img_class,index],shuffle=False)\n\nimg_path,label,idx = tf.convert_to_tensor(img_path),tf.convert_to_tensor(label),tf.convert_to_tensor(idx)\nimg_path = tf.cast(img_path,dtype=tf.string)\n\n#read file \nimage_file = tf.read_file(img_path)\n\n#decode jpeg/png/bmp\n#tf.image.decode_image won\'t give shape out. So it will give error while resizing\nimage = tf.image.decode_jpeg(image_file)\n\n#image preprocessing\nimage = tf.image.resize_images(image, [IMG_DIM,IMG_DIM])\n\nfloat_image = tf.cast(image,dtype=tf.float32)\n\n#subtracting mean and divide by standard deviation\nfloat_image = tf.image.per_image_standardization(float_image)\n\n#set the shape\nfloat_image.set_shape(IMG_SIZE)\nlabels_original = tf.cast(label,dtype=tf.int32)\nimg_index = tf.cast(idx,dtype=tf.int32)\n\n#parameters for shuffle\nbatch_size = BATCH_SIZE\nmin_fraction_of_examples_in_queue = 0.3\nnum_preprocess_threads = 1\nnum_examples_per_epoch = MAX_TEST_EXAMPLE\nmin_queue_examples = int(num_examples_per_epoch *\n                       min_fraction_of_examples_in_queue)\n\nimages_batch, label_batch,idx = tf.train.batch(\n        [float_image,label,img_index],\n        batch_size=batch_size,\n        num_threads=num_preprocess_threads,\n        capacity=min_queue_examples + 3 * batch_size)\n\n# Display the training images in the visualizer.\ntf.summary.image(\'images\', images_batch)\n\nreturn images_batch, label_batch,idx\n</code></pre>\n\n<p>Here,<code>tf.train.slice_input_producer([_img_names,_img_class,index],shuffle=False)</code> is an interesting thing to look at where if you put <code>shuffle=True</code> it will shuffle all three arrays in coordination. </p>\n\n<p>Second thing is, <code>num_preprocess_threads</code>. As long as you are using single threads for dequeue operation, batches will come out in a deterministic way. But more than one threads will shuffle the arrays randomly. for example for image 0001.jpg if True label is 1 you might get 2 or 4. Once its dequeue it is in tensor form. <code>tf.nn.softmax_cross_entropy_with_logits</code> shouldn\'t have problem with such tensors. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9788}"
199,62767445,"{'items': [{'owner': {'reputation': 1697, 'user_id': 2301843}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1594092993, 'answer_id': 62767756, 'question_id': 62767445, 'body': '<p>If there is no <code>initial_state</code>, dynamic_rnn will try to call <code>cell.get_initial_state(inputs=None, batch_size=batch_size, dtype=dtype)</code> to set <code>initial_state</code>, and if <code>cell.get_initial_state</code> is not defined, <code>cell.zero_state</code> is used. See the source code of dynamic_rnn <a href=""https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/ops/rnn.py#L671"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/ops/rnn.py#L671</a></p>\n<p>For most default cell implementations, <code>cell.get_initial_state</code> function is defined the same as <code>cell.zero_state</code> if <code>inputs is none</code>. For example <a href=""https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/ops/rnn_cell_impl.py#L281-L309"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/ops/rnn_cell_impl.py#L281-L309</a></p>\n<p>In conclusion, <code>cell.zero_state</code> is used whether you set the <code>initial_state</code> or not. But you can build your own cell and re-implement <code>cell.get_initial_state</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9788}"
200,55308630,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9783}"
201,68782423,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1667918884, 'answer_id': 74362664, 'question_id': 68782423, 'body': '<p>For the benefit of the community posting the comments of @<strong>Frightera</strong> and @<strong>RishabhGupta</strong>  in the Answer section.</p>\n<p>You can use <code>tf.squeeze()</code>, which removes dimensions of size 1 from the shape of a tensor like below</p>\n<pre><code>train_data.map(lambda x: tf.squeeze(x))\n</code></pre>\n<p>OR</p>\n<p>You can use <code>tf.reshape()</code>, which reshapes a tensor like below</p>\n<pre><code>tf.reshape(train_features_batch,shape=(10,))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9782}"
202,60047705,"{'items': [{'owner': {'reputation': 66, 'user_id': 13545353}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1589569758, 'answer_id': 61826667, 'question_id': 60047705, 'body': '<p>Maybe you find this helpful:</p>\n\n<p>I needed to compute the jacobian of an arbitrary function many, many times. My problem was that I was using <code>GradientTape</code> inappropriately, but the code I posted might help you or give you some insight. I posted a self contained example of calculating the jacobian using both the session based <code>tf.gradient()</code> function and the modern <code>GriadientTape</code> approach. With help, I got them to run within the same order of magnitude of each other.</p>\n\n<ul>\n<li>If your question is focused on trying to reuse the intermediate calculations between calls for a speed boost, then I think Nick\'s answer is more applicable.</li>\n<li>If your question is focused on trying to make GradientTape as fast as a static graph, then make sure you wrap it in <code>@tf.function</code> since it does just that.</li>\n</ul>\n\n<p>See my question: <a href=""https://stackoverflow.com/questions/61810094/abysmal-tf-gradienttape-performance-compared-to-tf-gradients-for-computing-jac"">Abysmal tf.GradientTape performance compared to tf.gradients() for computing jacobians</a></p>\n'}, {'owner': {'reputation': 611, 'user_id': 12765337}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1581004457, 'answer_id': 60098915, 'question_id': 60047705, 'body': '<p><strong>Am I correct in assuming that TensorFlow builds and stores (at least parts of) the analytical gradients needed to compute the Jacobian?</strong></p>\n\n<p>Nope - I think you must be misunderstanding something about automatic differentiation. </p>\n\n<p>While each elementary operation in tf ""knows"" about the analytic derivative of it\'s output with respect to the input, when the actual gradient or Jacobian values are computed, numerical values of adjoints (derivatives of the output) are passed to the operation on the backwards pass, and then more numerical values are computed using the analytic formula for each elementary operation and the chain rule. </p>\n\n<p><strong>And if so, is there a way to save this analytical gradient and re-evaluate the Jacobian with new inputs without having to reconstruct it via the GradientTape method?</strong></p>\n\n<p>Nope. If you want to compute the gradient or jacobian on a new input, you\'ll need to perform the whole calculation again. There is no way around this for deep neural networks. </p>\n\n<p>By the way, if you are taking gradients of the loss function of your neural network with respect to the parameters of you network, the time to compute the gradients will be O(1) the cost of computing the loss itself. This is backpropagation, and is part of the beauty of reverse-mode automatic differentiation. But if your network has N outputs, and you want to compute the full jacobian of your network, that will cost O(N) the time of computing the outputs of your network. That might be why it\'s so expensive to compute a Jacobian.</p>\n\n<p>For example, if you\'re training a network on MNIST, and your network has 10 outputs which you combine into a single loss function, computing the gradients of the loss function will take O(1) time, but computing the jacobian of the 10 outputs with respect to the parameters will take O(10) time. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9782}"
203,68319579,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1625848781, 'answer_id': 68320186, 'question_id': 68319579, 'body': '<p>When saving a <strong>complete</strong> Keras model (with its own structure in the <code>.h5</code> file) the <code>tf.keras.Model</code> object is <strong>completely</strong> serialized as a JSON: this means that every property of the model should be JSON serializable.</p>\n<p>NOTE: <code>tf.Tensor</code> are NOT JSON serializable.</p>\n<p>When using this multi optimizer from <code>tfa</code> you\'re adding properties to the model that the JSON serializer will try (and fail) to serialize.</p>\n<p>In particular there\'s this attribute <code>gv</code> that I think it comes from the custom optimizer used.</p>\n<pre><code>\'gv\': [(&lt;tf.Tensor \'gradient_tape/model/dense/Tensordot/MatMul/MatMul:0\' shape=(1, 1) dtype=float32&gt;, &lt;tf.Variable \'dense/kernel:0\' shape=(1, 1) dtype=float32, numpy=array([[-0.55191684]], dtype=float32)&gt;), (&lt;tf.Tensor \'gradient_tape/model/dense/BiasAdd/BiasAddGrad:0\' shape=(1,) dtype=float32&gt;, &lt;tf.Variable \'dense/bias:0\' shape=(1,) dtype=float32, numpy=array([-0.23444518], dtype=float32)&gt;)]},\n</code></pre>\n<p>All this <code>tf.Tensor</code> are not JSON serializable, that\'s why it fails.</p>\n<p>The only option is to do not save the model <strong>completely</strong> (with all its attributes, which should be defined as Keras layers, but in this case is not possible) but saving only the model parameters.</p>\n<p>In short, if you add the <code>save_weights_only=True</code> to the callback your training (and checkpoint of the weights) will work fine.</p>\n<pre class=""lang-py prettyprint-override""><code>model_checkpoint = ke.callbacks.ModelCheckpoint(\n    &quot;best_model.h5&quot;,\n    monitor=&quot;val_mse&quot;,\n    mode=&quot;min&quot;,\n    save_best_only=True,\n    verbose=1,\n    save_weights_only=True,\n)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9782}"
204,44478812,"{'items': [{'owner': {'reputation': 36237, 'user_id': 5352399}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': True, 'score': 0, 'creation_date': 1497149754, 'answer_id': 44479970, 'question_id': 44478812, 'body': '<h2><code>tf.nn.static_rnn</code> vs. <code>tf.nn.dynamic_rnn</code></h2>\n\n<p>Internally, <code>tf.nn.static_rnn</code> creates an unrolled graph for a fixed RNN length. That means that, if you call <code>tf.nn.static_rnn</code> with inputs having 200 time-steps you are creating a static graph with 200 RNN steps. First, graph creation is slow. Second, youre unable to pass in longer sequences (> 200) than you\'ve originally specified.</p>\n\n<p><code>tf.nn.dynamic_rnn</code> solves this. It uses a <code>tf.while_loop</code> to dynamically construct the graph when it is executed. That means graph creation is faster and you can feed batches of variable size. </p>\n\n<h3>What about performance?</h3>\n\n<p>You may think the <code>tf.nn.static_rnn</code> is faster than its dynamic counterpart because it pre-builds the graph.</p>\n\n<blockquote>\n  <p>Please note, it is strongly encouraged to use <code>tf.nn.dynamic_rnn</code>.</p>\n</blockquote>\n\n<p>Reference: <a href=""http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/"" rel=""nofollow noreferrer"">http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9782}"
205,73365851,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9782}"
206,47319390,"{'items': [{'owner': {'reputation': 15976, 'user_id': 1667256}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1510791446, 'answer_id': 47319511, 'question_id': 47319390, 'body': '<p>I think you are right; <code>tf.test.TestCase</code> is being <a href=""https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/framework/test_util.py#L242"" rel=""nofollow noreferrer"">setup</a> to use fixed seed.</p>\n\n<pre><code>class TensorFlowTestCase(googletest.TestCase):\n# ...\ndef setUp(self):\n  self._ClearCachedSession()\n  random.seed(random_seed.DEFAULT_GRAPH_SEED)\n  np.random.seed(random_seed.DEFAULT_GRAPH_SEED)\n  ops.reset_default_graph()\n  ops.get_default_graph().seed = random_seed.DEFAULT_GRAPH_SEED\n</code></pre>\n\n<p>and \n<code>DEFAULT_GRAPH_SEED = 87654321</code> see <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/random_seed.py#L27"" rel=""nofollow noreferrer"">this</a> line in <code>tensorflow/tensorflow/python/framework/random_seed.py</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9777}"
207,64780641,"{'items': [{'owner': {'reputation': 1, 'user_id': 17797638}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1678430585, 'answer_id': 75692964, 'question_id': 64780641, 'body': '<p>I Create A custom Layer for check <code>Shape</code> , <code>Device</code> and <code>Dtype</code> of my <code>InputTensor</code> and i use it Like Tensorflow</p>\n<pre class=""lang-py prettyprint-override""><code>from torch.nn import Module\n\nclass Input(Module):\n\n    def __init__(self, shape : tuple, device=torch.device(\'cpu\'), dtype=torch.float32):\n        \n        super().__init__()\n\n        self.shape = shape\n        self.device = device\n        self.dtype = dtype\n\n    def forward(self, x):\n        tensor_shape = tuple(x.shape[1:])\n\n        if x.device != self.device:\n            raise ValueError(f&quot;Input tensor must be on device {self.device} but got device {x.device} instead&quot;)\n        if x.dtype != self.dtype:\n            raise ValueError(f&quot;Input tensor must have data type {self.dtype} but got data type {x.dtype} instead&quot;)\n        if tensor_shape != self.shape:\n            raise ValueError(f&quot;Input shape must be {self.shape} but got {tensor_shape} instead&quot;)\n        \n        return (x.to(self.device, self.dtype))\n</code></pre>\n<h3>Utilisation With Subclassing Module</h3>\n<pre class=""lang-py prettyprint-override""><code>from torch.nn import Module\nfrom torch.nn import Linear\nfrom torch.nn import ReLU, Sigmoid\nfrom torch import Tensor\n\nINPUT_FEATURES = X.shape[1]\n\n\nclass TestModel(Module):\n\n      def __init__(self):\n\n            super().__init__()\n\n            self.InputLayer = Input(shape=(INPUT_FEATURES,))\n            self.HiddenLayer = Linear(in_features=INPUT_FEATURES, \n                                      out_features=10)\n            self.ReLU = ReLU()\n            self.Sigmoid = Sigmoid()\n            self.OutputLayer = Linear(in_features=10,\n                                      out_features=1)\n      \n      def forward(self, x : Tensor):\n\n            x = self.InputLayer(x)\n            z = self.HiddenLayer(x)\n            a = self.ReLU(z)\n            z = self.OutputLayer(a)\n            output = self.Sigmoid(z)\n\n            return (output)\n</code></pre>\n<h3>Utilisation With Sequential</h3>\n<pre class=""lang-py prettyprint-override""><code>from torch.nn import Linear\nfrom torch.nn import ReLU, Sigmoid\nfrom torch.nn import Sequential\n\ndevice = torch.device(\'cuda\' if torch.cuda.is_available() else \'cpu\')\ndtype = torch.float32\n\nmodel = Sequential(\n            Input(shape=(2,), device=device, dtype=dtype),\n            Linear(2, 5),\n            ReLU(),\n            Linear(5, 1),\n            Sigmoid()\n)\n</code></pre>\n<p>I hope it helped ;)</p>\n'}, {'owner': {'reputation': 752, 'user_id': 9218531}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1605073023, 'answer_id': 64781026, 'question_id': 64780641, 'body': '<p>There\'s no equivalent in PyTorch to the Keras\' Input. All you have to do is pass on the inputs as a tensor to the PyTorch model.</p>\n<p>For eg: If you\'re working with a Conv net:</p>\n<pre class=""lang-py prettyprint-override""><code>\n# Keras Code\ninput_image = Input(shape=(32,32,3)) # An input image of 32x32x3 (HxWxC)\nfeature = Conv2D(16, activation=\'relu\', kernel_size=(3, 3))(input_image)\n</code></pre>\n<pre class=""lang-py prettyprint-override""><code># PyTorch code\ninput_tensor = torch.randn(1, 3, 32, 32) # An input tensor of shape BatchSizexChannelsxHeightxWidth\nfeature = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(2, 2))(input_tensor)\n</code></pre>\n<p>If it is a normal Dense layer:</p>\n<pre class=""lang-py prettyprint-override""><code># Keras\ndense_input = Input(shape=(1,))\nfeatures = Dense(100)(dense_input)\n</code></pre>\n<pre class=""lang-py prettyprint-override""><code># PyTorch\ninput_tensor = torch.tensor([10]) # A 1x1 tensor with value 10\nfeatures = nn.Linear(1, 100)(input_tensor)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9777}"
208,75639137,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9777}"
209,58112355,"{'items': [{'owner': {'reputation': 192841, 'user_id': 240443}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1569485983, 'answer_id': 58112468, 'question_id': 58112355, 'body': '<p>Lazy execution delays evaluation as much as possible. In context of TensorFlow, it will create a plan of execution (a graph) before it does anything, then when everything is ready, it will feed the input into the graph and calculate everything to return the output. <code>tf.constant</code> creates an execution node in the graph that will receive a constant value when the execution starts. You can compare lazy evaluation to a Rube Goldberg machine: you build the whole thing, then you drop a marble into it and watch the magic unfold.</p>\n\n<p>Eager execution evaluates immediately. In context of TensorFlow, it does not create a graph. <code>tf.constant</code> creates a constant, with a certain value, right then and there. If compared to the Rube Goldberg machine, you could imagine building the first part of the machine, drop the marble in, then stop it when the marble exits, before building the next part of the machine, and reintroducing the marble with the same position and velocity. :P</p>\n\n<p>TensorFlow is much more efficient in the lazy evaluation mode, but the eager mode is easier to develop and debug on.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9777}"
210,52744559,"{'items': [{'owner': {'reputation': 23, 'user_id': 9475497}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1539802231, 'answer_id': 52861719, 'question_id': 52744559, 'body': ""<p>Problem solved.</p>\n\n<p><code>grad_new = tf.multiply(grad, np.array([0,1]))</code> actually works quite well. It's the saver who mess up the code.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9773}"
211,39450992,"{'items': [{'owner': {'reputation': 26, 'user_id': 3513603}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1482995985, 'answer_id': 41374949, 'question_id': 39450992, 'body': '<p>Here you can create the tfrecords which is the special type of binary file format used by the tensorflow. As you mentioned you have the training images and the labels, you can easily create the TFrecords for training and validation.</p>\n\n<p>After creating the TFrecords, all you need to right is decode the images from the encoded TFrecords and give it to your model input. There you can select the batch size and all.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9773}"
212,64096624,"{'items': [{'owner': {'reputation': 21403, 'user_id': 10375049}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1601277549, 'answer_id': 64097563, 'question_id': 64096624, 'body': ""<p>they are the same, you can test it on your own</p>\n<pre><code># generate data\nx = np.random.uniform(0,1, (5,20)).astype('float32')\n\n# 1st option\nX = Dense(10, activation=tf.nn.softmax)\nA = X(x)\n\n# 2nd option\nw,b = X.get_weights()\nB = Softmax()(tf.matmul(x,w) + b)\n\ntf.reduce_all(A == B)\n# &lt;tf.Tensor: shape=(), dtype=bool, numpy=True&gt;\n</code></pre>\n<p>Pay attention also when using <code>tf.keras.layers.Softmax</code>, it doesn't require to specify the units, it's a simple activation</p>\n<p>by default, the softmax is computed on the -1 axis, you can change this if you have tensor outputs &gt; 2D and want to operate softmax on other dimensionalities. You can change this easily in the second option</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9773}"
213,68788593,"{'items': [{'owner': {'reputation': 11, 'user_id': 18963568}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1651054892, 'answer_id': 72027125, 'question_id': 68788593, 'body': '<pre><code>W1 =  tf.Variable(initializer(shape=[25, 12288]))\nb1 = tf.Variable(initializer(shape=[25, 1]))\nW2 = tf.Variable(initializer(shape=[12, 25]))\nb2 = tf.Variable(initializer(shape=[12, 1]))\nW3 = tf.Variable(initializer(shape=[6, 12]))\nb3 = tf.Variable(initializer(shape=[6, 1]))\n</code></pre>\n<p>should be like this</p>\n'}, {'owner': {'reputation': 145, 'user_id': 5385597}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1629040849, 'answer_id': 68792881, 'question_id': 68788593, 'body': '<p>It should be <code>W1 = tf.Variable(initializer(shape=(25, 12288)))</code>. Notice the round bracket</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9773}"
214,50340211,"{'items': [{'owner': {'reputation': 4810, 'user_id': 4320693}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1526339579, 'answer_id': 50340263, 'question_id': 50340211, 'body': '<p>This is exactly what <a href=""https://www.tensorflow.org/api_docs/python/tf/where"" rel=""nofollow noreferrer""><code>tf.where()</code></a> is for. This code (tested):</p>\n\n\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\n\ndef func_for_event1(t):\n    return t + 1\n\ndef func_for_event0(t):\n    return t - 1\n\ntime = tf.placeholder(tf.float32, shape=[None])  # [3.2, 4.2, 1.0, 1.05, 1.8]\nevent = tf.placeholder(tf.int32, shape=[None])  # [0, 1, 1, 0, 1]\n\nresult = tf.where( tf.equal( 1, event ), func_for_event1( time ), func_for_event0( time ) )\n# result: [2.2, 5.2, 2.0, 0.05, 2.8]\n# For example, 3.2 should be sent to func_for_event0 because the first element in event is 0.\n\nwith tf.Session() as sess:\n    res = sess.run( result, feed_dict = {\n        time : np.array( [3.2, 4.2, 1.0, 1.05, 1.8] ),\n        event : np.array( [0, 1, 1, 0, 1] )\n    } )\n    print ( res )\n</code></pre>\n\n<p>outputs:</p>\n\n<blockquote>\n  <p>[2.2        5.2        2.         0.04999995 2.8       ]</p>\n</blockquote>\n\n<p>as desired.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9773}"
215,44226932,"{'items': [{'owner': {'reputation': 438, 'user_id': 8003239}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': False, 'score': 11, 'creation_date': 1523425239, 'answer_id': 49767312, 'question_id': 44226932, 'body': '<p>Let\'s see the sample code in <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/"" rel=""noreferrer"">TensorFlow API(r1.7)</a></p>\n\n<p>For <code>depthwise_conv2d</code>,</p>\n\n<pre><code>output[b, i, j, k * channel_multiplier + q] =\n    sum_{di, dj} input[b, strides[1] * i + rate[0] * di,\n                          strides[2] * j + rate[1] * dj, k] *\n                 filter[di, dj, k, q]\n</code></pre>\n\n<p>filter is <code>[filter_height, filter_width, in_channels, channel_multiplier]</code></p>\n\n<p>For <code>conv2d</code>,</p>\n\n<pre><code>output[b, i, j, k] =\n    sum_{di, dj, q} input[b, strides[1] * i + di,\n                             strides[2] * j + dj, q] *\n                    filter[di, dj, q, k]\n</code></pre>\n\n<p>filter is <code>[filter_height, filter_width, in_channels, out_channels]</code></p>\n\n<p>Focusing on <code>k</code> and <code>q</code>, we can see the difference shown above.</p>\n\n<p>The default format is <code>NHWC</code>, where <code>b</code> is batch size, <code>(i, j)</code> is a coordinate in feature map.</p>\n\n<p>(Note that <code>k</code> and <code>q</code> refer to different things in this two functions.)</p>\n\n<ol>\n<li>For <code>depthwise_conv2d</code>, <code>k</code> refers to an input channel and <code>q</code>, <code>0 &lt;= q &lt; channel_multiplier</code>, refers to an output channel. Each input channel <code>k</code> is expanded to <code>k*channel_multiplier</code> with different filters <code>[filter_height, filter_width, channel_multiplier]</code>. It does not conduct cross-channel operation, in some literature, it is referred as <code>channel-wise spatial convolution</code>. Above process can be concluded as applying kernels of each filter separately to each channel and concatenating the outputs.</li>\n<li>For <code>conv2d</code>, <code>k</code> refers to an output channel and <code>q</code> refers to an input channel. It sums up among all input channels, meaning that each output channel <code>k</code> is associated with all <code>q</code> input channels by a <code>[filter_height, filter_width, in_channels]</code> filter.</li>\n</ol>\n\n<p>For example, </p>\n\n<pre><code>input_size: (_, 14, 14, 32)\nfilter of conv2d: (3, 3, 32, 64)\nparams of conv2d filter: 3x3x32x64\nfilter of depthwise_conv2d: (3, 3, 32, 64)\nparams of depthwise_conv2d filter: 3x3x32x64\n</code></pre>\n\n<p>suppose stride = 1 with padding, then</p>\n\n<pre><code>output of conv2d: (_, 14, 14, 64)\noutput of depthwise_conv2d: (_, 14, 14, 32*64)\n</code></pre>\n\n<p>Some more insights:</p>\n\n<ul>\n<li>Standard convolution operation can be split into 2 steps: depthwise convolution and reduction (sum).</li>\n<li>Depthwise Convolution is equivalent to setting the number of group to input channel in Group Convolution.</li>\n<li>Usually, <code>depthwise_conv2d</code> is followed by <code>pointwise_conv2d</code>(a 1x1 convolution for reduction purpose), making a <code>separable_conv2d</code>. Check <a href=""https://arxiv.org/pdf/1610.02357.pdf"" rel=""noreferrer"">Xception</a>, <a href=""https://arxiv.org/pdf/1704.04861.pdf"" rel=""noreferrer"">MobileNet</a> for more details.</li>\n</ul>\n'}, {'owner': {'reputation': 127, 'user_id': 3431997}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1517294287, 'answer_id': 48515344, 'question_id': 44226932, 'body': '<p>The tf.nn.depthwise_conv2d means using <strong>N</strong> different filters for each input channel. The output will have <strong>N * channel_multiplier</strong> different output channels. Run the code and you will find out.</p>\n\n<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">\r\n<div class=""snippet-code"">\r\n<pre class=""snippet-code-html lang-html prettyprint-override""><code>import tensorflow as tf\r\nimport numpy as np\r\n# input image with 10x10 shape for 3 channels\r\n# filter with 10x10 shape for each input channel\r\n\r\nN_in_channel = 3\r\nN_out_channel_mul = 8\r\nx = tf.random_normal([1, 10, 10, N_in_channel])\r\nf = tf.random_normal([10, 10, N_in_channel, N_out_channel_mul])\r\ny = tf.nn.depthwise_conv2d(x, f, strides=[1, 1, 1, 1], padding=""VALID"", data_format=""NHWC"")\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n\r\nx_data, f_data, y_conv = sess.run([x, f, y])\r\n\r\ny_s = np.squeeze(y_conv)\r\nfor i in range(N_in_channel):\r\n    for j in range(N_out_channel_mul):\r\n        print(""np: %f, tf:%f"" % (np.sum(x_data[0, :, :, i] * f_data[:, :, i, j]), y_s[i * N_out_channel_mul + j]))</code></pre>\r\n</div>\r\n</div>\r\n</p>\n'}, {'owner': {'reputation': 358, 'user_id': 7030826}, 'down_vote_count': 0, 'up_vote_count': 23, 'is_accepted': True, 'score': 23, 'creation_date': 1500052567, 'answer_id': 45108482, 'question_id': 44226932, 'body': '<p>I am no expert on this, but as far as I understand the difference is this:</p>\n\n<p>Lets say you have an input colour image with length 100, width 100. So the dimensions are 100x100x3. For both examples we use the same filter of width and height 5. Lets say we want the next layer to have a depth of 8.</p>\n\n<p>In tf.nn.conv2d you define the kernel shape as [width, height, in_channels, out_channels]. In our case this means the kernel has shape [5,5,3,out_channels].\nThe weight-kernel that is strided over the image has a shape of 5x5x3, and it is strided over the whole image 8 times to produce 8 different feature maps.</p>\n\n<p>In tf.nn.depthwise_conv2d you define the kernel shape as [width, height, in_channels, channel_multiplier]. Now the output is produced differently. Separate filters of 5x5x1 are strided over each dimension of the input image, one filter per dimension, each producing one feature map per dimension. So here, a kernel size [5,5,3,1] would produce an output with depth 3. The channel_multiplier tells you how many different filters you want to apply <strong>per dimension</strong>. So the original desired output of depth 8 is not possible with 3 input dimensions. Only multiples of 3 are possible.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9768}"
216,67049850,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1618189106, 'answer_id': 67051511, 'question_id': 67049850, 'body': ""<p>I'm not sure why you'd do this in a Keras model. But just be careful when using these. For example, I'm not sure how well tested these are (for gradient flowing) if your <code>f1</code> <code>f2</code> are defining models in them. Nonetheless, you can do the following.</p>\n<ol>\n<li>Define your input as <code>int32</code> type. Because <code>tf.switch_case</code> expects <code>int32</code>.</li>\n<li>Make sure you define <code>batch_shape</code> and not <code>shape</code>, so that you can index the input tensor to get the scalar value to be passed to <code>tf.switch_case</code>.</li>\n<li>Wrap the <code>tf.switch_case</code> in a <code>Lambda</code> layer.</li>\n</ol>\n<pre><code>import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Lambda\n\ndef f1(): return tf.constant(17)\ndef f2(): return tf.constant(31)\ndef f3(): return tf.constant(-1)\n\nt_input = Input(batch_shape=(1,), dtype='int32', name=&quot;t_input&quot;)\n\nr = Lambda(lambda x: tf.switch_case(x[0], branch_fns={0: f1, 1: f2}, default=f3))(t_input)\nmodel = tf.keras.models.Model(inputs=t_input, outputs=r)\n</code></pre>\n<p>Using it</p>\n<pre><code>print(model.predict([1]))\n</code></pre>\n<p>Returns</p>\n<pre><code>31\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9768}"
217,60801403,"{'items': [{'owner': {}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': False, 'score': 0, 'creation_date': 1590507072, 'answer_id': 62025781, 'question_id': 60801403, 'body': '<p>I am able to execute your code in TF 2.2.0 in Google colab</p>\n\n<p>For the benefit of community, here i am posting the successful run with output</p>\n\n<pre><code>import tensorflow as tf\nprint(tf.__version__)\nimport itertools\n\ndef gen(): \n  for i in itertools.count(1): \n    yield (i, [1] * i) \n\ndataset = tf.data.Dataset.from_generator( \n     gen, \n     (tf.int64, tf.int64), \n     (tf.TensorShape([]), tf.TensorShape([None]))) \n\nlist(dataset.take(3).as_numpy_iterator()) \n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>2.2.0\n[(1, array([1])), (2, array([1, 1])), (3, array([1, 1, 1]))]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9768}"
218,63715707,"{'items': [{'owner': {'reputation': 2752, 'user_id': 13621630}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1599098522, 'answer_id': 63715753, 'question_id': 63715707, 'body': '<pre><code>tf.keras.preprocessing.image_dataset_from_directory(\n    directory, labels=\'inferred\', label_mode=\'int\', class_names=None,\n    color_mode=\'rgb\', batch_size=32, image_size=(256, 256), shuffle=True, seed=None,\n    validation_split=None, subset=None, interpolation=\'bilinear\', follow_links=False\n)\n</code></pre>\n<p>If you define batch size it will generate data <code>according to batch size</code> otherwise <code>default batch size is 32</code>. <strong>It is never possible to load the whole data in a single batch in normal computer.</strong> For more details read <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"" rel=""nofollow noreferrer"">documentation</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9768}"
219,60692861,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9768}"
220,65835387,"{'items': [{'owner': {'reputation': 21, 'user_id': 9070986}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1627878755, 'answer_id': 68616398, 'question_id': 65835387, 'body': '<p>You can plot it with the code below</p>\n<pre><code>import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(&quot;uint8&quot;))\n        plt.title(int(labels[i]))\n        plt.axis(&quot;off&quot;)\n</code></pre>\n<p>What actually the code does is printing nine images from your dataset and adding title to each image. <br>\nNote that there is no need to get labels in your first line of code.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9763}"
221,75993467,"{'items': [{'owner': {'reputation': 669, 'user_id': 21113996}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1681290193, 'answer_id': 75993672, 'question_id': 75993467, 'body': '<p>You can loop over 1D tensors that made up your 2D tensor to get all the indices of the unique values:</p>\n<pre class=""lang-py prettyprint-override""><code>indices = []\n\nfor value in input:\n   idx = tf.unique(value).idx\n   indices.append(idx)\n\nprint(indices)\n[&lt;tf.Tensor: shape=(6,), dtype=int32, numpy=array([0, 0, 1, 1, 1, 2])&gt;,\n &lt;tf.Tensor: shape=(6,), dtype=int32, numpy=array([0, 0, 1, 1, 1, 0])&gt;,\n &lt;tf.Tensor: shape=(6,), dtype=int32, numpy=array([0, 0, 0, 1, 1, 2])&gt;]\n</code></pre>\n<p>Lastly, if you need to you can <code>tf.concat(indices, axis=0)</code> or <code>tf.stack(indices)</code> them.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9763}"
222,74441089,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9763}"
223,56465794,"{'items': [{'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1559758665, 'answer_id': 56465981, 'question_id': 56465794, 'body': '<p>First of all, I think you meant <code>tf.keras.layers.MaxPool2D</code>, which is a class, not a function. If I got your point, it shouldn\'t be an issue. There are some minor difference in syntax, but nothing serious. Besides, <code>tf.keras.layers</code> is a direct substitute for <code>tf.layers</code>. As per official docs, <code>tf.layers</code> are wrappers around tf.keras.layers. <a href=""https://github.com/tensorflow/tensorflow/blob/a6d8ffae097d0132989ae4688d224121ec6d8f35/tensorflow/python/layers/convolutional.py#L28"" rel=""nofollow noreferrer"">For example</a>, convolutional layers in Layers API inherit from <code>tf.keras.layers</code>. </p>\n\n<pre class=""lang-py prettyprint-override""><code>@tf_export(\'layers.Conv1D\')\nclass Conv1D(keras_layers.Conv1D, base.Layer):\n  """"""1D convolution layer (e.g. temporal convolution). \n</code></pre>\n\n<p>Even more so, Layers API is deprecated and will be removed from TF 2.0.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9763}"
224,39627140,"{'items': [{'owner': {'reputation': 57117, 'user_id': 419116}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1474498324, 'answer_id': 39627705, 'question_id': 39627140, 'body': '<p>Suppose you start <code>shadow_variable=</code> update in multiple threads in parallel at the same time. After threads finish, <code>shadow_variable</code> will get the value computed by the slowest thread, so computation by other threads is wasted. To prevent this, you could introduce some kind of locking mechanism, or use the <code>-=</code> version</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9759}"
225,59847045,"{'items': [{'owner': {'reputation': 32742, 'user_id': 2099607}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1601117456, 'answer_id': 64076758, 'question_id': 59847045, 'body': '<p>Per my understanding and according to the documentation, using <code>tf.function</code> is highly recommended mainly for speeding up your code since the code wrapped by <code>tf.function</code> would be converted to a graph and therefore there is a room for some optimizations (e.g. op pruning, folding, etc.) to be done which may not be performed when the same code is run eagerly.</p>\n<p>However, there are also a few cases where using <code>tf.function</code> might incur additional overhead or does not result in noticeable speedups. One notable case is when the wrapped function is <strong>small</strong> and only <strong>used a few times</strong> in your code and therefore the overhead of calling the graph might be relatively large. Another case is when most of the computations are already done on an accelerator device (e.g. GPU, TPU), and therefore the speedups gained by graph computation might not be significant.</p>\n<p>There is also <a href=""https://www.tensorflow.org/guide/intro_to_graphs#seeing_the_speed_up"" rel=""nofollow noreferrer"">a section in the documentation</a> where the speedups are discussed in various scenarios, and at the beginning of this section the two cases above have been mentioned:</p>\n<blockquote>\n<p>Just wrapping a tensor-using function in <code>tf.function</code> does not automatically speed up your code. For small functions called a few times on a single machine, the overhead of calling a graph or graph fragment may dominate runtime. Also, if most of the computation was already happening on an accelerator, such as stacks of GPU-heavy convolutions, the graph speedup won\'t be large.</p>\n<p>For complicated computations, graphs can provide a significant speedup. This is because graphs reduce the Python-to-device communication and perform some speedups.</p>\n</blockquote>\n<p>But at the end of the day, <em>if it\'s applicable to your workflow</em>, I think the best way to determine this for your specific use case and environment is to profile your code when it gets executed in eager mode (i.e. without using <code>tf.function</code>) vs. when it gets executed in graph mode (i.e. using <code>tf.function</code> extensively).</p>\n'}, {'owner': {'reputation': 1166, 'user_id': 3595278}, 'down_vote_count': 1, 'up_vote_count': 37, 'is_accepted': False, 'score': 36, 'creation_date': 1588224608, 'answer_id': 61516502, 'question_id': 59847045, 'body': '<p>TLDR: It depends on your function and whether you are in production or development. Don\'t use <code>tf.function</code> if you want to be able to debug your function easily, or if it falls under the limitations of AutoGraph or tf.v1 code compatibility.\nI would highly recommend watching the Inside TensorFlow talks about <a href=""https://www.youtube.com/watch?v=NIEgzljyDyI"" rel=""noreferrer"">AutoGraph</a> and <a href=""https://www.youtube.com/watch?v=MSXouZPyTrc"" rel=""noreferrer"">Functions, not Sessions</a>.</p>\n\n<p>In the following I\'ll break down the reasons, which are all taken from information made available online by Google.</p>\n\n<p>In general, the <code>tf.function</code> decorator causes a function to be compiled as a callable that executes a TensorFlow graph. This entails:</p>\n\n<ul>\n<li>Conversion of the code through AutoGraph if required (including any functions called from an annotated function)</li>\n<li>Tracing and executing the generated graph code</li>\n</ul>\n\n<p><a href=""https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md"" rel=""noreferrer"">There is detailed information available on the design ideas behind this.</a></p>\n\n<h2>Benefits of decorating a function with <code>tf.function</code></h2>\n\n<h3>General benefits</h3>\n\n<ul>\n<li><em>Faster execution</em>, especially if the function consists of many small ops <a href=""https://www.tensorflow.org/guide/function"" rel=""noreferrer"">(Source)</a></li>\n</ul>\n\n<h3>For functions with Python code / Using AutoGraph via <code>tf.function</code> decoration</h3>\n\n<p>If you want to use AutoGraph, using <code>tf.function</code> is highly recommended over calling AutoGraph directly.\nReasons for this include: Automatic control dependencies, it is required for some APIs, more caching, and exception helpers <a href=""https://www.youtube.com/watch?v=NIEgzljyDyI&amp;t=1450s"" rel=""noreferrer"">(Source)</a>.</p>\n\n<h2>Drawbacks of decorating a function with <code>tf.function</code></h2>\n\n<h3>General drawbacks</h3>\n\n<ul>\n<li>If the function only consists of few expensive ops, there will not be much speedup <a href=""https://www.tensorflow.org/guide/function"" rel=""noreferrer"">(Source)</a></li>\n</ul>\n\n<h3>For functions with Python code / Using AutoGraph via <code>tf.function</code> decoration</h3>\n\n<ul>\n<li>No exception catching (should be done in eager mode; outside of the decorated function) <a href=""https://www.youtube.com/watch?v=NIEgzljyDyI&amp;t=2406s"" rel=""noreferrer"">(Source)</a></li>\n<li>Debugging is much harder</li>\n<li>Limitations due to hidden side effects and TF control flow</li>\n</ul>\n\n<p><a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md"" rel=""noreferrer"">Detailed information on AutoGraph limitations is available.</a></p>\n\n<h3>For functions with tf.v1 code</h3>\n\n<ul>\n<li>It is not allowed to create variables more than once in <code>tf.function</code>, but this is subject to change as tf.v1 code is phased out <a href=""https://www.youtube.com/watch?v=MSXouZPyTrc&amp;t=1018s"" rel=""noreferrer"">(Source)</a></li>\n</ul>\n\n<h3>For functions with tf.v2 code</h3>\n\n<ul>\n<li>No specific drawbacks</li>\n</ul>\n\n<h2>Examples of limitations</h2>\n\n<h3>Creating variables more than once</h3>\n\n<p>It is not allowed to create variables more than once, such as <code>v</code> in the following example:</p>\n\n<pre><code>@tf.function\ndef f(x):\n    v = tf.Variable(1)\n    return tf.add(x, v)\n\nf(tf.constant(2))\n\n# =&gt; ValueError: tf.function-decorated function tried to create variables on non-first call.\n</code></pre>\n\n<p>In the following code, this is mitigated by making sure that <code>self.v</code> is only created once:</p>\n\n<pre><code>class C(object):\n    def __init__(self):\n        self.v = None\n    @tf.function\n    def f(self, x):\n        if self.v is None:\n            self.v = tf.Variable(1)\n        return tf.add(x, self.v)\n\nc = C()\nprint(c.f(tf.constant(2)))\n\n# =&gt; tf.Tensor(3, shape=(), dtype=int32)\n</code></pre>\n\n<h3>Hidden side effects not captured by AutoGraph</h3>\n\n<p>Changes such as to <code>self.a</code> in this example can\'t be hidden, which leads to an error since cross-function analysis is not done (yet) <a href=""https://www.youtube.com/watch?v=NIEgzljyDyI&amp;t=2134"" rel=""noreferrer"">(Source)</a>:</p>\n\n<pre><code>class C(object):\n    def change_state(self):\n        self.a += 1\n\n    @tf.function\n    def f(self):\n        self.a = tf.constant(0)\n        if tf.constant(True):\n            self.change_state() # Mutation of self.a is hidden\n        tf.print(self.a)\n\nx = C()\nx.f()\n\n# =&gt; InaccessibleTensorError: The tensor \'Tensor(""add:0"", shape=(), dtype=int32)\' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=cond_true_5, id=5477800528); accessed from: FuncGraph(name=f, id=5476093776).\n</code></pre>\n\n<p>Changes in plain sight are no problem:</p>\n\n<pre><code>class C(object):\n    @tf.function\n    def f(self):\n        self.a = tf.constant(0)\n        if tf.constant(True):\n            self.a += 1 # Mutation of self.a is in plain sight\n        tf.print(self.a)\n\nx = C()\nx.f()\n\n# =&gt; 1\n</code></pre>\n\n<h3>Example of limitation due to TF control flow</h3>\n\n<p>This if statement leads to an error because the value for else needs to be defined for TF control flow:</p>\n\n<pre><code>@tf.function\ndef f(a, b):\n    if tf.greater(a, b):\n        return tf.constant(1)\n\n# If a &lt;= b would return None\nx = f(tf.constant(3), tf.constant(2))   \n\n# =&gt; ValueError: A value must also be returned from the else branch. If a value is returned from one branch of a conditional a value must be returned from all branches.\n</code></pre>\n'}, {'owner': {'reputation': 81, 'user_id': 13438268}, 'down_vote_count': 1, 'up_vote_count': 5, 'is_accepted': False, 'score': 4, 'creation_date': 1588223251, 'answer_id': 61516289, 'question_id': 59847045, 'body': '<p>tf.function is useful in creating and using computational graphs, they should be used in training and in deployment, however it isnt needed for most of your functions. </p>\n\n<p>Lets say that we are building a special layer that will be apart of a larger model. We would not want to have the tf.function decorator above the function that constructs that layer because it is merely a definition of what the layer will look like.</p>\n\n<p>On the other hand, lets say that we are going to either make a prediction or continue our training using some function. We would want to have the decorator tf.function because we are actually using the computational graph to get some value. </p>\n\n<p>A great example would be constructing a encoder-decoder model. \nDONT put the decorator around the function the create the encoder or decoder or any layer, that is only a definition of what it will do. \nDO put the decorator around the ""train"" or ""predict"" method because those are actually going to use the computational graph for computation.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9759}"
226,74330500,"{'items': [{'owner': {'reputation': 16941, 'user_id': 8143158}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1670422832, 'answer_id': 74718115, 'question_id': 74330500, 'body': '<p>You can use <code>matmul</code>,</p>\n<pre><code>heatmaps = tf.matmul(last_conv_layer_output, pooled_grads[:,tf.newaxis, :, tf.newaxis])\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9759}"
227,76222858,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9759}"
228,69777802,"{'items': [{'owner': {'reputation': 19782, 'user_id': 4281353}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1635586215, 'answer_id': 69778344, 'question_id': 69777802, 'body': ""<p>As @Proko suggested.</p>\n<pre><code>titanic_from_pandas = tf.data.Dataset.from_tensor_slices((\n    dict(df.loc[:, df.columns != 'survived']),\n    df.loc[:, 'survived']\n))\nfor row in titanic_from_pandas.batch(1).take(1):  # Take the first batch \n    features = row[0]        # Diectionary\n    label = row[1]\n    \n    for feature, value in features.items():\n        print(f&quot;{feature:20s}: {value}&quot;)\n    \n    print(f&quot;label/survived      : {label}&quot;)    \n---\nsex                 : [b'male']\nage                 : [22.]\nn_siblings_spouses  : [1]\nparch               : [0]\nfare                : [7.25]\nclass               : [b'Third']\ndeck                : [b'unknown']\nembark_town         : [b'Southampton']\nalone               : [b'n']\nlabel/survived      : [0]\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9759}"
229,71090570,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1644659940, 'answer_id': 71090829, 'question_id': 71090570, 'body': '<p>Try:</p>\n<pre class=""lang-py prettyprint-override""><code>import pandas as pd\nimport numpy as np\nimport tensorflow as tf  # Version 2.8.0\ndf = pd.DataFrame({&quot;id&quot;: \n                   [&quot;i123&quot;, &quot;i456&quot;],  \n                   &quot;col&quot;: [np.array([&quot;igh&quot;, &quot;ghdd&quot;, &quot;yu&quot;]),\n                           np.array([&quot;uh&quot;, &quot;lkk&quot;, &quot;nj&quot;])]})\n\nvalues = df[&quot;col&quot;].to_list()\nprint(tf.constant(values))\n</code></pre>\n<pre><code>tf.Tensor(\n[[b\'igh\' b\'ghdd\' b\'yu\']\n [b\'uh\' b\'lkk\' b\'nj\']], shape=(2, 3), dtype=string)\n</code></pre>\n<p>Or</p>\n<pre><code>values = np.stack(df[&quot;col&quot;].to_numpy())\nprint(tf.constant(values))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9754}"
230,58802573,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9754}"
231,41953678,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9754}"
232,64326029,"{'items': [{'owner': {'reputation': 1256, 'user_id': 3961841}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1602545879, 'answer_id': 64326654, 'question_id': 64326029, 'body': '<p>I believe you can use a python class generator. You can pass this generator to <code>model.fit</code> function if you want. I actually used it once for labels preprocessing.</p>\n<p>I wrote the following dataset generator that loads a batch from your dataset, splits the images from the batch into multiple images based on the <code>tile_shape</code> parameter. If there are enough images, the next batch is returned.</p>\n<p>In the example, I used a simple dataset from_tensor_slices for simplification. You can, of course, replace it with yours.</p>\n<pre><code>import tensorflow as tf\n\nclass TileDatasetGenerator:\n    \n    def __init__(self, dataset, batch_size, tile_shape):\n        self.dataset_iterator = iter(dataset)\n        self.batch_size = batch_size\n        self.tile_shape = tile_shape\n        self.image_queue = None\n    \n    def __iter__(self):\n        return self\n    \n    def __next__(self):\n        if self._has_queued_enough_for_batch():\n            return self._dequeue_batch()\n        \n        batch = next(self.dataset_iterator)\n        self._split_images(batch)    \n        return self.__next__()\n            \n    def _has_queued_enough_for_batch(self):\n        return self.image_queue is not None and tf.shape(self.image_queue)[0] &gt;= self.batch_size\n    \n    def _dequeue_batch(self):\n        batch, remainder = tf.split(self.image_queue, [self.batch_size, -1], axis=0)\n        self.image_queue = remainder\n        return batch\n        \n    def _split_images(self, batch):\n        batch_shape = tf.shape(batch)\n        batch_splitted = tf.reshape(batch, shape=[-1, self.tile_shape[0], self.tile_shape[1], batch_shape[-1]])\n        if self.image_queue is None:\n            self.image_queue = batch_splitted\n        else:\n            self.image_queue = tf.concat([self.image_queue, batch_splitted], axis=0)\n            \n\n\ndataset = tf.data.Dataset.from_tensor_slices(tf.ones(shape=[128, 64, 64, 3]))\ndataset.batch(32)\ngenerator = TileDatasetGenerator(dataset, batch_size = 16, tile_shape = [32,32])\n\nfor batch in generator:\n    tf.print(tf.shape(batch))\n</code></pre>\n<p><strong>Edit</strong>:\nIt is possible to convert the generator to <code>tf.data.Dataset</code> if you want, but it requires that you add a __call__ function to the generator returning an iterator (self in this case).</p>\n<pre><code>new_dataset = tf.data.Dataset.from_generator(generator, output_types=(tf.int64))\n</code></pre>\n'}, {'owner': {'reputation': 34678, 'user_id': 10908375}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1602546102, 'answer_id': 64326684, 'question_id': 64326029, 'body': '<p>What you\'re looking for is <a href=""https://www.tensorflow.org/api_docs/python/tf/image/extract_patches"" rel=""nofollow noreferrer""><code>tf.image.extract_patches</code></a>. Here\'s an example:</p>\n<pre><code>import tensorflow as tf\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndata = tfds.load(\'mnist\', split=\'test\', as_supervised=True)\n\nget_patches = lambda x, y: (tf.reshape(\n    tf.image.extract_patches(\n        images=tf.expand_dims(x, 0),\n        sizes=[1, 14, 14, 1],\n        strides=[1, 14, 14, 1],\n        rates=[1, 1, 1, 1],\n        padding=\'VALID\'), (4, 14, 14, 1)), y)\n\ndata = data.map(get_patches)\n\nfig = plt.figure()\nplt.subplots_adjust(wspace=.1, hspace=.2)\nimages, labels = next(iter(data))\nfor index, image in enumerate(images):\n    ax = plt.subplot(2, 2, index + 1)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(image)\nplt.show()\n</code></pre>\n<p><a href=""https://i.stack.imgur.com/qn1od.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qn1od.png"" alt=""enter image description here"" /></a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9754}"
233,52969867,"{'items': [{'owner': {'reputation': 147, 'user_id': 10354279}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1540470989, 'answer_id': 52989446, 'question_id': 52969867, 'body': ""<p>I found a way to do it using <code>tf.data.from_generator</code>\nThe trick I found was to make two separate Dataset (one for mat file and one for the jpg file) and then to combine them using <code>tf.data.Dataset.zip</code></p>\n\n<p>Here is how it works:</p>\n\n<pre><code>mat_dataset = tf.data.Dataset.from_generator(read_mat_file, tf.int64)\n\ndef read_mat_file():\n    while True:\n        with open('mat_addresses.txt', 'r') as input_:\n            for line in input_:\n                # open file and extract info from it as np.array\n                yield tuple(label)  # why tuple? https://github.com/tensorflow/tensorflow/issues/13101\n</code></pre>\n\n<p>in order to get the next batch one just have to do:</p>\n\n<pre><code>iter = mat_dataset.make_one_shot_iterator()\nsess.run(iter.get_next())\n</code></pre>\n\n<p>however, one can make <code>img_dataset</code> and combine it with <code>mat_dataset</code> like this:</p>\n\n<pre><code>img_dataset = tf.data.TextLineDataset('img_addresses.txt').map(read_img)\n\ndef read_img(path):\n    image_string = tf.read_file(path)\n    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n    return image_decoded\n\ndataset = tf.data.Dataset.zip((mat_dataset, img_dataset))\n</code></pre>\n\n<p>and now, getting next next batch like mentioned.</p>\n\n<p>PS. I have no idea about how efficient the code works in comparison to <code>feed_dict</code></p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9754}"
234,57246091,"{'items': [{'owner': {'reputation': 14390, 'user_id': 3641067}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1564362987, 'answer_id': 57246186, 'question_id': 57246091, 'body': '<p>If you just use;</p>\n\n<pre><code>print(a)\nprint(b)\n</code></pre>\n\n<p>you shall get the correct result;</p>\n\n<pre><code>tf.Tensor(\n[[1 2 3 4]\n [1 2 3 4]], shape=(2, 4), dtype=int32) #a\ntf.Tensor(\n[[1. 2. 3. 4.]\n [1. 2. 3. 4.]], shape=(2, 4), dtype=float32) #b\n</code></pre>\n\n<p>So the <code>tf.cast()</code> works as intended!</p>\n\n<hr>\n\n<p>With <a href=""https://www.tensorflow.org/api_docs/python/tf/shape"" rel=""noreferrer""><code>tf.shape()</code></a> you are getting a result that explains the shape details of input. </p>\n\n<blockquote>\n  <p>Returns: A Tensor of type out_type.</p>\n  \n  <p>out_type: (Optional) The specified output type of the operation (int32\n  or int64). Defaults to tf.int32</p>\n</blockquote>\n\n<p>So the <code>dtype</code> of <code>tf.shape()</code> result, is the <code>dtype</code> of the resulting ""<em>shape detailing tensor</em>"", not of <code>a</code>, or <code>b</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9749}"
235,63730066,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1616156121, 'answer_id': 66707999, 'question_id': 63730066, 'body': '<p>Providing workaround here for the benefit of community, though it is presented in <a href=""https://discourse.kedro.community/t/how-to-use-tf-data-dataset-with-kedro/124/2"" rel=""nofollow noreferrer"">kedro.community</a> by @DataEngineerOne.</p>\n<p>According to @DataEngineerOne.</p>\n<blockquote>\n<p>With kedro, is there a way to create a node and return the created\ntf.data.Dataset to use it in the next training node?</p>\n</blockquote>\n<p>Yes, absolutely!</p>\n<blockquote>\n<p>Can someone please elaborate a bit more on why/how this concurrent\nmodification could happen?</p>\n<p>From the docs, there seems to be a copy_mode = &quot;assign&quot; . Would it be\npossible to use this option in case the data is not picklable?</p>\n</blockquote>\n<p>I have yet to try this option, but it should theoretically work. All you would need to do is create a new dataset entry in the <code>catalog.yml</code> file that includes the <code>copy_mode</code> option.</p>\n<p>Ex:</p>\n<pre><code># catalog.yml\ntf_data:\n  type: MemoryDataSet\n  copy_mode: assign\n\n# pipeline.py\nnode(\n  tf_generator,\n  inputs=...,\n  outputs=&quot;tf_data&quot;,\n)\n</code></pre>\n<p>I can not vouch for this solution, but give it a go and let me know if it works for you.</p>\n<blockquote>\n<p>Another solution (also mentioned in issue 91) is to use just a\nfunction to generate the streaming tf.data.Dataset inside the training\nnode, without having the preceding dataset generation node. However, I\nam not sure what the drawbacks of this approach will be (if any).\nWould be greate if someone could give some examples.</p>\n</blockquote>\n<p>This is also a great alternative solution, and I think (guess) that the <code>MemoryDataSet</code> will automatically use <code>assign</code> in this case, rather than its normal <code>deepcopy</code>, so you should be alright.</p>\n<pre><code># node.py\n\ndef generate_tf_data(...):\n  tensor_slices = [1, 2, 3]\n  def _tf_data():\n    dataset = tf.data.Dataset.from_tensor_slices(tensor_slices)\n    return dataset\n  return _tf_data\n\ndef use_tf_data(tf_data_func):\n  dataset = tf_data_func()\n\n# pipeline.py\nPipeline([\nnode(\n  generate_tf_data,\n  inputs=...,\n  outputs=\'tf_data_func\',\n),\nnode(\n  use_tf_data,\n  inputs=\'tf_data_func\',\n  outputs=...\n),\n])\n</code></pre>\n<p>The only drawback here is the additional complexity. For more details you can refer <a href=""https://discourse.kedro.community/t/how-to-use-tf-data-dataset-with-kedro/124/2"" rel=""nofollow noreferrer"">here</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9749}"
236,56289685,"{'items': [{'owner': {'reputation': 5083, 'user_id': 3151567}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1558694099, 'answer_id': 56290913, 'question_id': 56289685, 'body': '<p>Warrpe your code like this (Promise based):</p>\n\n<pre><code>const compute = (data) =&gt; {\n\n    try {\n        const tensor = tf.tensor(data, [1, 100])\n        const prediction = this.model.predict(tensor)\n        return Promise.resolve(prediction.data())\n    }\n    catch(err){\n\n        return Promise.reject(err)\n\n    }\n\n  }\n</code></pre>\n\n<p>Later :</p>\n\n<pre><code>compute.then(res =&gt; consonle.log(res)).catch(err =&gt; console.log(err));\n</code></pre>\n'}, {'owner': {'reputation': 639, 'user_id': 8031029}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1558693835, 'answer_id': 56290847, 'question_id': 56289685, 'body': '<p>The problem is that you cannot wrap a blocking operation in a promise because that\'s not just how it works. See this made up example (which is basically what you\'re doing):</p>\n\n<pre><code>const blockFunction = () =&gt; {\n  const endBlock = Date.now() + 2000\n  while(Date.now() &lt; endBlock){}\n}\n\nconst promisedBlocking = () =&gt; new Promise((res, rej) =&gt; {\n  const endBlock = Date.now() + 2000\n\n  while (Date.now() &lt; endBlock) {}\n  return res(\'I cannot resolve before the blocking IO\')\n})\n\nconsole.log(\'before blocking\')\nblockFunction()\nconsole.log(\'after blocking\')\n\n\nconsole.log(\'before promised blocking\')\npromisedBlocking()\n.then(console.log)\nconsole.log(\'after promised blocking\')\n</code></pre>\n\n<p>If you\'re using tensorflow with node you can wrap your function calls in a separate file and call it with a child process (see the <a href=""https://nodejs.org/api/child_process.html#child_process_child_process_fork_modulepath_args_options"" rel=""nofollow noreferrer"">fork</a> method), or if you\'re using TF in the browser execute the background function using <a href=""https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers"" rel=""nofollow noreferrer"">WebWorkers</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9749}"
237,49785239,"{'items': [{'owner': {'reputation': 5662, 'user_id': 7770781}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1523568756, 'answer_id': 49806207, 'question_id': 49785239, 'body': '<p>I think <code>tf.fill</code>(<a href=""https://www.tensorflow.org/api_docs/python/tf/fill"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/fill</a>) can give you the ""constant"" tensor you want in the graph. Here is my MCVE:</p>\n\n<pre><code>import tensorflow as tf\n\nx = tf.constant([[1, 7], [2, 6], [3, 5], [4, 8]], dtype=tf.float32)\ny_true = tf.constant([[0, 4], [-1, 3], [-2, 2], [-3, 1]], dtype=tf.float32)\n\n# The section you want\nr = tf.placeholder(tf.float32, shape=[3, 1])\nglobal_bias_value = tf.reduce_mean(r)\nglobal_bias = tf.fill([4, 2], global_bias_value)\n\nw = tf.get_variable(\'weight\', [4, 2])\ny_pred = tf.multiply(x, w) + global_bias\nloss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\noptimizer = tf.train.GradientDescentOptimizer(0.01)\ntrain = optimizer.minimize(loss)\n\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\nfor i in range(3):\n  _, weight, bias = sess.run((train, w, global_bias),\n                           feed_dict={r: [[1], [2], [3]]})\n  print(\'Step: \', i)\n  print(\'Weight: \', weight)\n  print(\'Bias: \', bias)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9749}"
238,51687832,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9749}"
239,56547737,"{'items': [{'owner': {'reputation': 4900, 'user_id': 6546694}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1589263889, 'answer_id': 61744937, 'question_id': 56547737, 'body': ""<p>A few points to keep in mind about @tf.function (laymanesque):</p>\n<ol>\n<li>@tf.function builds a callable graph of the function that it decorates</li>\n<li>That graph is referenced to by using a key that is the function signature. This signature is <code>TensorSpec</code> if the input to the function is a Tensor and is a tuple with actual values of the arguments if the input to the function are not tensors</li>\n<li>Each time the graph is called the key is checked in all available 'callable graphs' and if a match is found then that 'already built callable graph' is used. If not, the function is converted to callable graph and then it is called. Building the graph is referred to as tracing the function by documentations. Now, you can see why calling the function with python natives creates a new graph each time it is called. That particular combination of inputs is simply not present as the key whereas in case of a tensor the <code>Tesnsorspec</code> key is same for each tensor with same shape and dtype</li>\n<li>If a python iterable is used inside the function then while 'tracing the function', the loop will be unrolled to create a gigantic graph. If a tensorflow equivalent like <code>tf.range</code> was used then tensorflow knows how to handle this without unrolling. This unrolling has an overhead the first time the function is run but, unrolled loops are always faster than the loop itself. So, the behavior you will notice is this: <strong>With python iterable, as opposed to tensorflow equivalnet (tf.range), The first function run is significantly slow, graph thus created will consume more memory on accelerator but, is significantly faster on all subsequent runs as the graph with python iterable uses unrolled loop</strong>.</li>\n</ol>\n<p>Demo:</p>\n<p>With tf.range</p>\n<pre><code>@tf.function\ndef loop__(x, y):\n    for i in tf.range(10000):\n        x.assign_add(y)\n    return x\n\n\n@tf.function\ndef loop2__(x, y):\n    for i in tf.range(100):\n        loop__(x, y)\n    return x\n\nx = tf.Variable(initial_value=0, dtype=np.float32)\ny = tf.Variable(initial_value=1, dtype=np.float32)\n\nstart = time()\nprint(loop2__(x, y))\nprint(&quot;first run with tf.range&quot;, time() - start)\nstart = time()\nprint(loop2__(x, y))\nprint(&quot;second run with tf.range&quot;, time() - start)\n\noutput:\ntf.Tensor(1000000.0, shape=(), dtype=float32)\nfirst run with tf.range 10.322974920272827\ntf.Tensor(2000000.0, shape=(), dtype=float32)\nsecond run with tf.range 11.379822969436646\n</code></pre>\n<p>with python range:</p>\n<pre><code>@tf.function\ndef loop__(x, y):\n    for i in range(10000):\n        x.assign_add(y)\n    return x\n\n\n@tf.function\ndef loop2__(x, y):\n    for i in tf.range(100):\n        loop__(x, y)\n    return x\n\nx = tf.Variable(initial_value=0, dtype=np.float32)\ny = tf.Variable(initial_value=1, dtype=np.float32)\n\nstart = time()\nprint(loop2__(x, y))\nprint(&quot;first run with python range&quot;, time() - start)\nstart = time()\nprint(loop2__(x, y))\nprint(&quot;second run with python range&quot;, time() - start)\n\noutput (with loads of warnings about inefficient graph unrolling):\ntf.Tensor(1000000.0, shape=(), dtype=float32)\nfirst run with python range 51.13001751899719\ntf.Tensor(2000000.0, shape=(), dtype=float32)\nsecond run with python range 1.1093688011169434\n</code></pre>\n""}, {'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 9, 'is_accepted': True, 'score': 9, 'creation_date': 1560271613, 'answer_id': 56548349, 'question_id': 56547737, 'body': '<p>You should read <a href=""https://pgaleone.eu/tensorflow/tf.function/2019/05/10/dissecting-tf-function-part-3/"" rel=""noreferrer"">part 3</a> of the article cited in the answer you linked.</p>\n\n<p>In part 3, you can see that the problem is not only when using Python native types, but also when using Python constructs (like <code>for</code>) that operate on Python types and not on <code>tf.Tensor</code> objects.</p>\n\n<p>In particular, when looping over a <code>range</code> and not on a <code>tf.range</code> you\'re building a huge graph since you\'re repeating <code>1000</code> times the body loop (you\'re unrolling the loop.</p>\n\n<p>If you replace <code>range</code> with <code>tf.range</code> everything goes way faster.</p>\n\n<p>Proof.</p>\n\n<p>Your code (with time measurements and 100 instead of 1000):</p>\n\n<pre class=""lang-py prettyprint-override""><code>import numpy as np\nimport tensorflow as tf\nfrom time import time\n\n@tf.function\ndef loop(x, y):\n    for i in range(100):\n        x.assign_add(y)\n    return x\n\n\n@tf.function\ndef loop2(x, y):\n    for i in range(100):\n        loop(x, y)\n    return x\n\n\ndef main():\n    print(""TensorFlow version: {}"".format(tf.__version__))\n    print(""Eager execution: {}"".format(tf.executing_eagerly()))\n\n    x = tf.Variable(initial_value=0, dtype=np.float32)\n    y = tf.Variable(initial_value=1, dtype=np.float32)\n    print(""one"")\n    start = time()\n    print(loop2(x, y))  # horribly slow\n    print(""end: "", time() - start)\n    print(""second: "")\n    start = time()\n    for i in range(100):  # faster\n        loop(x, y)\n    print(""end: "", time() - start)\n\n\nmain()\n</code></pre>\n\n<p>The output:</p>\n\n<pre><code>TensorFlow version: 2.0.0-beta0\nEager execution: True\none\ntf.Tensor(10000.0, shape=(), dtype=float32)\nend:  86.44128751754761\nsecond: \nend:  0.08476066589355469\n</code></pre>\n\n<p>Updated code using only TensorFlow methods:</p>\n\n<pre class=""lang-py prettyprint-override""><code>@tf.function\ndef loop__(x, y):\n    for i in tf.range(100):\n        x.assign_add(y)\n    return x\n\n\n@tf.function\ndef loop2__(x, y):\n    for i in tf.range(100):\n        loop__(x, y)\n    return x\n\n\ndef main():\n    print(""TensorFlow version: {}"".format(tf.__version__))\n    print(""Eager execution: {}"".format(tf.executing_eagerly()))\n\n    x = tf.Variable(initial_value=0, dtype=np.float32)\n    y = tf.Variable(initial_value=1, dtype=np.float32)\n    print(""one"")\n    start = time()\n    print(loop2__(x, y))  # horribly slow\n    print(""end: "", time() - start)\n    print(""second: "")\n    start = time()\n    for i in tf.range(100):  # faster\n        loop__(x, y)\n    print(""end: "", time() - start)\n\n\nmain()\n</code></pre>\n\n<p>The output:</p>\n\n<pre><code>TensorFlow version: 2.0.0-beta0\nEager execution: True\none\ntf.Tensor(10000.0, shape=(), dtype=float32)\nend:  0.4946322441101074\nsecond: \nend:  0.24096465110778809\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9744}"
240,59361689,"{'items': [{'owner': {'reputation': 3766, 'user_id': 2116766}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1576530707, 'answer_id': 59364358, 'question_id': 59361689, 'body': '<p>Short answer: Prefer tensorflow\'s native API such as <code>tf.math.*</code> to the<code>tf.keras.backend.*</code> API wherever possible.</p>\n\n<p>Longer answer:</p>\n\n<ul>\n<li>The <code>tf.keras.backend.*</code> API can be <em>mostly</em> viewed as a remnant of the <code>keras.backend.*</code> API. The latter is a design that serves the ""exchangeable backend"" design of the original (non-TF-specific) keras. This relates to the historical aspect of keras, which supports multiple backend libraries, among which tensorflow used to be just one of them. Back in 2015 and 2016, other backends, such as Theano and MXNet were quite popular too. But going into 2017 and 2018, tensorflow became the dominant backend of keras users. Eventually keras became a part of the tensorflow API (in 2.x and later minor versions of 1.x). In the old multi-backend world, the <code>backend.*</code> API provides a backend-independent abstraction over the myriad of supported backend. But in the tf.keras world, the value of the backend API is much more limited.</li>\n<li>The various functions in <code>tf.keras.backend.*</code> can be divided into a few categories:\n\n<ol>\n<li>Thin wrappers around the equivalent or mostly-equivalent tensorflow native API. Examples: <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L2363"" rel=""noreferrer"">tf.keras.backend.less</a>, <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L2431"" rel=""noreferrer"">tf.keras.backend.sin</a></li>\n<li>Slightly thicker wrappers around tensorflow native APIs, with more features included. Examples: <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L2589"" rel=""noreferrer"">tf.keras.backend.batch_normalization</a>, <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L4869"" rel=""noreferrer"">tf.keras.backend.conv2d</a>(<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L4869"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L4869</a>). They often perform proprocessing and implement other logics, which make your life easier than using native tensorflow API.</li>\n<li>Unique functions that don\'t have equivalent in the native tensorflow API. Examples: <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L3809"" rel=""noreferrer"">tf.keras.backend.rnn</a>, <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L342"" rel=""noreferrer"">tf.keras.backend.set_learning_phase</a></li>\n</ol></li>\n</ul>\n\n<p>For category 1, use native tensorflow APIs. For categories 2 and 3, you may want to use the <code>tf.keras.backend.*</code> API, as long as you can find it in the documentation page: <a href=""https://www.tensorflow.org/api_docs/python/"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/</a>, because the documented ones have backward compatibility guarantees, so that you don\'t need to worry about a future version of tensorflow removing it or changing its behavior.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9743}"
241,42897816,"{'items': [{'owner': {'reputation': 2862, 'user_id': 1373669}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1489999809, 'answer_id': 42899188, 'question_id': 42897816, 'body': '<p>From the documentation of <code>tf.Variable</code>:</p>\n\n<blockquote>\n  <p>dtype: If set, initial_value will be converted to the given type.\n          If <code>None</code>, either the datatype will be kept (if <code>initial_value</code> is\n          a Tensor), or <code>convert_to_tensor</code> will decide.</p>\n</blockquote>\n\n<p>And the documentation from <code>convert_to_tensor(value, dtype=None, ...)</code>:</p>\n\n<blockquote>\n  <p>dtype: Optional element type for the returned tensor. If missing, the\n        type is inferred from the type of <code>value</code>.</p>\n</blockquote>\n\n<p>Also, there is an example given in the documentation to <code>convert_to_tensor</code>:</p>\n\n<pre><code>import numpy as np\n\ndef my_func(arg):\n    arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n    return tf.matmul(arg, arg) + arg\n\n# The following calls are equivalent.\nvalue_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))\nvalue_2 = my_func([[1.0, 2.0], [3.0, 4.0]])\nvalue_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))\n</code></pre>\n\n<p>So, coming back to your question - Tensorflow does not know that you intended to use <code>tf.float32</code>, it just happened to be the datatype that was chosen by default by the <code>convert_to_tensor</code> function. Hence, it was mere coincidence that the returned Tensor had the datatype that you expected. If e.g. you call <code>tf.Variable([.3], tf.float64)</code> the resulting Tensor has the same <code>dtype</code> as when calling <code>tf.Variable([.3], tf.float32)</code>.</p>\n\n<p>In fact, I believe that both calls <code>tf.Variable([.3], tf.float32)</code> and <code>tf.Variable([.3], tf.float64)</code> are equivalent, as the second argument to <code>tf.Variable</code> is a boolean and thus <code>tf.floatX</code> is being converted to a boolean which always returns <code>True</code>. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9743}"
242,60287388,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9743}"
243,61790621,"{'items': [{'owner': {'reputation': 21403, 'user_id': 10375049}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1589448940, 'answer_id': 61794003, 'question_id': 61790621, 'body': '<p>try in this way:</p>\n\n<pre><code>labels = [0,1]\nlogits = np.asarray([[0.9,0.1],[0.1,0.9]])\n\nlabels = tf.cast(labels, tf.int64)\npredict = tf.argmax(input=logits, axis=1)\nacc = tf.keras.metrics.Accuracy()\nacc = acc.update_state(y_true=labels, y_pred=predict)\nacc\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9743}"
244,57098652,"{'items': [{'owner': {'reputation': 611, 'user_id': 8394292}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1563469059, 'answer_id': 57099423, 'question_id': 57098652, 'body': '<p>You can check their <a href=""https://www.tensorflow.org/api_docs/python/tf/Tensor#dtype"" rel=""nofollow noreferrer"">dtype attributes</a> e.g. assert <code>my_tensor.dtype == tf.float32</code>.</p>\n\n<p><a href=""https://stackoverflow.com/questions/52879126/how-are-tensors-immutable-in-tensorflow"">Tensors are immutable</a> outside of variables: they describe relationships between quantities. Data types will not change unless a <a href=""https://www.tensorflow.org/api_docs/python/tf/dtypes/cast"" rel=""nofollow noreferrer"">type cast</a> operation is added to the graph, adding an edge. If a value is passed to a tensor with a type that is different to the expected type, e.g. when loading data into a pipeline, an error is raised. You can check this by assigning a tensor with an incorrect type -- you will get an error.</p>\n\n<p>Try this code</p>\n\n<pre><code>import tensorflow as tf\nx = tf.get_variable(\'x\', shape=(2,), dtype=tf.float32)\ntf.assign(x[1], tf.ones(shape=(2,), dtype=tf.int32))\n</code></pre>\n\n<p>You should get an error to the effect of ""TypeError: Input \'value\' of \'StridedSliceAssign\' Op has type int32 that does not match type float32 of argument \'ref\'.""</p>\n'}, {'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1563467147, 'answer_id': 57098976, 'question_id': 57098652, 'body': ""<p>This is not part of the public API, but looking at how <code>tf.assign</code> is implemented, I think you can just do:</p>\n\n<pre><code>import tensorflow as tf\n\ndef is_assignable(x):\n    return x.dtype._is_ref_dtype or (isinstance(x, tf.Tensor) and hasattr(x, 'assign'))\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9739}"
245,45203872,"{'items': [{'owner': {'reputation': 109, 'user_id': 7109848}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1516446144, 'answer_id': 48355314, 'question_id': 45203872, 'body': '<p>tf.train.shuffle_batch() shuffles every epoch.</p>\n'}, {'owner': {'reputation': 3297, 'user_id': 15791}, 'down_vote_count': 0, 'up_vote_count': 22, 'is_accepted': True, 'score': 22, 'creation_date': 1500532699, 'answer_id': 45207025, 'question_id': 45203872, 'body': '<p>First take a look at the documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/train/shuffle_batch"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/train/shuffle_batch</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/train/batch"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/train/batch</a> ). Internally batch is build around a FIFOQueue and shuffle_batch is build around a RandomShuffleQueue.</p>\n\n<p>Consider the following toy example, it puts 1 to 100 in a constant which gets fed through tf.train.shuffle_batch and tf.train.batch and later on this prints the results. </p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ndata = np.arange(1, 100 + 1)\ndata_input = tf.constant(data)\n\nbatch_shuffle = tf.train.shuffle_batch([data_input], enqueue_many=True, batch_size=10, capacity=100, min_after_dequeue=10, allow_smaller_final_batch=True)\nbatch_no_shuffle = tf.train.batch([data_input], enqueue_many=True, batch_size=10, capacity=100, allow_smaller_final_batch=True)\n\nwith tf.Session() as sess:\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord)\n    for i in range(10):\n        print(i, sess.run([batch_shuffle, batch_no_shuffle]))\n    coord.request_stop()\n    coord.join(threads)\n</code></pre>\n\n<p>Which yields:</p>\n\n<pre><code>0 [array([23, 48, 15, 46, 78, 89, 18, 37, 88,  4]), array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])]\n1 [array([80, 10,  5, 76, 50, 53,  1, 72, 67, 14]), array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20])]\n2 [array([11, 85, 56, 21, 86, 12,  9,  7, 24,  1]), array([21, 22, 23, 24, 25, 26, 27, 28, 29, 30])]\n3 [array([ 8, 79, 90, 81, 71,  2, 20, 63, 73, 26]), array([31, 32, 33, 34, 35, 36, 37, 38, 39, 40])]\n4 [array([84, 82, 33,  6, 39,  6, 25, 19, 19, 34]), array([41, 42, 43, 44, 45, 46, 47, 48, 49, 50])]\n5 [array([27, 41, 21, 37, 60, 16, 12, 16, 24, 57]), array([51, 52, 53, 54, 55, 56, 57, 58, 59, 60])]\n6 [array([69, 40, 52, 55, 29, 15, 45,  4,  7, 42]), array([61, 62, 63, 64, 65, 66, 67, 68, 69, 70])]\n7 [array([61, 30, 53, 95, 22, 33, 10, 34, 41, 13]), array([71, 72, 73, 74, 75, 76, 77, 78, 79, 80])]\n8 [array([45, 52, 57, 35, 70, 51,  8, 94, 68, 47]), array([81, 82, 83, 84, 85, 86, 87, 88, 89, 90])]\n9 [array([35, 28, 83, 65, 80, 84, 71, 72, 26, 77]), array([ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100])]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9739}"
246,71129505,"{'items': [{'owner': {'reputation': 11, 'user_id': 20059329}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1677967760, 'answer_id': 75638973, 'question_id': 71129505, 'body': '<p>I can\'t comment, so have to answer to <a href=""https://stackoverflow.com/users/4373967/jeffreyshran"">JeffreyShran</a> about how we can be sure about <code>take</code> and <code>skip</code> taking the same pictures in that block. Here is the check code:</p>\n<pre class=""lang-py prettyprint-override""><code>dataset = tf.data.Dataset.range(10)\ntake = int(len(dataset)/2)\n\ntest = dataset.take(take)\nprint(\'test:\', list(test.as_numpy_iterator()))\ndataset = dataset.skip(take)\nprint(\'valid:\', list(dataset.as_numpy_iterator()))\n</code></pre>\n<p>We get:</p>\n<pre class=""lang-py prettyprint-override""><code>test: [0, 1, 2, 3, 4]\nvalid: [5, 6, 7, 8, 9]\n</code></pre>\n<p>I\'m a newcomer, so my apologies if I\'m writing not in the appropriate place. But I think that consideration above must have been proved.</p>\n'}, {'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1644994492, 'answer_id': 71137470, 'question_id': 71129505, 'body': '<p>The issue is that you are not taking and skipping samples when you do <code>test_val_ds.take(686)</code> and <code>test_val_ds.skip(686)</code>, but actually batches. Try running <code>print(val_dataset.cardinality())</code> and you will see how many batches you really have reserved for validation. I am guessing <code>val_dataset</code> is empty, because you do not have 686 batches for validation. Here is a working example:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport pathlib\n\ndataset_url = &quot;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&quot;\ndata_dir = tf.keras.utils.get_file(\'flower_photos\', origin=dataset_url, untar=True)\ndata_dir = pathlib.Path(data_dir)\n\nbatch_size = 32\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=&quot;training&quot;,\n  seed=123,\n  image_size=(180, 180),\n  batch_size=batch_size)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=&quot;validation&quot;,\n  seed=123,\n  image_size=(180, 180),\n  batch_size=batch_size)\n\ntest_dataset = val_ds.take(5)\nval_ds = val_ds.skip(5)\n\nprint(\'Batches for testing --&gt;\', test_dataset.cardinality())\nprint(\'Batches for validating --&gt;\', val_ds.cardinality())\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1./255, input_shape=(180, 180, 3)),\n  tf.keras.layers.Conv2D(16, 3, padding=\'same\', activation=\'relu\'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, padding=\'same\', activation=\'relu\'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(64, 3, padding=\'same\', activation=\'relu\'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation=\'relu\'),\n  tf.keras.layers.Dense(5)\n])\n\nmodel.compile(optimizer=\'adam\',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=[\'accuracy\'])\n\nepochs=1\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=1\n)\n</code></pre>\n<pre><code>Found 3670 files belonging to 5 classes.\nUsing 2936 files for training.\nFound 3670 files belonging to 5 classes.\nUsing 734 files for validation.\nBatches for testing --&gt; tf.Tensor(5, shape=(), dtype=int64)\nBatches for validating --&gt; tf.Tensor(18, shape=(), dtype=int64)\n92/92 [==============================] - 96s 1s/step - loss: 1.3516 - accuracy: 0.4489 - val_loss: 1.1332 - val_accuracy: 0.5645\n</code></pre>\n<p>In this example, with a <code>batch_size</code> of 32, you can clearly see that the validation set reserved 23 batches. Afterwards, 5 batches were given to the test set and 18 batches remained for the validation set.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9739}"
247,73206182,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9739}"
248,67557800,"{'items': [{'owner': {'reputation': 1218, 'user_id': 7061249}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1623227768, 'answer_id': 67900476, 'question_id': 67557800, 'body': '<p>Suppose you have a batch of B examples, each with exactly N text strings, which makes a 2-dimensional Tensor of shape [B, N]. With <a href=""https://www.tensorflow.org/api_docs/python/tf/reshape"" rel=""nofollow noreferrer"">tf.reshape()</a>, you can turn that into a 1-dimensional tensor of shape [B*N], send it through BERT (which preserves the order of inputs) and then reshape it back to [B,N]. (There\'s also <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape"" rel=""nofollow noreferrer"">tf.keras.layers.Reshape</a>, but that hides the batch dimension from you.)</p>\n<p>If it\'s not exactly N text strings each time, you\'ll have to do some bookkeeping on the side (e.g., store inputs in a <a href=""https://www.tensorflow.org/api_docs/python/tf/RaggedTensor"" rel=""nofollow noreferrer"">tf.RaggedTensor</a>, run BERT on its <code>.values</code>, and construct a new RaggedTensor with the same <code>.row_splits</code> from the result.)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9739}"
249,74568105,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9734}"
250,61628845,"{'items': [{'owner': {'reputation': 526, 'user_id': 9152509}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1588751535, 'answer_id': 61630018, 'question_id': 61628845, 'body': '<p>For converting from TF1 to TF2  code, you can do it easily by using the tf.keras api in TF2. For example the functions your provided.</p>\n\n<p><code>tf.losses.softmax_cross_entropy()</code> to\n<code>tf.keras.losses.CategoricalCrossentropy(from_logits=True)</code>\n<code>from_logits</code> parameter here specifies whether y_pred is expected to be a logits tensor. </p>\n\n<p><code>tf.train.MomentumOptimizer()</code> to <code>tf.keras.optimizers.SGD(momentum=...)</code>\nby providing the <code>momentum</code> parameter.</p>\n\n<p>As for the final function its still being used in the TF2.0 documentation so maybe there isn\'t an equivalent version in 2.0. </p>\n\n<p>You can check the this guide from the TF2.0 website whic would provide a great refrence for you. <a href=""https://www.tensorflow.org/guide/migrate"" rel=""nofollow noreferrer"">Migrate your TensorFlow 1 code to TensorFlow 2</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9734}"
251,53612973,"{'items': [{'owner': {'reputation': 32742, 'user_id': 2099607}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1543940433, 'answer_id': 53617271, 'question_id': 53612973, 'body': '<p>Both <code>tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(...))</code> and <code>tf.losses.sigmoid_cross_entropy(...)</code> (with default arguments) are computing the same thing. The problem is in your tests where you use <code>==</code> to compare two floating-point numbers. Instead, use <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.isclose.html"" rel=""nofollow noreferrer""><code>np.isclose</code></a> method to check whether two floating-point numbers are equal or not:</p>\n\n<pre><code># loss _should_(?) be the same for \'channels_first\' and \'channels_last\' data_format\n# test example_1\ne1 = np.isclose(l1, t_l1.T).all()\n# test example 2\ne2 = np.isclose(l2, t_l2.T).all()\n\n# loss calculated for each example and then batched together should be the same \n# as the loss calculated on the batched examples\nea = np.isclose(np.array([l1, l2]), bl).all()\nt_ea = np.isclose(np.array([t_l1, t_l2]), t_bl).all()\n\n# loss calculated on the batched examples for \'channels_first\' should be the same\n# as loss calculated on the batched examples for \'channels_last\'\neb = np.isclose(bl, np.transpose(t_bl, (0, 2, 1))).all()\n\n\ne1, e2, ea, t_ea, eb\n# (True, True, True, True, True)\n</code></pre>\n\n<p>And:</p>\n\n<pre><code>l_e1 = np.isclose(tf_l1, rm_l1)\nl_e2 = np.isclose(tf_l2, rm_l2)\nl_eb = np.isclose(tf_bl, rm_bl)\n\nl_t_e1 = np.isclose(tf_t_l1, rm_t_l1)\nl_t_e2 = np.isclose(tf_t_l2, rm_t_l2)\nl_t_eb = np.isclose(tf_t_bl, rm_t_bl)\n\nl_e1, l_e2, l_eb, l_t_e1, l_t_e2, l_t_eb\n# (True, True, True, True, True, True)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9734}"
252,34931121,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': True, 'score': 11, 'creation_date': 1453411091, 'answer_id': 34934543, 'question_id': 34931121, 'body': '<p>Your second version&mdash;where the <code>assign_add()</code> and <code>assign_sub()</code> ops are creating inside the lambdas passed to <code>cond()</code>&mdash;is the correct way to do this. Fortunately, each of the two lambdas is only evaluated once, during the call to <code>cond()</code>, so your graph will not grow without bound.</p>\n\n<p>Essentially what <code>cond()</code> does is the following:</p>\n\n<ol>\n<li><p>Create a <code>Switch</code> node, which forwards its input to only one of two outputs, depending on the value of <code>pred</code>. Let\'s call the outputs <code>pred_true</code> and <code>pred_false</code>. (They have the same value as <code>pred</code> but that\'s unimportant since this is never directly evaluated.)</p></li>\n<li><p>Build the subgraph corresponding to the <code>if_true</code> lambda, where all of the nodes have a control dependency on <code>pred_true</code>.</p></li>\n<li><p>Build the subgraph corresponding to the <code>if_false</code> lambda, where all of the nodes have a control dependency on <code>pred_false</code>.</p></li>\n<li><p>Zip together the lists of return values from the two lambdas, and create a <code>Merge</code> node for each of these. A <code>Merge</code> node takes two inputs, of which only one is expected to be produced, and forwards it to its output.</p></li>\n<li><p>Return the tensors that are the outputs of the <code>Merge</code> nodes.</p></li>\n</ol>\n\n<p>This means you can run your second version, and be content that the graph remains a fixed size, regardless of how many steps you run.</p>\n\n<p>The reason your first version doesn\'t work is that, when a <code>Tensor</code> is captured (like <code>adder</code> or <code>subtractor</code> in your example), an additional <code>Switch</code> node is added to enforce the logic that the value of the tensor is only forwarded to the branch that actually executes. This is an artifact of how TensorFlow combines feed-forward dataflow and control flow  in its execution model. The result is that the captured tensors (in this case the results of the <code>assign_add</code> and <code>assign_sub</code>) will always be evaluated, even if they aren\'t used, and you\'ll see their side effects. This is something we need to document better, and <a href=""https://stackoverflow.com/a/34934516/3574081"">as Michael says</a>, we\'re going to make this more usable in future.</p>\n'}, {'owner': {'reputation': 179, 'user_id': 5823391}, 'down_vote_count': 0, 'up_vote_count': 9, 'is_accepted': False, 'score': 9, 'creation_date': 1453410983, 'answer_id': 34934516, 'question_id': 34931121, 'body': '<p>The second case works because you have added the ops within the cond: this causes them to conditionally execute. </p>\n\n<p>The first case it is analogous to saying:</p>\n\n<pre><code>adder = (count += 1)\nsubtractor = (count -= 2)\nif (cond) { adder } else { subtractor }\n</code></pre>\n\n<p>Since adder and subtractor are outside the conditional, they are always executed.</p>\n\n<p>The second case is more like saying</p>\n\n<pre><code>if (cond) { adder = (count += 1) } else { subtractor = (count -= 2) }\n</code></pre>\n\n<p>which in this case does what you expected.</p>\n\n<p>We realize that the interaction between side effects and (somewhat) lazy evaluation is confusing, and we have a medium-term goal to make things more uniform. But the important thing to understand for now is that we do not do true lazy evaluation: the conditional acquires a dependency on every quantity defined outside the conditional that is used within either branch.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9734}"
253,72165812,"{'items': [{'owner': {'reputation': 3106, 'user_id': 11163122}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1652068054, 'answer_id': 72166793, 'question_id': 72165812, 'body': '<p>Okay I figured it out.  I needed to pass a <code>tf.Tensor</code>, not a <code>tf.data.Dataset</code>.  One can get a <code>Tensor</code> out by iterating over the <code>Dataset</code>.</p>\n<p>This can be done in a few ways:</p>\n<pre class=""lang-py prettyprint-override""><code>train_ds = tf.keras.preprocessing.image_dataset_from_directory(...)\n\n# Option 1\nbatch_images = next(iter(train_ds))[0]\npreprocessed_images = tf.keras.applications.vgg16.preprocess_input(batch_images)\n\n# Option 2:\nfor batch_images, batch_labels in train_ds:\n    preprocessed_images = tf.keras.applications.vgg16.preprocess_input(batch_images)\n</code></pre>\n<p>If you convert option 2 into a generator, it can be directly passed into the downstream <code>model.fit</code>. Cheers!</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9730}"
254,65640885,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9730}"
255,74359221,"{'items': [{'owner': {'reputation': 10889, 'user_id': 7370153}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1667907086, 'answer_id': 74360022, 'question_id': 74359221, 'body': ""<p>You can see a Tensor as a multidimensional vector, i.e a structure with a fixed size and dimension and containing elements sharing the same type. Your return value is a map between a string and a list of dictionaries. A list of dictionaries cannot be converted to a tensor, because there is no guarantee that the number of dimensions and their size is constant, nor a guarantee that each element is sharing the same type.</p>\n<p>You could instead return the raw output of your network, which should be a tensor and do your post processing outside of tensorflow-serving.</p>\n<hr />\n<p>If you really want to do something like in your question, you can use a Tensor of strings instead, and you could use some code like that:</p>\n<pre><code>labels = tf.constant(['label1', 'label2'])\n# if your batch size is dynamic, you can use tf.shape on your results variable to find it at runtime\nbatch_size = 32\n# assuming your model returns something with the shape (N,2)\nresults = tf.random.uniform((batch_size,2))\nres_as_str = tf.strings.as_string(results, precision=5)\nreturn {\n    &quot;results&quot;: tf.stack(\n        [tf.tile(labels[None, :], [batch_size, 1]), res_as_str], axis=-1\n    )\n} \n</code></pre>\n<p>The output will be a dictionary mapping the value &quot;results&quot; to a Tensor of dimensions <code>(Batch, number of labels, 2)</code>, the last dimension containing the label name and its corresponding value.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9730}"
256,43567551,"{'items': [{'owner': {'reputation': 899, 'user_id': 2084543}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1493768447, 'answer_id': 43748871, 'question_id': 43567551, 'body': '<p>I believe this should work ""as expected"" in the <a href=""https://github.com/tensorflow/tensorflow/#installation"" rel=""nofollow noreferrer"">tensorflow nightly builds</a>.  Please try this with a TF nightly build and report back:</p>\n\n<p>Oh, also call <code>tf.set_random_seed</code> <em>before</em> creating any ops.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9730}"
257,69587392,"{'items': [{'owner': {'reputation': 421, 'user_id': 14846465}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1634322086, 'answer_id': 69589059, 'question_id': 69587392, 'body': '<p>Okay, so I am not able to answer the whole question, but I can tell you why you are not able to print anything inside your function. As you can read in the documentation of tf.data.Dataset, a call of dataset.map() will execute the function that is mapped always in graph mode and not in eager mode, which does not allow any printing. For further information, check <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map</a></p>\n<p>In the same section, it is described what to do if you want to use python code inside such a function, which is using tf.py_function(). I have not worked with this yet, but it seems like you should be able to call it in the following way:</p>\n<pre><code>ds = ds.map(lambda x: tf.py_function(func=split_window, inp=[self, x], Tout=(tf.float32, tf.float32)))\n</code></pre>\n<p>This then should give you the necessary tools to find the answer to your question.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9730}"
258,55300544,"{'items': [{'owner': {'reputation': 965, 'user_id': 8114748}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1554083023, 'answer_id': 55447128, 'question_id': 55300544, 'body': '<p>Although this is not visible in the generated code, the step variable will actually be autoboxed to a Tensor by the for loop which is being converted to a TF while_loop.</p>\n\n<p>You can verify that by adding a print statement:</p>\n\n<pre><code>    loss = train_one_step(model, optimizer, x, y)\n    print(step)\n    if tf.equal(step % 10, 0):\n</code></pre>\n'}, {'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1553264477, 'answer_id': 55301670, 'question_id': 55300544, 'body': '<p>Yes, you\'re right. The integer variable step remains a Python variable even when converted to its graph representation. You can see the conversion result by calling <code>tf.autograph.to_code(train.python_function)</code>.</p>\n\n<p>Without reporting all the code but only the <code>step</code> variable related part, you\'ll see that</p>\n\n<pre><code>  def loop_body(loop_vars, loss_1, step_1):\n    with ag__.function_scope(\'loop_body\'):\n      x, y = loop_vars\n      step_1 += 1\n</code></pre>\n\n<p>Is still a python operation (otherwise it will be <code>step_1.assign_add(1)</code> if step 1 was a <code>tf.Tensor</code>).</p>\n\n<p>For more information about autograph and tf.function I suggest reading the article <a href=""https://pgaleone.eu/tensorflow/tf.function/2019/03/21/dissecting-tf-function-part-1/"" rel=""nofollow noreferrer"">https://pgaleone.eu/tensorflow/tf.function/2019/03/21/dissecting-tf-function-part-1/</a> that explains easily what happens when a function is converted.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9725}"
259,55996869,"{'items': [{'owner': {'reputation': 12542, 'user_id': 851699}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1680040992, 'answer_id': 75871438, 'question_id': 55996869, 'body': '<p>Another option for computing square root is to approximate it with an iterative solution like <a href=""https://en.wikipedia.org/wiki/Square_root_of_a_matrix#By_Denman%E2%80%93Beavers_iteration"" rel=""nofollow noreferrer"">Denmann-Beavers iteration</a>.  I had to do this when implementing a model in <code>tflite</code>, on which <code>tf.linalg.sqrtm()</code> is not supported (unless you go through the hassle of adding custom ops)</p>\n<pre><code>def tf_denmann_beavers_sqrtm(matrix: TensorInvCovMat, n_iter=10):\n    &quot;&quot;&quot;\n    Approximate the matrix-square-root by Denmann Beavers iteration\n        https://en.wikipedia.org/wiki/Square_root_of_a_matrix#By_Denman%E2%80%93Beavers_iteration\n    Convergence is not guaranteed.  Use at your own risk!\n    &quot;&quot;&quot;\n    ym = matrix\n    zm = tf.eye(tf.shape(matrix[0])[0], dtype=matrix.dtype)\n    for i in range(n_iter):\n        ym_ = 0.5 * (ym + tf.linalg.inv(zm))\n        zm = 0.5 * (zm + tf.linalg.inv(ym))\n        ym = ym_\n    return ym\n</code></pre>\n<pre><code>def test_tf_denmann_beavers_sqrtm():\n    invcov_matrix = tf.constant([\n        [4496.2685546875, -384.8538513183594, -3997.38623046875],\n        [-384.8897705078125, 8825.5615234375, -8400.1064453125],\n        [-3997.349853515625, -8400.1416015625, 12311.6171875]\n    ], dtype=tf.float32)\n    mat_sqrt = tf.linalg.sqrtm(invcov_matrix).numpy()\n    approx_mat_sqrt = tf_denmann_beavers_sqrtm(invcov_matrix, n_iter=10).numpy()\n    assert np.allclose(mat_sqrt, approx_mat_sqrt, atol=1e-3)\n\n</code></pre>\n'}, {'owner': {'reputation': 13934, 'user_id': 2455494}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1557161791, 'answer_id': 56009441, 'question_id': 55996869, 'body': '<p><code>tf.linalg.sqrtm</code> is just an alias for <code>matrix_square_root</code>. The source for which is hosted on github and can be found <a href=""https://github.com/tensorflow/tensorflow/blob/df3a3375941b9e920667acfe72fb4c33a8f45503/tensorflow/contrib/opt/python/training/matrix_functions.py"" rel=""nofollow noreferrer"">here</a>.</p>\n\n<p>TensorFlow code is open source under the Apache Licence so, sure, if you know what you are doing you can fork it and amend it to your own requirements. Maybe if your use-case is specific to your own requirements you could also just build your own alternative <code>sqrtm</code> function.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9725}"
260,44206534,"{'items': [{'owner': {'reputation': 3673, 'user_id': 4023951}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1495858835, 'answer_id': 44212933, 'question_id': 44206534, 'body': '<h1>Question</h1>\n\n<ol>\n<li>Why do I need <strong>tf.transpose()</strong>?</li>\n<li>What is the purpose of <strong>tf.transpose()</strong>?</li>\n</ol>\n\n<h1>Answer</h1>\n\n<ol>\n<li><p>Why do I need <strong>tf.transpose()</strong>?  I can\'t imagine why you would need it unless you coded your solution from the beginning to require it.  For example, suppose I have 120 student records with 50 stats per student and I want to use that to try and make a linear association with their chance of taking 3 classes.  I\'d state it like so</p>\n\n<p>c = r x m</p></li>\n</ol>\n\n<p>r = records, a matrix with a shape if [120x50]\nm = the induction matrix.  it has a shape of [50x3]\nc = the chance of all students taking one of three courses, a matrix with a shape of [120x3]</p>\n\n<p>Now if instead of making m [50x3], we goofed and made m [3x50], then we\'d have to transpose it before multiplication.</p>\n\n<ol start=""2"">\n<li>What is the purpose of <strong>tf.transpose()</strong>?</li>\n</ol>\n\n<p>Sometimes you just need to swap rows and columns, like above.  <a href=""https://en.wikipedia.org/wiki/Transpose"" rel=""nofollow noreferrer"">Wikipedia</a> has a fantastic page on it.  The transpose function has some excellent properties for matrix math function, like associativeness and associativeness with the inverse function.</p>\n\n<h1>Summary</h1>\n\n<p>I don\'t think I\'ve ever used <strong>tf.transpose</strong> in any <strong>CNN</strong> I\'ve written.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9723}"
261,48697799,"{'items': [{'owner': {'reputation': 5140, 'user_id': 1560163}, 'down_vote_count': 0, 'up_vote_count': 14, 'is_accepted': False, 'score': 14, 'creation_date': 1533254112, 'answer_id': 51663600, 'question_id': 48697799, 'body': '<p>Here is an example how to feed data to the indicator column:</p>\n\n<pre><code>features = {\'letter\': [[\'A\',\'A\'], [\'C\',\'D\'], [\'E\',\'F\'], [\'G\',\'A\'], [\'X\',\'R\']]}\n\nletter_feature = tf.feature_column.categorical_column_with_vocabulary_list(\n                ""letter"", [""A"", ""B"", ""C""], dtype=tf.string)\n\nindicator = tf.feature_column.indicator_column(letter_feature)\ntensor = tf.feature_column.input_layer(features, [indicator])\n\nwith tf.Session() as session:\n    session.run(tf.global_variables_initializer())\n    session.run(tf.tables_initializer())\n    print(session.run([tensor]))\n</code></pre>\n\n<p>Which outputs:</p>\n\n<pre><code>[array([[2., 0., 0.],\n       [0., 0., 1.],\n       [0., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 0.]], dtype=float32)]\n</code></pre>\n'}, {'owner': {'reputation': 141, 'user_id': 938746}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1518144442, 'answer_id': 48698005, 'question_id': 48697799, 'body': '<p>you should use tf.feature_column.indicator_column\nsee <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/indicator_column"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/indicator_column</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9723}"
262,45900233,"{'items': [{'owner': {'reputation': 11, 'user_id': 9388748}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1531289219, 'answer_id': 51278284, 'question_id': 45900233, 'body': '<p>The ValueError produced doesn\'t have anything to do with the first 2 calls to Strided_Slice. Your use of the Strided_Slice operation is correct in</p>\n<blockquote>\n<p>print(sess.run(tf.strided_slice(x, [1, 0, 0], [2, 1, 3], [1, 1, 1])))</p>\n<p>print(sess.run(tf.strided_slice(x, [1, -1, 0], [2, -3, 3], [1, -1, 1])))</p>\n</blockquote>\n<p>Your issue is with the call to</p>\n<blockquote>\n<p>print(sess.run(x[2,-3,3]))</p>\n</blockquote>\n<p>A negative index in a python array iterates in reverse through the array.</p>\n<p>For example, given an array like this</p>\n<pre><code>arr = [\'a\', \'b\', \'c\', \'d\', \'e\', \'f\']\n</code></pre>\n<p>A call to arr[-1] would yield \'f\'. Similarly, a call to arr[-4] would yield \'c\'. What would happen if we tried calling arr[-7]? This would be trying to access the index -1, which would throw an error.</p>\n<p>Keep in mind that arrays in Python have 0-based indexing. Your call to x[<strong>2</strong>,-3, 3] initially accesses the element at index 2 (3rd element) in the outer array, which is</p>\n<pre><code>[[311, 312, 313], [321, 322, 323]]\n</code></pre>\n<p>Now, in this outer array, there are 2 elements. However, your call x[2, <strong>-3</strong>, 3] attempts to access the element at index -1 as it iterates from the end of the array. This is what yields the error</p>\n<blockquote>\n<p>slice index -1 of dimension 1 out of bounds</p>\n</blockquote>\n<p><strong>NOTE</strong>: The last index you try to access in x[2, -3, <strong>3</strong>] will also yield a ValueError because it is attempting to access an index not in the array. To fix this, your call could be x[2, -2, 2].</p>\n<p>Here are a few links about Strided Slicing, Slicing, and array indexing in Python:\n<a href=""https://www.tensorflow.org/api_docs/python/tf/strided_slice"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/strided_slice</a></p>\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/slice"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/slice</a></p>\n<p><a href=""https://stackoverflow.com/questions/11367902/negative-list-index/11367936"">Negative list index?</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9721}"
263,55421386,"{'items': [{'owner': {'reputation': 1012, 'user_id': 8500534}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1566214030, 'answer_id': 57555814, 'question_id': 55421386, 'body': '<p>The behavior you desire could be achieved through following steps.</p>\n\n<p>This works in TF 2.0.0-beta1, but may being changed or even simplified in further reseases.</p>\n\n<p>Please check out issue in TensorFlow github repository <a href=""https://github.com/tensorflow/tensorflow/issues/27416#issuecomment-502218673"" rel=""nofollow noreferrer"">Unable to use FeatureColumn with Keras Functional API #27416</a>. There you will find the more general example and useful comments about <code>tf.feature_column</code> and <code>Keras Functional API</code>.</p>\n\n<p>Meanwhile, based on the code in your question the input tensor for feature_column could be get like this:</p>\n\n<pre><code># This you have defined feauture column\nkid_youngest_month = feature_column.numeric_column(""kid_youngest_month"")\n     kid_age_youngest_buckets = feature_column.bucketized_column(kid_youngest_month, boundaries=[12, 24, 36, 72, 96])\n\n# Then define layer\nfeature_layer = tf.keras.layers.DenseFeatures(kid_age_youngest_buckets)\n\n# The inputs for DenseFeature layer should be define for each original feature column as dictionary, where\n# keys - names of feature columns\n# values - tf.keras.Input with shape =(1,), name=\'name_of_feature_column\', dtype - actual type of original column \nfeature_layer_inputs = {}\nfeature_layer_inputs[\'kid_youngest_month\'] = tf.keras.Input(shape=(1,), name=\'kid_youngest_month\', dtype=tf.int8)\n\n# Then you can collect inputs of other layers and feature_layer_inputs into one list \ninputs=[review_meta_id_input, priors_input, [v for v in feature_layer_inputs.values()]]\n\n# Then define outputs of this DenseFeature layer\nfeature_layer_outputs = feature_layer(feature_layer_inputs)\n# And pass them into other layer like any other\nx = tf.keras.layers.Dense(256, activation=\'relu\')(feature_layer_outputs)\n# Or maybe concatenate them with outputs from your others layers\ncombined = tf.keras.layers.concatenate([x, feature_layer_outputs])\n\n#And probably you will finish with last output layer, maybe like this for calssification\no=tf.keras.layers.Dense(classes_number, activation=\'softmax\', name=\'sequential_output\')(combined)\n\n#So you pass to the model:\n\nmodel_combined = tf.keras.models.Model(inputs=[s_inputs, [v for v in feature_layer_inputs.values()]], outputs=o)\n</code></pre>\n\n<p>Also note. In model <code>fit()</code> method you should pass info which data sould be used for each input.</p>\n\n<p>One way, if you use <code>tf.data.Dataset</code>, take care that you have used the same names for features in <code>Dataset</code> and for keys in <code>feature_layer_inputs</code> dictionary</p>\n\n<p>Other way use explicite notation like:</p>\n\n<pre><code>model.fit({\'review_meta_id_input\': review_meta_id_data, \'priors_input\': priors_data, \'kid_youngest_month\': kid_youngest_month_data},\n          {\'outputs\': o},\n          ...\n         )\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9721}"
264,76444107,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9721}"
265,45347275,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 1, 'up_vote_count': 6, 'is_accepted': True, 'score': 5, 'creation_date': 1501150048, 'answer_id': 45347628, 'question_id': 45347275, 'body': '<p><a href=""https://www.tensorflow.org/api_docs/python/tf/gradients"" rel=""noreferrer""><code>tf.gradients</code></a> does not allow you to compute Jacobians, it aggregates the gradients of each input for every output (something like the summation of each column of the actual Jacobian matrix). In fact, there is no ""good"" way of computing Jacobians in TensorFlow (basically you have to call <code>tf.gradients</code> once per output, <a href=""https://github.com/tensorflow/tensorflow/issues/675"" rel=""noreferrer"">see this issue</a>).</p>\n\n<p>With respect to <a href=""https://www.tensorflow.org/api_docs/python/tf/train/Optimizer#compute_gradients"" rel=""noreferrer""><code>tf.train.Optimizer.compute_gradients</code></a>, yes, its result is basically the same, but taking care of some details automatically and with slightly more convenient output format. If you look at <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/optimizer.py"" rel=""noreferrer"">the implementation</a>, you will see that, at its core, is a call to <code>tf.gradients</code> (in this case aliased to <code>gradients.gradients</code>), but it is useful for optimizer implementations to have the surrounding logic already implemented. Also, having it as a method allows for extensible behaviour in subclasses, either to implement some kind of optimization strategy (not very likely at the <code>compute_gradients</code> step, really) or for auxiliary purposes, like tracing or debugging.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9721}"
266,64424397,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9717}"
267,37159372,"{'items': [{'owner': {'reputation': 2747, 'user_id': 5765409}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': False, 'score': 7, 'creation_date': 1463509130, 'answer_id': 37283580, 'question_id': 37159372, 'body': '<p>[NOTE: this answer is updated for r1.0 ... but explains <code>legacy_seq2seq</code> instead of <code>tensorflow/tensorflow/contrib/seq2seq/</code>]</p>\n\n<p>The good news is that the seq2seq models provided in tensorflow are pretty sophisticated including embeddings, buckets, attention mechanism, one-to-many multi-task models, etc.</p>\n\n<p>The bad news is that there is much complexity and layers of abstraction in the Python code, and that the code itself is the best available ""documentation"" of the higher-level RNN and seq2seq ""API"" as far as I can tell...thankfully the code is well docstring\'d.</p>\n\n<p>Practically speaking I think the examples and helper functions pointed to below are mainly useful for reference to understand coding patterns...and that in most cases you\'ll need to re-implement what you need using the basic functions in the lower-level <a href=""https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python"" rel=""nofollow noreferrer"">Python API</a></p>\n\n<p>Here is a breakdown of the RNN seq2seq code from the top down as of version r1.0:</p>\n\n<p><strong><a href=""https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/translate.py"" rel=""nofollow noreferrer""> models/tutorials/rnn/translate/translate.py </a></strong></p>\n\n<p>...provides <code>main()</code>, <code>train()</code>, <code>decode()</code> that works out-of-the-box to translate english to french...but you can adapt this code to other data sets</p>\n\n<p><strong><a href=""https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py"" rel=""nofollow noreferrer""> models/tutorials/rnn/translate/seq2seq_model.py </a></strong></p>\n\n<p>...<code>class Seq2SeqModel()</code> sets up a sophisticated RNN encoder-decoder with embeddings, buckets, attention mechanism...if you don\'t need embeddings, buckets, or attention you\'ll need to implement a similar class.</p>\n\n<p><strong><a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn.py"" rel=""nofollow noreferrer""> tensorflow/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py </a></strong></p>\n\n<p>...main entry point for seq2seq models via helper functions. See <code>model_with_buckets()</code>, <code>embedding_attention_seq2seq()</code>, <code>embedding_attention_decoder()</code>, <code>attention_decoder()</code>, <code>sequence_loss()</code>, etc. \nExamples include <code>one2many_rnn_seq2seq</code> and models without embeddings/attention also provided like <code>basic_rnn_seq2seq</code>. If you can jam your data into the tensors that these functions will accept this could be your best entry point to building your own model.</p>\n\n<p><strong><a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn.py"" rel=""nofollow noreferrer""> tensorflow/tensorflow/contrib/rnn/python/ops/core_rnn.py </a></strong></p>\n\n<p>...provides a wrappers for RNN networks like <code>static_rnn()</code> with some bell and whistles I usually don\'t need so I just use code like this instead:</p>\n\n<pre><code>def simple_rnn(cell, inputs, dtype, score):\n    with variable_scope.variable_scope(scope or ""simple_RNN"") as varscope1:\n            if varscope1.caching_device is None:\n                varscope1.set_caching_device(lambda op: op.device)\n\n        batch_size = array_ops.shape(inputs[0])[0]\n        outputs = []\n        state = cell.zero_state(batch_size, dtype)            \n\n        for time, input_t in enumerate(inputs):\n           if time &gt; 0:      \n             variable_scope.get_variable_scope().reuse_variables()\n\n\n           (output, state) = cell(input_t, state)\n\n           outputs.append(output)\n\n        return outputs, state\n</code></pre>\n'}, {'owner': {'reputation': 52331, 'user_id': 86967}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1473827057, 'answer_id': 39482453, 'question_id': 37159372, 'body': '<p>RNN docs for the current/master version of TensorFlow:\n<a href=""https://www.tensorflow.org/versions/master/api_docs/python/nn.html#recurrent-neural-networks"" rel=""nofollow"">https://www.tensorflow.org/versions/master/api_docs/python/nn.html#recurrent-neural-networks</a></p>\n\n<p>RNN docs for a specific version of TensorFlow:\n<a href=""https://www.tensorflow.org/versions/r0.10/api_docs/python/nn.html#recurrent-neural-networks"" rel=""nofollow"">https://www.tensorflow.org/versions/r0.10/api_docs/python/nn.html#recurrent-neural-networks</a></p>\n\n<p>For the curious, here are some notes about why the RNN docs weren\'t available initially:\n<a href=""https://github.com/tensorflow/tensorflow/issues/7"" rel=""nofollow"">API docs does not list RNNs</a></p>\n'}, {'owner': {'reputation': 704, 'user_id': 5860627}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1463026783, 'answer_id': 37177201, 'question_id': 37159372, 'body': '<p>So far I also can\'t find API references about rnn functions on their site.</p>\n\n<p>However, I believe you can see the comments for each functions on github as a function reference.</p>\n\n<p><a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py"" rel=""nofollow"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py</a></p>\n\n<p><a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py"" rel=""nofollow"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9717}"
268,66478545,"{'items': [{'owner': {'reputation': 1006, 'user_id': 4280842}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1614873835, 'answer_id': 66478710, 'question_id': 66478545, 'body': '<p><code>axis</code> means the axis along which to normalize. In your case, for each example among 60,000 examples, with <code>axis = 1</code>, all the rows of each matrix 28x28 will be normalized.</p>\n<p>Basically, your data has shape <code>(60000, 28, 28)</code>. This means <code>axis</code> can be 0, 1 or 2:</p>\n<pre><code>axis=0 -&gt; 60,000 elements\naxis=1 -&gt; 28 elements\naxis=2 -&gt; 28 elements\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9717}"
269,48732627,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9717}"
270,71446995,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9717}"
271,71893462,"{'items': [{'owner': {'reputation': 164, 'user_id': 3261764}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1651778278, 'answer_id': 72132554, 'question_id': 71893462, 'body': ""<p>Preprocess your data into three TFRecord files, one each for training, testing, and validation.  Then you can shuffle and never cross records between the sets.  This also speeds up data loading and can be done once and  reused many times while playing with hyperparameters.</p>\n<p>Here is an example of how you can preprocess and split your data. Your actual dataset data will have a different structure, this example has &quot;encdata&quot;, a 2048-wide vector of vggface2 face encoding data. This assumes you have a single directory of data, with subdirectories named for a class and containing all the files for that class.</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport pickle\nimport sys\nimport os\n\n# 80% to training, 10% to testing, 10% to validation\nvalidation_portion = 1\ntesting_portion = 1\ntraining_portion = 8\nfile_cycle_total = validation_portion + testing_portion + training_portion\n\n# Where to store the TFRecord files\ntraining_tfrecord_path = '/var/tmp/xtraining_tfrecords.tfr'\ntesting_tfrecord_path = '/var/tmp/xtesting_tfrecords.tfr'\nvalidation_tfrecord_path = '/var/tmp/xvalidation_tfrecords.tfr'\n\n# Where we keep the encodings\nFACELIB_DIR='/aimiassd/Datasets/LabeledAstroFaces'\n\n# Get list of all classes from all facelib dirs\nclassNames = sorted([x for x in os.listdir(FACELIB_DIR) if os.path.isdir(os.path.join(FACELIB_DIR,x)) and not x.startswith('.')])\nclassStrToInt = dict([(x,i) for i,x in enumerate(classNames)])\nprint('Found %d different classNames for labels\\n' % len(classNames))\n    \n# Create our record writers\ntrain_file_writer = tf.io.TFRecordWriter(training_tfrecord_path)\ntest_file_writer = tf.io.TFRecordWriter(testing_tfrecord_path)\nval_file_writer = tf.io.TFRecordWriter(validation_tfrecord_path)\n    \n# Create a dataset of filenames of every enc2048 file in the facelibraries\ncnt_records_written = [0,0,0]\nfor CN in classNames:\n    class_int = classStrToInt[CN]\n    # Get a list of all the encoding files\n    encfiles = sorted(filter((lambda x: x.endswith('.enc2048')), os.listdir(os.path.join(FACELIB_DIR, CN))))\n    # For each encoding file, read the encoding data and write it to the various tfrecords\n    for i, F in enumerate(encfiles):\n        file_path = os.path.join(FACELIB_DIR,CN,F)\n        with open(file_path,'rb') as fin:\n            encdata,_ = pickle.loads(fin.read())    # encodings, source_image_name\n        # Turn encdata into a tf.train.Example and serialize it for writing\n        record_bytes = tf.train.Example(features=tf.train.Features(feature={\n                &quot;x&quot;: tf.train.Feature(float_list=tf.train.FloatList(value=encdata)),\n                &quot;y&quot;: tf.train.Feature(int64_list=tf.train.Int64List(value=[class_int])),\n            })).SerializeToString()\n        # Write it out with the appropriate record writer\n        remainder = i % file_cycle_total\n        if remainder &lt; validation_portion:\n            val_file_writer.write(record_bytes)\n            cnt_records_written[2] += 1\n        elif remainder &lt; validation_portion + testing_portion:\n            test_file_writer.write(record_bytes)\n            cnt_records_written[1] += 1\n        else:\n            train_file_writer.write(record_bytes)\n            cnt_records_written[0] += 1\n   \nprint('Writing records done.')\nprint('Wrote %d training, %d testing, %d validation records' % \n    (cnt_records_written[0], cnt_records_written[1], cnt_records_written[2]) )\n\ntrain_file_writer.close()\ntest_file_writer.close()\nval_file_writer.close()\n\n\nprint('Reading data back out...')\n\n# Function to turn a serialized TFRecord back into a tf.train.Example\ndef decode_fn(record_bytes):\n  return tf.io.parse_single_example(\n      # Data\n      record_bytes,\n\n      # Schema\n      {&quot;x&quot;: tf.io.FixedLenFeature([2048], dtype=tf.float32),\n       &quot;y&quot;: tf.io.FixedLenFeature([], dtype=tf.int64)}\n  )\n\n\n# Read and deserialize the datasets\ntrain_ds = tf.data.TFRecordDataset([training_tfrecord_path]).map(decode_fn)\ntest_ds = tf.data.TFRecordDataset([ testing_tfrecord_path]).map(decode_fn)\nvalidation_ds = tf.data.TFRecordDataset([validation_tfrecord_path]).map(decode_fn)\n\n\n# Use a dataset\ncount = 0\nfor batch in tf.data.TFRecordDataset([training_tfrecord_path]).map(decode_fn):\n    print(batch)\n    count +=1\n    if count &gt; 4:\n        sys.exit(0)\n\nprint('Done.')\n</code></pre>\n<p>Note how as the data is being process into TFRecords, it is alternately being written into the three datasets.  Verify and Testing entries are written first, to ensure classes with very small amounts of samples still get something into the verify and testing datasets.  This is controlled by the variables at the top, validation_portion, testing_portion, and training_portion, adjust per your preferences.</p>\n<p>Finally, at the end, the TFRecords are re-read and used to build three new tf.data.Dataset, which can be fed to model.fit() and friends.  The example code just prints four records to show the data is of the correct, original shape.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9712}"
272,52711895,"{'items': [{'owner': {'reputation': 6270, 'user_id': 4282745}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1539073445, 'answer_id': 52716460, 'question_id': 52711895, 'body': '<p>As far as I can tell, you can only do it using a hack.</p>\n\n<p>The issue comes from the call to:</p>\n\n<pre><code>  if sampled_values is None:\n      sampled_values = candidate_sampling_ops.log_uniform_candidate_sampler(\n          true_classes=labels,\n          num_true=num_true,\n          num_sampled=num_sampled,\n          unique=True,\n          range_max=num_classes,\n          seed=seed)\n</code></pre>\n\n<p>which outputs an object of this type:</p>\n\n<pre><code>LogUniformCandidateSampler(\n    sampled_candidates=&lt;tf.Tensor \'LogUniformCandidateSampler:0\' shape=(128,) dtype=int64&gt;,\n    true_expected_count=&lt;tf.Tensor \'LogUniformCandidateSampler:1\' shape=(64, 1) dtype=float32&gt;,\n    sampled_expected_count=&lt;tf.Tensor \'LogUniformCandidateSampler:2\' shape=(128,) dtype=float32&gt;\n)\n</code></pre>\n\n<p>The hack would be to generate yourself the <code>LogUniformCandidateSampler</code>, to cast its result as <code>tf.float16</code> and pass it to <code>tf.nn.sampled_softmax_loss</code>.</p>\n\n<pre><code># Redefine it as the tensorflow one is not exposed.\nLogUniformCandidateSampler = namedtuple(""namedtuple"", [""sampled_candidates"", ""true_expected_count"", ""sampled_expected_count""]) \nsampled_values = tf.nn.log_uniform_candidate_sampler(\n      true_classes=tf.cast(train_labels, tf.int64), num_sampled=num_sampled,\n      num_true=1,\n      unique=True,\n      range_max=vocabulary_size,\n      seed=None)\n\nsampled_value_16 = LogUniformCandidateSampler(\n    sampled_values.sampled_candidates,\n    tf.cast(sampled_values.true_expected_count, tf.float16),\n    tf.cast(sampled_values.sampled_expected_count, tf.float16))\n\nsam_sof_los = tf.nn.sampled_softmax_loss(\n    weights=softmax_weights,\n    biases=softmax_biases,\n    inputs=averaged_embeds,\n    labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size, \n    sampled_values=sampled_value_16)\n</code></pre>\n\n<p>But this is really a hack and it might have unexpected consequences (an expected one would be that the <code>tf.cast</code> operation is not differentiable).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9712}"
273,62028248,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1591746079, 'answer_id': 62293632, 'question_id': 62028248, 'body': '<p>Here are the experiments that we have tried. The results for <code>tf.random.set_seed</code> are identical.</p>\n\n<p><strong>Experiment 1  :</strong> <code>tf.random.set_seed(1234)</code> set only once. </p>\n\n<pre><code>import tensorflow as tf\n\nfor i in range(5):\n  print(""Iteration Number :"", i)\n  tf.random.set_seed(1234)\n  print(tf.random.uniform([1]))  # generates \'A1\'\n  print(tf.random.uniform([1]))  # generates \'A2\'\n  print(tf.random.uniform([1]))  # generates \'A3\'\n</code></pre>\n\n<p><strong>Output -</strong> Generates same value for every iteration for <code>A1</code>, <code>A2</code> and <code>A3</code>.</p>\n\n<pre><code>Iteration Number : 0\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.3253647], shape=(1,), dtype=float32)\ntf.Tensor([0.59750986], shape=(1,), dtype=float32)\nIteration Number : 1\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.3253647], shape=(1,), dtype=float32)\ntf.Tensor([0.59750986], shape=(1,), dtype=float32)\nIteration Number : 2\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.3253647], shape=(1,), dtype=float32)\ntf.Tensor([0.59750986], shape=(1,), dtype=float32)\nIteration Number : 3\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.3253647], shape=(1,), dtype=float32)\ntf.Tensor([0.59750986], shape=(1,), dtype=float32)\nIteration Number : 4\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.3253647], shape=(1,), dtype=float32)\ntf.Tensor([0.59750986], shape=(1,), dtype=float32)\n</code></pre>\n\n<p>Lets restart the runtime or kernel and verify the result.</p>\n\n<p><strong>Output -</strong> Generates same value for every iteration for <code>A1</code>, <code>A2</code> and <code>A3</code>. And also the results match with the previous run results.</p>\n\n<pre><code>Iteration Number : 0\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.3253647], shape=(1,), dtype=float32)\ntf.Tensor([0.59750986], shape=(1,), dtype=float32)\nIteration Number : 1\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.3253647], shape=(1,), dtype=float32)\ntf.Tensor([0.59750986], shape=(1,), dtype=float32)\nIteration Number : 2\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.3253647], shape=(1,), dtype=float32)\ntf.Tensor([0.59750986], shape=(1,), dtype=float32)\nIteration Number : 3\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.3253647], shape=(1,), dtype=float32)\ntf.Tensor([0.59750986], shape=(1,), dtype=float32)\nIteration Number : 4\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.3253647], shape=(1,), dtype=float32)\ntf.Tensor([0.59750986], shape=(1,), dtype=float32)\n</code></pre>\n\n<p><strong>Experiment 2 :</strong> <code>tf.random.set_seed(1234)</code> set for every operation.</p>\n\n<pre><code>for i in range(5):\n  print(""Iteration Number :"", i)\n  tf.random.set_seed(1234)\n  print(tf.random.uniform([1]))  # generates \'A1\'\n  tf.random.set_seed(1234)\n  print(tf.random.uniform([1]))  # generates \'A1\'\n  tf.random.set_seed(1234)\n  print(tf.random.uniform([1]))  # generates \'A1\'\n</code></pre>\n\n<p><strong>Output -</strong> All the values are identical as <code>tf.random.set_seed</code> is set for every operation.</p>\n\n<pre><code>Iteration Number : 0\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\nIteration Number : 1\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\nIteration Number : 2\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\nIteration Number : 3\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\nIteration Number : 4\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\ntf.Tensor([0.5380393], shape=(1,), dtype=float32)\n</code></pre>\n\n<p>The values remain the same even after you restart the kernel.</p>\n\n<p>If you still have any doubts, kindly share the reproducible code with your expectations.</p>\n\n<p>Hope this answers your question. Happy Learning.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9712}"
274,54606302,"{'items': [{'owner': {'reputation': 932, 'user_id': 1757224}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': False, 'score': 7, 'creation_date': 1615020945, 'answer_id': 66503974, 'question_id': 54606302, 'body': ""<p>Here is my solution. To show how it works, I use cats/dogs datasets:</p>\n<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport tensorflow as tf\n\n\n_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\npath_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\nPATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n\ntrain_dir = os.path.join(PATH, 'train')\n#'/Users/mustafamuratarat/.keras/datasets/cats_and_dogs_filtered/train'\n\nBATCH_SIZE = 32\nIMG_SIZE = (160, 160)\n\nimg_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ngen = img_gen.flow_from_directory(train_dir, target_size=(160, 160), batch_size=32)\n#&lt;tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x7fb9fde3b250&gt;\n\n#gen.class_indices\n#{'cats': 0, 'dogs': 1}\n\n#gen.target_size\n#(160, 160)\n\n# gen.batch_size\n# 32\n\n# gen.num_classes\n# 2\n\ndataset = tf.data.Dataset.from_generator(\n    lambda: gen,\n    output_types = (tf.float32, tf.float32),\n    output_shapes = ([None, 160, 160, 3], [None, 2]),\n)\n\n#list(dataset.take(1).as_numpy_iterator())\n</code></pre>\n<p>Then you can feed <code>dataset</code> object to any model.</p>\n""}, {'owner': {'reputation': 4802, 'user_id': 2641587}, 'down_vote_count': 0, 'up_vote_count': 10, 'is_accepted': True, 'score': 10, 'creation_date': 1549721615, 'answer_id': 54607040, 'question_id': 54606302, 'body': '<p>Both <a href=""https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/keras/_impl/keras/preprocessing/image.py#L1351"" rel=""noreferrer"">batch_x</a> and <a href=""https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/keras/_impl/keras/preprocessing/image.py#L1383"" rel=""noreferrer"">batch_y</a> in <code>ImageDataGenerator</code> are of type <code>K.floatx()</code>, so must be <code>tf.float32</code> by default.</p>\n\n<p>Similar question was discussed already at <a href=""https://stackoverflow.com/questions/52636127/how-to-use-keras-generator-with-tf-data-api"">How to use Keras generator with tf.data API</a>. Let me copy-paste the answer from there:</p>\n\n<pre><code>def make_generator():\n    train_datagen = ImageDataGenerator(rescale=1. / 255)\n    train_generator = \n    train_datagen.flow_from_directory(train_dataset_folder,target_size=(224, 224), class_mode=\'categorical\', batch_size=32)\n    return train_generator\n\ntrain_dataset = tf.data.Dataset.from_generator(make_generator,(tf.float32, tf.float32))\n</code></pre>\n\n<p>The author faced another issue with the graph scope, but I guess it is unrelated to your question.</p>\n\n<p>Or as a one liner:</p>\n\n<pre><code>tf.data.Dataset.from_generator(lambda:\n    ImageDataGenerator().flow_from_directory(\'folder_path\'),(tf.float32, tf.float32))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9712}"
275,58096095,"{'items': [{'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 10, 'is_accepted': True, 'score': 10, 'creation_date': 1569409896, 'answer_id': 58097046, 'question_id': 58096095, 'body': ""<p>You're right, <code>tf.audio.decode_wav()</code> requires a tensor. You can provide one with \n<code>tf.io.read_file()</code> which reads wav file into tensor of type string.</p>\n\n<pre><code>raw_audio = tf.io.read_file(filename)\nwaveform = tf.audio.decode_wav(raw_audio)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9712}"
276,45879776,"{'items': [{'owner': {'reputation': 14166, 'user_id': 863713}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1504169665, 'answer_id': 45977297, 'question_id': 45879776, 'body': ""<p>I finally, found out how to make results reproducible. Just like @Anis suggested I should've set the graph seed and this can be done by:</p>\n\n<pre><code>with graph.as_default(), tf.device('/cpu:0'):\n    tf.set_random_seed(1234)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9707}"
277,63140320,"{'items': [{'owner': {'reputation': 1498, 'user_id': 7220545}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1595967623, 'answer_id': 63142173, 'question_id': 63140320, 'body': '<p>I understand that you are concerned about having your complete dataset in the memory.</p>\n<p>Do not worry, the <code>tf.data.Dataset</code> API is very efficient and it does not load your complete dataset in the memory.</p>\n<p>Internally it just creates a sequence of functions and when called with <code>model.fit()</code> it will load only the batch in the memory and not the complete dataset.</p>\n<p>You can read more in this <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""nofollow noreferrer"">link</a>, I am pasting the important part from the documentation.</p>\n<blockquote>\n<p>The tf.data.Dataset API supports writing descriptive and efficient\ninput pipelines. Dataset usage follows a common pattern:</p>\n<p>Create a source dataset from your input data. Apply dataset\ntransformations to preprocess the data. Iterate over the dataset and\nprocess the elements. Iteration happens in a streaming fashion, so the\nfull dataset does not need to fit into memory.</p>\n</blockquote>\n<p>From the last line you can understand that the <code>tf.data.Dataset</code> API does not load the complete dataset in the memory but one batch at a time.</p>\n<p>You will have to do the following to create batches of your dataset.</p>\n<p><code>train_ds.batch(32)</code></p>\n<p>This will create the batch of size <code>32</code>. Also you can use prefetch to prepare one batch berore it heads for training. This removes the bottleneck where the model is idle after training one batch and waiting for another batch.</p>\n<p><code>train_ds.batch(32).prefetch(1)</code></p>\n<p>You can also use the <code>cache</code> API to make your data pipeline even faster. It will cache your dataset and make the training much faster.</p>\n<p><code>train_ds.batch(32).prefetch(1).cache()</code></p>\n<p>So to answer in short, you do not need the <code>generator</code> if you are concerned about loading the whole dataset into memory, the <code>tf.data.Dataset</code> API takes care of it.</p>\n<p>I hope my answer finds you well.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9707}"
278,39971297,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1476191386, 'answer_id': 39978019, 'question_id': 39971297, 'body': '<p>The equivalent function in C++ is <a href=""https://github.com/tensorflow/tensorflow/blob/1975cd1e9d539e75a1b85b56f16448c91ef88d90/tensorflow/core/graph/gradients.h#L50"" rel=""nofollow""><code>tensorflow::AddSymbolicGradients()</code></a>. You will need to obtain a <code>tensorflow::Graph</code> object representing your graph to use this function. However, adding gradients in C++ is <strong>still experimental</strong>, so beware that this function signature is subject to change.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9707}"
279,62962147,"{'items': [{'owner': {'reputation': 17612, 'user_id': 5666087}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1595024456, 'answer_id': 62962498, 'question_id': 62962147, 'body': '<p>The number of steps per epoch is equal to <code>ceil(samples / batch_size)</code>. The default batch size in <code>model.fit</code> is 32 (<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">documentation</a>). If the MNIST training data has 60000 samples, then each epoch would take 60000 / 32 = 1875 steps.</p>\n<p><code>model.fit</code> also supports splitting your data into training and validation sets. You have done this with <code>validation_split=0.2</code>, so only 80% of the samples are part of the training set (20% are for validation). The new calculation would be 0.8 * 60000 / 32 = 1500. This is why you see 1500 steps per epoch.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9707}"
280,72360420,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1653388322, 'answer_id': 72361342, 'question_id': 72360420, 'body': ""<p>Maybe something like this (although each <code>Dense</code> layer receives data each time):</p>\n<pre><code>import tensorflow as tf\n\ndense1 = tf.keras.layers.Dense(64, activation='sigmoid')\ndense2 = tf.keras.layers.Dense(64, activation='relu')\ndense3 = tf.keras.layers.Dense(64, activation=None)\n\noperations = [dense1, dense2, dense3]\n\ndef call(x):\n    # Sample 2 of the 3 operations.\n    sampled_ids = tf.random.categorical(\n        tf.zeros((1, len(operations))), num_samples=2, dtype=tf.int32,\n    )[0]\n\n    op_results_eager = tf.stack([operations[op_id](x) for op_id in sampled_ids])\n \n    op_results_graph = tf.gather(tf.stack([dense1(x), dense2(x), dense3(x)]), sampled_ids)\n\n    tf.print(tf.reduce_all(tf.equal(op_results_eager, op_results_graph)))\n\n    return op_results_graph\n\n\nfor _ in range(10):\n    call(tf.ones(shape=(1, 5)))\n</code></pre>\n<pre><code>1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n</code></pre>\n<p>Or another alternative without calling each layer:</p>\n<pre><code>dense1 = tf.keras.layers.Dense(64, activation='sigmoid')\ndense2 = tf.keras.layers.Dense(64, activation='relu')\ndense3 = tf.keras.layers.Dense(64, activation=None)\n\noperations = [dense1, dense2, dense3]\n\ndef call(x):\n    # Sample 2 of the 3 operations.\n    sampled_ids = tf.random.categorical(\n        tf.zeros((1, len(operations))), num_samples=2, dtype=tf.int32,\n    )[0]\n\n    op_results_eager = tf.stack([operations[op_id](x) for op_id in sampled_ids])\n    \n    id1, id2 = tf.split(sampled_ids, 2)\n  \n    output1 = tf.stack([tf.cond(tf.equal(id1, 0), lambda: dense1(x), lambda: tf.zeros((1, 64))),tf.cond(tf.equal(id2, 0), lambda: dense1(x), lambda: tf.zeros((1, 64)))])\n    output2 = tf.stack([tf.cond(tf.equal(id1, 1), lambda: dense2(x), lambda: tf.zeros((1, 64))),tf.cond(tf.equal(id2, 1), lambda: dense2(x), lambda: tf.zeros((1, 64)))])\n    output3 = tf.stack([tf.cond(tf.equal(id1, 2), lambda: dense3(x), lambda: tf.zeros((1, 64))),tf.cond(tf.equal(id2, 2), lambda: dense3(x), lambda: tf.zeros((1, 64)))])\n    outputs = tf.stack([output1, output2, output3], axis=0)\n\n    op_results_graph = tf.expand_dims(tf.gather_nd(outputs, tf.where(tf.reduce_any(tf.not_equal(outputs, tf.zeros((64,))), axis=-1))), axis=1)\n\n    return op_results_graph\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9703}"
281,56166885,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1576216156, 'answer_id': 59316806, 'question_id': 56166885, 'body': '<p>There is no direct API for adding Metrics like <code>AUC</code> but you can create <code>Custom Metric Function</code> using <code>tf.keras.metrics</code>, and then use those Metrics in Estimator, using <code>tf.estimator.add_metrics</code>.</p>\n\n<p>Example code, which demonstrates the implementation of AUC is shown below:</p>\n\n<pre><code>  def my_auc(labels, predictions):\n    auc_metric = tf.keras.metrics.AUC(name=""my_auc"")\n    auc_metric.update_state(y_true=labels, y_pred=predictions[\'logistic\'])\n    return {\'auc\': auc_metric}\n\n  estimator = tf.estimator.DNNClassifier(...)\n  estimator = tf.estimator.add_metrics(estimator, my_auc)\n  estimator.train(...)\n  estimator.evaluate(...)\n</code></pre>\n\n<p>Or</p>\n\n<pre><code>  def my_auc(labels, predictions, features):\n    auc_metric = tf.keras.metrics.AUC(name=""my_auc"")\n    auc_metric.update_state(y_true=labels, y_pred=predictions[\'logistic\'],\n                            sample_weight=features[\'weight\'])\n    return {\'auc\': auc_metric}\n\n  estimator = tf.estimator.DNNClassifier(...)\n  estimator = tf.estimator.add_metrics(estimator, my_auc)\n  estimator.train(...)\n  estimator.evaluate(...)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9702}"
282,55560676,"{'items': [{'owner': {'reputation': 8315, 'user_id': 5154274}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1554653022, 'answer_id': 55560982, 'question_id': 55560676, 'body': '<p>You forgot to add return statement to your function:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\ndef b(i):\n    return tf.add(i, 1)\n\ni = tf.constant(0)\nc = lambda i: tf.less(i, 10)\ntf.while_loop(c, b, [i]) # &lt;tf.Tensor: id=51, shape=(), dtype=int32, numpy=10&gt;\n</code></pre>\n\n<p>Note that in your first example function <code>b</code> does return incremented value:</p>\n\n<pre class=""lang-py prettyprint-override""><code>i = tf.constant(0)\nb = lambda i: tf.add(i,1)\nc = lambda i: tf.less(i,10)\ntf.while_loop(c,b, [i])\nprint(b(1).numpy()) # 2\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9702}"
283,55788007,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9702}"
284,56969703,"{'items': [{'owner': {'reputation': 337, 'user_id': 7327257}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1562844748, 'answer_id': 56988219, 'question_id': 56969703, 'body': '<p>I\'ve been playing around with the function and I have found my mistake. If anyone is facing this problem, this is what I did to solve it:</p>\n\n<p>Considering <code>batch_size=2</code> and <code>3</code> points, <code>idx</code> tensor must have shape <code>[2, 3, 4]</code>, where first dimension correspond to the batch from where we are taking <code>update</code>value, second dimension must be equal to the second dimension of <code>updates</code> (number of points per batch) and the third dimension is <code>4</code> because we need <code>4</code> indices: [batch_number, channel, row, col]. Following the example in the question:</p>\n\n<pre class=""lang-py prettyprint-override""><code>updates = tf.constant([[1., 2., 3.], [4., 5., 6.]])  # [2, 3]\nidx = tf.constant([[[0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 1, 0]], [[1, 0, 1, 1], [1, 0, 0, 0], [1, 0, 1, 0]]])  # [2, 3, 4]\noutput = tf.scatter_nd(idx, updates, [2, 1, 4, 4])\n\nsess = tf.Session()\nprint(sess.run(output))\n\n[[[[2. 1. 0. 0.]\n   [3. 0. 0. 0.]\n   [0. 0. 0. 0.]\n   [0. 0. 0. 0.]]]\n\n\n [[[5. 0. 0. 0.]\n   [6. 4. 0. 0.]\n   [0. 0. 0. 0.]\n   [0. 0. 0. 0.]]]]\n\n</code></pre>\n\n<p>This way it\'s possible to place specific numbers in a new tensor.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9702}"
285,54096360,"{'items': [{'owner': {'reputation': 59, 'user_id': 10890778}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1547545367, 'answer_id': 54196245, 'question_id': 54096360, 'body': ""<p>Tensorflow's documentation makes use of all the <em>scatter</em> operations (such as scatter_nd_add, etc) by inputing the <em>ref</em> arguments as a <strong>tf.Variable</strong>:</p>\n\n<blockquote>\n  <p>ref: A mutable Tensor. Must be one of the following types: blablabla. A mutable Tensor. <strong>Should be from a Variable node</strong>.</p>\n</blockquote>\n\n<p>I had the same issue and it works fine when used on a tf variable for <em>ref</em>. All the other arguments can remain whatever they are I guess, but I did not investigate thoroughly.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9702}"
286,62411242,"{'items': [{'owner': {'reputation': 539, 'user_id': 6148086}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1592395775, 'answer_id': 62428706, 'question_id': 62411242, 'body': '<p>This is because the <code>g</code> in your example is a reference to the value in the list. When you assign to it you are merely changing the value to which it points (ie you are not modifying the current value it points to).\nConsider this example, I want to set all the values in <code>lst</code> to 5. Guess what happens when you run this code sample?</p>\n<pre class=""lang-py prettyprint-override""><code>lst = [1,2,3,4]\nfor ele in lst:\n    ele = 5\nprint(lst)\n</code></pre>\n<p>Nothing! You get the exact same list back. However within the loop you will see that ele is now 5, as you have already found out in your case. This was the case where the values in the list are immutable (tensors are immutable).</p>\n<p>However, you can modify mutable objects in place:</p>\n<pre class=""lang-py prettyprint-override""><code>lst = [[2], [2], [2]]\nfor ele in lst:\n    ele.append(3)\nprint(lst)\n</code></pre>\n<p>The above code will make each element <code>[2, 3]</code> as expected.</p>\n<p>One way of solving your problem is:</p>\n<pre><code>lst = [1,2,3,4]\nfor itr in range(len(lst)):\n    lst[itr] = 5\nprint(lst)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9697}"
287,37900780,"{'items': [{'owner': {'reputation': 267, 'user_id': 10163246}, 'down_vote_count': 4, 'up_vote_count': 0, 'is_accepted': False, 'score': -4, 'creation_date': 1550903995, 'answer_id': 54838970, 'question_id': 37900780, 'body': '<pre><code>a = [1,1,1,1]\nb = [1,1,1,1]\nw = tf.add(a, b)\n\n\nwith tf.Session() as sess:\n    p = sess.run(w)\n    print(p)\n\na+b\n</code></pre>\n\n<p>Now, the value of <code>p</code> printed will be <code>[2,2,2,2]</code> and simple <code>a+b</code> printed will be <code>[1,1,1,1,1,1,1,1]</code>.</p>\n'}, {'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': False, 'score': 11, 'creation_date': 1540354193, 'answer_id': 52960970, 'question_id': 37900780, 'body': '<p>Yaroslav nicely explained that there is no real difference. I will just add when using <code>tf.add</code> is beneficial.</p>\n\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/math/add"" rel=""noreferrer"">tf.add</a> has one important parameter which is <code>name</code>. It allows you to name the operation in a graph which will be visible in tensorboard. So my rule of thumb, if it will be beneficial to name an operation in tensorboard, I use <code>tf.</code> equivalent, otherwise I go for brevity and use overloaded version.</p>\n'}, {'owner': {'reputation': 57117, 'user_id': 419116}, 'down_vote_count': 0, 'up_vote_count': 66, 'is_accepted': True, 'score': 66, 'creation_date': 1466285709, 'answer_id': 37901852, 'question_id': 37900780, 'body': '<p>There\'s no difference in precision between <code>a+b</code> and <code>tf.add(a, b)</code>. The former translates to <code>a.__add__(b)</code> which gets mapped to <code>tf.add</code> by means of <a href=""https://github.com/tensorflow/tensorflow/blob/c43a32d5d0929170a057862e2cd0b59308421444/tensorflow/python/ops/math_ops.py#L845"" rel=""noreferrer"">following line</a> in math_ops.py </p>\n\n<p><code>_OverrideBinaryOperatorHelper(gen_math_ops.add, ""add"")</code></p>\n\n<p>The only difference is that node name in the underlying Graph is <code>add</code> instead of <code>Add</code>. You can generally compare things by looking at the underlying Graph representation like this</p>\n\n<pre><code>tf.reset_default_graph()\ndtype = tf.int32\na = tf.placeholder(dtype)\nb = tf.placeholder(dtype)\nc = a+b\nprint(tf.get_default_graph().as_graph_def())\n</code></pre>\n\n<p>You could also see this directly by inspecting the <code>__add__</code> method. There\'s an extra level of indirection because it\'s a closure, but you can get the underlying function as follows</p>\n\n<pre><code>real_function = tf.Tensor.__add__.im_func.func_closure[0].cell_contents\nprint(real_function.__module__ + ""."" + real_function.__name__)\nprint(tf.add.__module__ + ""."" + tf.add.__name__)\n</code></pre>\n\n<p>And you\'ll see output below which means that they call same underlying function</p>\n\n<pre><code>tensorflow.python.ops.gen_math_ops.add\ntensorflow.python.ops.gen_math_ops.add\n</code></pre>\n\n<p>You can see from <code>tf.Tensor.OVERLOADABLE_OPERATORS</code> that following Python special methods are potentially overloaded by appropriate TensorFlow versions</p>\n\n<pre><code>{\'__abs__\',\n \'__add__\',\n \'__and__\',\n \'__div__\',\n \'__floordiv__\',\n \'__ge__\',\n \'__getitem__\',\n \'__gt__\',\n \'__invert__\',\n \'__le__\',\n \'__lt__\',\n \'__mod__\',\n \'__mul__\',\n \'__neg__\',\n \'__or__\',\n \'__pow__\',\n \'__radd__\',\n \'__rand__\',\n \'__rdiv__\',\n \'__rfloordiv__\',\n \'__rmod__\',\n \'__rmul__\',\n \'__ror__\',\n \'__rpow__\',\n \'__rsub__\',\n \'__rtruediv__\',\n \'__rxor__\',\n \'__sub__\',\n \'__truediv__\',\n \'__xor__\'}\n</code></pre>\n\n<p>Those methods are described in <a href=""https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types"" rel=""noreferrer"">Python reference 3.3.7</a>: emulating numeric types. Note that Python data model does not provide a way to overload assignment operator <code>=</code> so assignment always uses native Python implementation.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9697}"
288,48736753,"{'items': [{'owner': {'reputation': 5778, 'user_id': 6824418}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1518726143, 'answer_id': 48815637, 'question_id': 48736753, 'body': '<p>I\'d use <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#export_savedmodel"" rel=""nofollow noreferrer""><code>Estimator.export_savedmodel()</code></a>. This will save the weights + graph in a format suitable for serving. You might also check out <a href=""https://github.com/ajbouh/tfi"" rel=""nofollow noreferrer"">https://github.com/ajbouh/tfi</a> for a super easy way to use <code>SavedModel</code>s from Python (but go with <a href=""https://www.tensorflow.org/serving/"" rel=""nofollow noreferrer"">TensorFlow serving</a> for production use-cases).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9697}"
289,60639731,"{'items': [{'owner': {'reputation': 1361, 'user_id': 2110869}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1586702012, 'answer_id': 61173060, 'question_id': 60639731, 'body': '<p>As answered <a href=""https://stackoverflow.com/a/61173028/2110869"">here</a>, I\'m sure there\'s a better way, but a simple workaround is to just use the existing tensorboard callback logic:</p>\n\n<pre><code>tb_callback = tf.keras.callbacks.TensorBoard(LOG_DIR)\ntb_callback.set_model(model) # Writes the graph to tensorboard summaries using \nan internal file writer\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9694}"
290,58384884,"{'items': [{'owner': {'reputation': 11, 'user_id': 17337839}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1645030319, 'answer_id': 71145984, 'question_id': 58384884, 'body': '<p>When I get an error similar to that, applying <code>tf.compat.v1.</code> usually works.</p>\n<p>This is the specific function where I applied it:</p>\n<pre class=""lang-py prettyprint-override""><code>tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=labels, logits=output)\n</code></pre>\n<p>I also applied it to similar functions and it worked.</p>\n'}, {'owner': {'reputation': 36, 'user_id': 8106370}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1604686789, 'answer_id': 64719755, 'question_id': 58384884, 'body': '<p>Replacing</p>\n<pre><code>tf.keras.losses.Reduction\n</code></pre>\n<p>with</p>\n<pre><code>tf.compat.v1.losses.Reduction\n</code></pre>\n<p>solved the issue for me in TensorFlow 1.14.0</p>\n'}, {'owner': {'reputation': 80, 'user_id': 11198960}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1595532835, 'answer_id': 63061858, 'question_id': 58384884, 'body': '<p>I ran into a similar problem when I installed the tensorflow 1.14.0. What I did to get this to work was to go to upgrade the tensorflow which seemed to revert me to 1.12.0.</p>\n<pre><code>    pip install --upgrade tensorflow\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9694}"
291,40518132,"{'items': [{'owner': {'reputation': 6287, 'user_id': 997378}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1478742583, 'answer_id': 40518831, 'question_id': 40518132, 'body': '<p>It makes multiple copies of the image along dimension 3.</p>\n\n<p>It looks up the (dynaminc) number of output channels:</p>\n\n<pre><code>outchannels = tf.shape(output)[3]\n</code></pre>\n\n<p>Then it builds a tensor containing the number of multiples along each dimension:</p>\n\n<pre><code>multiples = tf.pack([1, 1, 1, outchanels])\n</code></pre>\n\n<p>And makes that many copies:</p>\n\n<pre><code>tensor_sum_exp = tf.tile(sum_exp, multiples)\n</code></pre>\n\n<p>If for example, you know <code>outchannels</code> is always <code>n</code>, (check <code>sum_exp.get_shape()</code>), you could also:</p>\n\n<pre><code>tensor_sum_exp = tf.concat(3,[sum_exp]*n)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9694}"
292,52589043,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9694}"
293,53772787,"{'items': [{'owner': {'reputation': 6270, 'user_id': 4282745}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1544778167, 'answer_id': 53776431, 'question_id': 53772787, 'body': '<p>The method <code>tf.control_dependencies</code> allow to ensure that the operations used as inputs of the context manager are run before the operations defined inside the context manager.</p>\n\n<p>For example: </p>\n\n<pre><code>count = tf.get_variable(""count"", shape=(), initializer=tf.constant_initializer(1), trainable=False)\ncount_increment = tf.assign_add(count, 1)\nc = tf.constant(2.)\nwith tf.control_dependencies([count_increment]):\n    d = c + 3\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    print(""eval count"", count.eval())\n    print(""eval d"", d.eval())\n    print(""eval count"", count.eval())\n</code></pre>\n\n<p>This prints:</p>\n\n<pre><code>eval count 1\neval d 5.0 # Running d make count_increment operation being run\neval count 2 # count_increment operation has be run and now count hold 2.\n</code></pre>\n\n<p>So in your case, each time you run the <code>train_op</code> operation it will first run all the operations defined in the <code>tf.GraphKeys.UPDATE_OPS</code> collection.</p>\n'}, {'owner': {'reputation': 3545, 'user_id': 1173884}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1544792369, 'answer_id': 53780299, 'question_id': 53772787, 'body': '<p>If you use for example <code>tf.layers.batch_normalization</code> the layer will create some Ops, that need to be run every training step (update the moving average and variance of the variables).</p>\n\n<p><code>tf.GraphKeys.UPDATE_OPS</code> is a collection of these variables and if you put it in the <code>tf.control_dependencies</code> block, these Ops will get executed before the training op is run.</p>\n\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9694}"
294,42437115,"{'items': [{'owner': {'reputation': 1, 'user_id': 10399691}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1553399947, 'answer_id': 55320605, 'question_id': 42437115, 'body': '<p>Use <code>rnn_cell.LayerNormBasicLSTMCell._linear</code> instead of <code>_linear</code></p>\n'}, {'owner': {'reputation': 779, 'user_id': 7429461}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1541077463, 'answer_id': 53101886, 'question_id': 42437115, 'body': '<p>Right now when you what to use <code>_linear</code> function, please use it like this: </p>\n\n<p><code>from tensorflow.contrib.rnn.python.ops import core_rnn_cell</code></p>\n\n<pre><code>core_rnn_cell._linear(output, size)\n</code></pre>\n\n<p>Here is the link of its corresponding source file. <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell.py"" rel=""nofollow noreferrer"">source file</a></p>\n\n<p>This is because after tf r1.5, the location of this function is changed.</p>\n\n<p>When you are using tf r1.4 or even older version, please use it like this:</p>\n\n<pre><code>from tensorflow.python.ops import rnn_cell_impl\n\nrnn_cell_impl._linear(output, size)\n</code></pre>\n\n<p>Here is the link of this older version of <code>_linear</code>. <a href=""https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/ops/rnn_cell_impl.py"" rel=""nofollow noreferrer"">source file</a></p>\n\n<p>As for <code>tf.nn.rnn_cell._linear</code>, this function is not available a long time ago.</p>\n'}, {'owner': {'reputation': 11, 'user_id': 10490070}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1539273446, 'answer_id': 52764340, 'question_id': 42437115, 'body': ""<p>tensorflow.python.ops.rnn_cell_impl._linear now is at tensorflow.contrib.rnn.python.ops.core_rnn_cell._linear. And I prefer to use tf.layers.Dense to replace.\nfor example, change</p>\n\n<pre><code>from tensorflow.contrib.rnn.python.ops import core_rnn_cell\ncore_rnn_cell._linear(states, length, bias=True)\n</code></pre>\n\n<p>to</p>\n\n<pre><code>tf.layers.Dense(units=length)(states)\n</code></pre>\n\n<p>I'm using tensorflow 1.6.</p>\n""}, {'owner': {'reputation': 41, 'user_id': 8409755}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1504433088, 'answer_id': 46022279, 'question_id': 42437115, 'body': ""<p>I met this error while using SkFlow's TensorFlowDNNRegressor.\nThe first time I saw the answer of ruoho ruots, I am a bit confused. \nBut the next day I realized what he meant. </p>\n\n<p>Here is what I do:</p>\n\n<pre><code>from tensorflow.python.ops import rnn_cell_impl\n</code></pre>\n\n<p>replace <code>tf.nn.rnn_cell._linear</code> with <code>rnn_cell_impl._linear</code></p>\n""}, {'owner': {'reputation': 898, 'user_id': 1894478}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1496048267, 'answer_id': 44238429, 'question_id': 42437115, 'body': '<p>As for now (1.2r0) you can replace it with \n<a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected"" rel=""nofollow noreferrer""><code>tf.contrib.layers.fully_connected(inputs=[inputs, state], num_outputs=self._num_units, biases_initializer=tf.constant_initializer(0.0), activation_fn=None)</code></a>\nNote that <code>biases_initializer</code> defaults to all zeros for <code>_linear</code> and for no bias at all for <code>fully_connected</code>.</p>\n'}, {'owner': {'reputation': 1303, 'user_id': 3844056}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1488312612, 'answer_id': 42517842, 'question_id': 42437115, 'body': '<p>With version 1.0, stuff has moved all around. I\'ve had similar hunts updating <code>tf.nn.rnn_cell.LSTMCell</code> to <code>tf.contrib.rnn.BasicLSTMCell</code>.</p>\n\n<p>For your case <code>tf.nn.rnn_cell._linear</code> now lives in <code>tf.contrib.rnn.python.ops.core_rnn_cell_impl</code> as well as the definition of the <code>BasicRNNCell</code>. Checking the <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell"" rel=""nofollow noreferrer"">BasicRNNCell docs</a> and <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L113-L118"" rel=""nofollow noreferrer"">source code</a>, we see at L113-L118 the use of _linear. </p>\n\n<pre><code>  def __call__(self, inputs, state, scope=None):\n    """"""Most basic RNN: output = new_state = act(W * input + U * state + B).""""""\n    with _checked_scope(self, scope or ""basic_rnn_cell"", reuse=self._reuse):\n      output = self._activation(\n          _linear([inputs, state], self._num_units, True))\n    return output, output\n</code></pre>\n\n<p>the _linear method is defined at <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L854"" rel=""nofollow noreferrer"">line 854</a> as a:<br>\n<code>Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.</code></p>\n\n<p>Good luck!</p>\n'}, {'owner': {'reputation': 10260, 'user_id': 3607203}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1490364929, 'answer_id': 43001802, 'question_id': 42437115, 'body': '<p>The answer of ruoho ruotsi is almost correct:\nYet, the <em>definition</em> of <code>linear</code> is not located in <code>tf.contrib.rnn.basicRNNCell</code>, but in <code>tf.contrib.rnn.python.ops.rnn_cell</code>, or <code>tf.contrib.rnn.python.ops.core_rnn_cell_impl</code>, respectively.</p>\n\n<p>You can find their source code <a href=""https://github.com/tensorflow/tensorflow/blob/9967bf6702153631e27f52ac95ab822f73fe758d/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"" rel=""nofollow noreferrer"">here</a> and <a href=""https://github.com/tensorflow/tensorflow/blob/9967bf6702153631e27f52ac95ab822f73fe758d/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"" rel=""nofollow noreferrer"">here</a>.</p>\n'}, {'owner': {'reputation': 11, 'user_id': 7675704}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1488940819, 'answer_id': 42661991, 'question_id': 42437115, 'body': '<p>To solving this problem,we can define a linear() function.</p>\n\n<pre><code>def linear(input_, output_size, scope=None):\n    \'\'\'\n    Linear map: output[k] = sum_i(Matrix[k, i] * args[i] ) + Bias[k]\n    Args:\n        args: a tensor or a list of 2D, batch x n, Tensors.\n    output_size: int, second dimension of W[i].\n    scope: VariableScope for the created subgraph; defaults to ""Linear"".\n    Returns:\n    A 2D Tensor with shape [batch x output_size] equal to\n    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n    Raises:\n    ValueError: if some of the arguments has unspecified or wrong shape.\n    \'\'\'\n\n    shape = input_.get_shape().as_list()\n    if len(shape) != 2:\n        raise ValueError(""Linear is expecting 2D arguments: %s"" % str(shape))\n    if not shape[1]:\n        raise ValueError(""Linear expects shape[1] of arguments: %s"" % str(shape))\n    input_size = shape[1]\n\n    # Now the computation.\n    with tf.variable_scope(scope or ""SimpleLinear""):\n        matrix = tf.get_variable(""Matrix"", [output_size, input_size], dtype=input_.dtype)\n        bias_term = tf.get_variable(""Bias"", [output_size], dtype=input_.dtype)\n\n    return tf.matmul(input_, tf.transpose(matrix)) + bias_term\n\n\ndef highway(input_, size, num_layers=1, bias=-2.0, f=tf.nn.relu, scope=\'Highway\'):\n    """"""Highway Network (cf. http://arxiv.org/abs/1505.00387).\n    t = sigmoid(Wy + b)\n    z = t * g(Wy + b) + (1 - t) * y\n    where g is nonlinearity, t is transform gate, and (1 - t) is carry gate.\n    """"""\n\n    with tf.variable_scope(scope):\n        for idx in range(num_layers):\n            g = f(linear(input_, size, scope=\'highway_lin_%d\' % idx))\n\n            t = tf.sigmoid(linear(input_, size, scope=\'highway_gate_%d\' % idx) + bias)\n\n            output = t * g + (1. - t) * input_\n            input_ = output\n\n    return output\n</code></pre>\n\n<p><a href=""https://github.com/mkroutikov/tf-lstm-char-cnn/blob/7e899e6992cbf9a96e6d791e5d364eaaeec339a2/model.py"" rel=""nofollow noreferrer"">https://github.com/mkroutikov/tf-lstm-char-cnn/blob/7e899e6992cbf9a96e6d791e5d364eaaeec339a2/model.py</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9689}"
295,46647805,"{'items': [{'owner': {'reputation': 122, 'user_id': 1952835}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': True, 'score': 0, 'creation_date': 1508452534, 'answer_id': 46839874, 'question_id': 46647805, 'body': '<p>I think you should check your data and make sure the field you are missing (team_0) is showing up correctly. It could be many things like ill formed data or the field name might be incorrectly spelt in the training data source.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9689}"
296,56930821,"{'items': [{'owner': {'reputation': 161, 'user_id': 13521099}, 'down_vote_count': 0, 'up_vote_count': 16, 'is_accepted': False, 'score': 16, 'creation_date': 1589230944, 'answer_id': 61739263, 'question_id': 56930821, 'body': '<p>Looking around it, I found this argument <a href=""https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec"" rel=""noreferrer"">1</a>:</p>\n\n<blockquote>\n  <p>The reason we increase the embedding values before the addition is to\n  make the positional encoding relatively smaller. This means the\n  original meaning in the embedding vector wont be lost when we add\n  them together.</p>\n</blockquote>\n'}, {'owner': {'reputation': 31, 'user_id': 12664990}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1578359760, 'answer_id': 59620980, 'question_id': 56930821, 'body': ""<p>I believe the reason for this scaling has nothing to do with the scale applied at the attention layers. It is likely because the transformer shares the weights of the embedding layer and the output softmax. The scales you would use for the embeddings is different than the scale you use for a fully connected layer. </p>\n\n<p>Some implementations of the transformer use this scaling even though they don't actually share the embedding weights at the output layer, but that is probably kept there for consistency (or by mistake). Just make sure that the initialization of your embeddings is consistent.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9689}"
297,49662470,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9689}"
298,75305478,"{'items': [{'owner': {'reputation': 370, 'user_id': 9919423}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1675227190, 'answer_id': 75305810, 'question_id': 75305478, 'body': '<p>I found the answer from <a href=""https://www.tensorflow.org/guide/autodiff#2_did_calculations_outside_of_tensorflow"" rel=""nofollow noreferrer"">tf docs</a>. It says <code>The tape can\'t record the gradient path if the calculation exits TensorFlow. For example:</code></p>\n<pre><code>x = tf.Variable([[1.0, 2.0],\n                 [3.0, 4.0]], dtype=tf.float32)\n\nwith tf.GradientTape() as tape:\n  x2 = x**2\n\n  # This step is calculated with NumPy\n  y = np.mean(x2, axis=0)\n\n  # Like most ops, reduce_mean will cast the NumPy array to a constant tensor\n  # using `tf.convert_to_tensor`.\n  y = tf.reduce_mean(y, axis=0)\n\nprint(tape.gradient(y, x))\n</code></pre>\n<p>So, the answer to the question is &quot;No, tf can\'t calculate gradient of other library\'s functions&quot;.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9689}"
299,67197448,"{'items': [{'owner': {'reputation': 349, 'user_id': 13772559}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1620315235, 'answer_id': 67421396, 'question_id': 67197448, 'body': '<p>If you want the 0,2 and 3rd element of the last axis in the tensor, you can use tf.gather as follows: tf.gather(t,indices=[0, 2, 3],axis=-1))</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9684}"
300,48914952,"{'items': [{'owner': {'reputation': 51, 'user_id': 8846388}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1519258429, 'answer_id': 48917633, 'question_id': 48914952, 'body': '<p>If <code>list_of_unique_values_in_the_column</code> is known, you can save them in one file and read by <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file"" rel=""nofollow noreferrer""> tf.feature_column.categorical_column_with_vocabulary_file</a>. If unknown, you can use <a href=""https://www.tensorflow.org/versions/master/api_docs/python/tf/feature_column/categorical_column_with_hash_bucket"" rel=""nofollow noreferrer""> tf.feature_column.categorical_column_with_hash_bucket </a> with a large enough size.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9683}"
301,75225610,"{'items': [{'owner': {'reputation': 676, 'user_id': 16660603}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1674584674, 'answer_id': 75225703, 'question_id': 75225610, 'body': '<p><strong>EDIT</strong>:</p>\n<p>As per the GitHub source code, <a href=""https://github.com/tensorflow/tensorflow/blob/v2.11.0/tensorflow/python/eager/backprop.py#L751-L1391"" rel=""nofollow noreferrer"">GradientTape</a>,\nAt <code>Line 897</code>:</p>\n<pre class=""lang-py prettyprint-override""><code> @tf_contextlib.contextmanager\n  def _ensure_recording(self):\n    &quot;&quot;&quot;Ensures that this tape is recording.&quot;&quot;&quot;\n    if not self._recording:\n      try:\n        self._push_tape()\n        yield\n      finally:\n        self._pop_tape()\n    else:\n      yield\n</code></pre>\n<p>If you don\'t know, <code>contextmanager</code> triggers whenever <code>with</code> keyword is used. It tells us that it starts keeping track of tape.</p>\n<p><code>self._pop_tape()</code> is in <code>Line 891</code>:</p>\n<pre class=""lang-py prettyprint-override""><code>def _pop_tape(self):\n    if not self._recording:\n      raise ValueError(&quot;Tape is not recording.&quot;)\n    tape.pop_tape(self._tape)\n    self._recording = False\n</code></pre>\n<p><code>self._push_tape()</code> is in <code>Line 878</code>:</p>\n<pre class=""lang-py prettyprint-override""><code>def _push_tape(self):\n    &quot;&quot;&quot;Pushes a new tape onto the tape stack.&quot;&quot;&quot;\n    if self._recording:\n      raise ValueError(&quot;Tape is still recording, This can happen if you try to &quot;\n                       &quot;re-enter an already-active tape.&quot;)\n    if self._tape is None:\n      self._tape = tape.push_new_tape(\n          persistent=self._persistent,\n          watch_accessed_variables=self._watch_accessed_variables)\n    else:\n      tape.push_tape(self._tape)\n    self._recording = True\n</code></pre>\n<p>Here, you can notice <code>tape.push_new_tape</code> is being accessed here which can be found in this <a href=""https://github.com/tensorflow/tensorflow/blob/v2.11.0/tensorflow/python/eager/tape.py"" rel=""nofollow noreferrer"">source code</a> at <code>Line 43</code>:</p>\n<pre class=""lang-py prettyprint-override""><code>def push_new_tape(persistent=False, watch_accessed_variables=True):\n  &quot;&quot;&quot;Pushes a new tape onto the tape stack.&quot;&quot;&quot;\n  tape = pywrap_tfe.TFE_Py_TapeSetNew(persistent, watch_accessed_variables)\n  return Tape(tape)\n</code></pre>\n<p>In this you can see the <code>Tape</code> class just above at <code>Line 31</code>.</p>\n<pre class=""lang-py prettyprint-override""><code>class Tape(object):\n  &quot;&quot;&quot;Represents a gradient propagation trace.&quot;&quot;&quot;\n\n  __slots__ = [&quot;_tape&quot;]\n\n  def __init__(self, tape):\n    self._tape = tape\n\n  def watched_variables(self):\n    return pywrap_tfe.TFE_Py_TapeWatchedVariables(self._tape)\n</code></pre>\n<p>Also, I tried to track <code>pywrap_tfe.TFE_Py_TapeSetNew</code> but couldn\'t find it in this <a href=""https://github.com/tensorflow/tensorflow/blob/v2.11.0/tensorflow/python/pywrap_tfe.py"" rel=""nofollow noreferrer"">source code of the file</a>.</p>\n<p><strong>Original Answer</strong>:</p>\n<p>The documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/GradientTape"" rel=""nofollow noreferrer"">GradientTape</a> states:</p>\n<blockquote>\n<p>By default GradientTape will automatically watch any trainable variables that are accessed inside the context. If you want fine grained control over which variables are watched you can disable automatic tracking by passing watch_accessed_variables=False to the tape constructor</p>\n</blockquote>\n<p>With the following code:</p>\n<pre class=""lang-py prettyprint-override""><code>x = tf.Variable(2.0)\nw = tf.Variable(5.0)\nwith tf.GradientTape(\n    watch_accessed_variables=False, persistent=True) as tape:\n  tape.watch(x)\n  y = x ** 2  # Gradients will be available for `x`.\n  z = w ** 3  # No gradients will be available as `w` isn\'t being watched.\ndy_dx = tape.gradient(y, x)\n\nprint(dy_dx)\n&gt;&gt;&gt; tf.Tensor(4.0, shape=(), dtype=float32)\n\n# No gradients will be available as `w` isn\'t being watched.\ndz_dw = tape.gradient(z, w)\n\nprint(dz_dw)\n&gt;&gt;&gt; None\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9683}"
302,71791115,"{'items': [{'owner': {'reputation': 929, 'user_id': 12271381}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1654532089, 'answer_id': 72520543, 'question_id': 71791115, 'body': ""<p>Issue was that when we replaced special characters with blank space then for one record whole data became NULL ( for release field). Conclusively it was data issue rather than code issue. We then added below two lines to deal with such case <code>ds.replace(r'^\\s*$', 'None', regex=True)</code>. Below is the whole code with all changes made</p>\n<pre><code>import os\nimport pprint\nimport tempfile\n\nfrom typing import Dict, Text\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\n!pip install -q tensorflow-recommenders\nimport tensorflow_recommenders as tfrs  \n\nds=pd.read_csv('train_recom.csv')\n\nprint(ds['release'].isnull().sum())\nprint(ds['title'].isnull().sum())\nprint(ds['artist_name'].isnull().sum())\nprint(ds['year'].isnull().sum())\nprint(ds.isna().any(axis=None))\nprint(any(ds[c].hasnans for c in ds))\nfor c in ds:\n  if ds[c].hasnans:\n    print(c)\n\nds['year'].replace(0,1,inplace=True)\nds.release.replace({r'[^a-zA-Z0-9 ]+':''}, regex=True, inplace=True)\nds.artist_name.replace({r'[^a-zA-Z0-9 ]+':''}, regex=True, inplace=True)\nds.title.replace({r'[^a-zA-Z0-9 ]+':''}, regex=True, inplace=True)\nds2=ds.replace(r'^\\s*$', np.nan, regex=True)\nds2['release']=ds2['release'].fillna('None')\nds=ds2\nds_song=ds.groupby(['song_id','title','release','artist_name','year']).size().reset_index().rename(columns={0:'count'})\n\nds_song.to_csv('songs_details.csv')\nds.to_csv('train_recom_transformed.csv')\n\nratings = tf.data.experimental.make_csv_dataset(\n    &quot;./train_recom_transformed.csv&quot;,\n    batch_size=5,\n    select_columns=['user_id', 'song_id', 'listen_count', 'title', 'release', 'artist_name',\n       'year'],\n    header=True,\n    num_epochs=1,\n    ignore_errors=False,)\nsongs = tf.data.experimental.make_csv_dataset(\n    &quot;./songs_details.csv&quot;,\n    batch_size=128,\n    select_columns=['song_id','title','release','artist_name','year'],\n    num_epochs=1,\n    ignore_errors=True,)\nratings = ratings.unbatch().map(lambda x: {\n    &quot;song_id&quot;: x[&quot;song_id&quot;],\n    &quot;user_id&quot;: x[&quot;user_id&quot;],\n    &quot;release&quot; : x[&quot;release&quot;],\n    &quot;artist_name&quot; : x[&quot;artist_name&quot;],\n    &quot;title&quot; : x[&quot;title&quot;],\n    &quot;year&quot; : x[&quot;year&quot;],\n    &quot;listen_count&quot;: x[&quot;listen_count&quot;]\n})\nsongs = songs.unbatch().map(lambda x: {\n    &quot;song_id&quot;:x[&quot;song_id&quot;],\n    &quot;release&quot;:x[&quot;release&quot;],\n    &quot;artist_name&quot;:x[&quot;artist_name&quot;],\n    &quot;title&quot;:x[&quot;title&quot;],\n    &quot;year&quot;:x[&quot;year&quot;],\n}) \n\ntf.random.set_seed(42)\nshuffled = ratings.shuffle(16000, seed=42, reshuffle_each_iteration=False)\n\ntrain = shuffled.take(12000)\ntest = shuffled.skip(12000).take(4000)\ncached_train = train.shuffle(100_000).batch(1200).cache()\ncached_test = test.batch(400).cache()\n\ntitle = songs.batch(1000).map(lambda x: x[&quot;title&quot;])\nuser_ids = ratings.batch(1_000_000).map(lambda x: x[&quot;user_id&quot;])\nunique_song_titles = np.unique(np.concatenate(list(title)))\nunique_user_ids = np.unique(np.concatenate(list(user_ids)))\nyear_data=list(songs.map(lambda x: x['year']))\n\nclass UserModel(tf.keras.Model):\n\n    def __init__(self):\n        super().__init__()\n\n        max_tokens = 1_000_000\n\n        embedding_dimension = 32\n        self.user_embedding = tf.keras.Sequential([\n            tf.keras.layers.StringLookup(\n                vocabulary=unique_user_ids, mask_token=None),\n            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n          ])\n\n\n\n    def call(self, inputs):\n      return self.user_embedding(inputs['user_id'])\n\nclass ItemModel(tf.keras.Model):\n\n    def __init__(self):\n        super().__init__()\n\n        max_tokens = 10_000_00\n\n        embedding_dimension = 32\n\n        ## embed title from unique_song_titles\n        self.title_embedding = tf.keras.Sequential([\n        tf.keras.layers.StringLookup(\n            vocabulary=unique_song_titles, mask_token=None),\n        tf.keras.layers.Embedding(len(unique_song_titles) + 1, embedding_dimension)\n      ])\n\n        self.release_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n            max_tokens=max_tokens)\n        \n        self.release_text_embedding = tf.keras.Sequential([\n          self.release_vectorizer,\n          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True,input_length=144),\n          tf.keras.layers.GlobalAveragePooling1D(),\n        ])\n\n        self.release_vectorizer.adapt(songs.map(lambda x: x['release']))\n\n        self.artist_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n            max_tokens=max_tokens)\n        self.artist_text_embedding = tf.keras.Sequential([\n          self.artist_vectorizer,\n          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n          tf.keras.layers.GlobalAveragePooling1D(),\n        ])\n\n        self.artist_vectorizer.adapt(songs.map(lambda x: x['artist_name']))\n        \n        self.title_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n            max_tokens=max_tokens)\n        self.title_text_embedding = tf.keras.Sequential([\n          self.title_vectorizer,\n          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n          tf.keras.layers.GlobalAveragePooling1D(),\n        ])\n        self.title_vectorizer.adapt(songs.map(lambda x: x['title']))\n        \n        self.year_embedding = tf.keras.Sequential([\n              tf.keras.layers.Embedding(len(year_data) + 1, 32),\n              # tf.keras.layers.Embedding(2501, 32),\n            ])\n        \n    def call(self, inputs):\n      # return self.title_embedding(inputs['title'])\n      return tf.concat([\n    self.title_embedding(inputs['title']),\n    self.release_text_embedding(inputs['release'])\n    ,\n    self.year_embedding(inputs['year']), \n    self.artist_text_embedding(inputs['artist_name']),\n    self.title_text_embedding(inputs['title']),\n        ], axis=1)\n\nclass QueryModel(tf.keras.Model):\n  &quot;&quot;&quot;Model for encoding user queries.&quot;&quot;&quot;\n\n  def __init__(self, layer_sizes):\n    &quot;&quot;&quot;Model for encoding user queries.\n\n    Args:\n      layer_sizes:\n        A list of integers where the i-th entry represents the number of units\n        the i-th layer contains.\n    &quot;&quot;&quot;\n    super().__init__()\n\n    # We first use the user model for generating embeddings.\n    self.embedding_model = UserModel()\n\n    # Then construct the layers.\n    self.dense_layers = tf.keras.Sequential()\n\n    # Use the ReLU activation for all but the last layer.\n    for layer_size in layer_sizes[:-1]:\n      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=&quot;relu&quot;))\n\n    # No activation for the last layer.\n    for layer_size in layer_sizes[-1:]:\n      self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n\n  def call(self, inputs):\n    feature_embedding = self.embedding_model(inputs)\n    return self.dense_layers(feature_embedding)\n\nclass CandidateModel(tf.keras.Model):\n  &quot;&quot;&quot;Model for encoding movies.&quot;&quot;&quot;\n\n  def __init__(self, layer_sizes):\n    &quot;&quot;&quot;Model for encoding movies.\n\n    Args:\n      layer_sizes:\n        A list of integers where the i-th entry represents the number of units\n        the i-th layer contains.\n    &quot;&quot;&quot;\n    super().__init__()\n\n    self.embedding_model = ItemModel()\n\n    # Then construct the layers.\n    self.dense_layers = tf.keras.Sequential()\n\n    # Use the ReLU activation for all but the last layer.\n    for layer_size in layer_sizes[:-1]:\n      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=&quot;relu&quot;))\n\n    # No activation for the last layer.\n    for layer_size in layer_sizes[-1:]:\n      self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n\n  def call(self, inputs):\n    feature_embedding = self.embedding_model(inputs)\n    return self.dense_layers(feature_embedding)\n\nclass SongModel(tfrs.models.Model):\n\n    def __init__(self, layer_sizes):\n        super().__init__()\n        self.query_model = QueryModel(layer_sizes)\n        self.candidate_model = CandidateModel(layer_sizes)\n        self.task = tfrs.tasks.Retrieval(\n          metrics=tfrs.metrics.FactorizedTopK(\n              candidates=songs.batch(128).map(self.candidate_model),\n          ),\n      )\n\n    def compute_loss(self, features, training=False):\n        print('type of feature ----',type(features))\n\n        query_embeddings = self.query_model({\n            &quot;user_id&quot;: features[&quot;user_id&quot;]\n            ,\n        })\n\n        item_embeddings = self.candidate_model({            \n            &quot;song_id&quot;: features[&quot;song_id&quot;],\n                &quot;title&quot; : features[&quot;title&quot;],\n                 &quot;release&quot; : features[&quot;release&quot;]\n                ,\n                &quot;artist_name&quot; : features[&quot;artist_name&quot;],\n                &quot;title&quot;: features[&quot;title&quot;],\n                &quot;year&quot; : features[&quot;year&quot;],\n\n        })\n\n        return self.task(query_embeddings, item_embeddings)\n\nmodel = SongModel([32])\nmodel.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\nmodel_hist = model.fit(cached_train, epochs=9)\n</code></pre>\n""}, {'owner': {'reputation': 26, 'user_id': 8751550}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1653995791, 'answer_id': 72446810, 'question_id': 71791115, 'body': ""<p>I got a similar error when using tfrs on a custom dataset. And it turns out that I had some none print characters and sysmbols in the data. I simply searched and removed the symbols (manually, some regex) and i also limit the text columns in the dataframe to printable characters only.</p>\n<pre><code>from string import printable as pt\n\nallowed_set = set(pt)\ndf[col] = df[col].apply(lambda x:  ''.join([' ' if  s not in  allowed_set else s for s in x]))\n</code></pre>\n<p>I hope it helps.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9683}"
303,74809872,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9680}"
304,74005009,"{'items': [{'owner': {'reputation': 89, 'user_id': 20350181}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1666882698, 'answer_id': 74224171, 'question_id': 74005009, 'body': '<p>if your datagen_row() function yields input_data, label with format 500 and 1\nthan your output_signature should be:</p>\n<pre><code>  output_signature=(\n  tf.TensorSpec(shape=(None, 500), dtype=tf.float32, name=None),\n  tf.TensorSpec(shape=(), dtype=tf.int64, name=None))\n</code></pre>\n<p>where the first TensorSpec is for the data format and the second one for the label format.\nBut it would be helpful if you post the function + maybe data examples or data shape here. Otherwise it is hard to help.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9680}"
305,64770581,"{'items': [{'owner': {'reputation': 10889, 'user_id': 7370153}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1605018492, 'answer_id': 64770838, 'question_id': 64770581, 'body': '<p>Keras used to be able to support different backends (tensorflow, theano and CNTK). Since keras 2.3, there is no difference between <code>keras</code> and <code>tf.keras</code>.</p>\n<p>An excerpt from the Readme of the <a href=""https://github.com/keras-team/keras"" rel=""nofollow noreferrer"">keras repository on github</a> :</p>\n<blockquote>\n<p>Multi-backend Keras and tf.keras</p>\n<p>Multi-backend Keras has been discontinued. At this time, we recommend that Keras users who use multi-backend Keras with the TensorFlow backend switch to tf.keras in TensorFlow 2.0.</p>\n<p>Keras 2.2.5 was the last release of Keras implementing the 2.2.* API. It was the last release to only support TensorFlow 1 (as well as Theano and CNTK).</p>\n<p><strong>The current release is Keras 2.4.0, which simply redirects to tf.keras.</strong></p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9680}"
306,50514454,"{'items': [{'owner': {'reputation': 273, 'user_id': 8636859}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1527622614, 'answer_id': 50591724, 'question_id': 50514454, 'body': '<p>I posted this question as a github issue and here is the response from the Tensorflow team:</p>\n<p><a href=""https://github.com/tensorflow/tensorflow/issues/19541"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/19541</a></p>\n<p>Copying from &quot;xiejw&quot; for completeness:</p>\n<blockquote>\n<p>If I understand correctly, this issue is &quot;once give estimator an input_fn with dataset inside, the evaluate process will error out with OutOfRangeError.&quot;</p>\n<p>Estimator can handle this correctly actually. However, a known common root cause for this is metrics defined in model_fn have bug. We need to rule that part out first.</p>\n<p>@mrezak if possible, can you show the code about the model_fn? Or if you have a minimal reproducible script, that will be extremely helpful. -- Thanks in advance.</p>\n<p>A common problem for this is: metric in tensorflow should return two Ops: update_op and value_op. Estimator calls the update_op for each batch of the data in input source and, once it is exhausted, it call the value_op to get the metric values. The value_op here should have dependency back to variables reading only.</p>\n<p>Many model_fn puts the dependency of value_op with the input pipeline, so, estimator.evaluate will thereby trigger the input pipeline one more time, which errors out with OutOfRangeError</p>\n</blockquote>\n<p>The problem was indeed how I defined the <code>eval_metric</code> in <code>model_fn</code>. In my actual code my total loss to be optimized was composed of multiple losses (reconstruction + L2 + KL) and in the evaluation part I wanted to get the reconstruction loss (on the validation data), which depended on the input data pipeline. My actual reconstruction cost was more complex than MSE (none of the other tf.metric functions as well) which was not straightforward to be implemented using tf.metric basic functions.</p>\n<p>This is &quot;xiejw&quot;\'s suggestion which fixed the issue:</p>\n<pre><code>my_total_loss =  ... # the loss you care. Pay attention to how you reduce the loss. \neval_metric_ops = {\'total_loss: tf.metrics.mean(my_total_loss)}\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9680}"
307,55986982,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': False, 'score': 7, 'creation_date': 1557390975, 'answer_id': 56055386, 'question_id': 55986982, 'body': '<p>Using OpenCV + Tensorflow 2.0 is straightforward.</p>\n\n<p>Let\'s say we have the image ""wink.jpg"" (see wink image attached) in the current directory, then it is possible to use Tensorflow 2.0 to read the JPEG image and get a <code>tf.Tensor</code> with dtype=uint8, get a numpy array from it and use OpenCV to visualize it (in BGR format, as OpenCV needs).</p>\n\n<pre><code>import tensorflow as tf\nimport cv2\n\n\ndef load(image_file):\n    image = tf.io.read_file(image_file)\n    image = tf.image.decode_jpeg(image)\n    return image\n\n\nwink = load(""wink.jpg"")\nprint(wink.shape, wink.dtype)\n\n# Get a Numpy BGR image from a RGB tf.Tensor\nimage = cv2.cvtColor(wink.numpy(), cv2.COLOR_RGB2BGR)\n\ncv2.imshow(""image"", image)\ncv2.waitKey()\n</code></pre>\n\n<p><a href=""https://i.stack.imgur.com/rx7jv.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/rx7jv.jpg"" alt=""wink""></a></p>\n\n<p>If you have some problem related to the Graph architecture, it is probably because you\'re:</p>\n\n<ul>\n<li>Or using <code>tf.function</code> to convert the code the graph (in this case just remove the annotation)</li>\n<li>Or using OpenCV inside a <code>tf.data.Dataset</code> method (in this case just do not use OpenCV or use <code>tf.py_func</code> where OpenCV is needed)</li>\n<li>Or using a wrong version of Tensorflow, that is not 2 with eager mode enabled by default (check if everything is ok by running <code>pip list |grep tf</code> and <code>pip list | grep tensor</code> and if you see something weird like more than 1 version of TF installed, I suggest to delete the environment a start with a new installation).</li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9680}"
308,42734106,"{'items': [{'owner': {'reputation': 1907, 'user_id': 3531912}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1489235323, 'answer_id': 42735208, 'question_id': 42734106, 'body': '<p>Using the code that you reported, you are correctly restoring your variables and tensors. However, I suggest you a more idiomatic way to create and restore the variables that will let you manage better the graph elements.</p>\n\n<p>First of all, you should use <a href=""https://www.tensorflow.org/api_docs/python/tf/get_variable"" rel=""nofollow noreferrer"">tf.get_variable</a> function to create and to initialize a variable. Using the parameter <em>name</em> you should associate a name to your variable. This will allow you to retrieve it after the restore step. </p>\n\n<p>The restore step is correctly implemented in the code that you have reported. If you want to get the reference to your variable you should again use the <code>tf.get_variable</code> function without specifying any initializer or shape. The TensorFlow scope manager will recognize that you already have a initialized variable with the name that you have chosen and it will return it. See the following code for a better demonstration of this procedure:</p>\n\n<pre><code>import tensorflow as tf\n\nwith tf.Session() as sess:\n    saver = tf.train.import_meta_graph(\'data/sess.meta\')\n    saver.restore(sess, \'data/sess\')\n\n    # suppose that your variable is called ""variable_101""\n    var = tf.get_variable(""variable_101"")\n\n    # var will represent your initialized variable\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9675}"
309,61526556,"{'items': [{'owner': {'reputation': 2111, 'user_id': 4334120}, 'down_vote_count': 3, 'up_vote_count': 1, 'is_accepted': False, 'score': -2, 'creation_date': 1608722242, 'answer_id': 65423420, 'question_id': 61526556, 'body': ""<p>It's pretty straightforward:\nuse <code>x = tf.io.serialize_tensor(x).numpy()</code></p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9675}"
310,52234780,"{'items': [{'owner': {'reputation': 506, 'user_id': 9621080}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1617347939, 'answer_id': 66915739, 'question_id': 52234780, 'body': ""<p>This question is a little old, but it helped me to read and load tagged images (tagged with VoTT) for training YOLOv4/v3. Maybe this code is another &quot;example&quot; that might help someone:</p>\n<pre><code>def load_single_boxed_tfrecord(record):\n&quot;&quot;&quot;\nLoads a single tfrecord with its boundary boxes and corresponding labels, from a single tfrecord.\n\nArgs:\n    record: as tfrecord (Tensor), as yielded from tf.data.TFRecordDataset\nReturns:\n    (Tensor of image), (Tensor of labels), (Tensor of: x_top_left, x_lower_right, y_top_left, y_lower_right)\n\n&quot;&quot;&quot;\nfeature = {'image/encoded': tf.io.FixedLenFeature([], tf.string),\n           'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n           'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n           'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n           'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n           'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n           'image/filename': tf.io.FixedLenFeature([], tf.string),\n           'image/width': tf.io.FixedLenFeature([], tf.int64),\n           'image/height': tf.io.FixedLenFeature([], tf.int64)\n           }\n\ntf_file = tf.io.parse_single_example(record, feature)\n\ntf_img = tf.image.decode_image(tf_file[&quot;image/encoded&quot;], channels=COLOR_CHANNELS)\ntf_img = tf.image.convert_image_dtype(tf_img, tf.float32)\n\nlabel = tf.sparse.to_dense(tf_file['image/object/class/label'], default_value=0)\n# normalized values:\nx1norm = tf.sparse.to_dense(tf_file['image/object/bbox/xmin'], default_value=0)\nx2norm = tf.sparse.to_dense(tf_file['image/object/bbox/xmax'], default_value=0)\ny1norm = tf.sparse.to_dense(tf_file['image/object/bbox/ymin'], default_value=0)\ny2norm = tf.sparse.to_dense(tf_file['image/object/bbox/ymax'], default_value=0)\n\nreturn tf_img, label, [x1norm, x2norm, y1norm, y2norm]\n</code></pre>\n""}, {'owner': {'reputation': 816, 'user_id': 9540764}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1536423951, 'answer_id': 52237187, 'question_id': 52234780, 'body': '<p>I\'m still learning TensorFlow and tfrecordfile usage so I\'m not a master of these things, but I\'ve found this <a href=""https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564"" rel=""nofollow noreferrer"">guide</a> that was useful in my case and might be useful also for you.</p>\n'}, {'owner': {'reputation': 5724, 'user_id': 934904}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1536419865, 'answer_id': 52236642, 'question_id': 52234780, 'body': ""<p>I can't test your code because I don't have the train.tfrecords file. Does this code create an empty dataset?</p>\n\n<pre><code>dataset = tf.data.TFRecordDataset('train.tfrecords')\ndataset = dataset.map(parse_fn)\nitr = dataset.make_one_shot_iterator()\n\nwith tf.Session() as sess:\n    while True:\n        try:\n            print(sess.run(itr.get_next()))\n        except tf.errors.OutOfRangeError:\n            break\n</code></pre>\n\n<p>If this gives you an error, please let me know which line produces it.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9675}"
311,47981089,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9675}"
312,67723809,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9671}"
313,75401761,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9671}"
314,49768997,"{'items': [{'owner': {'reputation': 5480, 'user_id': 3584765}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1523434008, 'answer_id': 49769737, 'question_id': 49768997, 'body': ""<p>Since TFRecord is just a serialized version of your original data bundled with some extra information I am not sure you can accomplish what you are asking. Some questions that comes in my mind:</p>\n\n<ol>\n<li>How are you supposed to write to a file multiple examples\nsimultaneously?</li>\n<li>And if you succeed in the above goal (deal with all the concurrent issues etc) tensorflow will still read them in the same way: serially so I am not sure what's the benefit here.</li>\n<li>Also, TFRecord are supposed to be written once and used many times. Meaning they are not the product of any training or a process that may change in the future. They are supposed to be the input to your model. So, regardless of the effort to create them it's one time job. How big are your data. And in this case I think you will have more trouble dealing with them in the training procedure than writing them in TFRecords.</li>\n<li>A (naive) workaround I can think of is to create multiple TFRecord files simultaneously. This way for example you can speed up the writing of TFRecord if that's what is bothering you. You can then read them using a list of records instead of a single TFRecord file. Of course in this case tensorflow will read them serially once again.</li>\n</ol>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9671}"
315,66968102,"{'items': [{'owner': {'reputation': 22117, 'user_id': 50065}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1617720867, 'answer_id': 66971071, 'question_id': 66968102, 'body': '<p>I assume you would like your function to accept:</p>\n<ul>\n<li><code>tf.float32</code></li>\n<li><code>np.float32</code></li>\n<li><code>float</code></li>\n<li><code>tf.int32</code></li>\n<li><code>np.int32</code></li>\n<li><code>int</code></li>\n</ul>\n<p>and always return, say, <code>tf.float32</code>.  Not completely sure if this covers your use case, but I would put a broad type for your input argument and cast to the desired type in your function.</p>\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""nofollow noreferrer""><code>experimental_follow_type_hints</code></a> can be used along with type annotations to improve performance by reducing the number of expensive graph retracings. For example, an argument annotated with tf.Tensor is converted to Tensor even when the input is a non-Tensor value.</p>\n<pre><code>from typing import TYPE_CHECKING\nimport tensorflow as tf\nimport numpy as np\n\n\n@tf.function(experimental_follow_type_hints=True)\ndef foo(x: tf.Tensor) -&gt; tf.float32:\n    if x.dtype == tf.int32:\n        x = tf.dtypes.cast(x, tf.float32)\n    return x * 2\n\na = tf.cast(1.0, dtype=tf.float32)\nb = tf.cast(1.0, dtype=tf.int32)\n\nc = np.float32(1.0)\nd = np.int32(1.0)\n\ne = 1.0\nf = 1\n\nfor var in [a, b, c, d, e, f]:\n    print(f&quot;input: {var},\\tinput type: {type(var)},\\toutput: {foo(var)}\\toutput type: {type(foo(var))}&quot;)\n\nif TYPE_CHECKING:\n    reveal_locals()\n</code></pre>\n<p>Output of <code>python3 stack66968102.py</code>:</p>\n<pre><code>input: 1.0,     input type: &lt;class \'tensorflow.python.framework.ops.EagerTensor\'&gt;,      output: 2.0     output dtype: &lt;dtype: \'float32\'&gt;\ninput: 1,       input type: &lt;class \'tensorflow.python.framework.ops.EagerTensor\'&gt;,      output: 2.0     output dtype: &lt;dtype: \'float32\'&gt;\ninput: 1.0,     input type: &lt;class \'numpy.float32\'&gt;,    output: 2.0     output dtype: &lt;dtype: \'float32\'&gt;\ninput: 1,       input type: &lt;class \'numpy.int32\'&gt;,      output: 2.0     output dtype: &lt;dtype: \'float32\'&gt;\ninput: 1.0,     input type: &lt;class \'float\'&gt;,    output: 2.0     output dtype: &lt;dtype: \'float32\'&gt;\ninput: 1,       input type: &lt;class \'int\'&gt;,      output: 2.0     output dtype: &lt;dtype: \'float32\'&gt;\n</code></pre>\n<p>Output of <code>mypy stack66968102.py  --ignore-missing-imports</code>:</p>\n<pre><code>stack66968102.py:27: note: Revealed local types are:\nstack66968102.py:27: note:     a: Any\nstack66968102.py:27: note:     b: Any\nstack66968102.py:27: note:     c: numpy.floating[numpy.typing._32Bit*]\nstack66968102.py:27: note:     d: numpy.signedinteger[numpy.typing._32Bit*]\nstack66968102.py:27: note:     e: builtins.float\nstack66968102.py:27: note:     f: builtins.int\nstack66968102.py:27: note:     tf: Any\nstack66968102.py:27: note:     var: Any\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9671}"
316,49418325,"{'items': [{'owner': {'reputation': 922, 'user_id': 8858032}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1521835579, 'answer_id': 49457562, 'question_id': 49418325, 'body': '<blockquote>\n  <p>My question is why would this ""input_fn"" code does the trick? If I change the code to this, it will run into an infinite loop. Why??</p>\n</blockquote>\n\n<p>The documentation states that <code>input_fn</code> is called repeatedly until it returns a <code>tf.errors.OutOfRangeError</code>. Adorning your tensor with <code>tf.train.limit_epochs</code> ensures that the error is eventually raised, which signals to KMeans that it should stop training.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9671}"
317,61026862,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9666}"
318,45701681,"{'items': [{'owner': {'reputation': 2262, 'user_id': 7886651}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1503935506, 'answer_id': 45922890, 'question_id': 45701681, 'body': ""<p>So what I figured out is that using <code>tf.train.shuffle_batch_join</code> solves my issue as it starts shuffling images from different data sets. In other words, every batch is now containing images from all the datasets/file_names. Here is an example:</p>\n\n<pre><code>def read_my_file_format(filename_queue):\n    reader = tf.TFRecordReader()\n    key, serialized_example = reader.read(filename_queue)\n    features = tf.parse_single_example(\n        serialized_example,\n        # Defaults are not specified since both keys are required.\n        features={\n            'height': tf.FixedLenFeature([], tf.int64),\n            'width': tf.FixedLenFeature([], tf.int64),\n            'image_raw': tf.FixedLenFeature([], tf.string),\n            'annotation_raw': tf.FixedLenFeature([], tf.string)\n        })\n\n    # This is how we create one example, that is, extract one example from the database.\n    image = tf.decode_raw(features['image_raw'], tf.uint8)\n    # The height and the weights are used to\n    height = tf.cast(features['height'], tf.int32)\n    width = tf.cast(features['width'], tf.int32)\n\n    # The image is reshaped since when stored as a binary format, it is flattened. Therefore, we need the\n    # height and the weight to restore the original image back.\n    image = tf.reshape(image, [height, width, 3])\n\n    annotation = tf.cast(features['annotation_raw'], tf.string)\n    return annotation, image\n\ndef input_pipeline(filenames, batch_size, num_threads, num_epochs=None):\n    filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epoch, shuffle=False,\n                                                    name='queue')\n    # Therefore, Note that here we have created num_threads readers to read from the filename_queue.\n    example_list = [read_my_file_format(filename_queue=filename_queue) for _ in range(num_threads)]\n    min_after_dequeue = 100\n    capacity = min_after_dequeue + num_threads * batch_size\n    label_batch, images_batch = tf.train.shuffle_batch_join(example_list,\n                                                            shapes=[[], [112, 112, 3]],\n                                                            batch_size=batch_size,\n                                                            capacity=capacity,\n                                                            min_after_dequeue=min_after_dequeue)\n    return label_batch, images_batch, example_list\n\nlabel_batch, images_batch, input_ann_img = \\\n    input_pipeline(tfrecords_filename_seq, batch_size, num_threads, num_epochs=num_epoch)\n</code></pre>\n\n<p>And now this is going to create a number of readers to read from the <code>FIFOQueue</code>, and after each reader will have a different decoder. Finally, after decoding the images, they will fed into another <code>Queue</code> that is created after calling <code>tf.train.shuffle_batch_join</code> to feed the network a batch of images. </p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9666}"
319,53307954,"{'items': [{'owner': {'reputation': 1630, 'user_id': 10025506}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1542287674, 'answer_id': 53320326, 'question_id': 53307954, 'body': '<pre><code>to_predict = random_onehot((1, SEQUENCE_LENGTH, SEQUENCE_CHANNELS))\\\n        .astype(tf_type_string(I_DTYPE))\npred_features = {\'input_tensors\': to_predict}\n\npred_ds = tf.data.Dataset.from_tensor_slices(pred_features)\npredicted = est.predict(lambda: pred_ds, yield_single_examples=True)\n\nnext(predicted)\n</code></pre>\n\n<blockquote>\n  <p>ValueError: Tensor(""IteratorV2:0"", shape=(), dtype=resource) must be from the same graph as Tensor(""TensorSliceDataset:0"", shape=(), dtype=variant).</p>\n</blockquote>\n\n<p>When you use the <code>tf.data.Dataset</code> module, it actually defines an input graph which is independant from the model graph. What happens here is that you first created a small graph by calling <code>tf.data.Dataset.from_tensor_slices()</code>, then the estimator API created a second graph by calling <code>dataset.make_one_shot_iterator()</code> automatically. These 2 graphs can\'t communicate so it throws an error.</p>\n\n<p>To circumvent this, you should never create a dataset outside of estimator.train/evaluate/predict. This is why everything data related is wrapped inside input functions.</p>\n\n<pre><code>def predict_input_fn(data, batch_size=1):\n  dataset = tf.data.Dataset.from_tensor_slices(data)\n  return dataset.batch(batch_size).prefetch(None)\n\npredicted = est.predict(lambda: predict_input_fn(pred_features), yield_single_examples=True)\nnext(predicted)\n</code></pre>\n\n<p>Now, the graph is not created outside of the predict call.</p>\n\n<p>I also added <code>dataset.batch()</code> because the rest of your code expect batched data and it was throwing a shape error. Prefetch just speed things up.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9666}"
320,55310900,"{'items': [{'owner': {'reputation': 6098, 'user_id': 7389608}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1553324417, 'answer_id': 55311411, 'question_id': 55310900, 'body': '<p>All you need to do is not use <code>tf.boolean_mask</code>. First, I customized a similar picture.</p>\n\n<pre><code>import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage = np.zeros(shape=(256,256))\nnp.random.seed(0)\nimage[12:76,78:142] = np.random.random_sample(size=(64,64))\nplt.imshow(image)\nplt.show()\n</code></pre>\n\n<p><a href=""https://i.stack.imgur.com/T6jPR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/T6jPR.png"" alt=""enter image description here""></a></p>\n\n<p>Then get its the coordinates of maximum and minimum by tensorflow.</p>\n\n<pre><code>import tensorflow as tf\n\nimage_pred = tf.placeholder(shape=(256,256),dtype=tf.float32)\nzeros = tf.zeros_like(image_pred)\nmask = tf.greater(image_pred, zeros)\n\ncoordinates_pred = tf.where(mask)\nxy_min = tf.reduce_min(coordinates_pred, axis=0)\nxy_max = tf.reduce_max(coordinates_pred, axis=0)\n\nwith tf.Session() as sess:\n    print(sess.run(xy_min,feed_dict={image_pred:image}))\n    print(sess.run(xy_max,feed_dict={image_pred:image}))\n\n[12 78]\n[ 75 141]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9663}"
321,39008821,"{'items': [{'owner': {'reputation': 2018, 'user_id': 4093741}, 'down_vote_count': 1, 'up_vote_count': 70, 'is_accepted': True, 'score': 69, 'creation_date': 1471486972, 'answer_id': 39009002, 'question_id': 39008821, 'body': '<p><code>expand_dims</code> will not add or reduce elements in a tensor, it just changes the shape by adding <code>1</code> to dimensions. For example, a vector with 10 elements could be treated as a 10x1 matrix.</p>\n\n<p>The situation I have met to use <code>expand_dims</code> is when I tried to build a ConvNet to classify grayscale images. The grayscale images will be loaded as matrix of size <code>[320, 320]</code>. However, <code>tf.nn.conv2d</code> require input to be <code>[batch, in_height, in_width, in_channels]</code>, where the <code>in_channels</code> dimension is missing in my data which in this case should be <code>1</code>. So I used <code>expand_dims</code> to add one more dimension.</p>\n\n<p>In your case, I do not think you need <code>expand_dims</code>.</p>\n'}, {'owner': {'reputation': 6147, 'user_id': 4511978}, 'down_vote_count': 0, 'up_vote_count': 26, 'is_accepted': False, 'score': 26, 'creation_date': 1507074309, 'answer_id': 46555035, 'question_id': 39008821, 'body': '<p>To add to Da Tong\'s answer, you may want to expand more than one dimension at the same time. For instance, if you are performing TensorFlow\'s <code>conv1d</code> operation on vectors of rank 1, you need to feed them with rank three.</p>\n\n<p>Performing <code>expand_dims</code> several times is readable, but might introduce some overhead into the computational graph. You can get the same functionality in a one-liner with <code>reshape</code>:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\n# having some tensor of rank 1, it could be an audio signal, a word vector...\ntensor = tf.ones(100)\nprint(tensor.get_shape()) # =&gt; (100,)\n\n# expand its dimensionality to fit into conv2d\ntensor_expand = tf.expand_dims(tensor, 0)\ntensor_expand = tf.expand_dims(tensor_expand, 0)\ntensor_expand = tf.expand_dims(tensor_expand, -1)\nprint(tensor_expand.get_shape()) # =&gt; (1, 1, 100, 1)\n\n# do the same in one line with reshape\ntensor_reshape = tf.reshape(tensor, [1, 1, tensor.get_shape().as_list()[0],1])\nprint(tensor_reshape.get_shape()) # =&gt; (1, 1, 100, 1)\n</code></pre>\n\n<p><strong>NOTE:</strong> In case you get the error <code>TypeError: Failed to convert object of type &lt;type \'list\'&gt; to Tensor.</code>, try to pass <code>tf.shape(x)[0]</code> instead of <code>x.get_shape()[0]</code> as suggested <a href=""https://github.com/tensorflow/tensorflow/issues/7253"" rel=""noreferrer"">here</a>.</p>\n\n<p>Hope it helps!<br>\nCheers,<br>\nAndres</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9663}"
322,66980404,"{'items': [{'owner': {'reputation': 16444, 'user_id': 9215780}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1617802350, 'answer_id': 66987188, 'question_id': 66980404, 'body': '<p>Here are a few more cases. The main takeaway is that to update the content in <code>tf.Variable</code>, we use <code>assign</code>. But note that it will assign the value eagerly.</p>\n<pre><code>x = tf.Variable(range(5), shape=(5,), name=&quot;a&quot;)\nx.numpy()\narray([0, 1, 2, 3, 4], dtype=int32)\n\nx.assign(tf.where(x &gt; 2, x, -1)).numpy()\narray([-1, -1, -1,  3,  4], dtype=int32)\n\nx.assign(range(5,10)).numpy()\narray([5, 6, 7, 8, 9], dtype=int32)\n\nx.assign(tf.where(x &lt; 8, tf.range(5), tf.where(x &gt; 8 , x, -1))).numpy()\narray([ 0,  1,  2, -1,  9], dtype=int32)\n</code></pre>\n'}, {'owner': {'reputation': 10889, 'user_id': 7370153}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1617797964, 'answer_id': 66985933, 'question_id': 66980404, 'body': '<p>To update a <code>tf.Variable</code>, you need to call <code>assign</code>. Read more in the <a href=""https://www.tensorflow.org/guide/variable"" rel=""nofollow noreferrer"">Introduction to Variables</a> guide.</p>\n<pre><code>&gt;&gt;&gt; import tensorflow as tf\n&gt;&gt;&gt; tf.random.set_seed(0)\n&gt;&gt;&gt; x = tf.Variable(tf.random.uniform((3,4),-1,1), dtype=tf.float32)\n&gt;&gt;&gt; x\n&lt;tf.Variable \'Variable:0\' shape=(3, 4) dtype=float32, numpy=\narray([[-0.41604972, -0.5868671 ,  0.07078147,  0.12251496],\n       [-0.16665101,  0.6156559 , -0.0135498 ,  0.9962585 ],\n       [ 0.3934703 , -0.7492528 ,  0.4196334 ,  0.32483125]],\n      dtype=float32)&gt;\n&gt;&gt;&gt; x.assign(tf.where(x&gt;0,x,0))\n&lt;tf.Variable \'UnreadVariable\' shape=(3, 4) dtype=float32, numpy=\narray([[0.        , 0.        , 0.07078147, 0.12251496],\n       [0.        , 0.6156559 , 0.        , 0.9962585 ],\n       [0.3934703 , 0.        , 0.4196334 , 0.32483125]], dtype=float32)&gt;\n&gt;&gt;&gt; x\n&lt;tf.Variable \'Variable:0\' shape=(3, 4) dtype=float32, numpy=\narray([[0.        , 0.        , 0.07078147, 0.12251496],\n       [0.        , 0.6156559 , 0.        , 0.9962585 ],\n       [0.3934703 , 0.        , 0.4196334 , 0.32483125]], dtype=float32)&gt;\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9661}"
323,47485498,"{'items': [{'owner': {'reputation': 34138, 'user_id': 987185}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1511618741, 'answer_id': 47486848, 'question_id': 47485498, 'body': '<p>Yes, the embedding is learned. You can look at the <code>tf.nn.embedding_lookup</code> operation as doing the following matrix multiplication more efficiently:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\n\nNUM_CATEGORIES, EMBEDDING_SIZE = 5, 3\ny = tf.placeholder(name=\'class_idx\', shape=(1,), dtype=tf.int32)\n\nRS = np.random.RandomState(42)\nW_em_init = RS.randn(NUM_CATEGORIES, EMBEDDING_SIZE)\nW_em = tf.get_variable(name=\'W_em\',\n                       initializer=tf.constant_initializer(W_em_init),\n                       shape=(NUM_CATEGORIES, EMBEDDING_SIZE))\n\n# Using tf.nn.embedding_lookup\ny_em_1 = tf.nn.embedding_lookup(W_em, y)\n\n# Using multiplication\ny_one_hot = tf.one_hot(y, depth=NUM_CATEGORIES)\ny_em_2 = tf.matmul(y_one_hot, W_em)\n\nsess = tf.InteractiveSession()\nsess.run(tf.global_variables_initializer())\nsess.run([y_em_1, y_em_2], feed_dict={y: [1.0]})\n# [array([[ 1.5230298 , -0.23415338, -0.23413695]], dtype=float32),\n#  array([[ 1.5230298 , -0.23415338, -0.23413695]], dtype=float32)]\n</code></pre>\n\n<p>The variable <code>W_em</code> will be trained in exactly the same way irrespective of whether you use <code>y_em_1</code> or <code>y_em_2</code> formulation; <code>y_em_1</code> is likely to be more efficient, though.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9661}"
324,71711292,"{'items': [{'owner': {'reputation': 1343, 'user_id': 5558021}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1648842661, 'answer_id': 71712132, 'question_id': 71711292, 'body': '<p>Ok, I found the solution using .from_tensor_slice I can load images and labels simultaneously, but question about work in map function is still and what about third party augmentations?</p>\n<pre><code>def decode_img(img):\n    img = tf.io.decode_jpeg(img, channels=3)\n    return tf.image.resize(img, [img_height, img_width])\ndef process_path(file_path, label):\n    img = tf.io.read_file(train_path_f+file_path)\n    img = decode_img(img)\n    label = tf.reshape(label,[1])\n    return img, label\n\nimages = imgs_files\nlabels = train_csv.species_cat.values\ndataset = tf.data.Dataset.from_tensor_slices((images, labels))\ndataset = dataset.map(process_path)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9661}"
325,75639356,"{'items': [{'owner': {'reputation': 5250, 'user_id': 1149924}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1697420695, 'answer_id': 77299017, 'question_id': 75639356, 'body': '<p>The documentation is correct, Python <code>print()</code> is never converted to <code>tf.print()</code> during tracing. This is, for one, important for debugging and diagnostics: the majority of eh, well, unintended consequences happen during tracing. <code>print()</code> may be liberally used in the body of the function, and has its effect only during the tracing phase.</p>\n<p>The reason for this discrepancy is that the first example, a blog post, is six years older than the question, and apparently refers to TensorFlow 1.x. AFAIK, the decorator <code>@autograph.convert</code> was experimental in TF1, and had not made it into TF2; <code>@tf.function</code> subsumes the behavior. But generally, between a blog post and the documentation of any feature, the documentation is more authoritative.</p>\n<p>In addition to the Graph overview that you\'ve linked, there is a more detailed guide, <a href=""https://www.tensorflow.org/guide/function"" rel=""nofollow noreferrer""><em>Better performance with tf.function.</em></a> (I\'m not sure what the note about a very different view of graphs[...] for those [...] who are only familiar with TensorFlow 1.x in the Graph article is <em>really</em> about.) The <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""nofollow noreferrer""><code>tf.function</code> documentation</a> is also a must-read, not the least for the links to tutorials and guides it contains.</p>\n<blockquote>\n<p>In my understanding, AutoGraph is the one being used under @tf.function</p>\n</blockquote>\n<p>That\'s correct. A function is converted into a <a href=""https://www.tensorflow.org/api_docs/python/tf/types/experimental/GenericFunction"" rel=""nofollow noreferrer""><code>GenericFunction</code></a> object, which then can be <a href=""https://www.tensorflow.org/api_docs/python/tf/types/experimental/GenericFunction#get_concrete_function"" rel=""nofollow noreferrer"">instantiated</a> into a few <a href=""https://www.tensorflow.org/api_docs/python/tf/types/experimental/ConcreteFunction"" rel=""nofollow noreferrer""><code>ConcreteFunction</code></a>s, with different tensor shapes or data types, without re-tracing. However, a function may be re-traced if the reification process cannot <em>conclusively prove</em> that Python variables have <em>not</em> changed, when compared to all existing cached <code>GenericFunction</code> traces of the same Python function. AutoGraph proper is more involved with the second pass, reifying and optimising the <code>ConcreteFunction</code>, which (in addition to, basically, metadata) contains a <a href=""https://www.tensorflow.org/api_docs/python/tf/Graph"" rel=""nofollow noreferrer""><code>Graph</code></a> object, which can be placed and run on a device, or saved into a completely portable model (with some limitations, mainly concerning the TPU devices). The first pass primarily creates Python code rigged to call AutoGraph during the second phase.</p>\n<blockquote>\n<p>and <code>tf.py_function</code>.</p>\n</blockquote>\n<p><code>@tf.py_function</code> is a pragma directive <strong>for</strong> Autograph that tells it to create a graph op that calls back into Python from the graph. It has no effect in eager mode. (Needless to say, this makes the whole model less portable and unable to run without the full Python runtime, in addition to slowdown and synchronisation.) This is different from <code>@tf.function</code>, which declares that the function is intended to be transformed <strong>by</strong> Autograph, and causes the tracing of the function when it\'s called, if all conditions, documented in the <a href=""https://www.tensorflow.org/api_docs/python/tf/executing_eagerly"" rel=""nofollow noreferrer""><code>tf.executing_eagerly</code></a> article are met. They are both declarative, but their declarations are intended for different moving parts of the framework.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9661}"
326,45761087,"{'items': [{'owner': {'reputation': 3297, 'user_id': 15791}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1503075242, 'answer_id': 45761522, 'question_id': 45761087, 'body': '<p>Could it be that you are not using tensorflow v1.3 ?</p>\n\n<p>In v1.2 LinearRegressor was in <em>tf.contrib.learn</em> \n <a href=""https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/learn/LinearRegressor"" rel=""nofollow noreferrer"">api doc</a> since v1.3 is in <a href=""https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/estimator/LinearRegressor"" rel=""nofollow noreferrer"">api doc</a>.</p>\n\n<p>Use the following to print the version you installed.</p>\n\n<pre><code>import tensorflow as tf\nprint(tf.__version__)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9661}"
327,62956096,"{'items': [{'owner': {'reputation': 1689, 'user_id': 9353909}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1594997995, 'answer_id': 62956649, 'question_id': 62956096, 'body': '<p>When you create data for training, you encode the labels to numerical representations. After that the labels are lost, if you know the data with which the model was trained, then, you can know the label_names. Information of label_names is not stored in the model.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9656}"
328,43792961,"{'items': [{'owner': {'reputation': 4368, 'user_id': 1309401}, 'down_vote_count': 0, 'up_vote_count': 16, 'is_accepted': True, 'score': 16, 'creation_date': 1493932861, 'answer_id': 43792962, 'question_id': 43792961, 'body': '<p>This can be achieved using the <code>tf.while_loop()</code> and standard <a href=""https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences"" rel=""noreferrer"">tuples</a> as per the second example in the <a href=""https://www.tensorflow.org/api_docs/python/tf/while_loop"" rel=""noreferrer"">documentation</a>. </p>\n\n<pre><code>def rosenbrock(data_tensor):\n    columns = tf.unstack(data_tensor)\n\n    # Track both the loop index and summation in a tuple in the form (index, summation)\n    index_summation = (tf.constant(1), tf.constant(0.0))\n\n    # The loop condition, note the loop condition is \'i &lt; n-1\'\n    def condition(index, summation):\n        return tf.less(index, tf.subtract(tf.shape(columns)[0], 1))\n\n    # The loop body, this will return a result tuple in the same form (index, summation)\n    def body(index, summation):\n        x_i = tf.gather(columns, index)\n        x_ip1 = tf.gather(columns, tf.add(index, 1))\n\n        first_term = tf.square(tf.subtract(x_ip1, tf.square(x_i)))\n        second_term = tf.square(tf.subtract(x_i, 1.0))\n        summand = tf.add(tf.multiply(100.0, first_term), second_term)\n\n        return tf.add(index, 1), tf.add(summation, summand)\n\n    # We do not care about the index value here, return only the summation\n    return tf.while_loop(condition, body, index_summation)[1]\n</code></pre>\n\n<p>It is important to note that the index increment should occur in the body of the loop similar to a standard while loop. In the solution given, it is the first item in the tuple returned by the <code>body()</code> function. </p>\n\n<p>Additionally, the loop condition function must allot a parameter for the summation although it is not used in this particular example.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9656}"
329,41857602,"{'items': [{'owner': {'reputation': 47089, 'user_id': 121687}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1485371200, 'answer_id': 41859635, 'question_id': 41857602, 'body': '<p>As suggested by @Yaroslav you can just use the <code>top_k</code> values.</p>\n\n<pre><code>a = tf.Variable([[0.51, 0.52, 0.53, 0.94, 0.35],\n             [0.32, 0.72, 0.83, 0.74, 0.55],\n             [0.23, 0.72, 0.63, 0.64, 0.35],\n             [0.11, 0.02, 0.03, 0.14, 0.15],\n             [0.01, 0.72, 0.73, 0.04, 0.75]],tf.float32)\n\nrow_size = a.get_shape().as_list()[-1]\ntop_k = tf.nn.top_k(-a, k=row_size)\nsess.run(-top_k.values)\n</code></pre>\n\n<p>this prints for me</p>\n\n<pre><code>array([[ 0.34999999,  0.50999999,  0.51999998,  0.52999997,  0.94      ],\n       [ 0.31999999,  0.55000001,  0.72000003,  0.74000001,  0.82999998],\n       [ 0.23      ,  0.34999999,  0.63      ,  0.63999999,  0.72000003],\n       [ 0.02      ,  0.03      ,  0.11      ,  0.14      ,  0.15000001],\n       [ 0.01      ,  0.04      ,  0.72000003,  0.73000002,  0.75      ]], dtype=float32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9656}"
330,50149953,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9656}"
331,58069572,"{'items': [{'owner': {'reputation': 33, 'user_id': 12092080}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1569271575, 'answer_id': 58069981, 'question_id': 58069572, 'body': '<p>The following code has a solution using strided slice with dimensionality reduction and then reshape to get back the correct dimension.</p>\n\n<pre><code>import tensorflow.compat.v1 as tf\nimport numpy as np\n\ntf.disable_v2_behavior()\ninitial_input = tf.placeholder(dtype=tf.float32, shape=(None,5,1024))\ncap_i = tf.strided_slice(initial_input, [0,0,0], [0,5,1024], [1,1,1], \nshrink_axis_mask=1)\ncap_i_reshaped =tf.reshape(cap_i,[1,5,1024])\ncap_iT = tf.transpose(cap_i_reshaped, perm=[0,2,1])\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\ntf.io.write_graph(sess.graph_def, \'\', \'train.pbtxt\')\nconverter = tf.lite.TFLiteConverter.from_session(sess, [initial_input], \n[cap_iT])\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, \ntf.lite.OpsSet.SELECT_TF_OPS]\ntflite_model = converter.convert()\nopen(\'converted_model.tflite\', ""wb"").write(tflite_model)\nsess.close()\n</code></pre>\n\n<p>Previously thought slice was supported in TFLite but only strided_slice is.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9656}"
332,50029121,"{'items': [{'owner': {'reputation': 6711, 'user_id': 6708503}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1524766171, 'answer_id': 50049491, 'question_id': 50029121, 'body': '<p><code>tf.layers</code> and <code>tf.keras.layer</code> classes are generally interchangeable and in fact at head (and thus by the next release - 1.9), the former actually <a href=""https://github.com/tensorflow/tensorflow/blob/693b339/tensorflow/python/layers/base.py#L37"" rel=""nofollow noreferrer"">inherits from the latter</a>.</p>\n\n<p>TensorFlow is moving towards consolidating on <code>tf.keras</code> APIs for constructing models as that makes state ownership more explicit (e.g., parameters are ""owned"" by the <code>Layer</code> object, as opposed to the functional style where all model parameters are put in a ""collection"" associated with the complete graph). This style works well for both eager execution and graph construction (support for eager execution is improving with every release). I\'d recommend using <code>tf.keras.layers</code> and <code>tf.keras.Model</code>.</p>\n\n<p>Some examples that you may find useful:</p>\n\n<ul>\n<li>MNIST in the <a href=""https://github.com/tensorflow/models/blob/823da31/official/mnist/mnist.py"" rel=""nofollow noreferrer""><code>tensorflow/models</code></a> repository</li>\n<li>The <a href=""https://www.tensorflow.org/get_started/eager#create_a_model_using_keras"" rel=""nofollow noreferrer"">programmer\'s guide</a></li>\n<li>Other <a href=""https://github.com/tensorflow/tensorflow/tree/r1.8/tensorflow/contrib/eager/python/examples"" rel=""nofollow noreferrer"">eager execution samples</a> (where the exact same model definition works for both graph execution and eager execution).</li>\n</ul>\n\n<p>Not all existing TensorFlow examples have been moved to this style, but they slowly will.</p>\n\n<p>Hope that helps.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9651}"
333,55640642,"{'items': [{'owner': {'reputation': 790, 'user_id': 2912797}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1555091678, 'answer_id': 55657233, 'question_id': 55640642, 'body': '<p>You can use <a href=""https://www.tensorflow.org/api_docs/python/tf/py_function"" rel=""nofollow noreferrer""><code>py_function</code></a>, which allows you to switch from the graph mode (used by Keras) to the eager mode (where it is possible to iterate over tensors like in your function).</p>\n\n<pre><code>def to_docs(x):\n  return tf.py_function(embedding_to_docs, [x], tf.float32)\n\ntensor_of_shape2 = Lambda(to_docs)(tensor_of_shape1)\n</code></pre>\n\n<p>Note that the code run within your <code>embedding_to_docs</code> must be written in tensorflow eager instead of numpy. This means that you\'d need to replace some of the numpy calls with tensorflow. You\'d surely need to replace the return line with:</p>\n\n<pre><code>return tf.convert_to_tensor(new_output)\n</code></pre>\n\n<p>Using numpy arrays will stop the gradient computation, but you are likely not interested in gradient flowing through the input data anyway.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9651}"
334,41482823,"{'items': [{'owner': {'reputation': 451, 'user_id': 10123804}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1573668035, 'answer_id': 58843005, 'question_id': 41482823, 'body': '<p>tf.squeeze removes dimensions whose size is &quot;1&quot;. The example below shows use of tf.squeeze.</p>\n<pre><code>import tensorflow as tf\ntf.enable_eager_execution() ##if using TF1.4 for TF2.0 eager mode is the default mode.\n####example 1\na = tf.constant(value=[1,3,4,5],shape=(1,4))\nprint(a)\nOutput : tf.Tensor([[1 3 4 5]], shape=(1, 4), dtype=int32)\n\n#after applying tf.squeeze shape has been changed from  (4,1) to (4, )\nb = tf.squeeze(input=a)\nprint(b)\noutput: tf.Tensor([1 3 4 5], shape=(4,), dtype=int32)\n####example2\na = tf.constant(value=[1,3,4,5,4,6], shape=(3,1,2))\nprint(a)\nOutput:tf.Tensor(\n[[[1 3]]\n [[4 5]]\n [[4 6]]], shape=(3, 1, 2), dtype=int32)\n\n#after applying tf.squeeze shape has been chnaged from (3, 1, 2) to (3, 2)\nb = tf.squeeze(input=a)\nprint(b)\nOutput:tf.Tensor(\n[[1 3]\n [4 5]\n [4 6]], shape=(3, 2), dtype=int32)\n</code></pre>\n'}, {'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 15, 'is_accepted': True, 'score': 15, 'creation_date': 1483640732, 'answer_id': 41492093, 'question_id': 41482823, 'body': '<p>The best source of answers to questions like these is the <a href=""https://www.tensorflow.org/api_docs/"" rel=""noreferrer"">TensorFlow API documentation</a>. The two functions you mentioned create operations and symbolic tensors in a dataflow graph. In particular:</p>\n\n<ul>\n<li><p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/squeeze"" rel=""noreferrer""><code>tf.squeeze()</code></a> function returns a tensor with the same value as its first argument, but a different shape. It removes dimensions whose size is one. For example, if <code>t</code> is a tensor with shape <code>[batch_num, 1, elem_num]</code> (as in your question), <code>tf.squeeze(t, [1])</code> will return a tensor with the same contents but size <code>[batch_num, elem_num]</code>.</p></li>\n<li><p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/static_rnn"" rel=""noreferrer""><code>tf.nn.rnn()</code></a> function returns a pair of results, where the first element represents the outputs of a recurrent neural network for some given input, and the second element represents the final state of that network for that input. The TensorFlow website has a <a href=""https://www.tensorflow.org/tutorials/recurrent/"" rel=""noreferrer"">tutorial on recurrent neural networks</a> with more details.</p></li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9651}"
335,71596616,"{'items': [{'owner': {'reputation': 31, 'user_id': 6874041}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1654715349, 'answer_id': 72551004, 'question_id': 71596616, 'body': '<p>One way is to do Slicing <code>model.predict(data[:1])</code></p>\n<p>Another way is you can Try <code>model.predict(np.array([list(data[0])]))</code></p>\n'}, {'owner': {'reputation': 291, 'user_id': 18530075}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1648101128, 'answer_id': 71597622, 'question_id': 71596616, 'body': '<p>If <code>data.shape = (3, 3)</code>, when you pass <code>data[0]</code> to <code>model.predict()</code>, you are actually sending a vector of shape <code>(3, )</code>, but your model is expecting shape <code>(1, 3)</code> which means 1 example of size 3.</p>\n<p>Try slicing your data instead:</p>\n<pre><code>model.predict(data[:1])\n</code></pre>\n<p>This way your tensor will have shape (1, 3).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9651}"
336,64799299,"{'items': [{'owner': {'reputation': 755, 'user_id': 12812985}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1607766082, 'answer_id': 65263488, 'question_id': 64799299, 'body': ""<p>Consider that this colab notebook is a very simple version of how TF-Agents actually works. In reality you should use the Driver to sample trajectories instead of you manually calling</p>\n<pre><code>agent.action(state)\nenv.step(action)\n</code></pre>\n<p>at every iteration. The other advantage of the Driver is that it provides easy compatibility with all the metrics in TF-Agents.</p>\n<p>As to your question here is how:</p>\n<p>At the beginning of your training define a summary_writer with something like:</p>\n<pre><code>train_dir = os.path.join(root_dir, 'train')    \ntrain_summary_writer = tf.summary.create_file_writer(\n            train_dir, flush_millis=10000)\ntrain_summary_writer.set_as_default()\n</code></pre>\n<p>Now everytime you call agent.train it will flush to this summary writer and its tensorboard folder <code>train_dir</code>.</p>\n<p>To add some metrics into the mix simply define them with something like:</p>\n<pre><code>train_metrics = [\n        tf_metrics.NumberOfEpisodes(),\n        tf_metrics.EnvironmentSteps(),\n        tf_metrics.AverageReturnMetric(buffer_size=collect_episodes_per_epoch),\n        tf_metrics.AverageEpisodeLengthMetric(buffer_size=collect_episodes_per_epoch),\n    ]\n</code></pre>\n<p>Pass them to the Driver as observers together with your Replay Buffer like this:</p>\n<pre><code>dynamic_episode_driver.DynamicEpisodeDriver(\n            tf_env,\n            collect_policy,\n            observers=replay_observer + train_metrics,\n            num_episodes=collect_episodes_per_epoch).run()\n</code></pre>\n<p>And after this log them to your summaries with:</p>\n<pre><code>for train_metric in train_metrics:\n    train_metric.tf_summaries(train_step=epoch_counter, step_metrics=train_metrics[:2])\n</code></pre>\n<p>In case you're wondering, the <code>step_metrics</code> arg is to plot the last two metrics against the first two.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9647}"
337,64776769,"{'items': [{'owner': {'reputation': 9218, 'user_id': 867889}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1605054930, 'answer_id': 64778818, 'question_id': 64776769, 'body': ""<p>Attempt of an answer.</p>\n<p>This design tells us that minimizing second moment we would not want to propagate gradients through the first moment. Does it make sense? If we try to minimize <code>E[x^2]-E[x]^2</code> we would minimize  <code>E[x^2]</code> while simultaneously maximizing <code>E[x]^2</code>. First term would decrease absolute values of each element (drag them to the center). Second term would increase all values by gradient which would do nothing to minimize variance but might negatively affect other gradient paths.</p>\n<p>So, we don't propagate gradient of second moment through the first moment because this gradient would not effect second moment whatsoever, at least when using plain SGD.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9647}"
338,51507788,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9647}"
339,53895757,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9647}"
340,51397198,"{'items': [{'owner': {'reputation': 7528, 'user_id': 6246880}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1531910849, 'answer_id': 51400059, 'question_id': 51397198, 'body': '<p>To use the function <code>tf.graph_util.convert_variables_to_constants</code>, you need the graph and the session of your model.</p>\n\n<p>After going through the <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/estimator.py"" rel=""nofollow noreferrer"">TensorFlow code defining the estimators</a>, it appears that:</p>\n\n<ul>\n<li>This code is deprecated,</li>\n<li>The graph is created on the fly and not easily accessible (at least, I was not able to retrieve it).</li>\n</ul>\n\n<p>Thus, we will have to use the good old method.</p>\n\n<p>When you call <code>estimator.train</code>, checkpoints of your model are being saved in a specified directory (<code>estimator.model_dir</code>). You can use those files to access the graph and session and freeze the variables as follow:</p>\n\n<h3>1. Load meta graph</h3>\n\n<pre><code>saver = tf.train.import_meta_graph(\'/path/to/meta\')\n</code></pre>\n\n<h3>2. Load weights</h3>\n\n<pre><code>sess = tf.Session\nsaver.restore(sess, \'/path/to/weights\')\n</code></pre>\n\n<h3>3. Freeze variables</h3>\n\n<pre><code>tf.graph_util.convert_variables_to_constants(sess,\n                                             sess.graph.as_graph_def(),\n                                             [\'output\'])\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9643}"
341,43827792,"{'items': [{'owner': {'reputation': 343, 'user_id': 931831}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1501953381, 'answer_id': 45524542, 'question_id': 43827792, 'body': '<p>The following would work as well:</p>\n\n<pre><code>ph = tf.placeholder(shape=[None, 3], dtype=tf.int32)\nx = tf.strided_slice(ph, [0,0],[tf.shape(ph)[0],-1],[1,1])\ninput_ = np.array([[1,2,3],\n                  [3,4,5],\n                  [7,8,9]])\nsess = tf.InteractiveSession()\nsess.run(x,feed_dict={ph:input_})\n</code></pre>\n\n<p>ipython notebook screenshot at <a href=""https://i.stack.imgur.com/Eilzi.jpg"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/Eilzi.jpg</a></p>\n'}, {'owner': {'reputation': 3201, 'user_id': 6392807}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1494595207, 'answer_id': 43938772, 'question_id': 43827792, 'body': '<p>I having trouble understanding your question, but here\'s my attempt at answering it:</p>\n\n<p>You can use the <code>x[:, :, :]</code> syntax to select all elements of an array:</p>\n\n<pre><code>sess = tf.Session()\ninp = tf.constant([[[1, 1, 1], [2, 2, 2]],\n                   [[3, 3, 3], [4, 4, 4]],\n                   [[5, 5, 5], [6, 6, 6]]])\nprint(inp.shape)\n\nx = inp[:, :, :]\nprint(sess.run(x))\n</code></pre>\n\n<p>To get the last output you wanted, it\'s certainly possible with some manual  dimension calculations:</p>\n\n<pre><code>sess = tf.Session()\nx = tf.constant([[1,2,3],\n                 [3,4,5],\n                 [7,8,9]])\ny = tf.shape(x)\nbounds = tf.concat([y[:-1], [-1]], axis=0)\nout = tf.strided_slice(x, [0,0], bounds, [1,1])\nprint(sess.run(out))\n</code></pre>\n\n<p>In general the Tensorflow slicing syntax follows numpy\'s slicing syntax, which is documented here:\n<a href=""https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html"" rel=""nofollow noreferrer"">https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html</a></p>\n\n<p>Hope that helps!</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9642}"
342,44681810,"{'items': [{'owner': {'reputation': 3991, 'user_id': 5915270}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1498069831, 'answer_id': 44683665, 'question_id': 44681810, 'body': ""<p>Yes, it's the vanilla gradient descent. You can't say it is not SGD. Because it depends on your number of examples you consider when training a single epoch. </p>\n\n<p>Which means if you use only a mini-batch (ideally one single instance, but mini-batch is also fine) of data for a single epoch, We call it SGD. </p>\n\n<p>Yes functionally it should be equivalent to <code>numpy</code> implementation. </p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9642}"
343,51278422,"{'items': [{'owner': {'reputation': 5631, 'user_id': 6490351}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1531677306, 'answer_id': 51350771, 'question_id': 51278422, 'body': '<p>I\'ll give it a try:</p>\n\n<p>(1) From this example, looks like the first number is the ""self"" flops, the second number means the ""total"" flops under the naming scope. For example: for the 3 nodes respectively named random_uniform (if there is such a node), random_uniform/mul, random_uniform/sub, they respectively take 11.76k, 11.76k, and 1 flops, and in total 23.52k flops. </p>\n\n<p>For another example: 23.83k = 23.52k + 300.</p>\n\n<p>Does this make sense?</p>\n\n<p>(2) The root node is a ""virtual"" top-level node added by the profiler, which doesn\'t have a ""self"" flops , or in other words, it has zero self flops.</p>\n\n<p>(3) Not sure why it is 1. It would help if you can print the GraphDef and find out what this node really is, with print(sess.graph_def)</p>\n\n<p>Hope this helps.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9642}"
344,59531864,"{'items': [{'owner': {'reputation': 19216, 'user_id': 10133797}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1577795788, 'answer_id': 59544249, 'question_id': 59531864, 'body': '<p>Digging through the source code, I conclude that it\'s likely done for convenience and minimalism of implementation - details below. </p>\n\n<p>First, there is no ""reshaping"", only expanding, squeezing, and re-ordering dims, which bears a tiny overhead; no array elements are actually being moved in memory - only the tensor object\'s indexing specifiers are changed.</p>\n\n<p>Second, all <code>conv</code> ultimately route to <a href=""https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/ops/nn_ops.py#L942"" rel=""nofollow noreferrer""><code>tf.nn_ops.convolution_internal</code></a>, which then routes to either <code>gen_nn_ops.conv2d</code> or <code>gen_nn_ops.conv3d</code>; a <code>conv1d</code> does not exist in <code>gen_nn_ops.py</code>. Note that for some reason, you won\'t find that file in the Git respository - but it should be in your local install, <code>/python/ops/gen_nn_ops.py</code>.</p>\n\n<p>Lastly, to get a real answer on why there isn\'t a dedicated <code>conv1d</code> implementation, you\'ll need to ask the cuDNN developers behind the convolution algorithms found in <code>gen_nn_ops.py</code>; it\'s possible that they found no performance improvements, and that <code>conv2d</code> works just as fast. From a low-level standpoint, this makes sense, as the number of matrix multiplications in sliding a kernel with <code>N x 1</code> elements along an <code>M x 1</code> input is identical to that of <code>N</code> along <code>M</code> - again, the only difference is in indexing.</p>\n\n<p>Unfortunately devs decided to encapsulate the ultimate call, that is to <code>_pywrap_tensorflow_internal.TFE_Py_FastPathExecute</code>; the module consists of a <code>.lib</code> and a <code>.pyd</code> file - basically, compiled C (Cython) code that requires disassembly for introspection. </p>\n\n<hr>\n\n<p>TL;DR (1) the ""reshaping"" has a trivial overhead; (2) lack of a dedicated <code>conv1d</code> implementation is likely per sparing redundancy as <code>conv2d</code> is just as fast; (3) I\'m not a cuDNN expert, so if you need to be sure, better ask over at <a href=""https://developer.nvidia.com/cudnn"" rel=""nofollow noreferrer"">cuDNN</a>, or read their <a href=""https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html"" rel=""nofollow noreferrer"">SDK Documentation</a>. Alternatively, a dev at <a href=""https://github.com/tensorflow/tensorflow/issues"" rel=""nofollow noreferrer"">TF Github</a> may help. I haven\'t seen cuDNN devs answer on SO for years now, so posting here may not be the best bet.</p>\n\n<hr>\n\n<p><strong>Dim reordering performance demo</strong>:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import numpy as np\nfrom time import time\n\nx = np.random.randn(700, 800, 900) # 504,000,000 elements\n\nt0 = time()\nfor i in range(1000):\n    if i % 2 == 0:\n        x = x.reshape(700, 900, 800)\n    else:\n        x = x.reshape(700, 800, 900)\nprint(time() - t0)\n</code></pre>\n\n<pre><code>0.0009968280792236328\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9642}"
345,69458522,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9638}"
346,55951969,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9638}"
347,58317413,"{'items': [{'owner': {'reputation': 1, 'user_id': 10187580}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1570696740, 'answer_id': 58318751, 'question_id': 58317413, 'body': '<p>after seeing source code ,I understood that LSTM returns list that contains tesnors of output sequence , hidden state and cell states</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9638}"
348,57719398,"{'items': [{'owner': {'reputation': 2237, 'user_id': 4596078}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1637566473, 'answer_id': 70062312, 'question_id': 57719398, 'body': ""<p>You should change two things:</p>\n<ol>\n<li>Change the <code>decode</code> method to <code>call</code>, as you pointed out</li>\n<li>As your model is of type <code>Sequential</code>, and not built inside the class, you want to call the <code>save</code> method on the <code>self.network</code> attribute of the <code>model</code>, i.e.,</li>\n</ol>\n<pre><code>model.network.save('mymodel.h5')\n</code></pre>\n<p>alternatively, to keep things more standard, you can implement this method inside the <code>AE</code> class, as follows:</p>\n<pre><code>def save(self, save_dir):\n    self.network.save(save_dir)\n</code></pre>\n<p>Cheers mate</p>\n""}, {'owner': {'reputation': 408, 'user_id': 4515762}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1567180840, 'answer_id': 57729976, 'question_id': 57719398, 'body': '<p>I have tried the same minimal reproduction example in tensorflow-gpu 2.0.0-rc0 and the error was more revealing than what the beta version gave me. The error in RC says:</p>\n\n<blockquote>\n  <p>NotImplementedError: When subclassing the Model class, you should\n  implement a call method.</p>\n</blockquote>\n\n<p>This got me read through <a href=""https://www.tensorflow.org/beta/guide/keras/custom_layers_and_models"" rel=""nofollow noreferrer"">https://www.tensorflow.org/beta/guide/keras/custom_layers_and_models</a> where I found examples of how to do subclassing in TF2 in a way that allows saving. I was able to resolve the error and have the model saved by replacing my \'decode\' method by \'call\' in the above example (although this will be more complicated with my actual code where I had various methods defined for the class). This solved the error both in beta and in rc. Strangely, the training (or the saving) got also much faster in rc.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9638}"
349,75371111,"{'items': [{'owner': {'reputation': 41, 'user_id': 7811775}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1676423740, 'answer_id': 75454685, 'question_id': 75371111, 'body': ""<p>After some searching, I find the simplest solution is</p>\n<pre><code>features = tfds.features.FeaturesDict({\n    'image': tfds.features.Image(),  # &lt;&lt; Ideally best if add the `shape=(h, w, c)` info\n    'caption': tfds.features.Text(),\n    'height': tf.int32,\n    'width': tf.int32,\n})\n</code></pre>\n<p>Then I can load the data either with <code>tfds.folder_dataset.write_metadata</code> or directly with:</p>\n<pre><code>ds = tf.data.TFRecordDataset()\nds = ds.map(features.deserialize_example)\n</code></pre>\n<p><code>batch, shuffle ,...</code> will work as expected in both cases.</p>\n<p>The TFDS metadata would be helpful if fine-grained split control is needed.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9638}"
350,49494632,"{'items': [{'owner': {'reputation': 30867, 'user_id': 4790871}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1522079084, 'answer_id': 49495482, 'question_id': 49494632, 'body': '<p>Reshape the tensor before using tile, this example demonstrates:</p>\n\n<pre><code>import tensorflow as tf\nsess = tf.InteractiveSession()\n\ntensor = tf.constant([1, 2])\ntensor_reshaped = tf.reshape(tensor, (1,1,2))\ntf.tile(tensor_reshaped, [2, 2, 1]).eval()\n\nOut[22]: \narray([[[1, 2],\n        [1, 2]],\n       [[1, 2],\n        [1, 2]]], dtype=int32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9633}"
351,50383462,"{'items': [{'owner': {'reputation': 424, 'user_id': 7994236}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': True, 'score': 7, 'creation_date': 1526540584, 'answer_id': 50385301, 'question_id': 50383462, 'body': '<p>You should provide more information. For example, how do you initialize your variables in your graph? For initializing your weights in a neural network, you must initialize them randomly (biases are ok to be initialized all as zero). Thus you must use a code like the following for defining them with proper initialization:</p>\n\n<pre><code># initialize weights randomly from a Gaussian distribution\n# step 1: create the initializer for weights\nweight_initer = tf.truncated_normal_initializer(mean=0.0, stddev=0.01)\n# step 2: create the weight variable with proper initialization\nW = tf.get_variable(name=""Weight"", dtype=tf.float32, shape=[784, 200], initializer=weight_initer)\n\n# initialize biases as zero\n# step 1: create the initializer for biases\nbias_initer =tf.constant(0., shape=[200], dtype=tf.float32)\n# step 2: create the bias variable with proper initialization\nb = tf.get_variable(name=""Bias"", dtype=tf.float32, initializer=bias_initer)\n</code></pre>\n'}, {'owner': {'reputation': 339, 'user_id': 7391472}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1526535474, 'answer_id': 50384007, 'question_id': 50383462, 'body': '<p>I had same problem, it\'s like you are executing the line of code that is global_value_initializer() every time. What you need to do is this, for instance, if you\'re working on jupyter notebook then declare that part of session(declaring init) in one cell and rest of them in another cell(training part).</p>\n\n<p>Also, for when you want to continue training model after some pause you might wanna save the parameters and restore them. How to do that ,you can look <a href=""https://www.tensorflow.org/programmers_guide/saved_model"" rel=""nofollow noreferrer"">here</a>. If that doesn\'t solve your problem then show me that part of code you\'re dealing with. I might be able to help more.</p>\n\n<hr>\n\n<hr>\n\n<p><strong>PS:</strong> You can\'t restore your parameters when you change your optimizer, you gotta stick with one as far as I know. you can\'t do 100 iterations with one optimzer, and continue with another optimizer with those same parameters. Or maybe you can try some hack that might let you do that, let me know too.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9633}"
352,51690095,"{'items': [{'owner': {'reputation': 385600, 'user_id': 4909087}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1533423373, 'answer_id': 51690136, 'question_id': 51690095, 'body': '<p>Concatenate a range to <code>index</code>:</p>\n\n<pre><code>index = tf.stack([tf.range(index.shape[0])[:, None], index], axis=2)\nresult = tf.gather_nd(values, index)\n</code></pre>\n\n<p></p>\n\n<pre><code>result.eval(session=tf.Session())\narray([[0.8],\n       [0.6]], dtype=float32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9633}"
353,60516977,"{'items': [{'owner': {'reputation': 2069, 'user_id': 7555390}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1583288477, 'answer_id': 60518214, 'question_id': 60516977, 'body': '<ol>\n<li><blockquote>\n  <p>There is a lack of details on why second_order_and_transpose(ddy) returns two objects.</p>\n</blockquote></li>\n</ol>\n\n<p>Based on what I played with some examples, I believe you are correct. The official doc is somehow ambiguous (or incorrect). The <code>second_order_and_transpose(ddy)</code> should only return the one object, which is the calculated second-order gradient.</p>\n\n<ol start=""2"">\n<li><blockquote>\n  <p>It is also not even clear why did they name it unused_x.</p>\n</blockquote></li>\n</ol>\n\n<p>That is the tricky part. The <code>unused_x</code> explains why they name it (because you never going to use it...). The goal here is to wrap your second-order calculation function in a function called <code>first_order_custom</code>. You calculate the gradient of x from <code>fused_op</code>, and use that as a return value, instead of <code>unused_x</code>.</p>\n\n<p>To make this more clear, I passed an example extended from the official document to define a second-order gradient of the <code>log1pexp</code>:</p>\n\n<p><strong>NOTE:</strong> The second-order gradient is not numerically stable, so let\'s use (1 - tf.exp(x)) to represent it, just to make our life easier.</p>\n\n<pre class=""lang-py prettyprint-override""><code>@tf.custom_gradient\ndef log1pexp2(x):\n    e = tf.exp(x)\n    y = tf.math.log(1 + e)\n    x_grad = 1 - 1 / (1 + e)\n    def first_order_gradient(dy):\n        @tf.custom_gradient\n        def first_order_custom(unused_x):\n            def second_order_gradient(ddy):\n                # Let\'s define the second-order graidne to be (1 - e)\n                return ddy * (1 - e) \n            return x_grad, second_order_gradient\n        return dy * first_order_custom(x)\n    return y, first_order_gradient\n\n</code></pre>\n\n<p>To test the script, simply run:</p>\n\n<pre><code>import tensorflow as tf\n\n@tf.custom_gradient\ndef log1pexp2(x):\n    e = tf.exp(x)\n    y = tf.math.log(1 + e)\n    x_grad = 1 - 1 / (1 + e)\n    def first_order_gradient(dy):\n        @tf.custom_gradient\n        def first_order_custom(unused_x):\n            def second_order_gradient(ddy):\n                # Let\'s define the second-order graidne to be (1 - e)\n                return ddy * (1 - e) \n            return x_grad, second_order_gradient\n        return dy * first_order_custom(x)\n    return y, first_order_gradient\n\nx1 = tf.constant(1.)\ny1 = log1pexp2(x1)\ndy1 = tf.gradients(y1, x1)\nddy1 = tf.gradients(dy1, x1)\n\nx2 = tf.constant(100.)\ny2 = log1pexp2(x2)\ndy2 = tf.gradients(y2, x2)\nddy2 = tf.gradients(dy2, x2)\n\nwith tf.Session() as sess:\n    print(\'x=1, dy1:\', dy1[0].eval(session=sess))\n    print(\'x=1, ddy1:\', ddy1[0].eval(session=sess))\n    print(\'x=100, dy2:\', dy2[0].eval(session=sess))\n    print(\'x=100, ddy2:\', ddy2[0].eval(session=sess))\n\n</code></pre>\n\n<p>Result:</p>\n\n<pre><code>x=1, dy1: 0.7310586\nx=1, ddy1: -1.7182817\nx=100, dy2: 1.0\nx=100, ddy2: -inf\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9633}"
354,60678769,"{'items': [{'owner': {'reputation': 1824, 'user_id': 13071836}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1584421751, 'answer_id': 60716547, 'question_id': 60678769, 'body': '<p>You can use <strong>tf.contrib.estimator.stop_if_no_decrease_hook</strong> as indicated below:</p>\n\n<pre><code>estimator = tf.estimator.Estimator(model_fn, model_dir)\n\nos.makedirs(estimator.eval_dir())  # TODO This should not be expected IMO.\n\nearly_stopping = tf.contrib.estimator.stop_if_no_decrease_hook(\n    estimator,\n    metric_name=\'loss\',\n    max_steps_without_decrease=1000,\n    min_steps=100)\n\ntf.estimator.train_and_evaluate(\n    estimator,\n    train_spec=tf.estimator.TrainSpec(train_input_fn, hooks=[early_stopping]),\n    eval_spec=tf.estimator.EvalSpec(eval_input_fn))\n</code></pre>\n\n<p>But if it doesn\'t work for you it is better to use <strong>tf.estimator.experimental.stop_if_no_decrease_hook</strong> instead.</p>\n\n<p>For example:</p>\n\n<pre><code>estimator = ...\n# Hook to stop training if loss does not decrease in over 100000 steps.\nhook = early_stopping.stop_if_no_decrease_hook(estimator, ""loss"", 100000)\ntrain_spec = tf.estimator.TrainSpec(..., hooks=[hook])\ntf.estimator.train_and_evaluate(estimator, train_spec, ...)\n</code></pre>\n\n<p>The early-stopping hook uses the evaluation results to decide when it\'s time to cut the training, but you need to pass in the number of training steps you want to monitor and keep in mind how many evaluations will happen in that number of steps.\nIf you set the hook as <code>hook = early_stopping.stop_if_no_decrease_hook(estimator, ""loss"", 10000)</code> the hook will consider the evaluations happening in a range of 10k steps. </p>\n\n<p>Read more about the documentation here: <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/experimental/stop_if_no_decrease_hook"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/estimator/experimental/stop_if_no_decrease_hook</a> and for all the early stopping functions you can use, you may refer from this <a href=""https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/early_stopping.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/early_stopping.py</a> </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9629}"
355,46920307,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1508881618, 'answer_id': 46920585, 'question_id': 46920307, 'body': '<p>The <a href=""https://github.com/tensorflow/tensorflow/blob/15bd614fedc20d229f3e97a99e0748136ba4852c/tensorflow/python/layers/core.py#L361"" rel=""nofollow noreferrer"">implementation</a> of <a href=""https://www.tensorflow.org/versions/r1.4/api_docs/python/tf/layers/flatten"" rel=""nofollow noreferrer""><code>tf.layers.flatten()</code></a> reveals the answer. It is equivalent to the following:</p>\n\n<pre><code>flattened = tf.reshape(x, [tf.shape(x)[0], -1])\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9629}"
356,65596022,"{'items': [{'owner': {'reputation': 318, 'user_id': 8161411}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1610024444, 'answer_id': 65612862, 'question_id': 65596022, 'body': '<p>I managed to come up with a solution, here it is:</p>\n<pre><code>@tf.function\ndef unstackRaggedBBox(ragged):\n    #convert the ragged to a zero padded tensor\n    _tensor = ragged.to_tensor()\n    \n    ret = []\n    for i in range(_tensor.shape[0]):\n        #create a mask/remove the 0 values\n        mask = tf.cast(_tensor[i], dtype=tf.bool)              \n        row = tf.boolean_mask(_tensor[i], mask, axis=0)\n\n        #reshape the tensor to Nx4\n        size = tf.cast(tf.shape(row, out_type=tf.dtypes.int32) / 4, tf.int32)\n        row = tf.reshape(row, [size[0], 4])        \n        ret.append(row)\n        \n    return ret\n</code></pre>\n<p>I think the ragged_tensor slice operation caused the problem, lists are working fine in graphs.</p>\n'}, {'owner': {'reputation': 6124, 'user_id': 5561472}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1609938380, 'answer_id': 65596328, 'question_id': 65596022, 'body': '<p>I don\'t think it is possible to work with lists within tf.function: python side effects (like appending to lists) only happen the first time you call a Function with a set of inputs. Afterwards, the traced tf.Graph is reexecuted, without executing the Python code.</p>\n<p>See here: <a href=""https://www.tensorflow.org/guide/function#python_side_effects"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/function#python_side_effects</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9629}"
357,60213882,"{'items': [{'owner': {'reputation': 1233, 'user_id': 401884}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1581706555, 'answer_id': 60232075, 'question_id': 60213882, 'body': '<p>Interleave lets you process each file in a separate logical thread (in parallel), then combine the data from the files into a single dataset. Since your data comes from two corresponding files, you need to be careful to preserve the order. </p>\n\n<p>Here is an example of how you could put the interleave near the end of the dataset:</p>\n\n<pre><code>img_files = ...\nout_files = ...\nfiles = tf.data.Dataset.zip(img_files, out_files)\n\ndef parse_img_file(img_file):\n  imgd = tf.data.FixedLengthRecordDataset(img_files, inrez*inrez)\n  ...\n\ndef parse_out_file(out_file):\n  ...\n\ndef parse_files_fn(img_file, out_file):\n  img_file_dataset = parse_img_file(img_file)\n  out_file_dataset = parse_out_file(out_file)\n  return tf.data.Dataset.zip(img_file_dataset, out_file_dataset)\n\ndataset = files.interleave(parse_files_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\ndataset = dataset.repeat()\n</code></pre>\n\n<p>Each thread of the interleave will produce elements from a different pair of (img, out) files, and the elements produced from each pair of files will be interleaved together.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9629}"
358,66062973,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9629}"
359,62818943,"{'items': [{'owner': {'reputation': 618, 'user_id': 6165983}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1594376635, 'answer_id': 62832271, 'question_id': 62818943, 'body': ""<p>Generally, you are concerned with 'what scaling should I choose between [0, 1], [-1, 1] ?' As the answer may be different depending on the cases, I would like to point them out below.</p>\n<ol>\n<li><p>CNN architectures work better in short closed range input values. Therefore, both, [0, 1] and [-1, 1] may be a good choice. However, depending on the architecture, the selection can be different. As a result, it would be a good option to try various scales.</p>\n</li>\n<li><p>Concerning the pre-trained model of Keras, I noticed that most models that use residuals (such as, <code>ResNets</code>, <code>MobileNetV2</code>, <code>InceptionResNetV2</code>) use [-1, 1] scale. Using [-1, 1] scales in residuals, causes some edges to be deactivated in some cases. To further understand, let us consider a perceptron <code>y = wx + b</code>. If <code>w = 1</code> and <code>b = 1</code> then using input <code>x = 1</code> results <code>y = 0</code>. This states that using [-1, 1] scale, some input values can be nullified by the bias (without setting <code>w=0</code>). This concept is mostly true for the other models (excluding Keras) as well.</p>\n</li>\n<li><p>Almost all of the Keras architectures use scaling techniques. I believe in some cases, they did not perform the suggested operations instructed by the original papers. So, I believe you should stick with Keras' documentation in case of using their pre-trained model. If you do not find any scaling on their documentation, you should avoid scaling it.</p>\n</li>\n</ol>\n<p>Furthermore, you should try testing different scaling methods while you are using different datasets. However, this should not highly improve the accuracy of the model in most cases. Please let me know if you have more queries. Thanks.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9624}"
360,43604608,"{'items': [{'owner': {'reputation': 34138, 'user_id': 987185}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': True, 'score': 11, 'creation_date': 1493106750, 'answer_id': 43604747, 'question_id': 43604608, 'body': '<p><code>prob_placeholder</code> does not have any explicit dependence on <code>model.weights</code>, i.e. it is not functionally dependent on <code>model.weights</code> the way you have defined them.</p>\n\n<p>Hence, though technically the gradient should be zero, it is computed as <code>None</code> due to <a href=""https://github.com/tensorflow/tensorflow/issues/783"" rel=""noreferrer"">technical reasons in TensorFlow</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9623}"
361,63228543,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9623}"
362,54989442,"{'items': [{'owner': {'reputation': 86, 'user_id': 10923002}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': True, 'score': 7, 'creation_date': 1556718352, 'answer_id': 55937262, 'question_id': 54989442, 'body': '<p>No, but they are (or can be made to be) not so different either. </p>\n\n<h2>TL;DR</h2>\n\n<p><code>tf.nn.dynamic_rnn</code> replaces elements after the sequence end with 0s. This cannot be replicated with <code>tf.keras.layers.*</code> as far as I know, but you can get a similar behaviour with <code>RNN(Masking(...)</code> approach: it simply stops the computation and carries the last outputs and states forward. You will get the same (non-padding) outputs as those obtained from <code>tf.nn.dynamic_rnn</code>.</p>\n\n<h2>Experiment</h2>\n\n<p>Here is a minimal working example demonstrating the differences between <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""noreferrer""><code>tf.nn.dynamic_rnn</code></a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU"" rel=""noreferrer""><code>tf.keras.layers.GRU</code></a> with and without the use of <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking"" rel=""noreferrer""><code>tf.keras.layers.Masking</code></a> layer.</p>\n\n<pre class=""lang-py prettyprint-override""><code>import numpy as np\nimport tensorflow as tf\n\ntest_input = np.array([\n    [1, 2, 1, 0, 0],\n    [0, 1, 2, 1, 0]\n], dtype=int)\nseq_length = tf.constant(np.array([3, 4], dtype=int))\n\nemb_weights = (np.ones(shape=(3, 2)) * np.transpose([[0.37, 1, 2]])).astype(np.float32)\nemb = tf.keras.layers.Embedding(\n    *emb_weights.shape,\n    weights=[emb_weights],\n    trainable=False\n)\nmask = tf.keras.layers.Masking(mask_value=0.37)\nrnn = tf.keras.layers.GRU(\n    1,\n    return_sequences=True,\n    activation=None,\n    recurrent_activation=None,\n    kernel_initializer=\'ones\',\n    recurrent_initializer=\'zeros\',\n    use_bias=True,\n    bias_initializer=\'ones\'\n)\n\n\ndef old_rnn(inputs):\n    rnn_outputs, rnn_states = tf.nn.dynamic_rnn(\n        rnn.cell,\n        inputs,\n        dtype=tf.float32,\n        sequence_length=seq_length\n    )\n    return rnn_outputs\n\n\nx = tf.keras.layers.Input(shape=test_input.shape[1:])\nm0 = tf.keras.Model(inputs=x, outputs=emb(x))\nm1 = tf.keras.Model(inputs=x, outputs=rnn(emb(x)))\nm2 = tf.keras.Model(inputs=x, outputs=rnn(mask(emb(x))))\n\nprint(m0.predict(test_input).squeeze())\nprint(m1.predict(test_input).squeeze())\nprint(m2.predict(test_input).squeeze())\n\nsess = tf.keras.backend.get_session()\nprint(sess.run(old_rnn(mask(emb(x))), feed_dict={x: test_input}).squeeze())\n</code></pre>\n\n<p>The outputs from <code>m0</code> are there to show the result of applying the embedding layer.\nNote that there are no zero entries at all:</p>\n\n<pre><code>[[[1.   1.  ]    [[0.37 0.37]\n  [2.   2.  ]     [1.   1.  ]\n  [1.   1.  ]     [2.   2.  ]\n  [0.37 0.37]     [1.   1.  ]\n  [0.37 0.37]]    [0.37 0.37]]]\n</code></pre>\n\n<p>Now here are the actual outputs from the <code>m1</code>, <code>m2</code> and <code>old_rnn</code> architectures:</p>\n\n<pre><code>m1: [[  -6.  -50. -156. -272.7276 -475.83362]\n     [  -1.2876 -9.862801 -69.314 -213.94202 -373.54672 ]]\nm2: [[  -6.  -50. -156. -156. -156.]\n     [   0.   -6.  -50. -156. -156.]]\nold [[  -6.  -50. -156.    0.    0.]\n     [   0.   -6.  -50. -156.    0.]]\n</code></pre>\n\n<h2>Summary</h2>\n\n<ul>\n<li>The old <code>tf.nn.dynamic_rnn</code> used to mask padding elements with zeros.</li>\n<li>The new RNN layers <em>without masking</em> run over the padding elements as if they were data.</li>\n<li>The new <code>rnn(mask(...))</code> approach simply stops the computation and carries the last outputs and states forward. Note that the (non-padding) outputs that I obtained for this approach are exactly the same as those from <code>tf.nn.dynamic_rnn</code>.</li>\n</ul>\n\n<p>Anyway, I cannot cover all possible edge cases, but I hope that you can use this script to figure things out further.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9623}"
363,59609732,"{'items': [{'owner': {'reputation': 18097, 'user_id': 5069957}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1578308119, 'answer_id': 59610818, 'question_id': 59609732, 'body': '<p>There is <code>tf.image.resizeBilinear</code> (respectively <code>tf.image.resizeNearestNeighbor</code>) which will performs a resize using the bilinear sampling (respectively the nearest neighbor sampling)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9623}"
364,51806852,"{'items': [{'owner': {'reputation': 11, 'user_id': 16546429}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1627483045, 'answer_id': 68562408, 'question_id': 51806852, 'body': '<p>I found a way to solve it. Create a new model and load the weights from the saved .h5 model. This way is not preferred, but it works with keras 2.2.4 and tensorflow 1.12.</p>\n<pre><code>class MyModel(keras.Model):  \n     def __init__(self, inputs, *args, **kwargs):\n          outputs = func(inputs)\n     super(MyModel, self).__init__( inputs=inputs, outputs=outputs, *args, **kwargs)\n\ndef get_model():  \n    return MyModel(inputs, *args, **kwargs)\n\nmodel = get_model()\nmodel.save(file_path.h5)\n\nmodel_new = get_model()  \nmodel_new.compile(optimizer=optimizer, loss=loss, metrics=metrics) \nmodel_new.load_weights(file_path.h5)  \nmodel_new.evaluate(x_test, y_test, **kwargs)\n</code></pre>\n'}, {'owner': {'reputation': 19, 'user_id': 5451157}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': False, 'score': 0, 'creation_date': 1625083914, 'answer_id': 68201086, 'question_id': 51806852, 'body': '<p><strong>UPDATE: Jul 20</strong></p>\n<p>Recently I also tried to create my subclassed layers and model. Write your own <code>get_config()</code> function might be difficult. So I used <code>model.save_weights(path_to_model_weights)</code> and <code>model.load_weights(path_to_model_weights)</code>. When you want to load the weights, remember to create the model with the same architecture than do <code>model.load_weights()</code>. See the tensorflow <a href=""https://www.tensorflow.org/tutorials/keras/save_and_load#manually_save_weights"" rel=""nofollow noreferrer"">guide</a> for more details.</p>\n<p><strong>Old Answer (Still correct)</strong>\nActually, tensorflow document said:</p>\n<blockquote>\n<p>In order to save/load a model with custom-defined layers, or a subclassed model, you should overwrite the get_config and optionally from_config methods. Additionally, you should use register the custom object so that Keras is aware of it.</p>\n</blockquote>\n<p>For example:</p>\n<pre class=""lang-py prettyprint-override""><code>class Linear(keras.layers.Layer):\n    def __init__(self, units=32, **kwargs):\n        super(Linear, self).__init__(**kwargs)\n        self.units = units\n\n    def build(self, input_shape):\n        self.w = self.add_weight(\n            shape=(input_shape[-1], self.units),\n            initializer=&quot;random_normal&quot;,\n            trainable=True,\n        )\n        self.b = self.add_weight(\n            shape=(self.units,), initializer=&quot;random_normal&quot;, trainable=True\n        )\n\n    def call(self, inputs):\n        return tf.matmul(inputs, self.w) + self.b\n\n    def get_config(self):\n        config = super(Linear, self).get_config()\n        config.update({&quot;units&quot;: self.units})\n        return config\n\n\nlayer = Linear(64)\nconfig = layer.get_config()\nprint(config)\nnew_layer = Linear.from_config(config)\n</code></pre>\n<p>The output is:</p>\n<pre><code>{\'name\': \'linear_8\', \'trainable\': True, \'dtype\': \'float32\', \'units\': 64}\n</code></pre>\n<p>You can play with this simple code. For example, in function &quot;get_config()&quot;, remove config.update(), see what\'s going on. See <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models#you_can_optionally_enable_serialization_on_your_layers"" rel=""nofollow noreferrer"">this</a> and <a href=""https://www.tensorflow.org/guide/keras/save_and_serialize/#custom_objects"" rel=""nofollow noreferrer"">this</a> for more details. These are the Keras guide on tensorflow website.</p>\n'}, {'owner': {'reputation': 1546, 'user_id': 11053801}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1595241907, 'answer_id': 62993695, 'question_id': 51806852, 'body': ""<p>Actually recreating the model with</p>\n<pre><code>keras.models.load_model('path_to_my_model')\n</code></pre>\n<p>didn't work for me</p>\n<p>First we have to save_weights from the built model</p>\n<pre><code>model.save_weights('model_weights', save_format='tf')\n</code></pre>\n<p>Then\nwe have to initiate a new instance for the subclass Model then compile and train_on_batch with one record and load_weights of built model</p>\n<pre><code>loaded_model = ThreeLayerMLP(name='3_layer_mlp')\nloaded_model.compile(optimizer=&quot;adam&quot;, loss=&quot;binary_crossentropy&quot;, metrics=[&quot;accuracy&quot;])\nloaded_model.train_on_batch(x_train[:1], y_train[:1])\nloaded_model.load_weights('model_weights')\n</code></pre>\n<p>This work perfectly in TensorFlow==2.2.0</p>\n""}, {'owner': {'reputation': 2936, 'user_id': 1123955}, 'down_vote_count': 0, 'up_vote_count': 66, 'is_accepted': True, 'score': 66, 'creation_date': 1553720339, 'answer_id': 55386355, 'question_id': 51806852, 'body': '<h3>TensorFlow 2.2</h3>\n\n<p>Thanks for @cal for noticing me that the new TensorFlow has supported saving the custom models!</p>\n\n<blockquote>\n  <p>By using model.save to save the whole model and by using load_model to restore previously stored subclassed model. The following code snippets describe how to implement them.</p>\n</blockquote>\n\n<pre><code>class ThreeLayerMLP(keras.Model):\n\n  def __init__(self, name=None):\n    super(ThreeLayerMLP, self).__init__(name=name)\n    self.dense_1 = layers.Dense(64, activation=\'relu\', name=\'dense_1\')\n    self.dense_2 = layers.Dense(64, activation=\'relu\', name=\'dense_2\')\n    self.pred_layer = layers.Dense(10, name=\'predictions\')\n\n  def call(self, inputs):\n    x = self.dense_1(inputs)\n    x = self.dense_2(x)\n    return self.pred_layer(x)\n\ndef get_model():\n  return ThreeLayerMLP(name=\'3_layer_mlp\')\n\nmodel = get_model()\n# Save the model\nmodel.save(\'path_to_my_model\',save_format=\'tf\')\n\n# Recreate the exact same model purely from the file\nnew_model = keras.models.load_model(\'path_to_my_model\')\n</code></pre>\n\n<p>See: <a href=""https://www.tensorflow.org/guide/keras/save_and_serialize#part_ii_saving_and_loading_of_subclassed_models"" rel=""noreferrer"">Save and serialize models with Keras - Part II: Saving and Loading of Subclassed Models</a></p>\n\n<h3>TensorFlow 2.0</h3>\n\n<p>TL;DR:</p>\n\n<ol>\n<li>do not use <code>model.save()</code> for custom subclass keras model;</li>\n<li>use <code>save_weights()</code> and <code>load_weights()</code> instead.</li>\n</ol>\n\n<hr>\n\n<p>With the help of the Tensorflow Team, it turns out the best practice of saving a Custom Sub-Class Keras Model is to save its weights and load it back when needed.</p>\n\n<p>The reason that we can not simply save a Keras custom subclass model is that it contains custom codes, which can not be serialized safely. However, the weights can be saved/loaded when we have the same model structure and custom codes without any problem.</p>\n\n<p>There has a great tutorial written by Francois Chollet who is the author of Keras, for how to save/load Sequential/Functional/Keras/Custom Sub-Class Models in Tensorflow 2.0 in Colab at <a href=""https://colab.research.google.com/drive/172D4jishSgE3N7AO6U2OKAA_0wNnrMOq#scrollTo=mJqOn0snzCRy"" rel=""noreferrer"">here</a>. In <strong>Saving Subclassed Models</strong> section, it said that:</p>\n\n<blockquote>\n  <p>Sequential models and Functional models are datastructures that represent a DAG of layers. As such, they can be safely serialized and deserialized.</p>\n  \n  <p>A subclassed model differs in that it\'s not a datastructure, it\'s a\n  piece of code. The architecture of the model is defined via the body\n  of the call method. This means that the architecture of the model\n  cannot be safely serialized. To load a model, you\'ll need to have\n  access to the code that created it (the code of the model subclass).\n  Alternatively, you could be serializing this code as bytecode (e.g.\n  via pickling), but that\'s unsafe and generally not portable.</p>\n</blockquote>\n'}, {'owner': {'reputation': 504, 'user_id': 11731187}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1582481182, 'answer_id': 60365253, 'question_id': 51806852, 'body': '<p><strong>Tensorflow 2.1 allows to save subclassed models with SavedModel format</strong></p>\n\n<p>From my beginning using Tensorflow, i was always a fan of Model Subclass, i feel this way of build models more pythonic and collaborative friendly. But saving the model was always a point of pain with this approach.</p>\n\n<p>Recently i started to update my knowledge and reach to the following <a href=""https://www.tensorflow.org/guide/keras/functional#extending_the_api_by_writing_custom_layers"" rel=""nofollow noreferrer"">information</a> that seems to be True for <strong>Tensorflow 2.1</strong>:</p>\n\n<h2>Subclassed Models</h2>\n\n<p>I found <a href=""https://www.tensorflow.org/guide/keras/save_and_serialize#approach_2"" rel=""nofollow noreferrer"">this</a></p>\n\n<blockquote>\n  <p>Second approach is by using model.save to save whole model and by\n  using load_model to restore previously stored subclassed model.</p>\n</blockquote>\n\n<p>This last saves the model, the weight and other stuff into a SavedModel file</p>\n\n<p>And by last the <a href=""https://www.tensorflow.org/tutorials/keras/save_and_load"" rel=""nofollow noreferrer"">confirmation</a>:</p>\n\n<blockquote>\n  <p><strong>Saving custom objects</strong>: \n  If you are using the SavedModel format, you can\n  skip this section. The key difference between HDF5 and SavedModel is\n  that HDF5 uses object configs to save the model architecture, while\n  SavedModel saves the execution graph. Thus, <strong>SavedModels are able to</strong>\n  <strong>save custom objects like subclassed models and custom layers without</strong>\n  <strong>requiring the orginal code.</strong></p>\n</blockquote>\n\n<p>I tested this personally, and efectively, model.save() for subclassed models generate a SavedModel save. There is no more need for use model.save_weights() or related functions, they now are more for specific usecases.</p>\n\n<p>This is suposed to be the end of this painful path for all of us interested in Model Subclassing.</p>\n'}, {'owner': {'reputation': 1, 'user_id': 9618869}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1579279669, 'answer_id': 59791630, 'question_id': 51806852, 'body': '<p>use <code>model.predict</code> before <code>tf.saved_model.save</code></p>\n'}, {'owner': {'reputation': 69, 'user_id': 11022750}, 'down_vote_count': 1, 'up_vote_count': 6, 'is_accepted': False, 'score': 5, 'creation_date': 1549454737, 'answer_id': 54553269, 'question_id': 51806852, 'body': '<p>This will be fixed in an upcoming release according to the <a href=""https://github.com/tensorflow/tensorflow/blob/r1.13/RELEASE.md"" rel=""nofollow noreferrer"">1.13 pre-release patch notes</a>:</p>\n\n<blockquote>\n  <ul>\n  <li>Keras &amp; Python API:\n  \n  <ul>\n  <li>Subclassed Keras models can now be saved through <code>tf.contrib.saved_model.save_keras_model</code>.</li>\n  </ul></li>\n  </ul>\n</blockquote>\n\n<p>EDIT:\nIt seems this is not quite as finished as the notes suggest. The <a href=""https://www.tensorflow.org/versions/r1.13/api_docs/python/tf/contrib/saved_model/save_keras_model"" rel=""nofollow noreferrer"">docs for that function for v1.13</a> state:</p>\n\n<blockquote>\n  <p>Model limitations: - Sequential and functional models can always be saved. - Subclassed models can only be saved when serving_only=True. This is due to the current implementation copying the model in order to export the training and evaluation graphs. Because the topology of subclassed models cannot be determined, the subclassed models cannot be cloned. Subclassed models will be entirely exportable in the future.</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9619}"
365,42334855,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9619}"
366,63894153,"{'items': [{'owner': {'reputation': 11, 'user_id': 6767670}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1619398171, 'answer_id': 67259606, 'question_id': 63894153, 'body': '<p>What worked for me was creating a custom layer, and doing the map_fn there.</p>\n<pre><code>class custom_layer(tf.keras.layers.Layer):\n    def __init__(self):\n        super(custom_layer, self).__init__()\n\n    def call(self, inputs):\n        return tf.map_fn(single_conv, inputs, fn_output_signature=tf.float32)\n</code></pre>\n<p>In your case,</p>\n<pre><code>conditional_conv = custom_layer()((tf.expand_dims(input_img, 1), kernels))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9619}"
367,42695305,"{'items': [{'owner': {'reputation': 760, 'user_id': 16401339}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1627122899, 'answer_id': 68509159, 'question_id': 42695305, 'body': '<p>The <code>tf.slice</code> function (<a href=""https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/slice"" rel=""nofollow noreferrer"">see TF1.15 doc</a>) takes as third parameter the <code>size</code> of the slice, so the line <code>slice = tf.slice(distances_, [bmu, 0], [bmu, -1])</code> has to be replaced with</p>\n<pre><code>slice = tf.slice(distances_, [bmu, 0], [1, -1])\n</code></pre>\n<p>The error appears only when <code>bmu</code> is higher then half of the number of rows in <code>distances_</code>, because in this case a slice of the given size cannot be extracted. Otherwise the computation does not fail but it is incorrect because you don\'t extract a single row.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9619}"
368,75639435,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9619}"
369,48065164,"{'items': [{'owner': {'reputation': 63, 'user_id': 5532550}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1514917497, 'answer_id': 48065937, 'question_id': 48065164, 'body': '<p>The implementation of my_binary_crossentropy_np is wrong.\nHere is the right one:</p>\n\n<pre><code>l = (weight - 1.0) * labels + 1.0\n  loss1 = np.multiply(1.0 - labels, output)\n  loss2 = np.multiply(l, np.log(1.0 + np.exp(-abs(output))) + np.maximum(-output, 0))\n  loss = loss1 + loss2\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9614}"
370,61946509,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9614}"
371,61059725,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1586209429, 'answer_id': 61069438, 'question_id': 61059725, 'body': '<p>If you look at the source <a href=""https://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/framework/constant_op.py#L68"" rel=""nofollow noreferrer"">here</a>, you will see that <code>EagerTensor</code> gets a special treatment. Basically, if the <code>dtype</code> of an <code>EagerTensor</code> doesn\'t match the new <code>dtype</code>, an error is raised.</p>\n\n<p>Here, <code>tf.range()</code> produces an <code>EagerTensor</code>. I\'m not sure why the special treatment for <code>EagerTensors</code> though. Could be a performance related restriction.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9614}"
372,75354761,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9614}"
373,42560143,"{'items': [{'owner': {'reputation': 1303, 'user_id': 3844056}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1488476858, 'answer_id': 42562391, 'question_id': 42560143, 'body': '<p>Google <a href=""https://www.tensorflow.org/install/migration"" rel=""nofollow noreferrer"">just released TensorFlow 1.0 last week</a>, where the API has been updated, so things have been moved around. Because of the various contributions from the TF community, the contrib directory is reserved for this code, which has not yet been finalized for acceptance into core TF. </p>\n\n<p>Check out the <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/README.md"" rel=""nofollow noreferrer"">README</a> on contrib:</p>\n\n<blockquote>\n  <p>The contrib directory contains project directories, each of which has\n  designated owners. It is meant to contain features and contributions\n  that eventually should get merged into core TensorFlow, but whose\n  interfaces may still change, or which require some testing to see\n  whether they can find broader acceptance. We are trying to keep\n  duplication within contrib to a minimum, so you may be asked to\n  refactor code in contrib to use some feature inside core or in another\n  project in contrib rather than reimplementing the feature.</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9614}"
374,66546321,"{'items': [{'owner': {'reputation': 806, 'user_id': 774331}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1615303136, 'answer_id': 66549674, 'question_id': 66546321, 'body': ""<p>I'm not sure if this is actually a good idea, but you could use tf.squeeze like</p>\n<pre><code>inp = keras.Input(shape=(), dtype=tf.int32)\nbatch_indices = tf.range(tf.squeeze(inp))\nmodel = keras.Model(inputs=inp, outputs=batch_indices)\n</code></pre>\n<p>so that</p>\n<pre><code>model(6)\n</code></pre>\n<p>gives</p>\n<pre><code>&lt;tf.Tensor: shape=(6,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5])&gt;\n</code></pre>\n<p>Edit:\nDepending on what you want to achieve, it might also be worth looking into ragged tensors:</p>\n<pre><code>inp = keras.Input(shape=(), dtype=tf.int32)\nbatch_indices = tf.ragged.range(inp)\nmodel = keras.Model(inputs=inp, outputs=batch_indices)\n</code></pre>\n<p>would make</p>\n<pre><code>model(np.array([6,7]))\n</code></pre>\n<p>return</p>\n<pre><code>&lt;tf.RaggedTensor [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5, 6]]&gt;\n</code></pre>\n""}, {'owner': {'reputation': 17165, 'user_id': 3222797}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1615301728, 'answer_id': 66549261, 'question_id': 66546321, 'body': '<p>Don\'t use <code>tf.keras.Input</code> and just define the model by subclassing.</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\n\nclass ScalarModel(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n\n    def call(self, x):\n        return tf.range(0, x, 1)\n\n\nprint(ScalarModel()(10))\n# tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9609}"
375,34589335,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': True, 'score': 7, 'creation_date': 1451922615, 'answer_id': 34594851, 'question_id': 34589335, 'body': '<p>The <a href=""https://www.tensorflow.org/versions/master/api_docs/python/io_ops.html#shuffle_batch""><code>tf.train.shuffle_batch()</code></a> function can be used to produce (one or more) tensors containing a batch of inputs. Internally, <code>tf.train.shuffle_batch()</code> creates a <a href=""https://www.tensorflow.org/versions/master/api_docs/python/io_ops.html#RandomShuffleQueue""><code>tf.RandomShuffleQueue</code></a>, on which it calls <a href=""https://www.tensorflow.org/versions/master/api_docs/python/io_ops.html#QueueBase.enqueue""><code>q.enqueue()</code></a> with the image and label tensors to enqueue a single element (image-label pair). It then returns the result of <a href=""https://www.tensorflow.org/versions/master/api_docs/python/io_ops.html#QueueBase.dequeue_many""><code>q.dequeue_many(batch_size)</code></a>, which concatenates <code>batch_size</code> randomly selected elements (image-label pairs) into a batch of images and a batch of labels.</p>\n\n<p>Note that, although it looks from the code like <code>read_input</code> and <code>filename_queue</code> have a functional relationship, there is an additional wrinkle. Simply evaluating the result of <code>tf.train.shuffle_batch()</code> will block forever, because no elements have been added to the internal queue. To simplify this, when you call <code>tf.train.shuffle_batch()</code>, TensorFlow will add a <a href=""https://www.tensorflow.org/versions/master/api_docs/python/train.html#QueueRunner""><code>QueueRunner</code></a> to an internal collection in the graph. A later call to <a href=""https://www.tensorflow.org/versions/master/api_docs/python/train.html#start_queue_runners""><code>tf.train.start_queue_runners()</code></a> (e.g. <a href=""https://github.com/tensorflow/tensorflow/blob/2d5f0ac61fe4e4160fbb68d8031418528111dae9/tensorflow/models/image/cifar10/cifar10_train.py#L97"">here in <code>cifar10_train.py</code></a>) will start a thread that adds elements to the queue, and enables training to proceed. The <a href=""https://www.tensorflow.org/versions/master/how_tos/threading_and_queues/index.html"">Threading and Queues HOWTO</a> has more information on how this works.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9609}"
376,60453533,"{'items': [{'owner': {'reputation': 941, 'user_id': 9881203}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1582971362, 'answer_id': 60464013, 'question_id': 60453533, 'body': '<p>I think the same API is <code>nccl_ops.all_sum</code>. I have demoed this API by the following code. </p>\n\n<pre><code>import tensorflow as tf \nfrom tensorflow.python.ops import nccl_ops\n\na = []\n\nwith tf.device(""/GPU:0""):\n    g = tf.constant([1,1])\n    print(g)\n    a.append(g)\nwith tf.device(""/GPU:1""):\n    g = tf.constant([2,2])\n    a.append(g)\n\nb = nccl_ops.all_sum(a)\nwith tf.Session() as sess:\n    print(sess.run(b))\n</code></pre>\n\n<p>I am not sure what tensorflow team will do in the future. But now we can use it to do the collective operations.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9609}"
377,66019998,"{'items': [{'owner': {'reputation': 733, 'user_id': 2202359}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1612327313, 'answer_id': 66021376, 'question_id': 66019998, 'body': '<p>You can iterate over small portions of the dataset with the <code>tf.data.Dataset.take()</code> method.</p>\n<pre><code>sub_dataset = dataset.take(10)\nfor element in sub_dataset:\n    # work with the image\n</code></pre>\n<p>Here is the [documentation].(<a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take</a>)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9609}"
378,50457247,"{'items': [{'owner': {'reputation': 1, 'user_id': 3938049}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1527200769, 'answer_id': 50519032, 'question_id': 50457247, 'body': ""<p>Turns out I could do:</p>\n\n<pre><code>variables = []\nfor i, v in enumerate(tf.global_variables()):\n    name = v.name.split(':')[0].encode('ASCII')\n    if name in sess.run(tf.report_uninitialized_variables()[0]):\n        if b'train_step' in name:\n            variables.append(v)\n\ntrain_step_init = tf.variables_initializer(variables)\nsess.run(train_step_init)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9609}"
379,49564318,"{'items': [{'owner': {'reputation': 8945, 'user_id': 1586200}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1522359240, 'answer_id': 49565377, 'question_id': 49564318, 'body': '<p>Here are answers to your questions.</p>\n\n<ol>\n<li><p>You cannot give epochs directly to <code>slim.learning.train</code>. Instead, you give the number of batches as the argument. It is called <code>number_of_steps</code>. It is used to set an operation called <code>should_stop_op</code> on <a href=""https://github.com/tensorflow/tensorflow/blob/7a0def60d45c1841a4e79a0ddf6aa9d50bf551ac/tensorflow/contrib/slim/python/slim/learning.py#L709"" rel=""nofollow noreferrer"">line 709</a>. I assume you know how to convert number of epochs to batches.</p></li>\n<li><p>I don\'t think the <code>shuffle_batch</code> function will repeat images because internally it uses the <a href=""https://www.tensorflow.org/api_docs/python/tf/RandomShuffleQueue"" rel=""nofollow noreferrer"">RandomShuffleQueue</a>. According to <a href=""https://stackoverflow.com/a/43190902/1586200"">this answer</a>, the <code>RandomShuffleQueue</code> enqueues elements using a background thread as:</p>\n\n<ul>\n<li>While <code>size(queue) &lt; capacity</code>:\n\n<ul>\n<li>Add an element to the queue</li>\n</ul></li>\n</ul></li>\n</ol>\n\n<p>It dequeues elements as:</p>\n\n<ul>\n<li>While the <code>number of elements dequeued &lt; batch_size</code>:\n\n<ul>\n<li>Wait until the <code>size(queue) &gt;= min_after_dequeue + 1</code> elements.</li>\n<li>Select an element from the queue uniformly at random, remove it from the queue, and add it the output batch.</li>\n</ul></li>\n</ul>\n\n<p>So in my opinion, there is very little chance that the elements would be repeated, because in the <code>dequeuing</code> operation, the chosen element is removed from the queue. So it is sampling without replacement.</p>\n\n<p><strong>Will a new queue be created for every epoch?</strong></p>\n\n<p>The tensors being inputted to <code>tf.train.shuffle_batch</code> are <code>image</code> and <code>label</code> which ultimately come from the <code>filename_queue</code>. If that queue is producing TFRecord filenames indefinitely, then I don\'t think a new queue will be created by <code>shuffle_batch</code>. You can also create a toy code like <a href=""https://stackoverflow.com/a/45207025/1586200"">this</a> to understand how <code>shuffle_batch</code> works.</p>\n\n<p>Coming to the next point, how to train over the whole dataset? In your code, the following line gets the list of TFRecord filenames.</p>\n\n<pre><code>filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n</code></pre>\n\n<p>If <code>filename_queue</code> covers all TFRecords that you have, then you are surely training over the entire dataset. Now, how to shuffle the entire dataset is another question. As mentioned <a href=""https://github.com/tensorflow/tensorflow/issues/14857"" rel=""nofollow noreferrer"">here</a> by @mrry, there is no support (yet, AFAIK) to shuffle out-of-memory datasets. So the best way is to prepare many shards of your dataset such that each shard contains about 1024 examples. Shuffle the list of TFRecord filenames as:</p>\n\n<pre><code>filename_queue = tf.train.string_input_producer([data_path], shuffle=True, capacity=1000)\n</code></pre>\n\n<p>Note that I removed the <code>num_epochs = 1</code> argument and set <code>shuffle=True</code>. This way it will produce the <em>shuffled</em> list of TFRecord filenames indefinitely. Now on each file, if you use <code>tf.train.shuffle_batch</code>, you will get a near-to-uniform shuffling. Basically, as the number of examples in each shard tend to 1, your shuffling will get more and more uniform. I like to not set <code>num_epochs</code> and instead terminate the training using the <code>number_of_steps</code> argument mentioned earlier.</p>\n\n<ol start=""3"">\n<li>To print the loss values, you could probably just edit the <a href=""https://github.com/tensorflow/tensorflow/blob/024aecf414941e11eb643e29ceed3e1c47a115ad/tensorflow/contrib/slim/python/slim/learning.py#L768"" rel=""nofollow noreferrer""><code>training.py</code></a> and introduce <code>logging.info(\'total loss = %f\', total_loss)</code>. I don\'t know if there is any simpler way. Another way without changing the code is to view summaries in Tensorboard.</li>\n</ol>\n\n<p>There are very helpful articles on how to view summaries in Tensorboard, including the link at the end of this answer. Generally, you need to do the following things.</p>\n\n<ol>\n<li>Create <code>summary</code> object.</li>\n<li>Write variables of interest into <code>summary</code>.</li>\n<li>Merge all individual summaries.</li>\n<li>Create a <code>summary</code> op.</li>\n<li>Create a summary file writer.</li>\n<li>Write the summaries throughout the training at a desired frequency.</li>\n</ol>\n\n<p>Now steps 5 and 6 are already done automatically for you if you use <code>slim.learning.train</code>.</p>\n\n<p>For first 4 steps, you could check the file <a href=""https://github.com/tensorflow/models/blob/46377f8842e512805a3b9cbbfab026e39a82d346/research/slim/train_image_classifier.py#L472"" rel=""nofollow noreferrer""><code>train_image_classifier.py</code></a>. Line 472 shows you how to create a <code>summaries</code> object. Lines 490, 512 and 536 write the relevant variables into <code>summaries</code>. Line 549 merges all summaries and the line 553 creates an op. You can pass this op to <code>slim.learning.train</code> and you can also specify how frequently you want to write summaries. In my opinion, do not write anything apart from loss, total_loss, accuracy and learning rate into the summaries, unless you want to do specific debugging. If you write histograms, then the tensorboard file could take tens of hours to load for networks like ResNet-50 (my tensorboard file once was 28 GB, which took 12 hours to load the progress of 6 days!). By the way, you could actually use <code>train_image_classifier.py</code> file to finetune and you will skip most of the steps above. However, I prefer this as you get to learn a lot of things.</p>\n\n<p>See the <a href=""https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard"" rel=""nofollow noreferrer"">launching tensorboard</a> section on how to view the progress in a browser.</p>\n\n<p><strong>Additional remarks:</strong></p>\n\n<ul>\n<li><p>Instead of minimizing <code>total_loss + loss</code>, you could do the following:</p>\n\n<pre><code>loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits = logits)\ntf.losses.add_loss(loss)\ntotal_loss = tf.losses.get_total_loss()\ntrain_op = slim.learning.create_train_op(total_loss, optimizer=tf.train.AdamOptimizer(learning_rate=1e-4))\n</code></pre></li>\n<li><p>I found <a href=""https://kwotsin.github.io/tech/2017/02/11/transfer-learning.html"" rel=""nofollow noreferrer"">this</a> post to be very useful when I was learning Tensorflow.</p></li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9604}"
380,60215970,"{'items': [{'owner': {'reputation': 49, 'user_id': 5623016}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1581671075, 'answer_id': 60223091, 'question_id': 60215970, 'body': '<p>Solved. I just needed to read the dataset as <code>(left image, [left image, right image])</code> instead of <code>(left image, (left image, right image))</code> i.e. make the second item a list and not a tuple. I can then access the images as <code>input_r = y_true[:, 1, :, :]</code> and <code>input_l = y_true[:, 0, :, :]</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9603}"
381,34642595,"{'items': [{'owner': {'reputation': 6215, 'user_id': 5543198}, 'down_vote_count': 0, 'up_vote_count': 18, 'is_accepted': False, 'score': 18, 'creation_date': 1452115222, 'answer_id': 34642991, 'question_id': 34642595, 'body': '<p>The inputs are 4 dimensional and are of form: <code>[batch_size, image_rows, image_cols, number_of_colors]</code></p>\n\n<p>Strides, in general, define an overlap between applying operations. In the case of conv2d, it specifies what is the distance between consecutive applications of convolutional filters. The value of 1 in a specific dimension means that we apply the operator at every row/col, the value of 2 means every second, and so on.</p>\n\n<p><strong>Re 1)</strong> The values that matter for convolutions are 2nd and 3rd and they represent the overlap in the application of the convolutional filters along rows and columns. The value of [1, 2, 2, 1] says that we want to apply the filters on every second row and column.</p>\n\n<p><strong>Re 2)</strong> I don\'t know the technical limitations (might be CuDNN requirement) but typically people use strides along the rows or columns dimensions. It doesn\'t necessarily make sense to do it over batch size. Not sure of the \nlast dimension.</p>\n\n<p><strong>Re 3)</strong> Setting -1 for one of the dimension means, ""set the value for the first dimension so that the total number of elements in the tensor is unchanged"". In our case, the -1 will be equal to the batch_size.</p>\n'}, {'owner': {'reputation': 1274, 'user_id': 3901871}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1533089375, 'answer_id': 51624458, 'question_id': 34642595, 'body': '<p>@dga has done a wonderful job explaining and I can\'t be thankful enough how helpful it has been. In the like manner, I will like to share my findings on how <code>stride</code> works in 3D convolution.</p>\n\n<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv3d"" rel=""nofollow noreferrer"">TensorFlow documentation</a> on conv3d, the shape of the input must be in this order: </p>\n\n<p><code>[batch, in_depth, in_height, in_width, in_channels]</code></p>\n\n<p>Let\'s explain the variables from the extreme right to the left using an example. Assuming the input shape is \n<code>input_shape = [1000,16,112,112,3]</code></p>\n\n<pre><code>input_shape[4] is the number of colour channels (RGB or whichever format it is extracted in)\ninput_shape[3] is the width of the image\ninput_shape[2] is the height of the image\ninput_shape[1] is the number of frames that have been lumped into 1 complete data\ninput_shape[0] is the number of lumped frames of images we have.\n</code></pre>\n\n<p>Below is a summary documentation for how stride is used.</p>\n\n<blockquote>\n  <p>strides: A list of ints that has length >= 5. 1-D tensor of length 5.\n  The stride of the sliding window for each dimension of input. Must\n  have <code>strides[0] = strides[4] = 1</code></p>\n</blockquote>\n\n<p>As indicated in many works, strides simply mean how many steps away a window or kernel jumps away from the closest element, be it a data frame or pixel (this is paraphrased by the way).</p>\n\n<p>From the above documentation, a stride in 3D will look like this strides = (1,<strong>X</strong>,<strong>Y</strong>,<strong>Z</strong>,1). </p>\n\n<p>The documentation emphasizes that <code>strides[0] = strides[4] = 1</code>. </p>\n\n<pre><code>strides[0]=1 means that we do not want to skip any data in the batch \nstrides[4]=1 means that we do not want to skip in the channel \n</code></pre>\n\n<p>strides[X] means how many skips we should make in the lumped frames. So for example, if we have 16 frames, X=1 means use every frame. X=2 means use every second frame and it goes and on</p>\n\n<p>strides[y] and strides[z] follow the explanation by <a href=""https://stackoverflow.com/a/34643081/3901871"">@dga</a> so I will not redo that part.</p>\n\n<p>In keras however, you only need to specify a tuple/list of 3 integers, specifying the strides of the convolution along each spatial dimension, where spatial dimension is stride[x], strides[y] and strides[z]. strides[0] and strides[4] is already defaulted to 1.</p>\n\n<p>I hope someone finds this helpful!</p>\n'}, {'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': False, 'score': 11, 'creation_date': 1495413121, 'answer_id': 44103110, 'question_id': 34642595, 'body': '<h3>Let\'s start with what stride does in 1-dim case.</h3>\n<p>Let\'s assume your <code>input = [1, 0, 2, 3, 0, 1, 1]</code> and <code>kernel = [2, 1, 3]</code> the result of the convolution is <code>[8, 11, 7, 9, 4]</code>, which is calculated by sliding your kernel over the input, performing element-wise multiplication and summing everything. <a href=""http://www.riptutorial.com/tensorflow/example/30750/math-behind-1d-convolution-with-advanced-examples-in-tf"" rel=""noreferrer"">Like this</a>:</p>\n<ul>\n<li>8  = 1 * 2 + 0 * 1 + 2 * 3</li>\n<li>11 = 0 * 2 + 2 * 1 + 3 * 3</li>\n<li>7  = 2 * 2 + 3 * 1 + 0 * 3</li>\n<li>9  = 3 * 2 + 0 * 1 + 1 * 3</li>\n<li>4  = 0 * 2 + 1 * 1 + 1 * 3</li>\n</ul>\n<p>Here we slide by one element, but nothing stops you by using any other number. This number is your stride. You can think about it as downsampling the result of the 1-strided convolution by just taking every s-th result.</p>\n<p>Knowing the input size <strong>i</strong>, kernel size <strong>k</strong>, stride <strong>s</strong> and padding <strong>p</strong> you can easily calculate the output size of the convolution as:</p>\n<p><a href=""https://i.stack.imgur.com/OC5Tk.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/OC5Tk.png"" alt=""enter image description here"" /></a></p>\n<p>Here || operator means ceiling operation. For a pooling layer s = 1.</p>\n<hr />\n<h2>N-dim case.</h2>\n<p>Knowing the math for a 1-dim case, n-dim case is easy once you see that each dim is independent. So you just slide each dimension separately. Here is an <a href=""http://www.riptutorial.com/tensorflow/example/30756/padding-and-strides--the-most-general-case-"" rel=""noreferrer"">example for 2-d</a>. Notice that you do not need to have the same stride at all the dimensions. So for an N-dim input/kernel you should provide N strides.</p>\n<hr />\n<h2>So now it is easy to answer all your questions:</h2>\n<ol>\n<li><strong>What do each of the 4+ integers represent?</strong>. <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv2d"" rel=""noreferrer"">conv2d</a>, <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/max_pool"" rel=""noreferrer"">pool</a> tells you that this list represents the strides among each dimension. Notice that the length of strides list is the same as the rank of kernel tensor.</li>\n<li><strong>Why must they have strides[0] = strides<a href=""http://www.riptutorial.com/tensorflow/example/30756/padding-and-strides--the-most-general-case-"" rel=""noreferrer"">3</a> = 1 for convnets?</strong>. The first dimension is batch size, the last is channels. There is no point of skipping neither batch nor channel. So you make them 1. For width/height you can skip something and that\'s why they might be not 1.</li>\n<li><strong>tf.reshape(_X,shape=[-1, 28, 28, 1]). Why -1?</strong> <a href=""https://www.tensorflow.org/api_docs/python/tf/reshape"" rel=""noreferrer"">tf.reshape</a> has it covered for you:\n<blockquote>\n<p>If one component of shape is the special value -1, the size of that dimension is computed so that the total size remains constant. In particular, a shape of [-1] flattens into 1-D. At most one component of shape can be -1.</p>\n</blockquote>\n</li>\n</ol>\n'}, {'owner': {'reputation': 21757, 'user_id': 5545260}, 'down_vote_count': 0, 'up_vote_count': 230, 'is_accepted': True, 'score': 230, 'creation_date': 1452115557, 'answer_id': 34643081, 'question_id': 34642595, 'body': '<p>The pooling and convolutional ops slide a ""window"" across the input tensor.  Using <a href=""https://www.tensorflow.org/versions/master/api_docs/python/nn.html#conv2d""><code>tf.nn.conv2d</code></a> as an example: If the input tensor has 4 dimensions:  <code>[batch, height, width, channels]</code>, then the convolution operates on a 2D window on the <code>height, width</code> dimensions.</p>\n\n<p><code>strides</code> determines how much the window shifts by in each of the dimensions.  The typical use sets the first (the batch) and last (the depth) stride to 1.</p>\n\n<p>Let\'s use a very concrete example:  Running a 2-d convolution over a 32x32 greyscale input image.  I say greyscale because then the input image has depth=1, which helps keep it simple.  Let that image look like this:</p>\n\n<pre><code>00 01 02 03 04 ...\n10 11 12 13 14 ...\n20 21 22 23 24 ...\n30 31 32 33 34 ...\n...\n</code></pre>\n\n<p>Let\'s run a 2x2 convolution window over a single example (batch size = 1).  We\'ll give the convolution an output channel depth of 8.</p>\n\n<p>The input to the convolution has <code>shape=[1, 32, 32, 1]</code>.</p>\n\n<p>If you specify <code>strides=[1,1,1,1]</code> with <code>padding=SAME</code>, then the output of the filter will be [1, 32, 32, 8].</p>\n\n<p>The filter will first create an output for:</p>\n\n<pre><code>F(00 01\n  10 11)\n</code></pre>\n\n<p>And then for:</p>\n\n<pre><code>F(01 02\n  11 12)\n</code></pre>\n\n<p>and so on.  Then it will move to the second row, calculating:</p>\n\n<pre><code>F(10, 11\n  20, 21)\n</code></pre>\n\n<p>then</p>\n\n<pre><code>F(11, 12\n  21, 22)\n</code></pre>\n\n<p>If you specify a stride of [1, 2, 2, 1] it won\'t do overlapping windows.  It will compute:</p>\n\n<pre><code>F(00, 01\n  10, 11)\n</code></pre>\n\n<p>and then</p>\n\n<pre><code>F(02, 03\n  12, 13)\n</code></pre>\n\n<p>The stride operates similarly for the pooling operators.</p>\n\n<p><strong>Question 2:  Why strides [1, x, y, 1] for convnets</strong></p>\n\n<p>The first 1 is the batch:  You don\'t usually want to skip over examples in your batch, or you shouldn\'t have included them in the first place. :)</p>\n\n<p>The last 1 is the depth of the convolution:  You don\'t usually want to skip inputs, for the same reason.</p>\n\n<p>The conv2d operator is more general, so you <em>could</em> create convolutions that slide the window along other dimensions, but that\'s not a typical use in convnets.  The typical use is to use them spatially.</p>\n\n<p><strong>Why reshape to -1</strong>  -1 is a placeholder that says ""adjust as necessary to match the size needed for the full tensor.""  It\'s a way of making the code be independent of the input batch size, so that you can change your pipeline and not have to adjust the batch size everywhere in the code.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9603}"
382,62223016,"{'items': [{'owner': {'reputation': 483, 'user_id': 7212243}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1591521062, 'answer_id': 62243227, 'question_id': 62223016, 'body': ""<p>The image should be normalized that it should be divided by 255, if it's done during the training. Network will not be able to interpret that.</p>\n\n<p>Also, when we use test_datagen, we apply Rescaling by 1/255 for the predict generator. </p>\n\n<p>Normalization, mean subtraction and std deviation needs to be done at the testing time, if that has been applied during the training stage.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9603}"
383,51856041,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9603}"
384,58897066,"{'items': [{'owner': {'reputation': 366, 'user_id': 1600660}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1591269992, 'answer_id': 62193481, 'question_id': 58897066, 'body': '<p>If your TensorFlow dataset is named <code>dataset</code>, you can access the first element like this:</p>\n<pre><code>list(dataset.as_numpy_iterator())[0]\n</code></pre>\n<p>See <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#as_numpy_iterator"" rel=""nofollow noreferrer"">documentation</a>.</p>\n'}, {'owner': {'reputation': 1099, 'user_id': 11764049}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1671206453, 'answer_id': 74826904, 'question_id': 58897066, 'body': '<p>You can also combine the <code>as_numpy_iterator</code> method, proposed by J.V. with the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take"" rel=""nofollow noreferrer""><code>take</code></a> method that allows you to specify how many elements you want to extract from tf dataset. For example:</p>\n<pre><code>import tensorflow as tf\n\n&gt;&gt;&gt; dataset = tf.data.Dataset.range(10)\n&gt;&gt;&gt; dataset = dataset.take(1) # take one element (the first)\n&gt;&gt;&gt; list(dataset.as_numpy_iterator())\n0\n</code></pre>\n<p>Changing the number in the take method will allow you to extract a different number of elements (in the order they were inserted in the dataset).</p>\n'}, {'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1573965641, 'answer_id': 58897555, 'question_id': 58897066, 'body': '<p>In TF 1.x you can use the following. There are different iterators provided (some might be deprecated in future versions).</p>\n\n<pre><code>import tensorflow as tf\n\nd = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4])\nditer = d.make_one_shot_iterator()\ne1 = diter.get_next()\n\nwith tf.Session() as sess:\n  print(sess.run(e1))\n</code></pre>\n\n<p>Or in TF 2.x</p>\n\n<pre><code>import tensorflow as tf\n\nd = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4])\nprint(next(iter(d)).numpy())\n\n## You can also use loops as follows to traverse the full set one item at a time\nfor elem in d:\n    print(elem)\n\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9603}"
385,49201832,"{'items': [{'owner': {'reputation': 89, 'user_id': 6720191}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': False, 'score': 0, 'creation_date': 1521782153, 'answer_id': 49442786, 'question_id': 49201832, 'body': ""<p>Another choice is to use <code>tf.layers.Dense</code> instead of <code>tf.layers.dense</code> (difference between <code>d</code> and <code>D</code>).</p>\n\n<p>The paradigm for <code>Dense</code> is :</p>\n\n<pre><code>x = tf.placeholder(shape=[None, 100])\ndlayer = tf.layers.Dense(hidden_unit)\ny = dlayer(x)\n</code></pre>\n\n<p>With <code>dlayer</code> as intermediate, you're able to do:</p>\n\n<pre><code>k = dlayer.kernel\nb = dlayer.bias\nk_and_b = dlayer.weights\n</code></pre>\n\n<p>Note that you won't get the <code>dlayer.kernel</code> until you apply <code>y = dlayer(x)</code>.</p>\n\n<p>Things are similar for other layers such as convolution layer. Check them with any available auto-completion.</p>\n""}, {'owner': {'reputation': 4211, 'user_id': 4117331}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1521739719, 'answer_id': 49434941, 'question_id': 49201832, 'body': '<p>You can use something like this</p>\n\n<pre><code>with tf.name_scope(\'dense2\'):\n\n    preds = tf.layers.dense(inputs=dense1,units = 12,  \n                    activation=tf.nn.sigmoid, name=""dense2"")\n\n    d2_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \'dense2\')\n\n    tf.summary.histogram(""weights"", d2_vars[0])\n    tf.summary.histogram(""biases"", d2_vars[1])\n    tf.summary.histogram(""activations"", preds)\n</code></pre>\n'}, {'owner': {'reputation': 304, 'user_id': 6457747}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1520632500, 'answer_id': 49202745, 'question_id': 49201832, 'body': '<p>You should be able to use the output of your tf.layers call to get the activations. Taking the first convolutional layer of the linked layers tutorial:</p>\n\n<pre><code># Convolutional Layer #1\nconv1 = tf.layers.conv2d(\n    inputs=input_layer,\n    filters=32,\n    kernel_size=[5, 5],\n    padding=""same"",\n    activation=tf.nn.relu)\n</code></pre>\n\n<p>You could do:</p>\n\n<pre><code>tensor_name = conv1.op.name\ntf.summary.histogram(tensor_name + \'/activation\', conv1)\n</code></pre>\n\n<p>Not sure if this is the best way, but I believe it is the most direct way of doing what you want.</p>\n\n<p>Hope this helps!</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9598}"
386,73900721,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9598}"
387,57711285,"{'items': [{'owner': {'reputation': 315, 'user_id': 9637085}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1567088098, 'answer_id': 57712129, 'question_id': 57711285, 'body': '<p>You can also use this:</p>\n\n<pre><code>if mode == tf.estimator.ModeKeys.TRAIN:\n   global_step = tf.train.get_or_create_global_step()\n   learning_rate = learning_rate_fn(global_step)\n</code></pre>\n\n<p>where learning_rate_fn is a function that you can modify your learning rate.</p>\n\n<p>For more info look at <a href=""https://github.com/tensorflow/models/blob/57e075203f8fba8d85e6b74f17f63d0a07da233a/official/resnet/resnet_run_loop.py#L367"" rel=""nofollow noreferrer"">here</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9598}"
388,67740346,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1623935305, 'answer_id': 68020033, 'question_id': 67740346, 'body': ""<p>You get above ValueError is due to mixing <code>tf.keras</code> and <code>keras</code> imports, which is not supported in <code>TF2.5</code>.</p>\n<p>Working code as shown below</p>\n<pre><code>import tensorflow as tf\n#from keras.layers import TimeDistributed, GRU, Dense, Dropout\nfrom tensorflow.keras.layers import Flatten, GRU, Dropout, TimeDistributed, Dense\n\ndef build_convnet():\n\n    prevModel = tf.keras.applications.vgg16.VGG16(\n        include_top=False,\n        input_shape=(112, 112, 3),\n        weights='imagenet'  # ImageNet weights\n    )\n\n    model = tf.keras.models.Sequential()\n\n    model.add(prevModel)\n    model.add(Flatten())\n\n    return model\n\ndef action_model(shape=(5, 112, 112, 3), nbout=3):\n  # Create our convnet with (112, 112, 3) input shape\n  convnet = build_convnet()\n\n  # then create our final model\n  model = tf.keras.models.Sequential()\n  # add the convnet with (5, 112, 112, 3) shape\n  model.add(TimeDistributed(convnet, input_shape=shape))\n  # here, you can also use GRU or LSTM\n  model.add(GRU(64))\n  # and finally, we make a decision network\n  model.add(Dense(1024, activation='relu'))\n  model.add(Dropout(.5))\n  model.add(Dense(512, activation='relu'))\n  model.add(Dropout(.5))\n  model.add(Dense(128, activation='relu'))\n  model.add(Dropout(.5))\n  model.add(Dense(64, activation='relu'))\n  model.add(Dense(nbout, activation='softmax'))\n  return model\n\nmod=action_model()\nmod.summary()\n</code></pre>\n<p>Output:</p>\n<pre><code>Model: &quot;sequential_3&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntime_distributed_1 (TimeDist (None, 5, 4608)           14714688  \n_________________________________________________________________\ngru_1 (GRU)                  (None, 64)                897408    \n_________________________________________________________________\ndense (Dense)                (None, 1024)              66560     \n_________________________________________________________________\ndropout (Dropout)            (None, 1024)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               65664     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_4 (Dense)              (None, 3)                 195       \n=================================================================\nTotal params: 16,277,571\nTrainable params: 16,277,571\nNon-trainable params: 0\n_________________________________________________________________\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9598}"
389,52591291,"{'items': [{'owner': {'reputation': 158, 'user_id': 10240511}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1542495238, 'answer_id': 53356321, 'question_id': 52591291, 'body': '<p>The first thing that caught my attention is the number of hidden units. I would try to adjust your hidden units. Usually the layers should decrease in size, so I would try <code>[512,256,128]</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9598}"
390,68002490,"{'items': [{'owner': {'reputation': 3303, 'user_id': 10935717}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1623923111, 'answer_id': 68016827, 'question_id': 68002490, 'body': '<p>The functional <a href=""https://pytorch.org/docs/stable/generated/torch.nn.functional.conv_transpose2d.html#torch.nn.functional.conv_transpose2d"" rel=""nofollow noreferrer"">conv_tranpose2d</a> seems to be what you are looking for. You cannot specify the output shape like you do with the tensdorflow one but rather have to tweak the <code>output_padding</code> to get the shape you want, but that is the only difference I think.</p>\n<pre><code>import torch.nn.functional as F\ny_up_tor = F.conv_transpose(y_tor, feats_tor, output_padding=(1,1), stride=(2,2))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9593}"
391,72983226,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9593}"
392,73179836,"{'items': [{'owner': {'reputation': 3244, 'user_id': 14774959}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1659260020, 'answer_id': 73182117, 'question_id': 73179836, 'body': '<h4>Solution 1 (with eager execution):</h4>\n<p>In Tensorflow 2, eager execution should be enabled by default.</p>\n<p>I reproduced the exact same code as the Tensorflow tutorial without any problem (the assertion does not generate errors). I used Colab under Tensorflow 2.8.2 and Python 3.7.13.</p>\n<p>If you have problems you could try setting <code>tf.config.run_functions_eagerly(True)</code>, but really it should work even without this stuff.</p>\n<h4>Solution 2 (without eager execution):</h4>\n<p>If you want to keep eager execution disabled, you can work with sessions (more info about <a href=""https://www.tensorflow.org/api_docs/python/tf/compat/v1/Session"" rel=""nofollow noreferrer"">sessions</a>). Instead of calling <code>.numpy()</code> you should call <code>.eval()</code> on your Tensor and wrap everything in a session. That\'s it.</p>\n<pre><code>tf.compat.v1.disable_eager_execution()\n\ndef log_huber(x, m):\n  if tf.abs(x) &lt;= m:\n    return x**2\n  else:\n    return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))\n\nx = tf.constant(1.0)\nm = tf.constant(2.0)\n\n# Launch the graph in a session.\nsess = tf.compat.v1.Session()\n\nwith tf.GradientTape() as t:\n  t.watch([x, m])\n  y = tf.py_function(func=log_huber, inp=[x, m], Tout=tf.float32)\n\nwith sess.as_default():\n  dy_dx = t.gradient(y, x)\n  assert dy_dx.eval() == 2.0\n  print(dy_dx.eval())\n\nsess.close()\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9593}"
393,36620995,"{'items': [{'owner': {'reputation': 2138, 'user_id': 3251207}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1461046554, 'answer_id': 36710005, 'question_id': 36620995, 'body': ""<p>For those who may wonder, when I tried as in Yaroslav Bulatov's response, I could see better performance:</p>\n<pre><code>tf.sqrt(tf.nn.ave_pool(tf.square(h))\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9593}"
394,57301699,"{'items': [{'owner': {'reputation': 55360, 'user_id': 349130}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1564662475, 'answer_id': 57309083, 'question_id': 57301699, 'body': '<p>Seeds are used to produce deterministic behavior out of a random number generator, this is generally done for reproducibility of results.</p>\n\n<p>The actual value of the seed does not matter, the only purpose is to keep the seed to a constant value, you should not ""tune"" this value or select it in any way, as it will bias your results.</p>\n\n<p>In general you can set the seed if you need to test algorithms and have reproducible behavior, but after your know your algorithm is well implemented, seeds should not be set for evaluation, as it is very easy to tune the ""best seed"" in order to produce good results. Randomness in algorithms is there for a good reason. </p>\n'}, {'owner': {'reputation': 8381, 'user_id': 5810950}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1564633511, 'answer_id': 57301833, 'question_id': 57301699, 'body': '<p>Yeah, to make the random sequences generated by all ops be repeatable across sessions. By, the way <code>seed=1234</code> is random. You can select any value.</p>\n\n<p>For example:</p>\n\n<pre><code>a = tf.random.uniform([1])\nb = tf.random.normal([1])\n\n# Repeatedly running this block with the same graph will generate the \n# different sequences of \'a\' and \'b\' across sessions.\nprint(""Session 1"")\nwith tf.Session() as sess1:\n  print(sess1.run(a))  # generates \'A1\'\n  print(sess1.run(a))  # generates \'A2\'\n  print(sess1.run(b))  # generates \'B1\'\n  print(sess1.run(b))  # generates \'B2\'\n\nprint(""Session 2"")\nwith tf.Session() as sess2:\n  print(sess2.run(a))  # generates \'A3\'\n  print(sess2.run(a))  # generates \'A4\'\n  print(sess2.run(b))  # generates \'B3\'\n  print(sess2.run(b))  # generates \'B4\'\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>Session 1\n[0.35214436]\n[0.61644566]\n[-0.2290629]\n[0.8414659]\nSession 2\n[0.62713313]\n[0.5924448]\n[-0.5366475]\n[-0.36064562]\n</code></pre>\n\n<p>But, after setting a graph-level seed using <code>tf.random.set_random_seed(1234)</code>:</p>\n\n<pre><code>tf.random.set_random_seed(1234)\na = tf.random.uniform([1])\nb = tf.random.normal([1])\n\n# Repeatedly running this block with the same graph will generate the same\n# sequences of \'a\' and \'b\'.\nprint(""Session 1"")\nwith tf.Session() as sess1:\n  print(sess1.run(a))  # generates \'A1\'\n  print(sess1.run(a))  # generates \'A2\'\n  print(sess1.run(b))  # generates \'B1\'\n  print(sess1.run(b))  # generates \'B2\'\n\nprint(""Session 2"")\nwith tf.Session() as sess2:\n  print(sess2.run(a))  # generates \'A1\'\n  print(sess2.run(a))  # generates \'A2\'\n  print(sess2.run(b))  # generates \'B1\'\n  print(sess2.run(b))  # generates \'B2\'\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>Session 1\n[0.53202796]\n[0.91749656]\n[-1.3118125]\n[-0.44506428]\nSession 2\n[0.53202796]\n[0.91749656]\n[-1.3118125]\n[-0.44506428]\n</code></pre>\n\n<p>You can also set op-level seed like <code>a = tf.random.uniform([1], seed=1)</code>. Read more about it from official documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/random/set_random_seed"" rel=""nofollow noreferrer"">here</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9593}"
395,49066695,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9588}"
396,72850120,"{'items': [{'owner': {'reputation': 696, 'user_id': 1676589}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1656907774, 'answer_id': 72851698, 'question_id': 72850120, 'body': ""<blockquote>\n<p>This means when I am obtaining predictions, I don't use the tf.nn.sigmoid() function and instead simply check if the value is greater than 0.5, then 1, else 0. Is this correct?</p>\n</blockquote>\n<p>Yes, you don't even need the <code>from_logits</code> parameter since you're using the <code>sigmoid</code> function. I believe it's False by default.</p>\n<blockquote>\n<p>And then when I obtain predictions, I have the following:</p>\n</blockquote>\n<p>Depends on how (un)balanced your training data is. Ideally, if it's balanced, you're correct, pred &gt; 0.5 means the model thinks the image belongs closer to class <code>1</code>. If you have a disproportionately large amount of <code>1</code>, the model may be more biased to classifying an image as <code>1</code>. Conversely, if you choose to use the <code>softmax</code> function, you'll get an array with length = num_of_classes, with each prediction array adding up to 1.0, with each element in the array representing the model's confidence the image belongs to each class.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9588}"
397,60525257,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9588}"
398,49435335,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9588}"
399,49500873,"{'items': [{'owner': {'reputation': 30867, 'user_id': 4790871}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1522101544, 'answer_id': 49501298, 'question_id': 49500873, 'body': '<p>Great question! That stumped me for a minute, the answer is ultimately trivial, but an important lesson in how tensorflow operates.</p>\n\n<p>First some working code:</p>\n\n<pre><code>import tensorflow as tf\n\nmyArray = tf.random_normal([6], mean=1, stddev=4, seed = 1)\nmyMask =  tf.greater_equal(myArray, 0.5)\nmyScores = tf.boolean_mask( myArray, myMask )\n\nwith tf.Session() as sess:\n    print(sess.run([myArray, myMask, myScores]))\n</code></pre>\n\n<p>Result:</p>\n\n<pre><code>[array([-2.2452729,  6.938395 ,  1.2613175, -8.770817 ,  1.3969936, 3.3648973], dtype=float32), \n array([False,       True,       True,       False,      True,      True]), \n array([6.938395 , 1.2613175, 1.3969936, 3.3648973], dtype=float32)]\n</code></pre>\n\n<p>Notice that myArray is an OP, <strong>not</strong> a variable. An OP (short for operation) is computed at the time that you call <code>sess.run</code> (or <code>eval</code> in this case, but using <code>eval</code> made it less obvious).</p>\n\n<p>A variable, such as <code>myVar = tf.variable(...)</code> persists from one call to <code>sess.run</code> to another. Since myArray is an OP it was being recomputed each time you performed any operation against the tensorflow graph. Since you called the graph on 3 separate instances you got 3 different values for myArray in each call. You only printed myArray in the first instance of course and erroneously assumed it was remaining static.</p>\n\n<p>Notice with the modified code that I posted I now request all 3 variables in one <code>sess.run</code> call, hence they all use the same value of myArray, and all the results are as expected.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9584}"
400,59177677,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9583}"
401,71068368,"{'items': [{'owner': {'reputation': 21, 'user_id': 9675442}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1692252925, 'answer_id': 76918889, 'question_id': 71068368, 'body': '<p>I recently had the same problem. I do not remember if this was the trick that solved my problem, but try launching your CUDA kernel like this:</p>\n<pre class=""lang-py prettyprint-override""><code>// Get the optimal number of blocks and threads\nGpuLaunchConfig config = GetGpuLaunchConfig(size, d);\n// Launch the kernel\nTF_CHECK_OK(::tensorflow::GpuLaunchKernel(ExampleCudaKernel &lt;T&gt;,\n    config.block_count, config.thread_per_block, 0, d.stream(),\n    size, in, out\n));\n</code></pre>\n'}, {'owner': {'reputation': 11, 'user_id': 18090135}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1645196923, 'answer_id': 71175682, 'question_id': 71068368, 'body': '<p>I managed to solve the problem. After several trials I saw that sometimes it worked and sometimes not, I finally ended up in understanding that the reason was due to the specific GPU I was connected with and that adding the flag -arch to the nvcc compilation was the solution. In Colab you can see the Gpu model through <code>!nvidia-smi</code>.</p>\n<ul>\n<li>Tesla K80: <code>-arch=sm_37</code>, it\'s deprecated but it currently works.</li>\n<li>Tesla T4: you don\'t need to specify anything.</li>\n</ul>\n<p>Check this <a href=""https://arnon.dk/tag/nvcc-flags/#:%7E:text=When%20compiling%20with%20NVCC%2C%20the,many%20times%20for%20different%20architectures."" rel=""nofollow noreferrer"">link</a> to find what -arch you need to specify. For completeness I report the Makefile you need to use when you are connected to a Tesla K80:</p>\n<pre><code>TF_CFLAGS = `python -c &quot;import tensorflow as tf; print(\' \'.join(tf.sysconfig.get_compile_flags()))&quot;`\nTF_LFLAGS = `python -c &quot;import tensorflow as tf; print(\' \'.join(tf.sysconfig.get_link_flags()))&quot;`\n\ndefault: gpu\ngpu:\n    nvcc -std=c++14 -c -o kernel_example.cu.o kernel_example.cu.cc $(TF_CFLAGS) -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC --expt-relaxed-constexpr -arch=sm_37\n    g++ -std=c++14 -shared -o kernel_example.so kernel_example.cc kernel_example.cu.o $(TF_CFLAGS) -D GOOGLE_CUDA=1 -fPIC -L/usr/local/cuda-11.1/lib64/ -lcudart -lcuda $(TF_LFLAGS) \n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9583}"
402,43623121,"{'items': [{'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1493167982, 'answer_id': 43623228, 'question_id': 43623121, 'body': '<p>Use <a href=""https://www.tensorflow.org/api_docs/python/tf/Tensor#set_shape"" rel=""nofollow noreferrer""><code>x.set_shape()</code></a> to provide additional information about the shape of this tensor that cannot be inferred from the graph alone.</p>\n\n<p>You can get more information from the <a href=""https://www.tensorflow.org/programmers_guide/faq#tensor_shapes"" rel=""nofollow noreferrer"">FAQ</a>:</p>\n\n<blockquote>\n  <p>The tf.Tensor.set_shape method updates the static shape of a Tensor\n  object, and it is typically used to provide additional shape\n  information when this cannot be inferred directly. It does not change\n  the dynamic shape of the tensor.</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9583}"
403,60469970,"{'items': [{'owner': {'reputation': 2652, 'user_id': 8831165}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1583014268, 'answer_id': 60470059, 'question_id': 60469970, 'body': '<p>Well - it\'s more complicated than that. <code>autograph</code> is an entire ""subpackage"" on its own, so a lot happens under the hood when you call <code>@tf.function</code>. A nice place to start might be here: <a href=""https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/autograph/g3doc/reference"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/autograph/g3doc/reference</a>. You could also dive right into the code if you\'re really curious.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9583}"
404,72379091,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9579}"
405,42404564,"{'items': [{'owner': {'reputation': 1470, 'user_id': 8037585}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1529545229, 'answer_id': 50959195, 'question_id': 42404564, 'body': '<p><code>tf.train.get_global_step()</code> return global step(variable, tensor from variable node or None) through <code>get_collection(tf.GraphKeys.GLOBAL_STEP)</code> or <code>get_tensor_by_name(\'global_step:0\')</code></p>\n\n<p>global step is widely used in learn rate decay(like <code>tf.train.exponential_decay</code>, see <a href=""https://www.tensorflow.org/api_guides/python/train#Decaying_the_learning_rate"" rel=""nofollow noreferrer"">Decaying the learning rate</a> for more information). </p>\n\n<p>You can pass global step to optimzer apply_gradients or minimize method to  increment by one.</p>\n'}, {'owner': {'reputation': 2862, 'user_id': 1373669}, 'down_vote_count': 0, 'up_vote_count': 12, 'is_accepted': True, 'score': 12, 'creation_date': 1487851942, 'answer_id': 42415441, 'question_id': 42404564, 'body': '<p>You could use it to restart training exactly where you left off when the training procedure has been stopped for some reason. Of course you can always restart training without knowing the <code>global_step</code> (if you save checkpoints regularly in your code, that is), but unless you somehow keep track of how many iterations you already performed, you will not know how many iterations are left after the restart. Sometimes you really want your model to be trained exactly <code>n</code> iterations and not <code>n</code> plus <code>unknown amount before crash</code>. So in my opinion, this is more of a practicality than a theoretical machine learning concept.</p>\n'}, {'owner': {'reputation': 784, 'user_id': 4922660}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1487816416, 'answer_id': 42405877, 'question_id': 42404564, 'body': '<p>while you defined the global step operator, you can get value of it by sess.run(global_step_op)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9579}"
406,49605330,"{'items': [{'owner': {'reputation': 475, 'user_id': 7721459}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1564757591, 'answer_id': 57328916, 'question_id': 49605330, 'body': '<p>I hope this is an easy and clean way of visualizing it. It does NOT complete the (...) from your question though, but I think they illustrate how to use <code>tf.feature_column.indicator_column</code>:</p>\n<pre><code>import tensorflow as tf\n\ncolors_column = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(\n    key=\'color\',\n    vocabulary_list=[&quot;Green&quot;, &quot;Red&quot;, &quot;Blue&quot;, &quot;Yellow&quot;]\n))\n\n\ninput_layer = tf.feature_column.input_layer(\n    features={\'color\': tf.constant(value=&quot;Red&quot;, dtype=tf.string, shape=(1,))},\n    feature_columns=[colors_column])\n\n\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_tables())\n    print(sess.run(input_layer))\n</code></pre>\n<p><strong>Understanding it a bit more:</strong></p>\n<p>I strongly suggest the reading of <a href=""https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html"" rel=""nofollow noreferrer"">this</a>. Specifically, I really like this picture:</p>\n<p><a href=""https://i.stack.imgur.com/Xvwjz.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Xvwjz.jpg"" alt=""enter image description here"" /></a></p>\n<p>It shows that, while the categorical columns are mapping to integeres, the indicator column is in its turn doing the conversion to one-hot / multi-hot encoding.</p>\n'}, {'owner': {'reputation': 327, 'user_id': 2616173}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1540233896, 'answer_id': 52935868, 'question_id': 49605330, 'body': ""<p>I'm struggeling with the TF documentation myself.\nI believe the first ellipsis is just to indicate that one could have more than this single column. But for the 'parse_example' method a second input parameter ('serialized') is required (, as you probably already have found out yourself by now.)</p>\n\n<p>Following code works for me and returns values as described in the docu on evaluation:</p>\n\n<pre><code>import tensorflow as tf\n\nname = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(\n'name', ['bob', 'george', 'wanda']))\ncolumns = [name]\n\nfeature_dict = {'name': tf.train.Feature(bytes_list=tf.train.BytesList(value=['bob', 'wanda']))}\nexample = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n\ntf_example = tf.parse_example(serialized=[example.SerializeToString()], \n                           features=tf.feature_column.make_parse_example_spec(columns))\ndense_tensor = tf.feature_column.input_layer(tf_example, columns)\n\nsess = tf.InteractiveSession()\ntf.tables_initializer().run()\n\nprint(dense_tensor.eval())\n</code></pre>\n\n<p>There are probably more elegant ways, but since there are no other answers (for both of us) I hope this helps.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9579}"
407,43131606,"{'items': [{'owner': {'reputation': 1037, 'user_id': 2845263}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1490945616, 'answer_id': 43135048, 'question_id': 43131606, 'body': '<p>From the tensorflow documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/bias_add"" rel=""nofollow noreferrer"">here</a>: </p>\n\n<blockquote>\n  <p>Unlike tf.add, the type of bias is allowed to differ from value in the case where both types are quantized.</p>\n</blockquote>\n\n<p><code>tf.add</code> is a general addition operation, while <code>tf.nn.bias_add</code> is to be used specifically for adding bias to the weights, which raises an exception if the dtypes aren\'t same.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9579}"
408,58176215,"{'items': [{'owner': {'reputation': 812, 'user_id': 6470174}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1570630021, 'answer_id': 58306042, 'question_id': 58176215, 'body': '<p>I found a possible solution to my question and I\'m posting it here, in case someone may find it useful.</p>\n\n<p>Apparently, <code>tf.stop_gradients()</code> only stops the new gradients to be back-propagated through the layers, but: if we have a momentum term (e.g. when using Adam or RMSProp) the variables of such layers could still be updated due to some gradients cumulated in the past (contained in the momentum term). Let\'s have a look at the simple case of SGD + Momentum; the formula would be:</p>\n\n<pre><code>w1 = w0 - a*grad(loss) - b*v0\n</code></pre>\n\n<p>where <code>w1</code> and <code>w0</code> are the weights at time 0 and 1, <code>a</code> is the learning rate <code>v0</code> is the accumulated velocity (a function of the past gradients). Using <code>tf.stop_gradients()</code> is equivalent to multiplying the second term for zero. Then, the update rule becomes:</p>\n\n<pre><code>w1 = w0 - b*v0\n</code></pre>\n\n<p>e.g. we still have a momentum component that can update the weights. </p>\n\n<p>A workaround to this problem would be to explicitly passing the variables to be updated to the optimizer. For example:</p>\n\n<pre><code>var_list = take_all_variables_in_N2()\ntrain_op = tf.train.AdamOptimizer(lr).minimize(loss, var_list)\n</code></pre>\n\n<hr>\n\n<p><strong>References:</strong></p>\n\n<p>[1] <a href=""http://ruder.io/optimizing-gradient-descent/"" rel=""nofollow noreferrer"">http://ruder.io/optimizing-gradient-descent/</a></p>\n\n<p>[2] <a href=""https://stackoverflow.com/questions/51158399/using-stop-gradient-with-adamoptimizer-in-tensorflow"">Using stop_gradient with AdamOptimizer in TensorFlow</a> </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9579}"
409,64297691,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9574}"
410,74060508,"{'items': [{'owner': {'reputation': 746, 'user_id': 7848579}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1665693886, 'answer_id': 74061596, 'question_id': 74060508, 'body': ""<p>It simply saves as text or checkpoints.</p>\n<p>Sample:</p>\n<pre><code>import os\nfrom os.path import exists\n\nimport tensorflow as tf\nimport pandas as pd\n\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\nNone\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\nassert len(physical_devices) &gt; 0, &quot;Not enough GPU hardware devices available&quot;\nphysical_devices = tf.config.experimental.list_physical_devices()\nprint(physical_devices)\n\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n: Variables\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\nBATCH_SIZE = 1\nIMG_SIZE = (32, 32)\nnew_dataset_folder = &quot;F:\\\\temp\\\\Python\\\\excel&quot;\n\nPATH = 'F:\\\\datasets\\\\downloads\\\\cats_name'\ntrain_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'validation')\n\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(train_dir, shuffle=True,\n    batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n                                                            \nclass_names = train_dataset.class_names\n\nprint( 'class_names: ' + str( class_names ) )\nprint( train_dataset )\n\n### 1. Save dataset using .save()\npath = &quot;F:\\\\temp\\\\saved_dataset&quot;\ntrain_dataset.save(\n    path, compression=None, shard_func=None, checkpoint_args=None\n)\n\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n: Dataset\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\ndataset = {\n    &quot;image&quot; :[],\n    &quot;label&quot; : []\n}\n\nfile_order = 0\nfor data in train_dataset :\n    file_path = new_dataset_folder + &quot;\\\\&quot; + str(int(data[1][0])) + &quot;.npz&quot;\n    dataset[&quot;image&quot;].append(file_path)\n    dataset[&quot;label&quot;].append(str(int(data[1][0])))\n    # Save\n    encoding = &quot;utf-8&quot;\n    with open( new_dataset_folder + &quot;\\\\&quot; + str(file_order), &quot;wb&quot; ) as f:\n        f.write(str(data[0]).encode(encoding))\n    \n    file_order = file_order + 1\n\n### 2. Save dataset using Panda\ndf = pd.DataFrame(dataset)\ndf.to_csv(os.path.join(new_dataset_folder, &quot;train.csv&quot;), index=False)\n</code></pre>\n""}, {'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1665730207, 'answer_id': 74065365, 'question_id': 74060508, 'body': ""<p>With Tensorflow <code>2.10.0</code>, you can use <code>tf.data.Dataset.save</code>:</p>\n<pre><code>import tensorflow as tf\n\nprint(tf.__version__)\n# 2.10.0\n\npath = '/content/'\nt = tf.range(10)\nds = tf.data.Dataset.from_tensor_slices(t)\n\ntf.data.Dataset.save(ds, path)\nnew_ds = tf.data.Dataset.load(path)\n</code></pre>\n<p>Otherwise, use <code>tf.data.experimental.save</code> for older versions:</p>\n<pre><code>import tensorflow as tf\n\npath = '/content/'\nt = tf.range(10)\nds = tf.data.Dataset.from_tensor_slices(t)\ntf.data.experimental.save(ds, path)\nnew_ds = tf.data.experimental.load(path)\n</code></pre>\n""}, {'owner': {'reputation': 2782, 'user_id': 10626495}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1665687805, 'answer_id': 74060600, 'question_id': 74060508, 'body': '<p>You can convert <code>TensorSliceDataset</code> to numpy array and then save it.</p>\n<p>Sample code:</p>\n<pre class=""lang-py prettyprint-override""><code>np.save(\'data.npy\', np.array(list(dataset.as_numpy_iterator())))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9574}"
411,64172765,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9574}"
412,65157852,"{'items': [{'owner': {'reputation': 121, 'user_id': 8840524}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1607441259, 'answer_id': 65201784, 'question_id': 65157852, 'body': ""<p>Answering my own question here. I posted a bug report on HuggingFace GitHub and they fixed this in the new dev version (4.1.0.dev0 as of December 2020). The snippet below now works as expected:</p>\n<pre><code>input_ids = tf.keras.Input(shape=(128,), dtype='int32')\nattention_mask = tf.keras.Input(shape=(128, ), dtype='int32')\n\ntransformer = TFRobertaForSequenceClassification.from_pretrained(&quot;roberta-base&quot;, num_labels=6)\nencoded = transformer({&quot;input_ids&quot;: input_ids, &quot;attention_mask&quot;: attention_mask})\nlogits = encoded[0]\n \nmodel = tf.keras.models.Model(inputs = {&quot;input_ids&quot;: input_ids, &quot;attention_mask&quot;: attention_mask}, outputs = logits)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9574}"
413,55005915,"{'items': [{'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1551863789, 'answer_id': 55019421, 'question_id': 55005915, 'body': ""<p>You can resize prior to encoding. </p>\n\n<pre><code>def int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n</code></pre>\n\n<p>Convert from string and resize </p>\n\n<pre><code>image = numpy.fromstring(byte_arr).reshape((height, width, channels))\nimage_raw = image.tostring()\n</code></pre>\n\n<p>Then serialize as tfrecords file</p>\n\n<pre><code>writer = tf.python_io.TFRecordWriter(tfr_name)\nexample = tf.train.Example(features=tf.train.Features(feature{'height':int64_feature(height),\n                                                              'width': int64_feature(width),\n                                                              'channels': int64_feature(channels),\n                                                              'image_raw': bytes_feature(image_raw),\n\nwriter.write(example.SerializeToString())\nwriter.close()\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9574}"
414,64348896,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9569}"
415,46381790,"{'items': [{'owner': {'reputation': 95, 'user_id': 4189194}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1536058869, 'answer_id': 52164795, 'question_id': 46381790, 'body': '<p><code>[None, n_input]</code> ideally refers as: <code>None</code> refers to Batch_size which can be given by us and <code>n_input</code> refers to the number of features to be analysed.</p>\n\n<p>So <code>n_input</code> refers to 784 pixel data. So we would actual try to do <code>X.W+b</code> means <code>X</code> (<code>[None, 784]</code>) is multiplied by <code>[784, 256]</code> the model outputs <code>[None, 256]</code> and now comes the addition of bias, here + is also called as broadcasting plus which ideally takes care of adding 256 biases to the 256 hidden cells</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9569}"
416,48235239,"{'items': [{'owner': {'reputation': 52739, 'user_id': 712995}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1515844191, 'answer_id': 48239573, 'question_id': 48235239, 'body': '<blockquote>\n  <p>Instructions for updating: Please switch to tf.train.get_global_step</p>\n</blockquote>\n\n<p>Actually, this is not an error, but a warning. It\'s logged exactly because you\'re using <code>contrib</code> package (see <a href=""https://stackoverflow.com/q/44204897/712995"">this discussion</a>, short summary: it\'s deprecated).</p>\n\n<p>You should switch to the core <code>tf.estimator</code> API and that includes everything:</p>\n\n<ul>\n<li><code>tf.estimator.LinearRegressor</code> instead of <code>tf.contrib.learn.LinearRegressor</code></li>\n<li><code>tf.estimator.inputs.numpy_input_fn</code> instead of <code>tf.contrib.learn.io.numpy_input_fn</code></li>\n<li><code>tf.feature_column.numeric_column</code> instead of <code>tf.contrib.layers.real_valued_column</code></li>\n<li>...</li>\n</ul>\n\n<hr>\n\n<p>The reason for not seeing anything with the new <code>Estimator</code> is likely due to <code>eval_input_fn</code> function. Make sure you specify <code>num_epochs=1</code>, otherwise it will loop over the data set again and again during evaluation.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9569}"
417,59056872,"{'items': [{'owner': {'reputation': 11, 'user_id': 11474961}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1615797444, 'answer_id': 66634719, 'question_id': 59056872, 'body': ""<p>Not really a proper answer, but I wanted to add what I have found out on this issue (which is really puzzling me):</p>\n<ul>\n<li>I couldn't find any documentation on it</li>\n<li>using h5 format solved the problem for me: model.save('c:\\tmp\\oneneuron.h5')</li>\n<li>the changed object type really caused problems for me, e.g. model.layers[i].filters would work before but not after saving and reloading.</li>\n</ul>\n<p>My tensorflow version is 2.1</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9569}"
418,67101417,"{'items': [{'owner': {'reputation': 583, 'user_id': 15460480}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1618498463, 'answer_id': 67110806, 'question_id': 67101417, 'body': '<p>This is just a convention TF Hub proposes: &quot;Models for the same task are encouraged to implement a common API so that model consumers can easily exchange them without modifying the code that uses them, even if they come from different publishers&quot; (from <a href=""https://www.tensorflow.org/hub/common_saved_model_apis"" rel=""nofollow noreferrer"">here</a>).</p>\n<p>As you\'ve noted, the publisher of <a href=""https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4"" rel=""nofollow noreferrer"">google/tf2-preview/inception_v3/feature_vector/4</a> decided that input images &quot;are expected to have color values in the range [0,1]&quot;, while the publisher of <a href=""https://tfhub.dev/tensorflow/efficientdet/d1/1"" rel=""nofollow noreferrer"">tensorflow/efficientdet/d1/1</a> decided to add a <code>Rescaling</code> layer to the model itself such that &quot;[a tensor] with values in [0, 255]&quot; can be passed. So ultimately, it\'s up to the publisher how they implement their model. In any case, when using models from tfhub.dev, the expected preprocessing steps will always be documented on the model page.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9569}"
419,57858794,"{'items': [{'owner': {'reputation': 85288, 'user_id': 2097240}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1568643596, 'answer_id': 57958832, 'question_id': 57858794, 'body': '<p>The problem lies in <code>np.vectorize</code>.   </p>\n\n<p>It says it uses numpy\'s broadcasting rules, and it might have something to do with that. </p>\n\n<p>Check it out:</p>\n\n<pre><code>def test_func(value):\n    return value\n\ntest_func = np.vectorize(test_func)\nprint(test_func(2))\nprint(test_func(2).shape)\n</code></pre>\n\n<p>Notice the result is <code>()</code>. So, Keras/Tensorflow is working fine as they are getting the output shape given by numpy. Numpy probably doesn\'t know what it\'s getting as an input (because it doesn\'t work with symbolic tensors).   </p>\n\n<p>Notice how it works normally if you pass an actual numpy array to the function:    </p>\n\n<pre><code>print(test_func(np.array([2])))\nprint(test_func(np.array([2])).shape)\n\n&gt;&gt;&gt;&gt; [2]\n&gt;&gt;&gt;&gt; (1,)\n</code></pre>\n\n<p>But when Keras initializes a model, the actual numbers don\'t exist, and Numpy has no idea of what it will receive when you are ""using"" the model. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9564}"
420,47768298,"{'items': [{'owner': {'reputation': 2196, 'user_id': 8742505}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1513072737, 'answer_id': 47769761, 'question_id': 47768298, 'body': '<p>I think you might have got the order of the arguments to <code>tf.cond</code> confused. The call:</p>\n\n<pre><code>tf.cond(predicate, f, g)\n</code></pre>\n\n<p>is equivalent to ""if <code>predicate</code> is true then evaluate <code>f</code>, otherwise evaluate <code>g</code>""</p>\n\n<p>In your example, since your predicate <code>x &gt; y</code> is false, <code>f2</code> is evaluated</p>\n\n<hr>\n\n<p><strong>Note</strong></p>\n\n<p>Since tensorflow 1.4, <code>tf.cond</code> will accept key-word arguments <code>true_fn</code> and <code>false_fn</code>, so you can avoid any confusion by writing:</p>\n\n<pre><code>tf.cond(predicate, true_fn=f, false_fn=g)\n\n# Or equivalently...\ntf.cond(predicate, false_fn=g, true_fn=f)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9563}"
421,38601452,"{'items': [{'owner': {'reputation': 28028, 'user_id': 5098368}, 'down_vote_count': 0, 'up_vote_count': 50, 'is_accepted': True, 'score': 50, 'creation_date': 1469635082, 'answer_id': 38617951, 'question_id': 38601452, 'body': '<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/max_pool"" rel=""noreferrer"">documentation</a> states:</p>\n\n<blockquote>\n  <p>ksize: A list of ints that has length >= 4. The size of the window for each dimension of the input tensor.</p>\n</blockquote>\n\n<p>In general for images, your input is of shape <code>[batch_size, 64, 64, 3]</code> for an RGB image of 64x64 pixels.</p>\n\n<p>The kernel size <code>ksize</code> will typically be <code>[1, 2, 2, 1]</code> if you have a 2x2 window over which you take the maximum. On the batch size dimension and the channels dimension, <code>ksize</code> is <code>1</code> because we don\'t want to take the maximum over multiple examples, or over multiples channels.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9563}"
422,51923689,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9563}"
423,52300519,"{'items': [{'owner': {'reputation': 161, 'user_id': 5942643}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1547647716, 'answer_id': 54218869, 'question_id': 52300519, 'body': '<p>you can use <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/add_metrics"" rel=""nofollow noreferrer"">tf.contrib.estimator.add_metrics</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9563}"
424,66052849,"{'items': [{'owner': {'reputation': 1, 'user_id': 15886351}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1620647944, 'answer_id': 67470041, 'question_id': 66052849, 'body': '<p>you may also need to</p>\n<pre><code>import pickle5 as pickle\n</code></pre>\n<p>for Python 3.7.9</p>\n'}, {'owner': {'reputation': 2614, 'user_id': 759442}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1618882375, 'answer_id': 67171328, 'question_id': 66052849, 'body': ""<p>I don't know why the original code sample doesn't work.  But this did the trick for me:</p>\n<pre><code>import codecs\nimport dill as pickle\nimport tensorflow as tf\n\ndef dump(obj, filename):\n    &quot;&quot;&quot; Wrapper to dump an object to a file.&quot;&quot;&quot;\n    with tf.io.gfile.GFile(filename, &quot;wb&quot;) as f:\n        pickled = codecs.encode(\n            pickle.dumps(obj, protocol=pickle.HIGHEST_PROTOCOL),\n            &quot;base64&quot;).decode()\n        f.write(pickled)\n\n\ndef load(filename):\n    &quot;&quot;&quot; Wrapper to load an object from a file.&quot;&quot;&quot;\n    with tf.io.gfile.GFile(filename, &quot;rb&quot;) as f:\n        pickled = f.read()\n        return pickle.loads(codecs.decode(pickled, &quot;base64&quot;))\n</code></pre>\n<p>versions: Python 3.7.9, TensorFlow 2.3.0</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9559}"
425,51997426,"{'items': [{'owner': {'reputation': 23445, 'user_id': 1735003}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1535141876, 'answer_id': 52011198, 'question_id': 51997426, 'body': '<p>Simply provide unspecified (<code>None</code>) values for the shape on the axes where the dimension do not match. E.g.</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\n\ntraining_dataset = tf.data.Dataset.from_tensors(np.zeros((64, 64, 64), np.float32)).repeat().batch(4)\nvalidation_dataset = tf.data.Dataset.from_tensors(np.zeros((176, 176, 160), np.float32)).repeat().batch(1)\n\niterator = tf.data.Iterator.from_structure(\n    training_dataset.output_types,\n    <b>tf.TensorShape([None, None, None, None])</b>)\nnext_element = iterator.get_next()\n\ntraining_init_op = iterator.make_initializer(training_dataset)\nvalidation_init_op = iterator.make_initializer(validation_dataset)\n\nsess = tf.InteractiveSession()\nsess.run(training_init_op)\nprint(sess.run(next_element).shape)\nsess.run(validation_init_op)\nprint(sess.run(next_element).shape)\n\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9559}"
426,41048819,"{'items': [{'owner': {'reputation': 105, 'user_id': 6682696}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1543571269, 'answer_id': 53554989, 'question_id': 41048819, 'body': '<p>use only model.ckpt-1234</p>\n\n<p>at least it works for me</p>\n'}, {'owner': {'reputation': 41, 'user_id': 5076077}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1501830911, 'answer_id': 45500430, 'question_id': 41048819, 'body': ""<p>You can restore the model like this:</p>\n\n<pre><code>saver = tf.train.import_meta_graph('./src/models/20170512-110547/model-20170512-110547.meta')\n            saver.restore(sess,'./src/models/20170512-110547/model-20170512-110547.ckpt-250000'))\n</code></pre>\n\n<p>Where the path '/src/models/20170512-110547/' contains three files:</p>\n\n<pre><code>model-20170512-110547.meta\nmodel-20170512-110547.ckpt-250000.index\nmodel-20170512-110547.ckpt-250000.data-00000-of-00001\n</code></pre>\n\n<p>And if in one directory there are more than one checkpoints,eg: there are checkpoint files in  the path \n./20170807-231648/:</p>\n\n<pre><code>checkpoint     \nmodel-20170807-231648-0.data-00000-of-00001   \nmodel-20170807-231648-0.index    \nmodel-20170807-231648-0.meta   \nmodel-20170807-231648-100000.data-00000-of-00001   \nmodel-20170807-231648-100000.index   \nmodel-20170807-231648-100000.meta\n</code></pre>\n\n<p>you can see that there are two checkpoints, so you can use this:</p>\n\n<pre><code>saver =    tf.train.import_meta_graph('/home/tools/Tools/raoqiang/facenet/models/facenet/20170807-231648/model-20170807-231648-0.meta')\n\nsaver.restore(sess,tf.train.latest_checkpoint('/home/tools/Tools/raoqiang/facenet/models/facenet/20170807-231648/'))\n</code></pre>\n""}, {'owner': {'reputation': 1, 'user_id': 7522430}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1486374958, 'answer_id': 42064845, 'question_id': 41048819, 'body': ""<p>I'm new to TF and met the same issue. After reading Yuan Ma's comments, I copied the '.index' to the same 'train\\ckpt' folder together with '.data-00000-of-00001' file. Then it worked! \nSo, the .index file is sufficient when restoring the models.\nI used TF on Win7, r12.</p>\n""}, {'owner': {'reputation': 51, 'user_id': 7335572}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1482514089, 'answer_id': 41305559, 'question_id': 41048819, 'body': '<p>The R12 has changed the checkpoint format. You should save the model in the old format.</p>\n\n<pre><code>import tensorflow as tf\nfrom tensorflow.core.protobuf import saver_pb2\n...\nsaver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\nsaver.save(sess, \'./model.ckpt\', global_step = step)\n</code></pre>\n\n<p>According to the <a href=""https://github.com/tensorflow/tensorflow/releases"" rel=""nofollow noreferrer"">TensorFlow v0.12.0 RC0s release note</a>:</p>\n\n<blockquote>\n  <p>New checkpoint format becomes the default in tf.train.Saver. Old V1\n  checkpoints continue to be readable; controlled by the write_version\n  argument, tf.train.Saver now by default writes out in the new V2\n  format. It significantly reduces the peak memory required and latency\n  incurred during restore.</p>\n</blockquote>\n\n<p>see details in <a href=""http://votec.top/2016/12/24/tensorflow-r12-tf-train-Saver/"" rel=""nofollow noreferrer"">my blog</a>.</p>\n'}, {'owner': {'reputation': 858, 'user_id': 2846777}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': False, 'score': 8, 'creation_date': 1481470000, 'answer_id': 41087789, 'question_id': 41048819, 'body': '<p>I also used Tensorlfow r0.12 and I didn\'t think there is any issue for saving and restoring model. The following is a simple code that you can have a try:</p>\n\n<pre><code>import tensorflow as tf\n\n# Create some variables.\nv1 = tf.Variable(tf.random_normal([784, 200], stddev=0.35), name=""v1"")\nv2 = tf.Variable(tf.random_normal([784, 200], stddev=0.35), name=""v2"")\n\n# Add an op to initialize the variables.\ninit_op = tf.global_variables_initializer()\n\n# Add ops to save and restore all the variables.\nsaver = tf.train.Saver()\n\n# Later, launch the model, initialize the variables, do some work, save the\n# variables to disk.\nwith tf.Session() as sess:\n  sess.run(init_op)\n  # Do some work with the model.\n\n  # Save the variables to disk.\n  save_path = saver.save(sess, ""/tmp/model.ckpt"")\n  print(""Model saved in file: %s"" % save_path)\n\n# Later, launch the model, use the saver to restore variables from disk, and\n# do some work with the model.\nwith tf.Session() as sess:\n  # Restore variables from disk.\n  saver.restore(sess, ""/tmp/model.ckpt"")\n  print(""Model restored."")\n  # Do some work with the model\n</code></pre>\n\n<p>although in r0.12, the checkpoint is stored in multiple files, you can restore it by using the common prefix, which is \'model.ckpt\' in your case.</p>\n'}, {'owner': {'reputation': 363, 'user_id': 4487238}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1481306987, 'answer_id': 41066415, 'question_id': 41048819, 'body': ""<p>OK, I can answer my own question. What I found was that my python script was adding an extra '/' to my path so I was executing:\nsaver.restore(sess,'/path/to/train//model.ckpt-1234')</p>\n\n<p>somehow that was causing a problem with tensorflow.</p>\n\n<p>When I removed it, calling:\nsaver.restore(sess,'/path/to/trian/model.ckpt-1234')</p>\n\n<p>it worked as expected.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9559}"
427,43916019,"{'items': [{'owner': {'reputation': 5186, 'user_id': 992489}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1494534852, 'answer_id': 43925048, 'question_id': 43916019, 'body': ""<p>You're seeing problems because of the weird aliasing model for tensorflow variables. This is why things work with tf.identiy but not without.</p>\n\n<p>If you enable resource variables (use tf.get_variable(..., use_resource=True) to create your variables) you will get the behavior you want.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9559}"
428,53578484,"{'items': [{'owner': {'reputation': 2338, 'user_id': 4834515}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1543766873, 'answer_id': 53582074, 'question_id': 53578484, 'body': '<p>An equivalent function in numpy is <code>np.take</code>, a simple example:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import numpy as np\n\nparams = np.array([4, 3, 5, 7, 6, 8])\n\n# Scalar indices; (output is rank(params) - 1), i.e. 0 here.\nindices = 0\nprint(params[indices])\n\n# Vector indices; (output is rank(params)), i.e. 1 here.\nindices = [0, 1, 4]\nprint(params[indices])  # [4 3 6]\n\n# Vector indices; (output is rank(params)), i.e. 1 here.\nindices = [2, 3, 4]\nprint(params[indices])  # [5 7 6]\n\n# Higher rank indices; (output is rank(params) + rank(indices) - 1), i.e. 2 here\nindices = np.array([[0, 1, 4], [2, 3, 4]])\nprint(params[indices])  # equivalent to np.take(params, indices, axis=0)\n# [[4 3 6]\n# [5 7 6]]\n</code></pre>\n\n<p>In your case, the rank of <code>indices</code> is higher than <code>params</code>, so output is rank(<code>params</code>) + rank(<code>indices</code>) - 1 (i.e. 2 + 3 - 1 = 4, i.e. (32, 1024, 20, 3)). The <code>- 1</code> is because the <code>tf.gather(axis=0)</code> and <code>axis</code> must be rank 0 (so a scalar) at this moment. So the <code>indices</code> takes the elements of the first dimension (<code>axis=0</code>) in a ""fancy"" indexing way.</p>\n\n<p><strong>EDITED</strong>:</p>\n\n<p>In brief, in your case, (if I didn\'t misunderstand the code)</p>\n\n<ul>\n<li><code>point_cloud</code> is (32, 1024, 3), 32 batches 1024 points which have 3\ncoordinates. </li>\n<li><code>nn_idx</code> is (32, 1024, 20), indices of 20 neighbors of\n32 batches 1024 points. The indices are for indexing in <code>point_cloud</code>. </li>\n<li><code>nn_idx+idx_</code> (32, 1024, 20), indices of 20 neighbors of\n32 batches 1024 points. The indices are for indexing in <code>point_cloud_flat</code>.</li>\n<li><code>point_cloud_neighbors</code> finally is (32, 1024,\n20, 3), the same as <code>nn_idx+idx_</code> except that <code>point_cloud_neighbors</code> are their 3 coordinates while <code>nn_idx+idx_</code> are just their indices.</li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9559}"
429,57414387,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1565316346, 'answer_id': 57422682, 'question_id': 57414387, 'body': '<h2><code>activation</code> vs <code>recurrent_activation</code></h2>\n\n<p>If you look at the <a href=""https://colah.github.io/posts/2015-08-Understanding-LSTMs/"" rel=""nofollow noreferrer"">LSTM equations</a>. <code>activation</code> (defaults to <code>sigmoid</code>) refers to the activations used for the gates (i.e. input/forget/output), and <code>recurrent_activation</code> (defaults to <code>tanh</code>) refers to the activation used for other things (e.g. the cell output h). </p>\n\n<p>I can explain why the need to two intuitively. For a gate, a range between 0-1 sounds intuitive because a gate can be either on or off or in the middle, but not negative (thus <code>sigmoid</code>). However the cell output, will be more expressive and leads to less saturation as it ranges between -1 and 1 (thus <code>tanh</code>). It might also help with solving vanishing gradient. But I\'m not entirely sure about that.</p>\n\n<h2><code>use_bias</code></h2>\n\n<p>If <code>use_bias</code> is True, there will be a <code>+b</code> (e.g. <code>i_t = sigma(x_t Ui + h_t-1 Wi + bi)</code>) in the equations. If not there will be no bias (e.g. <code>i_t = sigma(x_t Ui + h_t-1 Wi)</code>). Personally, I always use a bias.</p>\n\n<h2><code>dropout</code> vs <code>recurrent_dropout</code></h2>\n\n<p>The need for <code>dropout</code> and <code>recurrent_dropout</code> is that, applying dropout on time-dimension can be quite disasterious, as you are influencing the memory of the model. However applying <code>dropout</code> on input data, is pretty much what we do day to day with feed-forward models. So,</p>\n\n<ul>\n<li><code>dropout</code>: Applies a dropout mask on the input data (<code>x</code>)</li>\n<li><code>recurrent_dropout</code>: Applices a dropout mask on the previous state data (<code>h_t-1</code>)</li>\n</ul>\n\n<h2><code>implementation</code></h2>\n\n<p>The implementation gives different ways to compute the same thing. The need for the differences might be the different memory requirements.</p>\n\n<ul>\n<li><code>implementation=1</code>\n\n<ul>\n<li>Here, the computations are done as if you would have written the following equations. In other words, do those in four steps.\n\n<ul>\n<li><code>i_t = sigma(x_t Ui + h_t-1 Wi + bi)</code></li>\n<li><code>f_t = sigma(x_t Uf + h_t-1 Wf + bf)</code></li>\n<li><code>o_t = sigma(x_t Uo + h_t-1 Wo + bo)</code></li>\n<li><code>tilde{c}_t = tanh(x_c Uc + h_t-1 Wc + bc)</code></li>\n</ul></li>\n</ul></li>\n<li><code>implementation=anything else</code>\n\n<ul>\n<li>You do the above computations at one go as,\n\n<ul>\n<li><code>z = x_t concat(Ui, Uf, Uo, Uc)</code></li>\n<li><code>z += h_t-1 concat(Wi, Wf, Wo, Wc)</code></li>\n<li><code>z += concat(bi, bf, bo, bc)</code></li>\n<li>apply activations</li>\n</ul></li>\n</ul></li>\n</ul>\n\n<p>So the second implementation is much efficiant as there\'s only two matrix multiplications taking place.</p>\n\n<h2><code>unroll</code></h2>\n\n<p>If true, it will unroll the RNN on the time dimension and do computations without a loop (which will be memory intensive). If false, this will be done with a <code>for</code> loop, which will take longer but less memory intensive.</p>\n\n<p>The source code I referred is found <a href=""https://github.com/tensorflow/tensorflow/blob/e19c354920c3b246dda6598229210a582caaa1a9/tensorflow/python/keras/layers/recurrent.py#L2028"" rel=""nofollow noreferrer"">here</a>. Hope this clarifies it.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9554}"
430,62237432,"{'items': [{'owner': {'reputation': 1, 'user_id': 14267872}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1599965190, 'answer_id': 63866671, 'question_id': 62237432, 'body': '<p>The trainable_variables = trainable_weights. But, they are in the numbers of the matrices of the weights not like the trainable_parameters.</p>\n'}, {'owner': {}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1591601374, 'answer_id': 62257054, 'question_id': 62237432, 'body': '<p>They both are same in Tensorflow version 2.2.0. If you go into the source code of base layer - <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer"" rel=""nofollow noreferrer"">tf.keras.layers.Layer</a> (click on ""View source on GitHub""), you can find the below assignment. <strong>This is the class from which all layers inherit.</strong></p>\n\n<pre><code>  @property\n  @doc_controls.do_not_generate_docs\n  def trainable_variables(self):\n    return self.trainable_weights\n\n  @property\n  @doc_controls.do_not_generate_docs\n  def non_trainable_variables(self):\n    return self.non_trainable_weights\n</code></pre>\n\n<p>Hope this answers your question. Happy Learning.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9554}"
431,57570041,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9554}"
432,45886201,"{'items': [{'owner': {'reputation': 4898, 'user_id': 1896918}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1503684637, 'answer_id': 45887256, 'question_id': 45886201, 'body': ""<p>Here's few changes you need to make.\nFor consistency you can set all return values as variable.</p>\n\n<pre><code># Since step is a scalar, scalar shape [() or [], not None] much be provided \nstep = tf.placeholder(dtype=tf.float32, shape=())\n\n\ndef fn1(step):\n    return tf.constant([1.])\n\n# Here you need to use Variable not constant, since you are modifying the value using placeholder\ndef fn2(step):\n    return tf.Variable([1.+step*EPSILON_DELTA_PHASE1])\n\ndef fn3(step):\n    return tf.Variable([1.+step*EPSILON_DELTA_PHASE2])\n\nepsilon_n = tf.case(\n    pred_fn_pairs=[\n        (tf.less(step, 3e4), lambda : fn1(step)),\n        (tf.less(step, 6e4), lambda : fn2(step)),\n        (tf.less(step, 1e5), lambda : fn3(step))],\n        default=lambda: tf.constant([1e5]),\n    exclusive=False)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9554}"
433,47254265,"{'items': [{'owner': {'reputation': 191, 'user_id': 1345071}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1512485049, 'answer_id': 47656303, 'question_id': 47254265, 'body': '<p>seems like you have to use initializable iterator, not one_shot</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9550}"
434,46418686,"{'items': [{'owner': {'reputation': 12607, 'user_id': 1990169}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1506426124, 'answer_id': 46425583, 'question_id': 46418686, 'body': '<p>You have two variables by the name <code>outputs</code>, i.e., the placeholder and the decoder outputs. Change the name of one variable.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9550}"
435,76380927,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9550}"
436,44540673,"{'items': [{'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1497433134, 'answer_id': 44540957, 'question_id': 44540673, 'body': ""<p>I think that your problem is not with <code>dontknow</code> variable, it is with one of these:</p>\n\n<pre><code>input_placeholder:train_batch_x,\nattr_placeholder:train_class_attr,\nlabel_placeholder:train_batch_y,  \n</code></pre>\n\n<p>When I remove them, I can execute your stuff without any error:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nindex = tf.placeholder(tf.int32, shape=[None], name='index')\ndontknow = np.random.choice(range(1,200), 180)\n\nwith tf.Session() as sess:\n    print sess.run(index, {index:dontknow})\n</code></pre>\n\n<p>Print each of them before doing your <code>sess.run</code> to find which one is the tensor</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9550}"
437,64578310,"{'items': [{'owner': {'reputation': 300, 'user_id': 12859833}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1604484949, 'answer_id': 64678110, 'question_id': 64578310, 'body': '<p>In my functions, I call the writer with <code>tf.io.TFRecordWriter</code>. Try changing your writer and see if it works:</p>\n<pre><code>writer = tf.io.TFRecordWriter\n...\n</code></pre>\n<p>As a further reference, this answer helped me:</p>\n<p><a href=""https://stackoverflow.com/a/60283571"">https://stackoverflow.com/a/60283571</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9546}"
438,59493127,"{'items': [{'owner': {'reputation': 5725, 'user_id': 4592059}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1577398711, 'answer_id': 59494032, 'question_id': 59493127, 'body': ""<p>If you have a prediction shape of <code>(samples of batch, classes)</code> <code>tf.keras.losses.categorical_crossentropy</code> returns the losses in the shape of <code>(samples of batch,)</code>.</p>\n\n<p>So, if your labels are:</p>\n\n<pre><code>[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n</code></pre>\n\n<p>And your predictions are:</p>\n\n<pre><code>[[0.9  0.05 0.05]\n [0.5  0.89 0.6 ]\n [0.05 0.01 0.94]]\n</code></pre>\n\n<p>You will get a loss like:</p>\n\n<pre><code>[0.10536055 0.8046684  0.06187541]\n</code></pre>\n\n<p>In most case your model will use these value's <strong>mean</strong> for the update of your model parameters. So if you manually do the updates you can use:</p>\n\n<pre><code>loss = tf.keras.backend.mean(losses)\n</code></pre>\n""}, {'owner': {'reputation': 85288, 'user_id': 2097240}, 'down_vote_count': 1, 'up_vote_count': 3, 'is_accepted': False, 'score': 2, 'creation_date': 1577393094, 'answer_id': 59493316, 'question_id': 59493127, 'body': '<p>Most usual losses return the original shape minus the last axis.</p>\n\n<p>So, if your original <code>y_pred</code> shape was <code>(samples, ..., ..., classes)</code>, then your resulting shape will be <code>(samples, ..., ...)</code>.</p>\n\n<p>This is probably because Keras may use this tensor in further calculations, for sample weights and maybe other things. </p>\n\n<p>In a custom loop, if these dimensions are useless, you can simply take a <code>K.mean(loss_result)</code> before calculating the gradients. (Where <code>K</code> is either <code>keras.backend</code> or <code>tensorflow.keras.backend</code>)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9546}"
439,61879049,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1591713476, 'answer_id': 62285156, 'question_id': 61879049, 'body': '<p>As per the <a href=""https://www.tensorflow.org/api_docs/python/tf/Module#attributes"" rel=""nofollow noreferrer"">documentation</a>, <code>variables</code> are Sequence of variables owned by this module and its submodules. But when we tested in Tensorflow version 2.2.0, the <code>model.variables</code> is not displaying variables of submodules. </p>\n\n<p>Variables are automatically tracked when assigned to attributes of types inheriting from <code>tf.Module</code>. As you are doing <code>model.saved_vars = tf.Module()</code>, the <code>model.saved_vars</code> submodule becomes a named container for <code>tf.Variables</code>. Since <code>tf.keras.Model</code> is by default a <code>tf.Module</code>, you can assign var directly. But as you rightly mentioned the <code>model.variables</code> must record <code>tf.Variables</code> of submodule <code>model.saved_vars</code>. </p>\n\n<p><strong>Code -</strong> Tried adding another submodule inside <code>model.saved_vars</code> to check if <code>print(model.saved_vars.variables)</code> gives submodule  variables. But still No.</p>\n\n<pre><code>import tensorflow as tf\n\ninputs_1 = tf.keras.Input(shape=(3,))\nvar = tf.Variable(3.0)\nout = var*inputs_1\n\nmodel = tf.keras.Model(inputs=inputs_1, outputs=out)\nprint(model.variables)             # prints []\n\n# Create Module\nmodel.saved_vars = tf.Module()\nmodel.saved_vars.var = var\n\nmodel.var = var\n\nprint(model.saved_vars.variables)\nprint(model.variables)  \n\n# Create Sub Module\nmodel.saved_vars.saved_vars2 = tf.Module()\nmodel.saved_vars.saved_vars2.var2 = var\n\nprint(model.saved_vars.variables)\nprint(model.variables)  \n</code></pre>\n\n<p><strong>Output -</strong></p>\n\n<pre><code>[]\n(&lt;tf.Variable \'Variable:0\' shape=() dtype=float32, numpy=3.0&gt;,)\n[&lt;tf.Variable \'Variable:0\' shape=() dtype=float32, numpy=3.0&gt;]\n(&lt;tf.Variable \'Variable:0\' shape=() dtype=float32, numpy=3.0&gt;,)\n[&lt;tf.Variable \'Variable:0\' shape=() dtype=float32, numpy=3.0&gt;]\n</code></pre>\n\n<p>Will share more information as and when we get. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9546}"
440,55964427,"{'items': [{'owner': {'reputation': 56309, 'user_id': 192373}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1556986359, 'answer_id': 55984420, 'question_id': 55964427, 'body': '<p>tf.keras HDF5 model and Keras HDF5 models are not different things, except for inevitable software version update synchronicity. <a href=""https://www.tensorflow.org/guide/keras"" rel=""nofollow noreferrer"">This is what the official docs say</a>:</p>\n\n<blockquote>\n  <p>tf.keras is TensorFlow\'s implementation of the Keras API specification. This is a high-level API to build and train models that includes first-class support for TensorFlow-specific functionality</p>\n</blockquote>\n\n<p>If the convertor can convert a keras model to tf.lite, it will deliver same results. But tf.lite functionality is more limited than tf.keras. If this feature set is not enough for you, you can still work with tensorflow, and enjoy its other advantages. </p>\n\n<p>May be, it won\'t take too long before your models can run on a smartphone.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9543}"
441,44946189,"{'items': [{'owner': {'reputation': 313, 'user_id': 9018916}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1616584327, 'answer_id': 66779825, 'question_id': 44946189, 'body': '<p>In version 2.4.1 I use <code>tf.constant()</code> instead</p>\n'}, {'owner': {'reputation': 93, 'user_id': 2504541}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1499338619, 'answer_id': 44947002, 'question_id': 44946189, 'body': '<p>It appears that the book I\'m using is a bit out of date. The following code appears to work so far.</p>\n\n<pre><code>v = tf.get_variable(""v"", shape=[1], initializer=tf.zeros_initializer)\n</code></pre>\n\n<p>I will check if it actually works with more code added later.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9543}"
442,56767246,"{'items': [{'owner': {'reputation': 8315, 'user_id': 5154274}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1561541637, 'answer_id': 56769569, 'question_id': 56767246, 'body': '<p>Since the body of your true function is very big, you could create a custom layer like this:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\nclass CustomLayer(tf.keras.layers.Layer):\n\n  def __init__(self, **kwargs):\n    super(CustomLayer, self).__init__()\n    self.pred = kwargs.get(\'pred\', False)\n\n  def call(self, inputs):\n    def true_fn(x):\n      return x + 1.\n\n    return tf.cond(self.pred,\n                   true_fn=lambda: true_fn(inputs),\n                   false_fn=lambda: tf.identity(inputs))\n</code></pre>\n\n<p>Testing:</p>\n\n<pre class=""lang-py prettyprint-override""><code>inputs = tf.placeholder(tf.float32, shape=(None, 1))\npred = tf.placeholder(tf.bool, shape=())\n\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Dense(1, kernel_initializer=tf.initializers.ones))\nmodel.add(CustomLayer(pred=pred))\n\noutputs = model(inputs)\n\nwith tf.Session() as sess:\n  sess.run(tf.global_variables_initializer())\n  print(outputs.eval({inputs: [[1.]], pred: False})) # [[1.]]\n  print(outputs.eval({inputs: [[1.]], pred: True})) # [[2.]]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9543}"
443,56939282,"{'items': [{'owner': {'reputation': 30867, 'user_id': 4790871}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1562804655, 'answer_id': 56980166, 'question_id': 56939282, 'body': '<p>I just realized that the answer to this question is trivial:</p>\n\n<blockquote>\n  <p>Just create a new dataset!</p>\n</blockquote>\n\n<p>In non-eager mode the code below would have degraded in performance because each dataset operation would have been added to the graph and never released, and in non-eager mode we have the initializable iterator to resolve that issue.</p>\n\n<p>However, in eager execution mode tensorflow operations like this are ephemeral, added iterators aren\'t being added to a global graph, they just get created and die when no longer referenced. Win one for TF2.0!</p>\n\n<p>The code below (copy/paste runnable) demonstrates:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport time\n\n\ntf.enable_eager_execution()\n\ninp = np.ones(shape=5000, dtype=np.float32)\n\nt = time.time()\nwhile True:\n    ds = tf.data.Dataset.from_tensors(inp).batch(1)\n    val = next(iter(ds))\n    assert np.all(np.squeeze(val, axis=0) == inp)\n    print(\'Processing time {:.2f}\'.format(time.time() - t))\n    t = time.time()\n</code></pre>\n\n<p>The motivation for the question came on the heels of this issue in 1.14 where creating multiple dataset operations in graph mode under Keras constitutes a memory leak. </p>\n\n<p><a href=""https://github.com/tensorflow/tensorflow/issues/30448"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/30448</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9540}"
444,52597523,"{'items': [{'owner': {'reputation': 1359, 'user_id': 5266767}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1612543156, 'answer_id': 66067127, 'question_id': 52597523, 'body': ""<p>You can create a separate graph, load your checkpoint normally and then transfer weights to your Keras model:</p>\n<pre><code>_graph = tf.Graph()\n_sess = tf.Session(graph=_graph)\n\ntf.saved_model.load(_sess, ['serve'], '../tf1_save/')\n\n_weights_all, _bias_all = [], []\nwith _graph.as_default():\n  for idx, t_var in enumerate(tf.trainable_variables()):\n    # substitue variable_scope with your scope\n    if 'variable_scope/' not in t_var.name: break\n    \n    print(t_var.name)\n    val = _sess.run(t_var)\n    _weights_all.append(val) if idx % 2 == 0 else _bias_all.append(val)\n\nfor layer, (weight, bias) in enumerate(zip(_weights_all, _bias_all)):\n  self.model.layers[layer].set_weights([np.array(weight), np.array(bias)])\n\n</code></pre>\n""}, {'owner': {'reputation': 21, 'user_id': 10537190}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1540145879, 'answer_id': 52918442, 'question_id': 52597523, 'body': ""<p>I'm not sure but maybe you can change <code>keras_model.ckpt.index</code> to <code>keras_model.ckpt</code> for test.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9540}"
445,61762324,"{'items': [{'owner': {'reputation': 1030, 'user_id': 3926152}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1589386933, 'answer_id': 61779748, 'question_id': 61762324, 'body': '<p>it was a bug. \nticket created <a href=""https://github.com/tensorflow/tensorflow/issues/39475"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/39475</a> and fixed.</p>\n'}, {'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1589324685, 'answer_id': 61763507, 'question_id': 61762324, 'body': '<p>TLDR; It\'s probably a bug</p>\n\n<p>If you look at the source, you will see that the <code>divide()</code> method returns <code>x/y</code>, where the other arithmetic operations return the result as, <code>gen_math_ops.xx()</code>.</p>\n\n<p>This is why when you call <code>divide</code> with python variables, you just get a python variable. However if you do the same with any other function, you get a proper <code>tf.Tensor</code>.</p>\n\n<p>You can see what <code>gen_math_ops</code> does by running the following (answer from <a href=""https://stackoverflow.com/questions/36783977/where-is-gen-math-ops-script-in-tensorflow"">this</a>) in Jupyter for example. <code>gen_math_ops</code> is auto-generated so you won\'t find it in the repo. But in short, it executes these operations in a proper TensorFlow environment.</p>\n\n<pre><code>from tensorflow.python.ops import gen_math_ops\ngen_math_ops??\n</code></pre>\n\n<p>The source for <code>tf.divide</code> is <a href=""https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/math_ops.py#L305-L332"" rel=""nofollow noreferrer"">here</a>. It is probably a mistake. So I\'ll leave it up to you to raise an issue on Github to fix that. This is a very subtle bug, and can lead to some cryptic difficult-to-debug issues (in my opinion).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9540}"
446,55425811,"{'items': [{'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1554015761, 'answer_id': 55438598, 'question_id': 55425811, 'body': '<p>Gradient computation occurs inside <code>optimizer.minimize</code> function, so, no explicit use inside loss function is needed. However, your implementation simply lacks an optimizable, trainable variable. </p>\n\n<pre><code>iou = get_iou(masks, predictions)\nmean_iou_loss = tf.Variable(initial_value=-tf.log(tf.reduce_sum(iou)), name=\'loss\', trainable=True)\ntrain_op = tf.train.AdamOptimizer(0.001).minimize(mean_iou_loss)\n</code></pre>\n\n<p>Numerical stability, differentiability and particular implementation aside, this should be enough to use it as a loss function, which will change with iterations.</p>\n\n<p>Also take a look:</p>\n\n<p><a href=""https://arxiv.org/pdf/1902.09630.pdf"" rel=""noreferrer"">https://arxiv.org/pdf/1902.09630.pdf</a></p>\n\n<p><a href=""https://stackoverflow.com/questions/40475246/why-does-one-not-use-iou-for-training"">Why does one not use IOU for training?</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9540}"
447,49949463,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1524296687, 'answer_id': 49953535, 'question_id': 49949463, 'body': '<p>If you read carefully <a href=""https://www.tensorflow.org/api_docs/python/tf/transpose"" rel=""nofollow noreferrer"">the documentation</a> you can find the answer:</p>\n\n<blockquote>\n  <p>Numpy Compatibility</p>\n  \n  <p>In numpy transposes are memory-efficient constant time operations as they simply return a new view of the same data with adjusted strides.</p>\n  \n  <p>TensorFlow does not support strides, so transpose returns a new tensor with the items permuted.</p>\n</blockquote>\n\n<p>Hence <code>tf.transpose</code> returns a new tensor with the desired shape (and therefore is inefficient), so yes, it changes the memory layout.</p>\n\n<p>However, instead of using <code>tf.trasnpose</code> you could use <a href=""https://www.tensorflow.org/api_docs/python/tf/reshape"" rel=""nofollow noreferrer""><code>tf.reshape</code></a> for changing the tensor shape without creating a new one</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9536}"
448,45595419,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1502298319, 'answer_id': 45596727, 'question_id': 45595419, 'body': '<p><code>tf.while_loop</code> accepts a generic callable (python functions defined with <code>def</code>) or lambdas) that must return a boolean tensor.</p>\n\n<p>You can, therefore, chain multiple conditions within the body of the condition using the <a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/control_flow_ops/logical_operators"" rel=""nofollow noreferrer"">logical operators</a>, like <code>tf.logical_and</code>, <code>tf.logical_or</code>, ...</p>\n\n<p>Even <code>body</code> is a general python callable, thus you\'re not limited to lambdas and single statement functions.</p>\n\n<p>Something like that is perfectly acceptable and works well:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\n\ndef body(x):\n    a = tf.random_uniform(shape=[2, 2], dtype=tf.int32, maxval=100)\n    b = tf.constant(np.array([[1, 2], [3, 4]]), dtype=tf.int32)\n    c = a + b\n    return tf.nn.relu(x + c)\n\n\ndef condition(x):\n    x = tf.Print(x, [x])\n    return tf.logical_or(tf.less(tf.reduce_sum(x), 1000), tf.equal(x[0, 0], 15))\n\n\nx = tf.Variable(tf.constant(0, shape=[2, 2]))\nresult = tf.while_loop(condition, body, [x])\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    print(sess.run(result))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9536}"
449,54557468,"{'items': [{'owner': {'reputation': 5763, 'user_id': 9883438}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': False, 'score': 7, 'creation_date': 1549470170, 'answer_id': 54558149, 'question_id': 54557468, 'body': ""<p>Because internally, the embedding layer is nothing but a matrix of size <code>vocab_size x embedding_size</code>. It is a simple lookup table: row <code>n</code> of that matrix stores the vector for word <code>n</code>.</p>\n\n<p>So, if you have e.g. 1000 distinct words, your embedding layer needs to know this number in order to store 1000 vectors (as a matrix).</p>\n\n<p>Don't confuse the internal storage of a layer with its input or output shape.\nThe input shape is <code>(batch_size, sequence_length)</code> where each entry is an integer in the range <code>[0, vocab_size[</code>. For each of these integers the layer will return the corresponding row (which is a vector of size <code>embedding_size</code>) of the internal matrix, so that the output shape becomes <code>(batch_size, sequence_length, embedding_size)</code>.</p>\n""}, {'owner': {'reputation': 5415, 'user_id': 3987085}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1549468392, 'answer_id': 54557596, 'question_id': 54557468, 'body': ""<p>In such setting, the dimensions/shapes of the tensors are the following:</p>\n\n<ul>\n<li>The input tensor has size <code>[batch_size, max_time_steps]</code> such that each element of that tensor can have a value in the range <code>0 to vocab_size-1</code>.</li>\n<li>Then, each of the values from the input tensor pass through an embedding layer, that has a shape <code>[vocab_size, embedding_size]</code>. The output of the embedding layer is of shape <code>[batch_size, max_time_steps, embedding_size]</code>.</li>\n<li>Then, in a typical seq2seq scenario, this <code>3D</code> tensor is the input of a recurrent neural network.</li>\n<li>...</li>\n</ul>\n\n<p>Here's how this is implemented in Tensorflow so you can get a better idea:</p>\n\n<pre><code>inputs = tf.placeholder(shape=(batch_size, max_time_steps), ...)\nembeddings = tf.Variable(shape=(vocab_size, embedding_size], ...)\ninputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n</code></pre>\n\n<p>Now, the output of the embedding lookup table has the <code>[batch_size, max_time_steps, embedding_size]</code> shape.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9536}"
450,54055707,"{'items': [{'owner': {'reputation': 992, 'user_id': 10111931}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1546786226, 'answer_id': 54062683, 'question_id': 54055707, 'body': '<p>Probably tf.py_func produces an unknown shape which Keras cannot infer. We can set the shape of the tensor returned by it using set_shape(your_shape) method and that would help Keras infer the shape of the result.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9536}"
451,54059805,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1546778226, 'answer_id': 54061559, 'question_id': 54059805, 'body': '<p>You can dereference a <code>_ref</code> type using <a href=""https://www.tensorflow.org/api_docs/python/tf/identity"" rel=""nofollow noreferrer""><code>tf.identity</code></a></p>\n\n<pre><code>word_embeddings = tf.identity(word_embeddings)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9532}"
452,56804123,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9532}"
453,64652064,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1604360206, 'answer_id': 64654803, 'question_id': 64652064, 'body': ""<p>It's a special case of multiplication that becomes intersection.</p>\n<p>Consider,</p>\n<pre><code>y_true = [\n[0,1,0],\n[1,1,0],\n[1,0,1]\n]\n</code></pre>\n<p>and</p>\n<pre><code>y_pred = [\n[0,1,1],\n[1,0,0],\n[1,0,1]\n]\n</code></pre>\n<p>then <code>y_true * y_pred</code> will be,</p>\n<pre><code>res = [\n[0,1,0],\n[1,0,0],\n[1,0,1]\n</code></pre>\n<p>Next <code>tf.reduce_sum()</code> gives the sum of all the ones in <code>res</code> (which is intersection). In other words <code>res</code> will have an element set to 1, only if both <code>y_true</code> and <code>y_pred</code> has 1 for that position.</p>\n<pre><code>intersection = 4\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9532}"
454,65696549,"{'items': [{'owner': {'reputation': 3739, 'user_id': 1762295}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1610520257, 'answer_id': 65696889, 'question_id': 65696549, 'body': ""<p>This works\ntf.strings.regex_replace(_string, '[\\xc2\\xa0]', ' ')</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9532}"
455,49969957,"{'items': [{'owner': {'reputation': 634, 'user_id': 9675667}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1524474913, 'answer_id': 49977348, 'question_id': 49969957, 'body': '<p>You can not really plot the Adam learning rate like this, since Adam is a momentum optimizer. The applied gradient for each steps depends on a moving average of the mean and standard deviation of the gradients of previous steps.</p>\n\n<p>In general there is no guarantee for the learning to converge, the raw learning rate <code>alpha</code> itself is not directly changed by Adams. It is only rescaled using the momentums of the gradient. The learning only converges well if mean and standard deviation of the gradient decrease over time when reaching the global minimum, which is often the case for simple neural networks. </p>\n\n<p>For highly stochastic problems however one might still need to implement some form of learning rate decay to suppress \'oscillations\' around the optimal parameters, or at least make them smaller to make sure there really is convergence.</p>\n\n<p>If you really want to understand how exactly this works you might want to read the Adam <a href=""https://arxiv.org/abs/1412.6980"" rel=""nofollow noreferrer"">paper</a>, it is much simpler than it seems on first sight.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9532}"
456,45151015,"{'items': [{'owner': {'reputation': 23445, 'user_id': 1735003}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1500318195, 'answer_id': 45151785, 'question_id': 45151015, 'body': ""<p>This is due to the fact that you are using <code>tf.constant</code>, which in theory shouldn't be affected by inputs.</p>\n\n<p>If you replace your experiments with anything else (e.g. <code>Variables</code>) it works as expected.</p>\n\n<p>When you apply an operator to the constant (be it addition, or even identity), you obtain a new tensor that is not <code>constant</code>, even though they depand on <code>constant</code>s only -- and therefore you obtain the expected behavior.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9527}"
457,47205160,"{'items': [{'owner': {'reputation': 6711, 'user_id': 6708503}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1510721245, 'answer_id': 47299529, 'question_id': 47205160, 'body': '<p>Keras <code>Model</code>s are not yet supported with eager execution, but Keras layers are. Which means that while you can\'t use <code>tf.keras.models.Sequential</code> yet, you could combine layers yourself. See <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/g3doc/guide.md#using-keras-and-the-layers-api"" rel=""nofollow noreferrer"">the user guide</a>.</p>\n\n<p>Hope that helps.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9527}"
458,69370662,"{'items': [{'owner': {'reputation': 328, 'user_id': 4593302}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1632894658, 'answer_id': 69371040, 'question_id': 69370662, 'body': '<p>To print the value, you can convert the tensor to numpy and then print it:</p>\n<pre><code>import tensorflow as tf\n\n# defining a float tensor\na = tf.constant(2.34)\n\n# print tensor\nprint(a)              # output: tf.Tensor(2.34, shape=(), dtype=float32)\n\n# convert to numpy and then print\nprint(a.numpy())      # output: 2.34\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9527}"
459,51077930,"{'items': [{'owner': {'reputation': 8335, 'user_id': 1197860}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1538478410, 'answer_id': 52607107, 'question_id': 51077930, 'body': '<p>For backward compatability, it seems. The link </p>\n\n<p><a href=""https://hackernoon.com/how-tensorflows-tf-image-resize-stole-60-days-of-my-life-aba5eb093f35"" rel=""nofollow noreferrer"">https://hackernoon.com/how-tensorflows-tf-image-resize-stole-60-days-of-my-life-aba5eb093f35</a></p>\n\n<p>suggests to me to always use align_corners=True</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9527}"
460,42728235,"{'items': [{'owner': {'reputation': 706, 'user_id': 1232944}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1491827477, 'answer_id': 43323231, 'question_id': 42728235, 'body': '<p>This was answered in <a href=""https://github.com/tensorflow/tensorflow/issues/8776"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/8776</a></p>\n\n<p>It turns out that <code>tf.case</code> behavior is undefined if, in <code>fn_tensors</code>, the lambdas return a tensor that was created outside of the lambda.  The correct usage is to define the lambdas such that they return a newly-created tensor.</p>\n\n<p>According to the linked Github issue, this usage is required because <code>tf.case</code> must create the tensor itself in order to hook up the tensor\'s inputs to the correct branch of the predicate.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9523}"
461,63578924,"{'items': [{'owner': {'reputation': 14062, 'user_id': 6117017}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1598363256, 'answer_id': 63580288, 'question_id': 63578924, 'body': '<p>Keras does have that operation; what you are actually looking for is called the <code>Concatenate()</code> layer.</p>\n<p>You can have a look here : <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate</a></p>\n<p>You may also want to have a look here: <a href=""https://stackoverflow.com/questions/43196636/how-to-concatenate-two-layers-in-keras/43196972"">How to concatenate two layers in keras?</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9522}"
462,55044905,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9522}"
463,57813806,"{'items': [{'owner': {'reputation': 714, 'user_id': 8725045}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1567734577, 'answer_id': 57814782, 'question_id': 57813806, 'body': ""<p>Just found the issue:\ntf.feature_column.categorical_column_with_hash_bucket() takes an optional argument dtype, which is set to tf.dtypes.string by default.\nHowever, the datatype of my columns is numerical (tf.dtypes.int32).\nThis solved the issue:</p>\n\n<pre><code>tf.feature_column.categorical_column_with_hash_bucket(key='UserID', hash_bucket_size=1000, dtype=tf.dtypes.int32)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9522}"
464,71074606,"{'items': [{'owner': {'reputation': 125, 'user_id': 14986336}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1644926653, 'answer_id': 71126132, 'question_id': 71074606, 'body': '<h2>Preprocessing layer</h2>\n<pre><code> class FIFOLayer(tf.keras.layers.Layer):\n    def __init__(self, window_size, **kwargs):\n        super(FIFOLayer, self).__init__(**kwargs)\n\n        self.window_size = window_size\n\n    def build(self, input_shape):\n        super(FIFOLayer, self).build(input_shape)\n\n        # init FIFO\n        self.queue = self.add_weight(\n            shape=(self.window_size, input_shape[-1]), \n            initializer=tf.keras.initializers.Constant(value=np.nan),\n            trainable=False\n        )\n\n    def call(self, inputs, training):\n        if inputs.shape.rank == 2:\n            assert self.queue.shape[-1] == inputs.shape[-1]\n            timesteps = tf.shape(inputs)[0]\n        elif inputs.shape.rank == 1:\n            inputs = tf.reshape(inputs, (1, self.queue.shape[-1]))\n            timesteps = 1\n        else:\n            raise ValueError(&quot;The rank of inputs is not 2 or 1 !&quot;)\n\n        self.queue.assign(tf.concat(\n            [\n                self.queue[timesteps:self.window_size],\n                inputs\n            ],\n            axis=0,\n        ))\n\n        # generate mask\n        attention_mask = tf.cast(\n            tf.math.reduce_all(\n                tf.math.logical_not(tf.math.is_nan(self.queue)), axis=-1\n            ),\n            dtype=tf.float32,\n        )\n        attention_mask = tf.matmul(\n            attention_mask[..., tf.newaxis],\n            attention_mask[..., tf.newaxis],\n            transpose_b=True,\n        )\n        return self.queue, attention_mask\n\n    def clear(self):\n        self.queue.assign(tf.fill((self.window_size, self.queue.shape[-1]), np.nan))\n</code></pre>\n<h2>Test</h2>\n<pre><code>preprocessing_layer = FIFOLayer(\n    window_size = 10,\n)\ndataset = tf.data.Dataset.from_tensor_slices((\n    np.random.normal(size=(64, 10)),\n    np.ones((64,))\n))\ndataset = dataset.map(lambda x, y: (preprocessing_layer(x), y))\n\nfor features in dataset.take(10):\n    print(features)\n\npreprocessing_layer.clear()\n\nfor features in dataset.take(10):\n    print(features)\n</code></pre>\n'}, {'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1644597002, 'answer_id': 71083438, 'question_id': 71074606, 'body': '<p>Using <code>tf.TensorArray</code>, you can try something like this:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\ntf.random.set_seed(111)\n\nclass FIFOLayer(tf.keras.layers.Layer):\n    def __init__(self, window_size, **kwargs):\n        super(FIFOLayer, self).__init__(**kwargs)\n\n        self.window_size = window_size\n        self.count = 0\n\n    def build(self, input_shape):\n        super(FIFOLayer, self).build(input_shape)\n\n        self.queue_array = tf.TensorArray(dtype=tf.float32, size=self.window_size)\n        self.queue_array = self.queue_array.scatter(tf.range(self.window_size), tf.constant(np.nan)*tf.ones((self.window_size, input_shape[-1])))\n\n    def call(self, inputs, training):\n        timesteps = tf.shape(inputs)[0]\n\n        # check if batch_size is more than queue capacity\n        if timesteps &gt; self.window_size:\n            raise ValueError()\n\n        self.queue_array = self.queue_array.scatter(tf.range(self.window_size), tf.concat([self.queue_array.gather(tf.range(timesteps, self.window_size)), inputs], axis=0))\n        queue_tensor = self.queue_array.stack()\n        self.count += timesteps\n        # 2. feed-forward\n        if self.count &lt; self.window_size:\n            # generate mask\n            attention_mask = tf.cast(\n                tf.math.reduce_all(\n                    tf.math.logical_not(tf.math.is_nan(queue_tensor)), axis=-1\n                ),\n                dtype=tf.float32,\n            )\n            attention_mask = tf.matmul(\n                attention_mask[..., tf.newaxis],\n                attention_mask[..., tf.newaxis],\n                transpose_b=True,\n            )\n            return queue_tensor[tf.newaxis, ...], attention_mask\n        # !!! check overflow\n        elif self.count &gt; self.window_size:\n            self.count = self.window_size\n\n        return queue_tensor[tf.newaxis, ...], None\n\n    @property\n    def is_full(self):\n        return self.count == self.window_size\n\n    def clear(self):\n        self.count = 0\n        shape = tf.shape(self.queue_array.stack())[-1]\n        self.queue_array = tf.TensorArray(dtype=tf.float32, size=self.window_size)\n        self.queue_array = self.queue_array.scatter(tf.range(self.window_size), tf.constant(np.nan)*tf.ones((self.window_size, shape)))\n\nl = FIFOLayer(window_size=10)\nfor i in range(6):\n    x = tf.random.normal((2, 12))\n    y = l(x)\n    print(y)\n\nprint(l.is_full, &quot;\\n\\n&quot;)\n\nl.clear()\n\nprint(l(x))\nprint(l.is_full, &quot;\\n\\n&quot;)\n</code></pre>\n<pre><code>(&lt;tf.Tensor: shape=(1, 10, 12), dtype=float32, numpy=\narray([[[        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [ 0.7558127 ,  1.5447265 ,  1.6315602 , -0.19868968,\n          0.08828261,  0.01711658, -1.8133892 ,  0.12930395,\n          0.47128937,  0.08567389, -1.7158676 , -0.5843805 ],\n        [-0.7664911 , -0.7145203 , -1.089696  ,  0.14649415,\n          0.03585422,  0.9916008 ,  0.9384322 ,  0.34755042,\n         -0.09592161,  0.76490027, -1.2517685 , -1.5740465 ]]],\n      dtype=float32)&gt;, &lt;tf.Tensor: shape=(10, 10), dtype=float32, numpy=\narray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]], dtype=float32)&gt;)\n(&lt;tf.Tensor: shape=(1, 10, 12), dtype=float32, numpy=\narray([[[        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [ 0.7558127 ,  1.5447265 ,  1.6315602 , -0.19868968,\n          0.08828261,  0.01711658, -1.8133892 ,  0.12930395,\n          0.47128937,  0.08567389, -1.7158676 , -0.5843805 ],\n        [-0.7664911 , -0.7145203 , -1.089696  ,  0.14649415,\n          0.03585422,  0.9916008 ,  0.9384322 ,  0.34755042,\n         -0.09592161,  0.76490027, -1.2517685 , -1.5740465 ],\n        [-0.31995258, -0.43669155, -0.28932425, -0.06870204,\n         -0.01291991,  1.171546  ,  0.75079876, -0.7693662 ,\n          0.05902815,  0.60606545, -1.1038904 , -0.99837613],\n        [-0.6687948 ,  0.22192897, -0.02249479, -0.08962449,\n          1.2408841 ,  0.119805  , -0.53699344,  1.020805  ,\n          0.9610218 ,  0.6133564 , -0.4358486 ,  2.733222  ]]],\n      dtype=float32)&gt;, &lt;tf.Tensor: shape=(10, 10), dtype=float32, numpy=\narray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.]], dtype=float32)&gt;)\n(&lt;tf.Tensor: shape=(1, 10, 12), dtype=float32, numpy=\narray([[[        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [ 0.7558127 ,  1.5447265 ,  1.6315602 , -0.19868968,\n          0.08828261,  0.01711658, -1.8133892 ,  0.12930395,\n          0.47128937,  0.08567389, -1.7158676 , -0.5843805 ],\n        [-0.7664911 , -0.7145203 , -1.089696  ,  0.14649415,\n          0.03585422,  0.9916008 ,  0.9384322 ,  0.34755042,\n         -0.09592161,  0.76490027, -1.2517685 , -1.5740465 ],\n        [-0.31995258, -0.43669155, -0.28932425, -0.06870204,\n         -0.01291991,  1.171546  ,  0.75079876, -0.7693662 ,\n          0.05902815,  0.60606545, -1.1038904 , -0.99837613],\n        [-0.6687948 ,  0.22192897, -0.02249479, -0.08962449,\n          1.2408841 ,  0.119805  , -0.53699344,  1.020805  ,\n          0.9610218 ,  0.6133564 , -0.4358486 ,  2.733222  ],\n        [-0.33772066,  0.80799913, -0.00896128,  1.606288  ,\n          1.1561627 ,  0.17252289,  0.2451608 ,  1.4633939 ,\n         -0.9294784 ,  0.42795137, -0.3016553 , -1.1823792 ],\n        [ 0.30927372,  0.3482721 ,  1.0262096 , -0.97228396,\n         -0.55333287, -0.7914886 ,  1.0115404 , -0.5656188 ,\n          0.30958036, -0.8476673 ,  2.4919312 ,  0.9093976 ]]],\n      dtype=float32)&gt;, &lt;tf.Tensor: shape=(10, 10), dtype=float32, numpy=\narray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]], dtype=float32)&gt;)\n(&lt;tf.Tensor: shape=(1, 10, 12), dtype=float32, numpy=\narray([[[        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [        nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan,\n                 nan,         nan,         nan,         nan],\n        [ 0.7558127 ,  1.5447265 ,  1.6315602 , -0.19868968,\n          0.08828261,  0.01711658, -1.8133892 ,  0.12930395,\n          0.47128937,  0.08567389, -1.7158676 , -0.5843805 ],\n        [-0.7664911 , -0.7145203 , -1.089696  ,  0.14649415,\n          0.03585422,  0.9916008 ,  0.9384322 ,  0.34755042,\n         -0.09592161,  0.76490027, -1.2517685 , -1.5740465 ],\n        [-0.31995258, -0.43669155, -0.28932425, -0.06870204,\n         -0.01291991,  1.171546  ,  0.75079876, -0.7693662 ,\n          0.05902815,  0.60606545, -1.1038904 , -0.99837613],\n        [-0.6687948 ,  0.22192897, -0.02249479, -0.08962449,\n          1.2408841 ,  0.119805  , -0.53699344,  1.020805  ,\n          0.9610218 ,  0.6133564 , -0.4358486 ,  2.733222  ],\n        [-0.33772066,  0.80799913, -0.00896128,  1.606288  ,\n          1.1561627 ,  0.17252289,  0.2451608 ,  1.4633939 ,\n         -0.9294784 ,  0.42795137, -0.3016553 , -1.1823792 ],\n        [ 0.30927372,  0.3482721 ,  1.0262096 , -0.97228396,\n         -0.55333287, -0.7914886 ,  1.0115404 , -0.5656188 ,\n          0.30958036, -0.8476673 ,  2.4919312 ,  0.9093976 ],\n        [-0.44241378, -0.6971805 , -0.37439492,  1.0154608 ,\n         -0.34494257,  0.1988212 , -0.9541314 , -0.44339198,\n          0.162457  , -0.31033182, -0.34568167,  1.0341203 ],\n        [-0.89020306, -0.8646532 ,  0.13348487, -0.6604107 ,\n          0.07642484,  1.3407826 ,  0.79119945, -0.7598532 ,\n          0.85146165, -0.2791065 , -0.4600736 ,  0.809218  ]]],\n      dtype=float32)&gt;, &lt;tf.Tensor: shape=(10, 10), dtype=float32, numpy=\narray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n       [0., 0., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)&gt;)\n(&lt;tf.Tensor: shape=(1, 10, 12), dtype=float32, numpy=\narray([[[ 7.5581270e-01,  1.5447265e+00,  1.6315602e+00, -1.9868968e-01,\n          8.8282607e-02,  1.7116580e-02, -1.8133892e+00,  1.2930395e-01,\n          4.7128937e-01,  8.5673891e-02, -1.7158676e+00, -5.8438051e-01],\n        [-7.6649112e-01, -7.1452028e-01, -1.0896960e+00,  1.4649415e-01,\n          3.5854220e-02,  9.9160081e-01,  9.3843222e-01,  3.4755042e-01,\n         -9.5921606e-02,  7.6490027e-01, -1.2517685e+00, -1.5740465e+00],\n        [-3.1995258e-01, -4.3669155e-01, -2.8932425e-01, -6.8702042e-02,\n         -1.2919909e-02,  1.1715460e+00,  7.5079876e-01, -7.6936620e-01,\n          5.9028149e-02,  6.0606545e-01, -1.1038904e+00, -9.9837613e-01],\n        [-6.6879481e-01,  2.2192897e-01, -2.2494787e-02, -8.9624494e-02,\n          1.2408841e+00,  1.1980500e-01, -5.3699344e-01,  1.0208050e+00,\n          9.6102178e-01,  6.1335641e-01, -4.3584859e-01,  2.7332220e+00],\n        [-3.3772066e-01,  8.0799913e-01, -8.9612845e-03,  1.6062880e+00,\n          1.1561627e+00,  1.7252289e-01,  2.4516080e-01,  1.4633939e+00,\n         -9.2947841e-01,  4.2795137e-01, -3.0165529e-01, -1.1823792e+00],\n        [ 3.0927372e-01,  3.4827209e-01,  1.0262096e+00, -9.7228396e-01,\n         -5.5333287e-01, -7.9148859e-01,  1.0115404e+00, -5.6561881e-01,\n          3.0958036e-01, -8.4766728e-01,  2.4919312e+00,  9.0939760e-01],\n        [-4.4241378e-01, -6.9718051e-01, -3.7439492e-01,  1.0154608e+00,\n         -3.4494257e-01,  1.9882120e-01, -9.5413142e-01, -4.4339198e-01,\n          1.6245700e-01, -3.1033182e-01, -3.4568167e-01,  1.0341203e+00],\n        [-8.9020306e-01, -8.6465323e-01,  1.3348487e-01, -6.6041070e-01,\n          7.6424837e-02,  1.3407826e+00,  7.9119945e-01, -7.5985318e-01,\n          8.5146165e-01, -2.7910650e-01, -4.6007359e-01,  8.0921799e-01],\n        [-6.7833281e-01,  4.7877081e-02, -2.0416839e+00, -1.5634586e+00,\n         -5.1782840e-01,  5.2898288e-01, -1.4573561e+00,  4.6455118e-01,\n         -3.2871577e-01, -1.5697428e+00,  1.4454672e-01,  8.2387424e-01],\n        [ 2.5552011e-03,  1.2834518e+00,  4.1382611e-01,  1.6535892e+00,\n          7.8654990e-02, -1.2952465e-01,  3.6811054e-01,  1.1675907e+00,\n          9.6434945e-01, -4.2399967e-01, -1.3700709e-01, -5.2056974e-01]]],\n      dtype=float32)&gt;, None)\n(&lt;tf.Tensor: shape=(1, 10, 12), dtype=float32, numpy=\narray([[[-3.1995258e-01, -4.3669155e-01, -2.8932425e-01, -6.8702042e-02,\n         -1.2919909e-02,  1.1715460e+00,  7.5079876e-01, -7.6936620e-01,\n          5.9028149e-02,  6.0606545e-01, -1.1038904e+00, -9.9837613e-01],\n        [-6.6879481e-01,  2.2192897e-01, -2.2494787e-02, -8.9624494e-02,\n          1.2408841e+00,  1.1980500e-01, -5.3699344e-01,  1.0208050e+00,\n          9.6102178e-01,  6.1335641e-01, -4.3584859e-01,  2.7332220e+00],\n        [-3.3772066e-01,  8.0799913e-01, -8.9612845e-03,  1.6062880e+00,\n          1.1561627e+00,  1.7252289e-01,  2.4516080e-01,  1.4633939e+00,\n         -9.2947841e-01,  4.2795137e-01, -3.0165529e-01, -1.1823792e+00],\n        [ 3.0927372e-01,  3.4827209e-01,  1.0262096e+00, -9.7228396e-01,\n         -5.5333287e-01, -7.9148859e-01,  1.0115404e+00, -5.6561881e-01,\n          3.0958036e-01, -8.4766728e-01,  2.4919312e+00,  9.0939760e-01],\n        [-4.4241378e-01, -6.9718051e-01, -3.7439492e-01,  1.0154608e+00,\n         -3.4494257e-01,  1.9882120e-01, -9.5413142e-01, -4.4339198e-01,\n          1.6245700e-01, -3.1033182e-01, -3.4568167e-01,  1.0341203e+00],\n        [-8.9020306e-01, -8.6465323e-01,  1.3348487e-01, -6.6041070e-01,\n          7.6424837e-02,  1.3407826e+00,  7.9119945e-01, -7.5985318e-01,\n          8.5146165e-01, -2.7910650e-01, -4.6007359e-01,  8.0921799e-01],\n        [-6.7833281e-01,  4.7877081e-02, -2.0416839e+00, -1.5634586e+00,\n         -5.1782840e-01,  5.2898288e-01, -1.4573561e+00,  4.6455118e-01,\n         -3.2871577e-01, -1.5697428e+00,  1.4454672e-01,  8.2387424e-01],\n        [ 2.5552011e-03,  1.2834518e+00,  4.1382611e-01,  1.6535892e+00,\n          7.8654990e-02, -1.2952465e-01,  3.6811054e-01,  1.1675907e+00,\n          9.6434945e-01, -4.2399967e-01, -1.3700709e-01, -5.2056974e-01],\n        [ 1.3070145e+00, -6.7240512e-01,  1.9308577e+00,  1.7688200e-03,\n          3.0533668e-01,  6.5813893e-01,  5.2471739e-01,  2.1659613e+00,\n         -8.7725663e-01,  3.5695407e-01, -1.2751107e+00, -7.7276069e-01],\n        [-4.3180370e-01, -1.1814500e+00,  2.4167557e-01,  5.7490116e-01,\n          5.6998456e-01, -7.4528801e-01, -9.1826969e-01, -7.3694932e-01,\n         -1.2400552e+00,  1.6947891e+00, -2.6127639e-01,  7.8419834e-01]]],\n      dtype=float32)&gt;, None)\nTrue \n\n\n(&lt;tf.Tensor: shape=(1, 10, 12), dtype=float32, numpy=\narray([[[           nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan],\n        [           nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan],\n        [           nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan],\n        [           nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan],\n        [           nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan],\n        [           nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan],\n        [           nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan],\n        [           nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan,\n                    nan,            nan,            nan,            nan],\n        [ 1.3070145e+00, -6.7240512e-01,  1.9308577e+00,  1.7688200e-03,\n          3.0533668e-01,  6.5813893e-01,  5.2471739e-01,  2.1659613e+00,\n         -8.7725663e-01,  3.5695407e-01, -1.2751107e+00, -7.7276069e-01],\n        [-4.3180370e-01, -1.1814500e+00,  2.4167557e-01,  5.7490116e-01,\n          5.6998456e-01, -7.4528801e-01, -9.1826969e-01, -7.3694932e-01,\n         -1.2400552e+00,  1.6947891e+00, -2.6127639e-01,  7.8419834e-01]]],\n      dtype=float32)&gt;, &lt;tf.Tensor: shape=(10, 10), dtype=float32, numpy=\narray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]], dtype=float32)&gt;)\ntf.Tensor(False, shape=(), dtype=bool) \n</code></pre>\n<p>On a side note, using <code>tf.queue.FIFOQueue</code> is really slow.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9522}"
465,55718702,"{'items': [{'owner': {'reputation': 455, 'user_id': 3943508}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1571629212, 'answer_id': 58479508, 'question_id': 55718702, 'body': '<p>According to <a href=""https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/layers/batch_normalization"" rel=""nofollow noreferrer"">the official doc</a></p>\n\n<blockquote>\n  <p>In particular, tf.control_dependencies(tf.GraphKeys.UPDATE_OPS) should not be used (consult the tf.keras.layers.batch_normalization documentation).</p>\n</blockquote>\n\n<p>You should collect the update ops from <code>tf.keras.layers.BatchNormalization()</code> as follows. See <a href=""https://github.com/tensorflow/tensorflow/issues/16102#issuecomment-394527301"" rel=""nofollow noreferrer"">discussion</a></p>\n\n<pre><code>...\nbatch_normalizer = tf.keras.layers.BatchNormalization()\nnormalized_tensor = batch_normalizer(raw_tensor, training=is_training)\ntotal_loss = ... # Get loss tensor\noptimizer = tf.train.AdamOptimizer()\nminimization_op = optimizer.minimize(total_loss, global_step=tf.get_global_step())\n# Get ""regular update ops""\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n# Get BatchNorm updates\nupdate_ops.extend(batch_normalizer.updates)\n# Group two sets of operations to form a train_op\ntrain_ops = tf.group([minimization_op, update_ops])\n</code></pre>\n'}, {'owner': {'reputation': 407, 'user_id': 9325099}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1562623696, 'answer_id': 56943090, 'question_id': 55718702, 'body': '<p>The answer is no, it\'s not needed. It is mentioned in the current documentation at <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization</a>.</p>\n\n<p>On a side note, I\'m currently using tf.layers.BatchNormalization WITH explicit dependence on UPDATE_OPS (TF version 1.10) because tf.layers.keras.BatchNormalization seems bugged to me. My model validation was failing while using tf.layers.keras.BatchNormalization. Maybe it has been fixed in the recent update.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9518}"
466,61743921,"{'items': [{'owner': {'reputation': 16, 'user_id': 13523001}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1589260351, 'answer_id': 61744266, 'question_id': 61743921, 'body': '<p>Keras is a high level API. But if you want to use only Tensorflow then you have to implement the architecture using low level API. You can certainly implement but you have to code it yourself to build all the convolutional layers and dense layer by yourself. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9518}"
467,57170737,"{'items': [{'owner': {'reputation': 1, 'user_id': 18664188}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1648819522, 'answer_id': 71707647, 'question_id': 57170737, 'body': '<p>It is because you are some how using the full interpreter of tf.\nsee here</p>\n<pre><code>interpreter = tf.lite.Interpreter(model_path=&quot;model.tflite&quot;).\n</code></pre>\n<p>What you can do is install</p>\n<pre><code>python3 -m pip install tflite-runtime\n</code></pre>\n<p>and use</p>\n<pre><code>import tflite_runtime.interpreter as tflite\ninterpreter = tflite.Interpreter(model_path=args.model_file)\n</code></pre>\n<p>and you should be able to run things fine.</p>\n<p>I hope it helps!</p>\n'}, {'owner': {}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1615174694, 'answer_id': 66524006, 'question_id': 57170737, 'body': '<p>TFLite doesn\'t support Nvidia GPUs as per this <a href=""https://github.com/tensorflow/tensorflow/issues/34536"" rel=""nofollow noreferrer"">link</a></p>\n'}, {'owner': {'reputation': 149, 'user_id': 12516289}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1614746745, 'answer_id': 66450945, 'question_id': 57170737, 'body': '<p>Does your Jetson Nano support OpenCL?\nIf it does, you can use OpenCL delegate with TFLite.\n<a href=""https://www.tensorflow.org/lite/guide/build_cmake#opencl_gpu_delegate"" rel=""nofollow noreferrer"">https://www.tensorflow.org/lite/guide/build_cmake#opencl_gpu_delegate</a></p>\n'}, {'owner': {'reputation': 66, 'user_id': 14376993}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1601606639, 'answer_id': 64165576, 'question_id': 57170737, 'body': '<p>It seems to be available on the jetson nano according to <a href=""https://forums.developer.nvidia.com/t/official-tensorflow-for-jetson-nano/71770"" rel=""nofollow noreferrer"">this</a> recent thread.\nBut it\'s look like a custom build, try it instead of tensorflow lite.</p>\n<p>If you already installed it maybe ask for nvidia developper if the release is supposed to support GPU.</p>\n<p>Or you can Install the nvidia custom tensorflow this way.</p>\n<p><strong>Python 3.6+JetPack4.4</strong></p>\n<pre class=""lang-sh prettyprint-override""><code>sudo apt-get install libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev liblapack-dev libblas-dev gfortran\nsudo apt-get install python3-pip\nsudo pip3 install -U pip\nsudo pip3 install -U pip testresources setuptools numpy==1.16.1 future==0.17.1 mock==3.0.5 h5py==2.9.0 keras_preprocessing==1.0.5 keras_applications==1.0.8 gast==0.2.2 futures protobuf pybind11\n# TF-2.x\n$ sudo pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v44 tensorflow==2.2.0+nv20.8\n# TF-1.15\n$ sudo pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v44 tensorflow&lt;2\n</code></pre>\n<p><strong>Python 3.6+JetPack4.3</strong></p>\n<pre class=""lang-sh prettyprint-override""><code>$ sudo apt-get install libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev\n$ sudo apt-get install python3-pip\n$ sudo pip3 install -U pip\n$ sudo pip3 install -U numpy grpcio absl-py py-cpuinfo psutil portpicker six mock requests gast h5py astor termcolor protobuf keras-applications keras-preprocessing wrapt google-pasta\n# TF-2.x\n$ sudo pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v43 tensorflow==2.1.0+nv20.3\n# TF-1.15\n$ sudo pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v43 tensorflow==1.15.2+nv20.3\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9518}"
468,62395187,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9518}"
469,68434740,"{'items': [{'owner': {'reputation': 2532, 'user_id': 9579075}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1626697440, 'answer_id': 68440457, 'question_id': 68434740, 'body': '<p>You need to pass the variables to the <code>tape.gradient</code> call like this</p>\n<p><code>grad = tape.gradient(pred, model.trainable_variables)</code></p>\n<p>Edit:</p>\n<p>If you want to compute the gradient wrt to a tensor, you will need explicitly ask the tape to trace the operations on the said tensor.</p>\n<pre class=""lang-py prettyprint-override""><code>ta = tf.cast(input1,tf.float32) #ta in 2 dimension, tb in 3 dimension\ntb = tf.cast(input2,tf.float32)\ninp_tensor_list = [ta,tb]\n\nwith tf.GradientTape() as tape:\n    tape.watch(ta) \n    tape.watch(tb)\n    pred = model(inp_tensor_list)  #pred return correct value here\ngrad = tape.gradient(pred, inp_tensor_list)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9518}"
470,53033780,"{'items': [{'owner': {'reputation': 11854, 'user_id': 5140223}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1540760157, 'answer_id': 53035991, 'question_id': 53033780, 'body': '<p>I believe this is not possible. However, you could instead use <a href=""https://www.tensorflow.org/api_docs/python/tf/stack"" rel=""nofollow noreferrer"">tf.stack</a> to stack the operations\' output tensors, and then use <a href=""https://www.tensorflow.org/api_docs/python/tf/gather"" rel=""nofollow noreferrer"">tf.gather</a> to obtain the desired output.</p>\n\n<p>Here you have an example:</p>\n\n<pre><code>import tensorflow as tf\n\n\ndef condition(i, x):\n    return tf.less(i, 10)\n\n\ndef body_1(my_ops):\n    def b(i, x):\n        stacked_results = tf.stack([op(x) for op in my_ops])\n        gather_idx = tf.mod(i, 2)\n        return [i + 1, tf.gather(stacked_results, gather_idx)]\n\n    return b\n\n\ndef body_2(my_ops):\n    def b(i, x):\n        nb_ops = len(my_ops)\n        pred_fn_pairs = [(tf.equal(tf.mod(i, nb_ops), 0), lambda: my_ops[0](x)),\n                         (tf.equal(tf.mod(i, nb_ops), 1), lambda: my_ops[1](x))]\n        result = tf.case(pred_fn_pairs)\n        return [i + 1, result]\n\n    return b\n\n\nmy_ops = [lambda x: tf.Print(x + 1, [x, 1]),\n          lambda x: tf.Print(x + 2, [x, 2])]\ni = tf.constant(0)\nx = tf.constant(0)\nr = tf.while_loop(condition, body_2(my_ops), [i, x])  # See the difference with body_1\n\nwith tf.Session() as sess:\n    i, x = sess.run(r)\n    print(x)  # Prints 15 = 5*2 + 5*1\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9513}"
471,68367159,"{'items': [{'owner': {'reputation': 811, 'user_id': 13610744}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1626222095, 'answer_id': 68370618, 'question_id': 68367159, 'body': '<p>One can simply use an arrow function.</p>\n<pre class=""lang-js prettyprint-override""><code>const tf = require(\'@tensorflow/tfjs-node\');\n\nfunction* dataGenerator(test) {\n    let len = test.length\n    let idx = 0\n    while (idx &lt; len) {\n        idx++\n        console.log(idx)\n    }\n}\n\nlet trainDs = tf.data.generator(() =&gt; dataGenerator([\'hi\', \'hi2\', \'hi3\']));\n\ntrainDs.forEachAsync(e =&gt; console.log(e));\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9513}"
472,52802359,"{'items': [{'owner': {'reputation': 1330, 'user_id': 8315956}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1539544356, 'answer_id': 52806192, 'question_id': 52802359, 'body': '<p>There are two problems.\nFirst the problem in Tensorflow code. Change <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py#L593"" rel=""nofollow noreferrer"">this line</a> to:</p>\n\n<pre><code>var.indices.set_shape(tensor_shape.TensorShape([None, shape[0]]))\n</code></pre>\n\n<p>Another small problem in your code. You have to use int64 type for indexing variable:</p>\n\n<pre><code>i = tf.constant(1, dtype=tf.int64)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9513}"
473,73198391,"{'items': [{'owner': {'reputation': 1, 'user_id': 13098227}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1662574830, 'answer_id': 73640023, 'question_id': 73198391, 'body': '<p>After</p>\n<pre><code>!pip install git+https://github.com/tensorflow/docs\n</code></pre>\n<p>Open (if you are using Colab)</p>\n<pre><code>/usr/local/lib/python3.7/dist-packages/tensorflow_docs/api_generator/reference_resolver.py\n</code></pre>\n<p>and add <code>from __future__ import annotations</code> at the BEGINNING OF THE FILE and then import</p>\n<pre><code>import tensorflow_docs as tfdocs\nimport tensorflow_docs.modeling\nimport tensorflow_docs.plots\n</code></pre>\n<p>Source: <a href=""https://github.com/tensorflow/docs/pull/2116/files"" rel=""nofollow noreferrer"">https://github.com/tensorflow/docs/pull/2116/files</a></p>\n'}, {'owner': {'reputation': 58, 'user_id': 15895688}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1662044275, 'answer_id': 73571500, 'question_id': 73198391, 'body': ""<p>I assuming you are using Google Colab. As I struggled the same with Google Colab since the default Google Colab is in Python 3.7. Here's what I did to make Google Colab upgrade to Python 3.9</p>\n<pre><code>!wget -O mini.sh https://repo.anaconda.com/miniconda/Miniconda3-py39_4.9.2-Linux-x86_64.sh\n!chmod +x mini.sh\n!bash ./mini.sh -b -f -p /usr/local\n!conda install -q -y jupyter\n!conda install -q -y google-colab -c conda-forge\n!python -m ipykernel install --name &quot;py39&quot; --user\n</code></pre>\n<p>Hope this helps you to move on as I did!</p>\n""}, {'owner': {'reputation': 7656, 'user_id': 17328}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1661153799, 'answer_id': 73441629, 'question_id': 73198391, 'body': '<pre><code>---&gt; 88       physical_path: Optional[dict[str, str]] = None,\n     89   ):\n     90     &quot;&quot;&quot;Initializes a Reference Resolver.\n\nTypeError: \'type\' object is not subscriptable\n</code></pre>\n<p>This error is caused by the <code>dict[str, str]</code> line. This is <a href=""https://peps.python.org/pep-0585/"" rel=""nofollow noreferrer"">PEP-585</a> compliant code that works in Python 3.9, but it looks like Colab is still running Python 3.7, so it\'s failing.</p>\n<p>Feel free to send us PRs adding <code>from __future__ import annotations</code> to the affected files if you spot these, but ultimately we run 3.9 internally at Google so these may keep sneaking through.</p>\n<p>Some other ideas that you might be able to make work:</p>\n<ul>\n<li>Use a Python 3.9 kernel for colab (e.g. via Google Cloud)</li>\n<li>Strip out type hints with something like <a href=""https://pypi.org/project/strip-hints/"" rel=""nofollow noreferrer""><code>strip-hints</code></a></li>\n</ul>\n'}, {'owner': {'reputation': 66, 'user_id': 10682223}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1661009877, 'answer_id': 73427982, 'question_id': 73198391, 'body': '<p>You can try this:</p>\n<pre><code>!pip install -q git+https://github.com/MJAHMADEE/docs\nimport tensorflow_docs as tfdocs   \nimport tensorflow_docs.modeling   \nimport tensorflow_docs.plots\n</code></pre>\n'}, {'owner': {'reputation': 31, 'user_id': 9552900}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1660674653, 'answer_id': 73378687, 'question_id': 73198391, 'body': ""<p>I had also a problem with a script using tensor flow in colab, that had been running for months without any problem.\nSuddenly I start having the same error as you mention:</p>\n<pre><code>TypeError: 'type' object is not subscriptable\n</code></pre>\n<p>The script finished in the following line, at the top of the script:</p>\n<pre><code>from tensorflow_docs.vis import embed\n</code></pre>\n<p>I have just commented the line, and the script started working again... :</p>\n<pre><code># from tensorflow_docs.vis import embed\n</code></pre>\n<p>I hope this may help some of you having the same error.</p>\n""}, {'owner': {'reputation': 3244, 'user_id': 14774959}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1659385783, 'answer_id': 73199280, 'question_id': 73198391, 'body': ""<p>I have this problem too, but sadly I don't have a solution. However, this is what I've tried so far:</p>\n<ul>\n<li>Downgrading to Tensorflow 2.6</li>\n<li>Installing a previous version of <code>tensorflow_docs</code> with <code>!pip install git+https://github.com/tensorflow/docs@my_version</code> choosing as <code>my_version</code> a commit from a few weeks ago.</li>\n<li>Installing <code>tensorflow_docs</code> in a different way, first downloading it with <code>!git clone https://github.com/tensorflow/docs</code> and then installing it via <code>!pip install docs/</code></li>\n</ul>\n<p>All without success.</p>\n<p>Anyway from the error it seems it is a problem of the <code>tensorflow_docs</code>'<code>ReferenceResolver</code>, it looks like it is not able to find the library. However with the following instruction <code>tensorflow-docs</code> is found:</p>\n<pre><code>!pip3 freeze | grep tensorflow\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9513}"
474,61031226,"{'items': [{'owner': {'reputation': 3098, 'user_id': 9936228}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1586071087, 'answer_id': 61039263, 'question_id': 61031226, 'body': '<p>I think you can follow this example <a href=""https://www.tensorflow.org/tutorials/images/classification"" rel=""nofollow noreferrer"">here</a> and <a href=""https://colab.sandbox.google.com/github/tensorflow/examples/blob/master/community/en/flowers_tf_lite.ipynb"" rel=""nofollow noreferrer"">this example</a>. These two simple examples demonstrate how to use input data pipeline. Hope This helps. Thanks!</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9509}"
475,64119612,"{'items': [{'owner': {'reputation': 6942, 'user_id': 3015734}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1601382763, 'answer_id': 64119717, 'question_id': 64119612, 'body': '<p>I figured it out... There is a <a href=""https://www.tensorflow.org/api_docs/python/tf/strings/reduce_join"" rel=""nofollow noreferrer""><code>tf.strings.reduce_join</code></a> that can accomplish this:</p>\n<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; tf.strings.reduce_join(x, axis=1)\n&lt;tf.Tensor: shape=(25,), dtype=string, numpy=\narray([b\'721041\', b\'4506\', b\'0157\', b\'84665\', b\'407401\', b\'313472\',\n       b\'712117\', b\'423512\', b\'446355\', b\'60415\', b\'78374\', b\'643070\',\n       b\'21732\', b\'77627\', b\'847361\', b\'36314\', b\'17660\', b\'5421\',\n       b\'4873\', b\'7442\', b\'54767\', b\'058566\', b\'578101\', b\'646731\',\n       b\'718202\'], dtype=object)&gt;\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9508}"
476,48169791,"{'items': [{'owner': {'reputation': 3026, 'user_id': 8676953}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1515506599, 'answer_id': 48169914, 'question_id': 48169791, 'body': ""<p>In your example <code>feature_map</code> doesn't have a value as it's an operation. Therefore you can't change it's value as such. What you can do, is pass another value in as part of the <code>feed_dict</code> parameter of <code>session.run</code>.</p>\n\n<p>So for example if your feature_map is followed by an operation like this:</p>\n\n<pre><code>other_op = tf.gradient(feature_map, X)\n</code></pre>\n\n<p>Then you can change the value passed in to that op (<code>gradient</code> in this case) via <code>feed_dict</code> like so:</p>\n\n<pre><code>session.run(other_op, feed_dict={feature_map: &lt;new value&gt;})\n</code></pre>\n""}, {'owner': {'reputation': 52739, 'user_id': 712995}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1515506547, 'answer_id': 48169888, 'question_id': 48169791, 'body': '<p>That\'s not possible. A tensor is the output of <code>tf.Operation</code>. From <a href=""https://www.tensorflow.org/api_docs/python/tf/Tensor"" rel=""nofollow noreferrer"">documentation</a>:</p>\n\n<blockquote>\n  <p>A Tensor is a symbolic handle to one of the outputs of an <code>Operation</code>. It does not hold the values of that operation\'s output, but instead provides a means of computing those values in a TensorFlow <code>tf.Session</code>.</p>\n</blockquote>\n\n<p>So you can\'t change its value independently.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9508}"
477,64611137,"{'items': [{'owner': {'reputation': 41, 'user_id': 6634635}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1605959453, 'answer_id': 64942713, 'question_id': 64611137, 'body': ""<p>After plenty of manuals I got how to do that was hiding under the hood of <code>sess.run</code> in tf1, but without an optimizer:</p>\n<ol>\n<li>Counting loss</li>\n<li>Conunting gradients with respect to variables trained</li>\n<li>Adjust grow speed of function relative to each trained var to learning rate</li>\n<li>Assing new values to <code>k</code> and <code>b</code></li>\n</ol>\n<pre><code>X_batch, y_batch = X_data[indices], y_data[indices]\nX.assign(tf.convert_to_tensor(X_batch))\ny.assign(tf.convert_to_tensor(y_batch))\nwith tf.GradientTape(persistent=True) as tape:\n  loss_val = loss()\n\ndy_dk = tape.gradient(loss_val, k)\ndy_db = tape.gradient(loss_val, b)\n\nk.assign_sub(dy_dk * learn_rate)\nb.assign_sub(dy_db * learn_rate)\nif (i+1) % display_step == 0:\n  print('Epoch %d: %.8f, k=%.4f, b=%.4f' %\n        (i+1, loss_val, k.numpy(), b.numpy()))\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9508}"
478,58186564,"{'items': [{'owner': {'reputation': 2457, 'user_id': 8842694}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1569939825, 'answer_id': 58186914, 'question_id': 58186564, 'body': '<blockquote>\n  <p>How do i add other classes (like ""dog"") ? </p>\n</blockquote>\n\n<p>You can make model predict also on another class is by adding the new class to your training dataset. Let\'s say you added <code>Dog</code> class, so now your dataset consists <code>Cat</code> and <code>Dog</code> pictures.</p>\n\n<blockquote>\n  <p>Should it look like that (abstracted): model.fit([img1, img2, img3], [label1, label2, label3] ...) </p>\n</blockquote>\n\n<p>Yes, images <code>x = [img1, img2, img3]</code> and labels to corresponding images, <code>y = [label1, label2, label3]</code>. In x, <code>img1</code> or <code>img2</code> or any other image can be a cat image or dog image. For simplicity, you can feed images represented as numpy arrays. <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">Here</a> is how the input training data must look like. </p>\n\n<blockquote>\n  <p>What is the relation between the labels and the training set.</p>\n</blockquote>\n\n<p>Labels are a part of training set. If you are performing supervised classification then labels have to be fed along with your input features (images).</p>\n\n<p><strong>UPDATE</strong> for updated question</p>\n\n<pre><code>    [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]\n</code></pre>\n\n<p>In this you have a shape mismatch. The shape here is <code>(10,10)</code> but the model expects label input with shape <code>(10,)</code>.</p>\n\n<p>If you have two classes, you don\'t need to represent one class with <code>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]</code> or other with <code>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</code> in <code>Y</code> (Label). What does the rest of the zeroes do?. Just keep it simple and define as follows.</p>\n\n<p>If you have a <code>cat</code> you label it <code>0</code>, and for <code>dog</code> image, you label it <code>1</code> or vice-versa. \nand then you feed it like <code>[0,1,0]</code>, here first <code>0</code> is the label for img1, <code>1</code> for img2 and <code>0</code> for img3.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9508}"
479,72749893,"{'items': [{'owner': {'reputation': 10070, 'user_id': 9393102}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1656232096, 'answer_id': 72760011, 'question_id': 72749893, 'body': '<p>The problem is that <code>Adam</code> creates additional variables to store the momentum terms for the model variables. By creating a new optimizer every training step, these variables are also re-created, resulting in the error message.</p>\n<p>Note that it would also be a bad idea to do this without tf.function (which would not throw an error), precisely because the momentum terms would be re-initialized at every step, instead of being accumulated properly as they should be. This is why you should create the optimizer outside the training step, one time, at the beginning of training.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9504}"
480,55909188,"{'items': [{'owner': {'reputation': 23251, 'user_id': 10886420}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1556572364, 'answer_id': 55910879, 'question_id': 55909188, 'body': '<p>AFAIK there is no way around it. It seems (<a href=""https://stackoverflow.com/questions/50779869/does-tensorflow-tf-slice-incur-allocation-and-or-memory-copy"">here</a> and <a href=""https://stackoverflow.com/questions/53398721/tensorflow-can-reshape-create-a-copy"">here</a>) that the first operation creates a copy (someone correct me if I\'m wrong). You may use <a href=""https://www.tensorflow.org/api_docs/python/tf/expand_dims"" rel=""nofollow noreferrer""><code>tf.expand_dims</code></a> instead though, it\'s IMO more readable because of it\'s verbosity.</p>\n\n<p>On the other hand, taking <code>0</code> element from the tensor should not perform a copy in this case and is almost free.</p>\n\n<p><strong>Most importantly</strong>, except for a little inconvenience with syntax (e.g. <code>[0]</code>) those operations definitely <strong>are not costly</strong>, especially in the context of performing convolution.</p>\n\n<p>BTW. Other ready alternative layers like the ones in <code>tf.keras</code>, require batch as first dimension as well.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9503}"
481,53527368,"{'items': [{'owner': {'reputation': 145, 'user_id': 10658208}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1543494677, 'answer_id': 53539143, 'question_id': 53527368, 'body': '<p>Things are slow for you because you are using loops. Implementing with vector operations will be much faster but not as efficient as the high-level APIs such as tf.nn.conv2d or tf.nn.convolution. This post should be able to help you with the vectorized implementation of the same in numpy : <a href=""https://wiseodd.github.io/techblog/2016/07/16/convnet-conv-layer/"" rel=""nofollow noreferrer"">https://wiseodd.github.io/techblog/2016/07/16/convnet-conv-layer/</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9503}"
482,51612489,"{'items': [{'owner': {'reputation': 1848, 'user_id': 1140684}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1533047545, 'answer_id': 51615875, 'question_id': 51612489, 'body': '<p>hypothesis in dense form looks like this</p>\n\n<pre><code>[[[\'a\']],\n [[\'b\']]] # (2, 1, 1)\n</code></pre>\n\n<p>truth is this</p>\n\n<pre><code>[[[],[\'a\']],\n [[\'b\', \'c\'], [\'a\']]] # (2, 2, 2)\n</code></pre>\n\n<p>We are trying to find the <a href=""https://en.wikipedia.org/wiki/Levenshtein_distance"" rel=""nofollow noreferrer"">Levenshtein distance</a> between hypothesis and truth value.\nSo, here is what is happening:</p>\n\n<p>at (0,0,0) - how far is [\'a\'] in hypothesis from [] - no truth in that position so can\'t calculate distance</p>\n\n<p>at (0,0,1) - since there is nothing in that position at hypothesis we return 1. Unlike the case above, the distance is 1 because in theory the hypothesis can be made same as truth by inserting one character (See Levenshtein distance calculations)</p>\n\n<p>at (1,0,0) - how far is [\'b\'] in hyp from [\'b\', \'c\'] in truth. This is again 1, since we can insert a character to make hyp same as truth. But, we selected to normalize the output distance. So we divide by length of truth segment, which is 2. So you get 0.5</p>\n\n<p>at (1,0,1) - how far is [] in hyp from [\'a\'], since there is nothing in that position at hyp, we return 1</p>\n\n<p>Output is (2,2) because rank of hyp and truth is 3. The function returns tensor with rank (rank-1) </p>\n\n<p>It helps by imagining what we are trying to do here. You have 2 sequences in hypothesis and 2 sequences in the truth. So your output score will be such that you get scores for each position in each sequence.</p>\n\n<p>Here is an example where we try to match 4 hypotheses to a truth value. I think you have to do this for each truth sequence for the use case that you describe in your comment - let me know if you find something more efficient :-)</p>\n\n<pre><code>import tensorflow as tf\n\nhypothesis = tf.SparseTensor(\n            [[0, 0, 0],\n             [1, 0, 0],\n             [2, 0, 0],\n             [3, 0, 0]],\n             [""a"", ""b"", ""c"", ""d""],\n            (4, 1, 1))\n\ntruth = tf.SparseTensor([[0, 0, 0], [0, 0, 1], [0, 1, 0]], [""b"", ""c"", ""a""], (1,2,2))\nnum_hyp = 4\ntruth = tf.sparse_concat(0, [truth] * num_hyp)\n\nd = tf.edit_distance(hypothesis, truth)\n\nwith tf.Session() as sess:\n    print(sess.run(d))\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>[[1.  1. ]\n [0.5 1. ]\n [0.5 1. ]\n [1.  1. ]]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9503}"
483,56247113,"{'items': [{'owner': {'reputation': 9218, 'user_id': 867889}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1558499848, 'answer_id': 56249407, 'question_id': 56247113, 'body': '<p>Linear classifiers and other ""shallow models"" are picky about sourts of inputs that they can accept. <code>categorical_column_with_hash_bucket</code> is a hacky way of squeezing an variable size input or a enormous sparse vector into a nice fixed size numeric representation. </p>\n\n<p>In DNN terms we therefore should take a look at 2 cases to replace <code>categorical_column_with_hash_bucket</code>. One for strings and one for sparse vectors.</p>\n\n<p>In case of strings we can project a string into fixed size representation using an embedding layer. It allows a reacher, higher dimensional representation and, most of all, it is trainable. Embedding can be trained along with the main part of network.</p>\n\n<p>When it comes to sparse vectors things become tricky. First of all, DNNs don\'t shine when it comes to low dimensional data and sparse vectors typically have very little information (low entropy). Because of that sparse data can be easily overfit by a DNN that has millions of parameters. Nevertheless, you can still try using embedding layer for your case. Otherwise, stick to linear models - they are much more robust and adopted to sparse vectors.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9500}"
484,59142986,"{'items': [{'owner': {'reputation': 1, 'user_id': 2320962}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1588802195, 'answer_id': 61646121, 'question_id': 59142986, 'body': '<blockquote>\n  <p>Tensorflow squashes my two usefull numeric features into a useless\n  string input crap called ""inputs""</p>\n</blockquote>\n\n<p>is not exactly true, as the exported model expects a serialized tf.Example proto. So, you can warp your <code>age</code> and <code>time_spent</code> into two features which will look like:</p>\n\n<pre><code>features {\n  feature {\n    key: ""age""\n    value {\n      float32_list {\n        value: 10.2\n      }\n    }\n  }\n  feature {\n    key: ""time_spent""\n    value {\n      float32_list {\n        value: 40.3\n      }\n    }\n  }\n}\n</code></pre>\n\n<p>you can then call your regress function with the serialized string.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9500}"
485,62755661,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9500}"
486,63146831,"{'items': [{'owner': {'reputation': 3156, 'user_id': 1217998}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1596178014, 'answer_id': 63187019, 'question_id': 63146831, 'body': '<p>I finally figured it out. The <code>dy</code> should be called <code>upstream_gradient</code> or <code>upstream_dy_dx</code>.</p>\n<p>By chain rule we know that</p>\n<p><a href=""https://i.stack.imgur.com/7g3aZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7g3aZ.png"" alt=""chain rule"" /></a></p>\n<p>where <code>dx[i]/dx[i+1]</code> is the gradient of the current function.</p>\n<p>So <code>dy</code> is the product of all the gradients upstream before this function.</p>\n<p><a href=""https://i.stack.imgur.com/nu4Z8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nu4Z8.png"" alt=""enter image description here"" /></a></p>\n<p>So, if you forget to multiply the <code>dy</code> it is effectively the same as <a href=""https://www.tensorflow.org/api_docs/python/tf/stop_gradient"" rel=""nofollow noreferrer"">tf.stop_gradient</a></p>\n<p>Here is a code which demos this. Full notebook <a href=""https://github.com/Ghost---Shadow/differentiable-programming-handbook/blob/master/notebooks/custom-gradient.ipynb"" rel=""nofollow noreferrer"">here</a></p>\n<pre class=""lang-py prettyprint-override""><code>@tf.custom_gradient\ndef foo(x):\n    tf.debugging.assert_rank(x, 0)\n\n    def grad(dy_dx_upstream):\n        dy_dx = 2 * x\n        dy_dx_downstream = dy_dx * dy_dx_upstream\n        tf.print(f\'x={x}\\tupstream={dy_dx_upstream}\\tcurrent={dy_dx}\\t\\tdownstream={dy_dx_downstream}\')\n        return dy_dx_downstream\n    \n    y = x ** 2\n    tf.print(f\'x={x}\\ty={y}\')\n    \n    return y, grad\n\n\nx = tf.constant(2.0, dtype=tf.float32)\n\nwith tf.GradientTape(persistent=True) as tape:\n    tape.watch(x)\n    y = foo(foo(foo(x))) # y = x ** 8\n\ntf.print(f\'\\nfinal dy/dx={tape.gradient(y, x)}\')\n</code></pre>\n<p>Output</p>\n<pre><code>x=2.0   y=4.0\nx=4.0   y=16.0\nx=16.0  y=256.0\nx=16.0  upstream=1.0    current=32.0        downstream=32.0\nx=4.0   upstream=32.0   current=8.0     downstream=256.0\nx=2.0   upstream=256.0  current=4.0     downstream=1024.0\n\nfinal dy/dx=1024.0\n</code></pre>\n'}, {'owner': {'reputation': 1689, 'user_id': 9353909}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1596008281, 'answer_id': 63148622, 'question_id': 63146831, 'body': '<p>The extra <code>dy</code> you are looking at is the value of activation itself. Because the optimizer equation if you look at requires you multiply the gradient with the output value. Hence, this is why that has been done.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9500}"
487,49808208,"{'items': [{'owner': {'reputation': 29147, 'user_id': 4686625}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1523586580, 'answer_id': 49808431, 'question_id': 49808208, 'body': '<p>Not quite. <code>tf.constant([1, 2, 3])</code> creates a rank 1 constant tensor (a vector). Thus the shape is <code>(3,)</code>.</p>\n\n<pre><code>&gt;&gt;&gt; sess = tf.InteractiveSession()\n\n&gt;&gt;&gt; tf.constant([1, 2, 3]).eval()\narray([1, 2, 3], dtype=int32)\n</code></pre>\n\n<p>While <code>tf.constant([[1, 2, 3]])</code> creates a rank 2 constant tensor (a matrix), with 1 row and 3 columns.. so its shape is <code>(1, 3)</code>. </p>\n\n<pre><code>&gt;&gt;&gt; tf.constant([[1, 2, 3]]).eval()\narray([[1, 2, 3]], dtype=int32)\n</code></pre>\n\n<p>If you really wanted a scalar (rank 0), you wouldn\'t construct it with a sequence but rather just a scalar value. </p>\n\n<pre><code>&gt;&gt;&gt; tf.constant(3)\n&lt;tf.Tensor \'Const_5:0\' shape=() dtype=int32&gt;\n</code></pre>\n\n<p>Notice the empty shape here, making it clear it is rank 0. </p>\n\n<p>See <a href=""https://www.tensorflow.org/programmers_guide/tensors#rank"" rel=""nofollow noreferrer"">Tensor/Rank</a> in the documentation. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9496}"
488,53568337,"{'items': [{'owner': {'reputation': 151, 'user_id': 10498246}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1543647210, 'answer_id': 53568516, 'question_id': 53568337, 'body': '<p>You want to use the \'hooks\' option in the estimator train.</p>\n\n<p>The particular hook you want to use is this one: <a href=""https://www.tensorflow.org/api_docs/python/tf/train/LoggingTensorHook"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/train/LoggingTensorHook</a></p>\n\n<p>A similar problem was solved here:\n<a href=""https://stackoverflow.com/a/45716062/10498246"">https://stackoverflow.com/a/45716062/10498246</a>\nwhere they used the Logging Tensor Hook on a different training function.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9496}"
489,42287954,"{'items': [{'owner': {'reputation': 8038, 'user_id': 7677598}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1561457555, 'answer_id': 56751665, 'question_id': 42287954, 'body': ""<p>With TensorFlow version <strong>1.14.0</strong> it's suggested to use <code>tf.math.argmax</code> function. And also <code>dimension</code> parameter is deprecated instead of it you can use <code>axis</code>.</p>\n\n<p>Sample</p>\n\n<pre><code>tf.math.argmax(input, axis=1)\n</code></pre>\n""}, {'owner': {'reputation': 356, 'user_id': 3502070}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': False, 'score': 7, 'creation_date': 1487306440, 'answer_id': 42289528, 'question_id': 42287954, 'body': '<p>The following is the source code of <code>argmax</code> (from <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py</a>).</p>\n\n<pre><code># pylint: disable=redefined-builtin\n# TODO(aselle): deprecate arg_max\ndef argmax(input, axis=None, name=None, dimension=None):\n  if dimension is not None:\n    if axis is not None:\n      raise ValueError(""Cannot specify both \'axis\' and \'dimension\'"")\n    axis = dimension\n  elif axis is None:\n    axis = 0\n  return gen_math_ops.arg_max(input, axis, name)\n</code></pre>\n\n<p>As you can see, <code>argmax</code> is using <code>arg_max</code> inside. Also from the code, I recommend using <code>argmax</code> because <code>arg_max</code> could be deprecated soon.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9496}"
490,53924692,"{'items': [{'owner': {'reputation': 83, 'user_id': 5040070}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1545762930, 'answer_id': 53924739, 'question_id': 53924692, 'body': '<p>So there is a small mistake you are making in your understanding of a Tensor. A Tensor can have different ""ranks"". A single scalar such as 1 is a Rank 0 Tensor. A list/vector such as [1,2,3,4] is a Rank 1 Tensor. a 2-D Matrix such as [[0,0],[0,0]] is a Rank 2 Tensor and 3D Matrix are Rank 3 Tensors and so on. So the input you have here is a vector or Rank 1 Tensor not a 4-D Tensor.</p>\n\n<p><a href=""https://www.gsrikar.com/2017/06/what-is-tensor-rank-and-tensor-shape.html"" rel=""nofollow noreferrer"">Here is a nice blog post about this.</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9496}"
491,37376861,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 12, 'is_accepted': True, 'score': 12, 'creation_date': 1463937565, 'answer_id': 37377303, 'question_id': 37376861, 'body': '<p><code>tf.nn.lrn</code> is a short for <code>tf.nn.local_response_normalization</code>.\nTherefore, the documentation you may want to look at is: <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/local_response_normalization"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/local_response_normalization</a></p>\n'}, {'owner': {'reputation': 629, 'user_id': 1883727}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1463973412, 'answer_id': 37382135, 'question_id': 37376861, 'body': '<p>As <a href=""https://stackoverflow.com/a/37377303/1883727"">nessuno</a> mentioned, <code>tf.nn.lrn</code> is short for <code>tf.nn.local_response_normalization</code> (<a href=""https://www.tensorflow.org/versions/master/api_docs/python/nn.html#local_response_normalization"" rel=""nofollow noreferrer"">documentation</a>)</p>\n\n<p>Further, <a href=""https://stats.stackexchange.com/questions/145768/importance-of-local-response-normalization-in-cnn"">this question</a> provides good resources for more information into <em>response normalization layers</em>.</p>\n\n<p><strong>From:</strong> <a href=""http://caffe.berkeleyvision.org/tutorial/layers.html#data-layers"" rel=""nofollow noreferrer"">http://caffe.berkeleyvision.org/tutorial/layers.html#data-layers</a></p>\n\n<blockquote>\n  <p>""The local response normalization layer performs a kind of lateral inhibition by normalizing over local input regions. In ACROSS_CHANNELS mode, the local regions extend across nearby channels, but have no spatial extent (i.e., they have shape local_size x 1 x 1). In WITHIN_CHANNEL mode, the local regions extend spatially, but are in separate channels (i.e., they have shape 1 x local_size x local_size). Each input value is divided by (1+(/n)ix2i), where n is the size of each local region, and the sum is taken over the region centered at that value (zero padding is added where necessary).""</p>\n</blockquote>\n\n<p>These layers have fallen out of favor because they had very little impact on results, and other techniques proved to be more beneficial.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9496}"
492,51882846,"{'items': [{'owner': {'reputation': 10070, 'user_id': 9393102}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1534444383, 'answer_id': 51883350, 'question_id': 51882846, 'body': '<p>You can just define a function based on <code>leaky_relu</code>. </p>\n\n<p>For example you could use <code>activation_fn=lambda x: tf.nn.leaky_relu(x, alpha=0.01)</code>.</p>\n\n<p>This is the same as <code>def lrelu_01(x): return tf.nn.leaky_relu(x, alpha=0.01)</code> and then passing <code>activation_fn=lrelu_01</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9491}"
493,62530401,"{'items': [{'owner': {'reputation': 1689, 'user_id': 9353909}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1592907209, 'answer_id': 62532368, 'question_id': 62530401, 'body': '<p>The <code>num_words</code> actually helps in doing the same thing, here <code>num_words</code> will take the top <code>num_words</code> words with the highest frequency.</p>\n<p>So, the functionality you got from <code>min_frequency</code> in <code>tf.contrib.learn.preprocessing.VocabularyProcessor</code> you can get the same but not in the same way though.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9491}"
494,52966243,"{'items': [{'owner': {'reputation': 121, 'user_id': 1387006}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1554955659, 'answer_id': 55624542, 'question_id': 52966243, 'body': '<p>The problem here is that when you call the <code>.reduce()</code> function it\'s applying to the outer dataset.\nThe dataset after calling <code>.window</code> is now a dataset where each element is itself a dataset.\nWhat you want to do is to use reduce on those individual datasets created by window.\nYou can do this using map, and then mapping each of the inner datasets to a reduce.</p>\n\n<pre class=""lang-py prettyprint-override""><code>def reduce_func(old_state, input_element):\n    pdb.set_trace()\n    return new_state\n\ndataset = tf.data.Dataset.from_generator(frame_generator, (tf.string, tf.string))\ndataset = dataset.window(2).map(lambda ds: ds.reduce(np.int64(0), reduce_func))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9491}"
495,66030439,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9491}"
496,47657835,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1512495063, 'answer_id': 47659409, 'question_id': 47657835, 'body': '<p>You can use the <a href=""https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor"" rel=""nofollow noreferrer""><code>tf.convert_to_tensor()</code></a> function to do this:</p>\n\n<pre><code>x = tf.placeholder(tf.int32)  # NOTE: You should probably pass `shape=[]` as well.\ny = tf.convert_to_tensor([[x, x], [0, 0]])\n</code></pre>\n\n<p>Also note that TensorFlow will implicitly call <code>tf.convert_to_tensor()</code> on the inputs to any function that expects a <code>tf.Tensor</code> as input, so you may be able to pass <code>[[x, x], [0, 0]]</code> directly to many functions.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9491}"
497,76391276,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1685717929, 'answer_id': 76391277, 'question_id': 76391276, 'body': '<p>Although not part of the public API, TensorFlow implements utilities for this purpose. In particular, there is a helper <a href=""https://github.com/tensorflow/tensorflow/blob/v2.12.0/tensorflow/core/ops/array_ops.cc#L1968-L1982"" rel=""nofollow noreferrer""><code>BroadcastGradientArgs</code></a> op type that calculates how you have to reduce and/or reshape the gradients of two broadcasting inputs. This is used internally by functions like <a href=""https://github.com/tensorflow/tensorflow/blob/v2.12.0/tensorflow/core/ops/math_grad.cc#L394-L431"" rel=""nofollow noreferrer""><code>GradForBinaryCwise</code></a> to simplify the definition of gradients.</p>\n<p>At the Python level, there is <a href=""https://github.com/tensorflow/tensorflow/blob/v2.12.0/tensorflow/python/ops/math_grad.py#L63-L84"" rel=""nofollow noreferrer""><code>tensorflow.python.ops.math_grad.SmartBroadcastGradientArgs</code></a>, which essentially uses the same op but with some additional logic to save work when possible.</p>\n<p>For example, for the case of a binary component-wise operation like multiplication, you can define the following helper:</p>\n<pre class=""lang-py prettyprint-override""><code>import functools\nfrom typing import Callable, Tuple\nimport tensorflow as tf\n\ndef grad_for_binary_cwise(grad_fn: Callable[[tf.Tensor], Tuple[tf.Tensor, tf.Tensor]], x: tf.Tensor, y: tf.Tensor) -&gt; Callable[[tf.Tensor], Tuple[tf.Tensor, tf.Tensor]]:\n    &quot;&quot;&quot;\n    Helper to define custom gradients for binary broadcasting\n    component-wise operations.\n    Args:\n        grad_fn: Base gradient function. This should accept the gradient of the\n                 output and return the gradients of the two inputs, under the\n                 assumption that both inputs and the output have the same shape\n                 (i.e. no broadcasting was required).\n        x: First input to the operation.\n        y: Second input to the operation.\n\n    Returns:\n        A function that can be used as custom gradient for the broadcasting operation.\n    &quot;&quot;&quot;\n    @functools.wraps(grad_fn)\n    def wrapper(dz):\n        from tensorflow.python.ops.math_grad import SmartBroadcastGradientArgs\n        (sx, rx, must_reduce_x), (sy, ry, must_reduce_y) = SmartBroadcastGradientArgs(x, y, dz)\n        dx, dy = grad_fn(dz)\n        if must_reduce_x:\n            dx = tf.reshape(tf.math.reduce_sum(dx, rx), sx)\n        if must_reduce_y:\n            dy = tf.reshape(tf.math.reduce_sum(dy, ry), sy)\n        return dx, dy\n    return wrapper\n</code></pre>\n<p>Then, you would simply define the custom gradient as follows:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\n@tf.custom_gradient\ndef bar(x, y):\n    def grad(upstream):\n        dz_dx = y\n        dz_dy = x\n        return upstream * dz_dx, upstream * dz_dy\n    z = x * y\n    return z, grad_for_binary_cwise(grad, x, y)\n</code></pre>\n<p>Now the gradient works as expected:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\nwith tf.GradientTape() as tape:\n    a = tf.ones([10, 1])\n    b = tf.ones([5])\n    tape.watch([a, b])\n    c = bar(a, b)\ngrad_a, grad_b = tape.gradient(c, [a, b])\nprint(grad_a.shape, grad_b.shape)\n# (10, 1) (5,)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9486}"
498,54047604,"{'items': [{'owner': {'reputation': 812, 'user_id': 6470174}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1565107196, 'answer_id': 57379955, 'question_id': 54047604, 'body': ""<p>I ran into a similar problem some time ago and I think the documentation is not very clear on this. In general, the code should be something like:</p>\n\n<pre><code>@tf.custom_gradient\ndef custom_operation(x, y, scope='custom_op'):\n\n    # define the gradient\n    def grad(g):\n        return g, g\n\n    # define the forward pass (a multiplication, in this example)\n    with tf.variable_scope(scope):\n        forward_pass = x * y\n\n    return forward_pass, grad\n</code></pre>\n\n<p>In practice, your internal grad function should return the gradient N times, where N is the number of argument that the custom_operation takes as input (apart from the scope). By using two inputs (x and y), the grad function must return the gradients twice (once for x and once for y). In general, you could also make the grad() function return g1 != g2 instead of g for both the inputs.\nSo, in your example it becomes:</p>\n\n<pre><code>@tf.custom_gradient\ndef my_identity(x, z):\n\n    def grad(dy):\n        return dy, dy\n\n    return tf.identity(x*z), grad\n</code></pre>\n""}, {'owner': {'reputation': 56, 'user_id': 10293553}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1551318517, 'answer_id': 54917180, 'question_id': 54047604, 'body': '<p>If we use multiple variables as input, the number of gradients return from ""grad"" function should be equals to number of input variables, though we maybe don\'t care about some of them. </p>\n\n<p>For example:</p>\n\n<pre><code>@tf.custom_gradient\ndef my_multiple(x,z):\n\ndef grad(dy):\n    # return two gradients, one for \'x\' and one for \'z\'\n    return (dy*z, dy*x)\n\nreturn tf.identity(x*z), grad\n</code></pre>\n\n<p>Note that the second output of ""my_multiple"" is a function, not a gradient tensor. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9486}"
499,65481591,"{'items': [{'owner': {'reputation': 116, 'user_id': 14795008}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1609252747, 'answer_id': 65493907, 'question_id': 65481591, 'body': '<p>In documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator</a>), is stated that you can use <code>output_types=None</code> as an argument. Did you try this or something else?</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9486}"
500,39650169,"{'items': [{'owner': {'reputation': 4577, 'user_id': 1951176}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1474586980, 'answer_id': 39650353, 'question_id': 39650169, 'body': '<p>Ok, I have found a solution (that works on <code>SparseTensor</code>s, but not on <code>SparseTensorValue</code>s):</p>\n\n<pre><code>tiled = tf.sparse_concat(0, [g] * 10)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9483}"
501,44796793,"{'items': [{'owner': {'reputation': 6144, 'user_id': 7456923}, 'down_vote_count': 0, 'up_vote_count': 46, 'is_accepted': True, 'score': 46, 'creation_date': 1498640662, 'answer_id': 44798131, 'question_id': 44796793, 'body': '<p><strong>TL;DR</strong>: use <code>tf.clip_by_global_norm</code> for gradient clipping, with &quot;some high value&quot; as max value.</p>\n<h3>clip_by_value</h3>\n<p><code>tf.clip_by_value</code> clips each value inside one tensor, regardless of the other values in the tensor. For instance,</p>\n<pre><code>tf.clip_by_value([-1, 2, 10], 0, 3)  -&gt; [0, 2, 3]  # Only the values below 0 or above 3 are changed\n</code></pre>\n<p>Consequently, it can change the direction of the tensor, so it should be used if the values in the tensor are decorrelated one from another (which is not the case for gradient clipping), or to avoid zero / infinite values in a tensor that could lead to Nan / infinite values elsewhere (by clipping with a minimum of epsilon=1e-8 and a very big max value for instance).</p>\n<h3>clip_by_norm</h3>\n<p><code>tf.clip_by_norm</code> rescales one tensor if necessary, so that its L2 norm does not exceed a certain threshold. It\'s useful typically to avoid exploding gradient on one tensor, because you keep the gradient direction. For instance:</p>\n<pre><code>tf.clip_by_norm([-2, 3, 6], 5)  -&gt; [-2, 3, 6]*5/7  # The original L2 norm is 7, which is &gt;5, so the final one is 5\ntf.clip_by_norm([-2, 3, 6], 9)  -&gt; [-2, 3, 6]  # The original L2 norm is 7, which is &lt;9, so it is left unchanged\n</code></pre>\n<p>However, <code>clip_by_norm</code> works on only one gradient, so if you use it on all your gradient tensors, you\'ll unbalance them (some will be rescaled, others not, and not all with the same scale).</p>\n<p>Note that the two first ones work on only one tensor, while the last one is used on a list of tensors.</p>\n<h3>clip_by_global_norm</h3>\n<p><code>tf.clip_by_global_norm</code> rescales a list of tensors so that the total norm of the vector of all their norms does not exceed a threshold. The goal is the same as  <code>clip_by_norm</code> (avoid exploding gradient, keep the gradient directions), but it works on all the gradients at once rather than on each one separately (that is, all of them are rescaled by the same factor if necessary, or none of them are rescaled). This is better, because the balance between the different gradients is maintained.</p>\n<p>For instance:</p>\n<pre><code>tf.clip_by_global_norm([tf.constant([-2, 3, 6]),tf.constant([-4, 6, 12])] , 14.5)\n</code></pre>\n<p>will rescale both tensors by a factor <code>14.5/sqrt(49 + 196)</code>, because the first tensor has a L2 norm of 7, the second one 14, and <code>sqrt(7^2+ 14^2)&gt;14.5</code></p>\n<p>This (<code>tf.clip_by_global_norm</code>) is the one that you should use for gradient clipping. See <a href=""https://arxiv.org/pdf/1211.5063.pdf"" rel=""nofollow noreferrer"">this</a> for instance for more information.</p>\n<h3>Choosing the value</h3>\n<p>Choosing the max value is the hardest part. You should use the biggest value such that you don\'t have exploding gradient (whose effects can be <code>Nan</code>s or <code>infinite</code> values appearing in your tensors, constant loss /accuracy after a few training steps). The value should be bigger for <code>tf.clip_by_global_norm</code> than for the others, since the global L2 norm will be mechanically bigger than the other ones due to the number of tensors implied.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9483}"
502,44905344,"{'items': [{'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1499200689, 'answer_id': 44913730, 'question_id': 44905344, 'body': '<p>You can do two things:</p>\n\n<ol>\n<li>Convert sparse to dense and then create a ones tensor. Something like <code>tf.ones_like(tf.sparse_tensor_to_dense(x))</code></li>\n<li>Get a shape of sparse tensor and use it to create a ones tensor. It looks like <a href=""https://www.tensorflow.org/api_docs/python/tf/SparseTensor#dense_shape"" rel=""nofollow noreferrer"">dense_shape does this</a>. Then use <a href=""https://www.tensorflow.org/api_docs/python/tf/ones"" rel=""nofollow noreferrer"">tf.ones</a> with that shape.</li>\n</ol>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9483}"
503,49003393,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9483}"
504,61692802,"{'items': [{'owner': {'reputation': 2856, 'user_id': 7160346}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1606709956, 'answer_id': 65068075, 'question_id': 61692802, 'body': '<p>TensorFlow 1.x scripts will not work directly with TensorFlow 2.x but they need converting.</p>\n<pre><code>tf_upgrade_v2 --infile tensorflow_v1.py --outfile tensorflow_v2.py\n</code></pre>\n<p>If you have multiple files within a folder, you can use the below command.</p>\n<pre><code>tf_upgrade_v2  v1-code-folder  code-upgraded-folder\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9479}"
505,42773379,"{'items': [{'owner': {'reputation': 113, 'user_id': 7674512}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1489445370, 'answer_id': 42774850, 'question_id': 42773379, 'body': '<p>During the <a href=""https://www.youtube.com/playlist?list=PLOU2XLYxmsIKGc_NBoIhTn2Qhraji53cv"" rel=""nofollow noreferrer"">2017 TensorFlow Dev Summit</a>, the <code>tf.contrib</code> section of the TensorFlow project was described as a testing ground for higher level functions.  These functions are for the community to use and test.  However, there is no guarantee that there won\'t be changes to the interface when functions are moved to tf.core.  Between Tensorflow versions r0.12 at r1.0, many of the <code>tf.contrib.layer</code> functions were moved to <code>tf.layers</code> (which did not exist before r1.0).  In short, documentation of tf.contrib will never by as good as tf.core.</p>\n'}, {'owner': {'reputation': 77582, 'user_id': 3125566}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1489441844, 'answer_id': 42774074, 'question_id': 42773379, 'body': '<p>They are not the same thing.</p>\n\n<p>The latter is not an activation function but a <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected"" rel=""noreferrer""><code>fully_connected</code></a> <strong>layer</strong> that has its activation function preset as <code>nn.relu</code>:</p>\n\n<pre><code>relu = functools.partial(fully_connected, activation_fn=nn.relu)\n# ^                                                     |&lt;   &gt;|\n# |_ tf.contrib.layers.relu                     tf.nn.relu_|\n</code></pre>\n\n<hr>\n\n<p>If you read the docs for <a href=""https://www.tensorflow.org/api_guides/python/contrib.layers"" rel=""noreferrer""><code>contrib.layers</code></a>, you\'ll find:</p>\n\n<blockquote>\n  <p>Aliases for <code>fully_connected</code> which set a default activation function\n  are available: <code>relu</code>, <code>relu6</code> and <code>linear</code>.</p>\n</blockquote>\n\n<p>Summarily, <a href=""https://github.com/tensorflow/tensorflow/blob/4433079e7f317724eaa92ec120c6b1c3c0c52f2f/tensorflow/contrib/layers/python/layers/layers.py#L2137"" rel=""noreferrer""><code>tf.contrib.layers.relu</code></a> is an alias for a <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected"" rel=""noreferrer""><code>fully_connected</code></a> layer with <em>relu</em> activation while <code>tf.nn.relu</code> is the REctified Linear Unit activation function itself.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9479}"
506,53027716,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9479}"
507,61461381,"{'items': [{'owner': {'reputation': 140, 'user_id': 3180445}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1588015805, 'answer_id': 61466894, 'question_id': 61461381, 'body': '<p>From the tutorial you are missing this part</p>\n\n<pre><code>for image, label in images_ds.take(5):\n    show(image, label)\n</code></pre>\n\n<p>The line</p>\n\n<pre><code>images_ds = list_ds.map(parse_image)\n</code></pre>\n\n<p>only creates a placeholder\nand there is no image being passed to the function\nif you put prints the file_path is blank\nBut if your use </p>\n\n<pre><code>for image, label in images_ds.take(5)\n</code></pre>\n\n<p>it iterates over each image passing it through the parse_image function.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9479}"
508,51776390,"{'items': [{'owner': {'reputation': 4189, 'user_id': 1008596}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1534022080, 'answer_id': 51803805, 'question_id': 51776390, 'body': '<p>I don\'t think you can run tfdbg in datalab.  You can take the code and run it at the console like so using this <a href=""https://www.tensorflow.org/guide/debugger#debugging_tensorflow_estimators"" rel=""nofollow noreferrer"">guide</a>:</p>\n\n<ol>\n<li><p>I am using the datalab notebook which uses a model.py and task.py.   My code originally was modeled after this <a href=""https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/03_tensorflow/e_cloudmle.ipynb"" rel=""nofollow noreferrer"">file</a>.</p></li>\n<li><p>Make this change to the <code>model.py</code> code as shown in the guide mentioned above.</p>\n\n<pre><code>from tensorflow.python import debug as tf_debug\n# for debugging\nhooks = [tf_debug.LocalCLIDebugHook()]\n</code></pre></li>\n</ol>\n\n<p>Then in the <code>train_and_evaluate(args)</code> routine add a reference to the hooks in the parameter list for the <code>EvalSpec()</code> call.  Like so:</p>\n\n<pre><code>    # .. also need an EvalSpec which controls the evaluation and\n    # the checkpointing of the model since they happen at the same time\n    eval_spec = tf.estimator.EvalSpec(\n        input_fn = read_dataset(\n            args[\'eval_data_paths\'],\n            batch_size = 10000,  # original 10000\n            mode = tf.estimator.ModeKeys.EVAL),\n        steps=None, # evals on 100 batches\n        start_delay_secs = args[\'eval_delay_secs\'], # start evaluating after N secoonds. \n        throttle_secs = args[\'min_eval_frequency\'], # eval no more than every N seconds.\n        exporters = exporter,# how to export the model for production.\n        hooks = hooks) # for the debugger \n</code></pre>\n\n<p>Then using your pereferred virtual python environment, do the following: (I am using anaconda)</p>\n\n<ol>\n<li><p>Open a python 2.7 environment with anaconda</p>\n\n<pre><code>$ . ~/bin/setenv-anaconda2.sh\n</code></pre></li>\n<li><p>Activate the tensorflow python2.7 anaconda environment</p>\n\n<pre><code>$ conda activate tensorflow\n</code></pre></li>\n<li><p>get the gcloud environment</p>\n\n<pre><code>$ . ~/progs/datalab-notebooks/bin/setenv_google.sh\n</code></pre></li>\n<li><p>For this model, set a python path to find modules</p>\n\n<pre><code>cd ~/progs/datalab-notebooks/tf-debug\nexport PYTHONPATH=${PYTHONPATH}:${PWD}/taxisimple\n</code></pre></li>\n</ol>\n\n<p>Then this to train:  --train_steps=1000. appears to be max steps.</p>\n\n<pre><code>python -m trainer.task \\\n   --train_data_paths=""${PWD}/taxi-train*"" \\\n   --eval_data_paths=${PWD}/taxi-valid.csv  \\\n   --output_dir=${PWD}/taxi_trained \\\n   --train_steps=1000 --job-dir=./tmp\n</code></pre>\n\n<p>This will give you a tftdbg prompt.  From here you can explore the model using tfdbg.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9479}"
509,50246535,"{'items': [{'owner': {'reputation': 1286, 'user_id': 4713386}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1525847777, 'answer_id': 50246934, 'question_id': 50246535, 'body': '<p>In case of <code>numeric_column</code> with same <code>dtype</code>\'s the only difference is shape of the resultant input:</p>\n\n<p>Option 1 creates input of shape: <code>[120,4,1]</code>: 120 samples, each represented by 4 vectors of 1 number.</p>\n\n<p>Whereas option 2 creates input of shape: <code>[120,1,4]</code>: 120 samples, each represented by a single vector consisting of 4 numbers.</p>\n\n<p>In the end, it does not really matter because both get flattened to <code>[120,4]</code> before being fed to the network.</p>\n\n<hr>\n\n<p>First I created the features.</p>\n\n<pre><code>features1 = {\n    \'sepal_length\' : np.random.rand(120),\n    \'sepal_width\': np.random.rand(120),\n    \'petal_length\': np.random.rand(120),\n    \'petal_width\': np.random.rand(120)\n}\n\nfeatures2 = {\n    \'everything\' : np.random.rand(120, 4)\n}\n</code></pre>\n\n<p>\nThen I prepared the feature columns -- same as you did.</p>\n\n<pre><code>feature_columns1 = [\n    tf.feature_column.numeric_column(key=""sepal_length""),\n    tf.feature_column.numeric_column(key=""sepal_width""),\n    tf.feature_column.numeric_column(key=""petal_length""),\n    tf.feature_column.numeric_column(key=""petal_width"")\n]\n\nfeature_columns2 = [\n    tf.feature_column.numeric_column(key=""everything"", shape=4),\n]\n</code></pre>\n\n<p>\nNow, to see what exactly is done with them when they\'re fed to the network we can use the <code>feature_column.input_layer()</code>.</p>\n\n<pre><code>inputs1 = tf.feature_column.input_layer(features1, feature_columns1)\ninputs2 = tf.feature_column.input_layer(features2, feature_columns2)\n</code></pre>\n\n<p>\nAnd as we can see, both ways produced the same shape.</p>\n\n<pre><code>with tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    res1 = sess.run(inputs1)\n    res2 = sess.run(inputs2)\n</code></pre>\n\n \n\n<pre><code>print(res1.shape)\nprint(res2.shape)\n(120, 4)\n(120, 4)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9474}"
510,67066760,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1618277537, 'answer_id': 67067589, 'question_id': 67066760, 'body': '<p>Instead of thinking of each row as a single example, think of each <em>element</em> as a single example. In other words, first example has the label 0 and the model predicted 0.6, the second example has the label 1 and the model predicted 0.4, and so on.</p>\n<p>At least this is how TensorFlow computes the crossentropy for the above tensor. So, each row doesn\'t need to sum up to 1.</p>\n<p>You can check the validity of this by using the function <code>K.binary_crossentropy()</code> that is used by <code>tf.keras.losses.BinaryCrossentropy()</code>.</p>\n<pre><code>K.binary_crossentropy(y_true, y_pred)\n</code></pre>\n<p>which will return,</p>\n<pre><code>[[0.9162906 0.9162905]\n [0.5108254 0.9162906]]\n</code></pre>\n<p>The <code>tf.keras.losses.BinaryCrossentropy()</code> function does a reduction on the last axis of the above output as said in the documentation <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy#__call__"" rel=""nofollow noreferrer"">here</a>,</p>\n<blockquote>\n<p>Weighted loss float Tensor. If reduction is NONE, this has shape [batch_size, d0, .. dN-1]; otherwise, it is scalar. (Note dN-1 because all loss functions reduce by 1 dimension, usually axis=-1.)</p>\n</blockquote>\n<p>This is why you, if you execute,</p>\n<pre><code>bce = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n</code></pre>\n<p>you\'d see only two entries as,</p>\n<pre><code>[0.9162905  0.71355796]\n</code></pre>\n<p>Hope this clears it.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9474}"
511,72772487,"{'items': [{'owner': {'reputation': 11, 'user_id': 19478194}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1656927845, 'answer_id': 72854723, 'question_id': 72772487, 'body': ""<p>For me, the solution was following:</p>\n<pre><code># first define detect_fn and decorate with tf.function\ndetect_fn = tf.function(tf.saved_model.load(visa_icon_model))\n\n# when predicting \nvisa_icon_detections = detect_fn.signatures['serving_default'](input_tensor)\n</code></pre>\n<p>I did a stress test with about 100 requests (I have a running model inside docker container) and it went for about 3 GB maximum after allocation and it uses about 1.9-2.5 GB stable.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9474}"
512,53107594,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9474}"
513,59962253,"{'items': [{'owner': {'reputation': 8601, 'user_id': 3211422}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1580736056, 'answer_id': 60040103, 'question_id': 59962253, 'body': ""<p>The culprit seems to be </p>\n\n<pre><code># This doesn't seem to compatible with Estimator API\nhp.hparams_config(hparams=hparams_list, metrics=metrics_to_monitor)\n</code></pre>\n\n<p>Simply calling hparams logs all metrics logged with <code>tf.summary</code>. Then in tensorboard, you can filter only the metrics you need and then compare trials.</p>\n\n<pre><code>with tf.summary.create_file_writer(train_folder).as_default():\n    # params is a dict which contains\n    # { 'learning_rate': 0.001, 'distance_margin': 0.5,...}\n    hp.hparams(hparams=params))\n\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9474}"
514,56212366,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9469}"
515,45634450,"{'items': [{'owner': {'reputation': 47103, 'user_id': 38626}, 'down_vote_count': 0, 'up_vote_count': 18, 'is_accepted': False, 'score': 18, 'creation_date': 1552230245, 'answer_id': 55089024, 'question_id': 45634450, 'body': '<p>Here are the definitions of the <code>Example</code> and <code>SequenceExample</code> protocol buffers, and all the protos they may contain:</p>\n\n<pre class=""lang-java prettyprint-override""><code>message BytesList { repeated bytes value = 1; }\nmessage FloatList { repeated float value = 1 [packed = true]; }\nmessage Int64List { repeated int64 value = 1 [packed = true]; }\nmessage Feature {\n    oneof kind {\n        BytesList bytes_list = 1;\n        FloatList float_list = 2;\n        Int64List int64_list = 3;\n    }\n};\nmessage Features { map&lt;string, Feature&gt; feature = 1; };\nmessage Example { Features features = 1; };\n\nmessage FeatureList { repeated Feature feature = 1; };\nmessage FeatureLists { map&lt;string, FeatureList&gt; feature_list = 1; };\nmessage SequenceExample {\n  Features context = 1;\n  FeatureLists feature_lists = 2;\n};\n</code></pre>\n\n<p>An <code>Example</code> contains a <code>Features</code>, which contains a mapping from feature name to <code>Feature</code>, which contains either a <code>bytes</code> list, or a <code>float</code> list or an <code>int64</code> list.</p>\n\n<p>A <code>SequenceExample</code> also contains a <code>Features</code>, but it also contains a <code>FeatureLists</code>, which contains a mapping from list name to <code>FeatureList</code>, which contains a list of <code>Feature</code>. So it can do everything an <code>Example</code> can do, and more. But do you really need that extra functionality? What does it do?</p>\n\n<p>Since each <code>Feature</code> contains a list of values, a <code>FeatureList</code> is a list of lists. And that\'s the key: if you need lists of lists of values, then you need <code>SequenceExample</code>.</p>\n\n<p>For example, if you handle text, you can represent it as one big string:</p>\n\n<pre class=""lang-py prettyprint-override""><code>from tensorflow.train import BytesList\n\nBytesList(value=[b""This is the first sentence. And here\'s another.""])\n</code></pre>\n\n<p>Or you could represent it as a list of words and tokens:</p>\n\n<pre class=""lang-py prettyprint-override""><code>BytesList(value=[b""This"", b""is"", b""the"", b""first"", b""sentence"", b""."", b""And"", b""here"",\n                 b""\'s"", b""another"", b"".""])\n</code></pre>\n\n<p>Or you could represent each sentence separately. That\'s where you would need a list of lists:</p>\n\n<pre class=""lang-py prettyprint-override""><code>from tensorflow.train import BytesList, Feature, FeatureList\n\ns1 = BytesList(value=[b""This"", b""is"", b""the"", b""first"", b""sentence"", b"".""])\ns2 = BytesList(value=[b""And"", b""here"", b""\'s"", b""another"", b"".""])\nfl = FeatureList(feature=[Feature(bytes_list=s1), Feature(bytes_list=s2)])\n</code></pre>\n\n<p>Then create the <code>SequenceExample</code>:</p>\n\n<pre class=""lang-py prettyprint-override""><code>from tensorflow.train import SequenceExample, FeatureLists\n\nseq = SequenceExample(feature_lists=FeatureLists(feature_list={\n    ""sentences"": fl\n}))\n</code></pre>\n\n<p>And you can serialize it and perhaps save it to a TFRecord file.</p>\n\n<pre class=""lang-py prettyprint-override""><code>data = seq.SerializeToString()\n</code></pre>\n\n<p>Later, when you read the data, you can parse it using <code>tf.io.parse_single_sequence_example()</code>.</p>\n'}, {'owner': {'reputation': 3596, 'user_id': 6780025}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1503529550, 'answer_id': 45850566, 'question_id': 45634450, 'body': '<p>The link you provided lists some benefits. You can see how <a href=""https://www.tensorflow.org/api_docs/python/tf/parse_single_sequence_example"" rel=""nofollow noreferrer"">parse_single_sequence_example</a> is used here  <a href=""https://github.com/tensorflow/magenta/blob/master/magenta/common/sequence_example_lib.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/magenta/blob/master/magenta/common/sequence_example_lib.py</a></p>\n\n<p>If you managed to get the data into your model with <code>Example</code>, it should be fine. <code>SequenceExample</code> just gives a little more structure to your data and some utilities for working with it.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9469}"
516,49472402,"{'items': [{'owner': {'reputation': 367, 'user_id': 6152419}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1543242761, 'answer_id': 53483337, 'question_id': 49472402, 'body': '<p>To summary, the following implementation works. You can run this through <a href=""https://tensorflow.rstudio.com/tensorflow/articles/tutorial_mnist_beginners.html"" rel=""nofollow noreferrer"">MNIST beginner example</a> and obtain the same accuracy.</p>\n\n<pre><code># My softmax:\ny1 = tf.exp(logits)\ny_ = y1 / tf.reduce_sum(y1, keepdims=True, axis=1)\n</code></pre>\n'}, {'owner': {'reputation': 3270, 'user_id': 5361479}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1521970985, 'answer_id': 49474464, 'question_id': 49472402, 'body': '<ul>\n<li>Assuming your softmax implementation is correct</li>\n<li>First of all it is not fair to compare tensorflow softmax with handwritten softmax because there is randomness included in your program</li>\n<li>By this what I mean is the line <code>W = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))</code> introduces randomness in you program because the weights are intially set randomly so every time you run your program you will get different results </li>\n<li>You can only compare both the softmax if you have some kind of seed(some kind of starting point)</li>\n<li>Now if you have performed the above experiment multiple times and every time the tensorflow softmax beats the handwritten softmax then your question is valid</li>\n<li>The <code>tf.truncated_normal</code> function does take a seed argument ... you can use that argument and see what the outcomes are</li>\n<li>Anyways if your handwritten softmax is correct then with the seed the tensorflow softmax and your softmax should output the same results</li>\n<li>And even I think your axis should be 1 in your case which is the last axis as the softmax should be along the axis where there are classes </li>\n</ul>\n'}, {'owner': {'reputation': 10070, 'user_id': 9393102}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1521970463, 'answer_id': 49474408, 'question_id': 49472402, 'body': '<p>You are passing <code>axis=0</code> to ""your"" softmax. Although I don\'t know how your data looks, 0 is usually the batch axis and performing softmax along this axis is incorrect. See the docs of <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/softmax"" rel=""nofollow noreferrer""><code>tf.nn.softmax</code></a>: The default value for <code>axis</code> is -1. In general, <code>axis</code> should be the dimension that contains the different classes.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9469}"
517,51999636,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9469}"
518,56458133,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9469}"
519,46484373,"{'items': [{'owner': {'reputation': 160, 'user_id': 2156623}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1506689184, 'answer_id': 46489133, 'question_id': 46484373, 'body': ""<p>Although, I don't know very well the dynamics of <code>EstimatorSpec</code>, it seems you are trying to feed the model the <code>weight_layer</code> into <code>sparsity</code> Variable, but as they have different shapes due to <code>tf.reduce_sum</code>, hence it's raising the error.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9464}"
520,72928149,"{'items': [{'owner': {'reputation': 772, 'user_id': 11609834}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1657474789, 'answer_id': 72930589, 'question_id': 72928149, 'body': '<p>If you find something in an <code>experimental</code> module and something in the same package by the same name, these will typically be aliases of one another. For the sake of backwards compatibility, they don\'t remove the experimental one (at least not for a few iterations.)</p>\n<p>You should generally use the non-experimental one if it exists, since this is considered stable and should not be removed or changed later.</p>\n<p>The following page shows Keras preprocessing exerimental. If it redirects to the preprocessing module, it\'s an alias. <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9463}"
521,37086098,"{'items': [{'owner': {'reputation': 906, 'user_id': 7348956}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1574336094, 'answer_id': 58974040, 'question_id': 37086098, 'body': ""<p>you can combine approaches described in this page to pass a number of tensors and arguments to be considered when calling to your function, for example - </p>\n\n<pre><code>import tensorflow as tf\ncnn = tf.keras.layers.Conv1D(name, filters=64, kernel_size=4, padding='same')\npool = tf.keras.layers.GlobalAveragePooling1D()\n\ndef stack_inputs(inp1, inp2, axis=1):\n    return tf.stack([inp1, inp2], axis)\n\ndef attention_op(q, p, cnn):\n    q_encoded = pool(cnn(q))\n    q_v_att = pool(tf.keras.layers.Attention()([cnn(q), cnn(p)]))\n    return tf.keras.layers.Concatenate()([q_encoded, q_v_att])\n\ncnn1 = cnn('cnn_layer_1')\nstacked_inputs = stack_inputs(inp1, inp2)\nmap_result = tf.keras.backend.map_fn(lambda x: attention_op(x[0], x[1], cnn1), stacked_inputs, dtype=tf.float32)\n</code></pre>\n""}, {'owner': {'reputation': 329, 'user_id': 7050212}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1538665054, 'answer_id': 52649825, 'question_id': 37086098, 'body': '<p>If Tensors are of the same shape (most cases), stack the tensors in the first dimension and slide them inside the map function: </p>\n\n<pre><code>import tensorflow as tf\n# declare variables\na = tf.constant([1, 2, 3, 4])\nb = tf.constant([17, 12, 11, 10])\n\n# NOTE: use stack because map_tf only takes one input tensor\nab = tf.stack([a, b], 1)\n\n\ndef map_operation(value_ab):\n    # iterates each value_ab\n    value_a = value_ab[0]\n    value_b = value_ab[1]\n    return value_a+value_b\n\n# print(map(lambda x,y:x+y, a,b)) # ==&gt; [18, 14, 14, 14]\n# iterates each value_ab at map_operation()\nmap_result = tf.map_fn(map_operation, ab, dtype=tf.int32)\n\nwith tf.Session() as sess:\n    tf.initialize_all_variables().run()\n    print(sess.run(map_result))   # [18 14 14 14]\n</code></pre>\n\n<p>reference <a href=""http://www.guidetomlandai.com/tutorials/tensorflow/map_fn/"" rel=""nofollow noreferrer"">LINK</a></p>\n'}, {'owner': {'reputation': 817, 'user_id': 6227444}, 'down_vote_count': 0, 'up_vote_count': 17, 'is_accepted': False, 'score': 17, 'creation_date': 1478849210, 'answer_id': 40543116, 'question_id': 37086098, 'body': '<p>As on today, I see that map_fn is enhanced to take two tensors as the documentation says that - ""elems: A tensor or (possibly nested) sequence of tensors, each of which will be unpacked along their first dimension. The nested sequence of the resulting slices will be applied to fn.""\nThe example (though given in numpy form) also shows that it can take two tensors. I\'m copying it here.</p>\n\n<pre><code>elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\nalternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\n# alternate == [-1, 2, -3]\n</code></pre>\n\n<p><a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functional_ops.md"" rel=""noreferrer"">Source:</a> </p>\n'}, {'owner': {'reputation': 324, 'user_id': 3372150}, 'down_vote_count': 6, 'up_vote_count': 10, 'is_accepted': False, 'score': 4, 'creation_date': 1478199132, 'answer_id': 40409177, 'question_id': 37086098, 'body': ""<p>Not natively, but here's a quick function that achieves it:</p>\n\n<pre><code>def map(fn, arrays, dtype=tf.float32):\n    # assumes all arrays have same leading dim\n    indices = tf.range(tf.shape(arrays[0])[0])\n    out = tf.map_fn(lambda ii: fn(*[array[ii] for array in arrays]), indices, dtype=dtype)\n    return out\n\n# example: batch affine tranformation\nx = tf.random_normal([4,5,6])\nM = tf.random_normal([4,6,10])\nb = tf.random_normal([4,10])\n\nf = lambda x0,M0,b0: tf.matmul(x0,M0) + b0\nbatch_y = map(f, [x,M,b])\n</code></pre>\n""}, {'owner': {'reputation': 8427, 'user_id': 364772}, 'down_vote_count': 1, 'up_vote_count': 2, 'is_accepted': False, 'score': 1, 'creation_date': 1462686876, 'answer_id': 37096712, 'question_id': 37086098, 'body': ""<p>The source code shows that this function takes only one elems tensor:</p>\n\n<pre><code>def map_fn(fn, elems, dtype=None, parallel_iterations=10, back_prop=True,\n       swap_memory=False, name=None):\n</code></pre>\n\n<p>I don't see any * and ** parameters.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9463}"
522,55770009,"{'items': [{'owner': {'reputation': 81, 'user_id': 11262856}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': False, 'score': 8, 'creation_date': 1564556029, 'answer_id': 57284862, 'question_id': 55770009, 'body': '<p>I was trying to do the same thing and getting the exact same error. The problem was that weights in the Embedding layer is currently deprecated. Changing <code>weights=</code> to <code>embeddings_initializer=</code> worked for me.</p>\n\n<pre><code>self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, \nembeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\ntrainable=False)\n</code></pre>\n'}, {'owner': {'reputation': 41, 'user_id': 11718368}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1561836633, 'answer_id': 56820340, 'question_id': 55770009, 'body': '<p>firslty : load pretrained embedding matrix using</p>\n\n<pre><code>      def pretrained_embeddings(file_path, EMBEDDING_DIM, VOCAB_SIZE, word2idx):\n          # 1.load in pre-trained word vectors     #feature vector for each word\n          print(""graph in function"",tf.get_default_graph())   \n          print(\'Loading word vectors...\')\n          word2vec = {}\n          with open(os.path.join(file_path+\'.%sd.txt\' % EMBEDDING_DIM),  errors=\'ignore\', encoding=\'utf8\') as f:\n          # is just a space-separated text file in the format:\n          # word vec[0] vec[1] vec[2] ...\n          for line in f:\n             values = line.split()\n             word = values[0]\n             vec = np.asarray(values[1:], dtype=\'float32\')\n             word2vec[word] = vec\n\n          print(\'Found %s word vectors.\' % len(word2vec))\n\n          # 2.prepare embedding matrix\n          print(\'Filling pre-trained embeddings...\')\n          num_words = VOCAB_SIZE\n          # initialization by zeros\n          embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n          for word, i in word2idx.items():\n            if i &lt; VOCAB_SIZE:\n                embedding_vector = word2vec.get(word)\n                if embedding_vector is not None:\n                  # words not found in embedding index will be all zeros.\n                  embedding_matrix[i] = embedding_vector\n\n          return embedding_matrix\n</code></pre>\n\n<p>2-then update Encoder class as following:</p>\n\n<pre><code>    class Encoder(tf.keras.Model):\n       def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz,embedding_matrix):\n          super(Encoder, self).__init__()\n          self.batch_sz = batch_sz\n          self.enc_units = enc_units\n          self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix])\n          self.gru = tf.keras.layers.GRU(self.enc_units,\n                                   return_sequences=True,\n                                   return_state=True,\n                                   recurrent_initializer=\'glorot_uniform\')\n\n       def call(self, x, hidden):\n           x = self.embedding(x)\n           output, state = self.gru(x, initial_state = hidden)\n           return output, state\n\n       def initialize_hidden_state(self):\n           return tf.zeros((self.batch_sz, self.enc_units))\n</code></pre>\n\n<p>3-calling function that loads pre-trained embedding to get embedding matrix</p>\n\n<pre><code>    embedding_matrix = pretrained_embeddings(file_path, EMBEDDING_DIM,vocab_size, word2idx) \n    encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE,embedding_matrix)\n\n    # sample input\n    sample_hidden = encoder.initialize_hidden_state()\n    sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n    print (\'Encoder output shape: (batch size, sequence length, units) {}\'.format(sample_output.shape))\n    print (\'Encoder Hidden state shape: (batch size, units) {}\'.format(sample_hidden.shape))\n</code></pre>\n\n<p>Note : this works on tensorflow 1.13.1 well</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9463}"
523,52763539,"{'items': [{'owner': {'reputation': 480, 'user_id': 9415153}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1539639917, 'answer_id': 52825181, 'question_id': 52763539, 'body': '<p>You can compute the reduced mean from the reduced sum by dividing by the size of the 0th dimension:</p>\n\n<pre><code>tRatings = tf.SparseTensor(indices, values, dense_shape)\nreduced_sum = tf.sparse_reduce_sum(tRatings, 0)  # Sum of each row\nreduced_mean = reduced_sum / tf.cast(tRatings.dense_shape[0], tf.float64)  # Mean of each row\n</code></pre>\n'}, {'owner': {'reputation': 816, 'user_id': 9540764}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1539271148, 'answer_id': 52763633, 'question_id': 52763539, 'body': '<p>Try to use <code>get_shape()</code> and then multiply <code>shape[0] * shape[1]</code> this is the total number of elements</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9463}"
524,59497372,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 9, 'is_accepted': True, 'score': 9, 'creation_date': 1577527961, 'answer_id': 59509922, 'question_id': 59497372, 'body': '<p>There is no other way of doing it, because <code>tf.data.Dataset</code>s are still (and they will always be, I suppose, for performance reasons) executed in graph mode and, thus, you cannot use anything outside of the <code>tf.*</code> methods, that can be easily converted by TensorFlow to its graph representation.</p>\n\n<p>Using <code>tf.py_function</code> is the only way to mix Python execution (and thus, you can use any Python library) and graph execution when using a <code>tf.data.Dataset</code> object (on the contrary of what happens when using TensorFlow 2.0, that being eager by default allow this mixed execution naturally).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9459}"
525,44415901,"{'items': [{'owner': {'reputation': 1792, 'user_id': 2505209}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1496847705, 'answer_id': 44416293, 'question_id': 44415901, 'body': '<p>Try</p>\n\n<pre><code>init2 = tf.local_variables_initializer()\nsess.run(init2)\n</code></pre>\n\n<p>Variabes (num_epochs or capacity) inside tf.train.string_input_producer() are local variables. You have to initialize them with local variable initializer as shown above. </p>\n\n<p>Let me know if this helped. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9459}"
526,64807842,"{'items': [{'owner': {'reputation': 757, 'user_id': 7656080}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1605198706, 'answer_id': 64807843, 'question_id': 64807842, 'body': ""<p>It is assumed that the CSV file is already sorted w.r.t. time. First, read the CSV file using:</p>\n<pre><code>building_dataset = tf.data.experimental.make_csv_dataset(file_pattern=csv_file,\n                                                        batch_size=5,num_epochs=1, shuffle=False,select_columns=feature_columns)\n</code></pre>\n<p>Then define a <code>pack_features_vector</code> to convert to a features vector and unbatch using flat_map(). The tensors are also cast to float32.</p>\n<pre><code>def pack_features_vector(features):\n    &quot;&quot;&quot;Pack the features into a single array.&quot;&quot;&quot;\n    \n    features = tf.stack([tf.cast(x,tf.float32) for x in list(features.values())], axis=1)\n    return features\n\n   \nbuilding_dataset = building_dataset.map(pack_features_vector)\nbuilding_dataset = building_dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x))\nfor feature in building_dataset.take(1):\n    print('Stacked tensor:',feature)\n</code></pre>\n<p>Then use the window and flat map method.</p>\n<pre><code>building_dataset = building_dataset.window(window_size, shift=1, drop_remainder=True)\nbuilding_dataset = building_dataset.flat_map(lambda window: window.batch(window_size))\n</code></pre>\n<p>Then use map method to separate features and labels.</p>\n<pre><code>building_dataset = building_dataset.map(lambda window: (window[:,:-1], window[-1:,-1]))\nfor feature, label in building_dataset.take(5):\n    print(feature.shape)\n    print('feature:',feature[:,0:4])\n    print('label:',label)\n</code></pre>\n<p>Finally create batches using batch() and use as inputs to model training.</p>\n<pre><code>building_dataset = building_dataset.batch(32)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9459}"
527,50047909,"{'items': [{'owner': {'reputation': 23445, 'user_id': 1735003}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1524763849, 'answer_id': 50048886, 'question_id': 50047909, 'body': ""<p>They both do similar things, and one could indeed use batch norm to normalize input images.</p>\n\n<p>However, I would not use batch norm for this purpose:</p>\n\n<ul>\n<li>It is clearer to use <code>tf.image.per_image_standardization</code> for image normalization than batch norm.</li>\n<li>Batch normalization is a broader concept than a per-channel normalization. Libraries like tensorflow let you normalize along any axis you want.</li>\n<li>Batch normalization is usually paired with streaming statistics of the means and variances used for normalization, that are meant to be used for testing and deployement. You don't need those statistics when you normalize your input image per sample.</li>\n</ul>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9459}"
528,63851431,"{'items': [{'owner': {'reputation': 16316, 'user_id': 423926}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1599850250, 'answer_id': 63852739, 'question_id': 63851431, 'body': ""<p>Use custom <code>Callback</code> and hook into <code>on_epoch_end</code>. After each epoch end change the angle of the data iterator object.</p>\n<h3>Sample  (documented inline)</h3>\n<pre><code>from skimage.io import imread\nfrom skimage.transform import resize, rotate\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.utils import Sequence \nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Activation, Flatten, Dense\n\n# Model architecture  (dummy)\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(15, 15, 4)))\nmodel.add(Activation('relu'))\nmodel.add(Flatten())\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n# Data iterator \nclass CIFAR10Sequence(Sequence):\n    def __init__(self, filenames, labels, batch_size):\n        self.filenames, self.labels = filenames, labels\n        self.batch_size = batch_size\n        self.angles = [0,90,180,270]\n        self.current_angle_idx = 0\n\n    # Method to loop throught the available angles\n    def change_angle(self):\n      self.current_angle_idx += 1\n      if self.current_angle_idx &gt;= len(self.angles):\n        self.current_angle_idx = 0\n  \n    def __len__(self):\n        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n\n    # read, resize and rotate the image and return a batch of images\n    def __getitem__(self, idx):\n        angle = self.angles[self.current_angle_idx]\n        print (f&quot;Rotating Angle: {angle}&quot;)\n\n        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n        return np.array([\n            rotate(resize(imread(filename), (15, 15)), angle)\n               for filename in batch_x]), np.array(batch_y)\n\n# Custom call back to hook into on epoch end\nclass CustomCallback(keras.callbacks.Callback):\n    def __init__(self, sequence):\n      self.sequence = sequence\n\n    # after end of each epoch change the rotation for next epoch\n    def on_epoch_end(self, epoch, logs=None):\n      self.sequence.change_angle()               \n\n\n# Create data reader\nsequence = CIFAR10Sequence([&quot;f1.PNG&quot;]*10, [0, 1]*5, 8)\n# fit the model and hook in the custom call back\nmodel.fit(sequence, epochs=10, callbacks=[CustomCallback(sequence)])\n</code></pre>\n<p>Output:</p>\n<pre><code>Rotating Angle: 0\nEpoch 1/10\nRotating Angle: 0\nRotating Angle: 0\n2/2 [==============================] - 2s 755ms/step - loss: 1.0153 - accuracy: 0.5000\nEpoch 2/10\nRotating Angle: 90\nRotating Angle: 90\n2/2 [==============================] - 0s 190ms/step - loss: 0.6975 - accuracy: 0.5000\nEpoch 3/10\nRotating Angle: 180\nRotating Angle: 180\n2/2 [==============================] - 2s 772ms/step - loss: 0.6931 - accuracy: 0.5000\nEpoch 4/10\nRotating Angle: 270\nRotating Angle: 270\n2/2 [==============================] - 0s 197ms/step - loss: 0.6931 - accuracy: 0.5000\nEpoch 5/10\nRotating Angle: 0\nRotating Angle: 0\n2/2 [==============================] - 0s 189ms/step - loss: 0.6931 - accuracy: 0.5000\nEpoch 6/10\nRotating Angle: 90\nRotating Angle: 90\n2/2 [==============================] - 2s 757ms/step - loss: 0.6932 - accuracy: 0.5000\nEpoch 7/10\nRotating Angle: 180\nRotating Angle: 180\n2/2 [==============================] - 2s 757ms/step - loss: 0.6931 - accuracy: 0.5000\nEpoch 8/10\nRotating Angle: 270\nRotating Angle: 270\n2/2 [==============================] - 2s 761ms/step - loss: 0.6932 - accuracy: 0.5000\nEpoch 9/10\nRotating Angle: 0\nRotating Angle: 0\n2/2 [==============================] - 1s 744ms/step - loss: 0.6932 - accuracy: 0.5000\nEpoch 10/10\nRotating Angle: 90\nRotating Angle: 90\n2/2 [==============================] - 0s 192ms/step - loss: 0.6931 - accuracy: 0.5000\n&lt;tensorflow.python.keras.callbacks.History at 0x7fcbdf8bcdd8&gt;\n</code></pre>\n<pre><code></code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9459}"
529,71619495,"{'items': [{'owner': {'reputation': 23572, 'user_id': 1740577}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1648228738, 'answer_id': 71620821, 'question_id': 71619495, 'body': ""<p>When using <code>convert_image_dtype(image, tf.float32)</code> only type of number in image convert to <code>float32</code> and don't place [0,1) but when you divide by <code>255.0</code> you move number to [0,1) and we do this for <code>Convolutional Layers</code>.</p>\n<pre><code>import tensorflow_datasets as tfds\nimport tensorflow as tf\n\ndataset = tfds.load('cifar10', as_supervised=True, split='train').batch(1)\n\nfor image, label in dataset.take(1):\n    print(image[0])\n    \nIMG_SIZE = 64\ndef preprocess_image(image, label):\n    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n    image = tf.image.convert_image_dtype(image, tf.float32) / 255.0\n    # or\n    # image = tf.cast(image, tf.float32) / 255.0\n    return image, label\n\ndataset = dataset.map(preprocess_image)\nfor image, label in dataset.take(1):\n    print(image[0])\n</code></pre>\n<p>Output:</p>\n<pre><code>tf.Tensor(\n[[[143  96  70]\n  [141  96  72]\n  [135  93  72]\n  ...\n  [212 177 147]\n  [219 185 155]\n  [221 187 157]]], shape=(32, 32, 3), dtype=uint8)\n\n\ntf.Tensor(\n[[[0.56078434 0.3764706  0.27450982]\n  [0.5588235  0.3764706  0.2764706 ]\n  [0.55490196 0.3764706  0.28039217]\n  ...\n  [0.8607843  0.72745097 0.6098039 ]\n  [0.86470586 0.73137254 0.6137255 ]\n  [0.8666667  0.73333335 0.6156863 ]]], shape=(64, 64, 3), dtype=float32)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9454}"
530,53541803,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1543916634, 'answer_id': 53609892, 'question_id': 53541803, 'body': '<p>This is one possible solution, although it is still expensive in time and memory so it is probably not feasible for a big use case:</p>\n\n<pre><code>import tensorflow as tf\n\ndef sparse_select_indices(sp_input, indices, axis=0):\n    # Only necessary if indices may have non-unique elements\n    indices, _ = tf.unique(indices)\n    n_indices = tf.size(indices)\n    # Only necessary if indices may not be sorted\n    indices, _ = tf.math.top_k(indices, n_indices)\n    indices = tf.reverse(indices, [0])\n    # Get indices for the axis\n    idx = sp_input.indices[:, axis]\n    # Find where indices match the selection\n    eq = tf.equal(tf.expand_dims(idx, 1), tf.cast(indices, tf.int64))\n    # Mask for selected values\n    sel = tf.reduce_any(eq, axis=1)\n    # Selected values\n    values_new = tf.boolean_mask(sp_input.values, sel, axis=0)\n    # New index value for selected elements\n    n_indices = tf.cast(n_indices, tf.int64)\n    idx_new = tf.reduce_sum(tf.cast(eq, tf.int64) * tf.range(n_indices), axis=1)\n    idx_new = tf.boolean_mask(idx_new, sel, axis=0)\n    # New full indices tensor\n    indices_new = tf.boolean_mask(sp_input.indices, sel, axis=0)\n    indices_new = tf.concat([indices_new[:, :axis],\n                             tf.expand_dims(idx_new, 1),\n                             indices_new[:, axis + 1:]], axis=1)\n    # New shape\n    shape_new = tf.concat([sp_input.dense_shape[:axis],\n                           [n_indices],\n                           sp_input.dense_shape[axis + 1:]], axis=0)\n    return tf.SparseTensor(indices_new, values_new, shape_new)\n</code></pre>\n\n<p>Here is an example of use:</p>\n\n<pre><code>import tensorflow as tf\n\nwith tf.Session() as sess:\n    # Input\n    sp1 = tf.SparseTensor([[0, 1], [2, 3], [4, 5]], [10, 20, 30], [6, 7])\n    print(sess.run(tf.sparse.to_dense(sp1)))\n    # [[ 0 10  0  0  0  0  0]\n    #  [ 0  0  0  0  0  0  0]\n    #  [ 0  0  0 20  0  0  0]\n    #  [ 0  0  0  0  0  0  0]\n    #  [ 0  0  0  0  0 30  0]\n    #  [ 0  0  0  0  0  0  0]]\n\n    # Select rows 0, 1, 2\n    sp2 = sparse_select_indices(sp1, [0, 1, 2])\n    print(sess.run(tf.sparse.to_dense(sp2)))\n    # [[ 0 10  0  0  0  0  0]\n    #  [ 0  0  0  0  0  0  0]\n    #  [ 0  0  0 20  0  0  0]]\n\n    # Select columns 4, 5\n    sp3 = sparse_select_indices(sp1, [4, 5], axis=1)\n    print(sess.run(tf.sparse.to_dense(sp3)))\n    # [[ 0  0]\n    #  [ 0  0]\n    #  [ 0  0]\n    #  [ 0  0]\n    #  [ 0 30]\n    #  [ 0  0]]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9454}"
531,42333101,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9454}"
532,50252720,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9454}"
533,72465331,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9450}"
534,41941940,"{'items': [{'owner': {'reputation': 8109, 'user_id': 195651}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': True, 'score': 8, 'creation_date': 1485810047, 'answer_id': 41945333, 'question_id': 41941940, 'body': ""<p>It's a hidden gem! You can provide it a list of strings of your choice that label the summary node, e.g.</p>\n\n<pre><code>tf.summary.scalar('learning_rate', p_lr, collections=['train'])\ntf.summary.scalar('loss', t_loss, collections=['train', 'test'])\n</code></pre>\n\n<p>and then fetch the summaries by their label, e.g. like so:</p>\n\n<pre><code>s_training = tf.summary.merge_all('train')\ns_test = tf.summary.merge_all('test')\n</code></pre>\n\n<p>I'm doing it like that because I often want to log extra information during the validation phase; in the above example, I don't have to provide a value for the learning rate placeholder <code>p_lr</code> when evaluating (and writing) the accuracy, for example - or anything really that the inference part of the graph relies on.</p>\n\n<p>Providing (only) custom categories also has the nice side effect of hiding the node from <code>Supervisor</code>, for example. If you really want to have control over when exactly you write a summary (e.g. using <code>sv.summary_computed()</code> in case of <code>Supervisor</code>), that's an easy way to go.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9450}"
535,53572533,"{'items': [{'owner': {'reputation': 1132, 'user_id': 7676920}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1543679972, 'answer_id': 53572562, 'question_id': 53572533, 'body': '<p>Okay, of course I finally got it just after submitting the question. As I suspected, this was my own doing. The <code>map()</code> is returning a tuple of <code>(features, label)</code>. The second argument is of course the <code>label</code> as a tensor.</p>\n\n<p>Hopefully this is of help for someone from the future :)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9450}"
536,57873334,"{'items': [{'owner': {'reputation': 742, 'user_id': 11160943}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1625230096, 'answer_id': 68225513, 'question_id': 57873334, 'body': '<p>The comment of @lanery leads me to the answer provided by tensorflow <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/apply_affine_transform"" rel=""nofollow noreferrer"">here</a>\nThis was not avaiable in  1.4 &lt; tensorflow &lt;= 2.3</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9450}"
537,53367734,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1542627587, 'answer_id': 53373859, 'question_id': 53367734, 'body': '<p>One option is to add an additional dimension to your data and then remove it:</p>\n\n<pre><code>def avg_pool(conv_out):\n    conv_out_2d = conv_out[:, tf.newaxis]\n    pool_out_2d = tf.nn.avg_pool(conv_out_2d,\n                                 ksize=[1, 1, 2, 1],\n                                 strides=[1, 1, 2, 1],\n                                 padding=\'SAME\')\n    pool_out = pool_out_2d[:, 0]\n    return pool_out\n</code></pre>\n\n<p>Another possibility is to use the generic <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/pool"" rel=""nofollow noreferrer""><code>tf.nn.pool</code></a>:</p>\n\n<pre><code>def avg_pool(conv_out):\n    return tf.nn.pool(conv_out, window_shape=[2], pooling_type=\'AVG\', padding=\'SAME\')\n</code></pre>\n\n<p>Note in this case I am not including the stride because the default value matches what you used for your example, but you can modify it too if you want.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9450}"
538,61305781,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1590514256, 'answer_id': 62028030, 'question_id': 61305781, 'body': ""<p><code>make_parse_example_spec</code> expects <code>FeatureColumn instances</code>. You can create the FeatureColumn instance using the below method for the category list.</p>\n\n<pre><code>colors = feature_column.categorical_column_with_vocabulary_list(key='colors',vocabulary_lis=('R', 'G', 'B', 'Y'),num_oov_buckets=2)\nmy_feature_columns = [feature_column.indicator_column(colors)]\nfeature_column.make_parse_example_spec(my_feature_columns)\n</code></pre>\n\n<p>Output :</p>\n\n<pre><code>{'colors': VarLenFeature(dtype=tf.string)}  \n</code></pre>\n\n<p>If you want to create a dense embedding tensor on your categorical column, you can follow the below example.  </p>\n\n<pre><code>data = {'colors': ['X', 'R', 'G', 'B', 'Y']}\n\ndf = pd.DataFrame(data)\n\ncolors = feature_column.categorical_column_with_vocabulary_list('colors', df['colors'].unique())\n\ncolors_embedding = feature_column.embedding_column(colors, dimension=4)\n\ndense_tensor = tf.keras.layers.DenseFeatures(colors_embedding)(data)\n</code></pre>\n\n<p>Result: </p>\n\n<pre><code>tf.Tensor(\n[[ 0.17071894  0.29407692 -0.26661882  0.07768019]\n [ 0.26196313  0.14372464 -0.41102907 -0.7207164 ]\n [-0.7888006  -0.07049363 -0.49007863  0.45744416]\n [ 0.56329435 -0.7051675   0.04742934 -0.69377   ]\n [-0.52031726  0.488502   -0.37031132 -0.44338205]], shape=(5, 4), dtype=float32)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9445}"
539,44690363,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9445}"
540,49830843,"{'items': [{'owner': {'reputation': 1585, 'user_id': 5973334}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1530982591, 'answer_id': 51225193, 'question_id': 49830843, 'body': '<p>I\'ve not solved it yet either.\nOne set of explanation is here:</p>\n\n<blockquote>\n  <p><code>tf.contrib.learn.preprocessing:</code> Deprecated. The python-only\n  preprocessing functions are not a good fit for TensorFlow. Please use\n  tf.data, and consider tensorflow/transform for more complex use cases.</p>\n</blockquote>\n\n<p><a href=""https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/learn/README.md"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/learn/README.md</a></p>\n\n<p>This example should help... but it doesn\'t explain much\n<a href=""https://github.com/tensorflow/transform/blob/master/examples/sentiment_example.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/transform/blob/master/examples/sentiment_example.py</a></p>\n\n<pre><code>review_indices = tft.compute_and_apply_vocabulary(\n                    review_tokens, top_k=VOCAB_SIZE)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9443}"
541,62413757,"{'items': [{'owner': {'reputation': 423, 'user_id': 8671242}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1637181454, 'answer_id': 70011222, 'question_id': 62413757, 'body': '<p>Since the provided notebook is no longer available I will assume that you were using this (oficial?) <a href=""https://github.com/tensorflow/models/tree/master/official/nlp"" rel=""nofollow noreferrer"">BERT implementation for thensorflow</a>\nsince I was having the same issue with it.</p>\n<hr />\n<p>TL;DR: You can\'t load the model due to missing proper <code>get_config</code> methods in the <a href=""https://github.com/tensorflow/models/blob/c0af8f0b2d86e6d567681d86416e6f96a4c1997d/official/nlp/modeling/networks/bert_encoder.py#L273"" rel=""nofollow noreferrer"">subclassed model</a> and (possibly) <a href=""https://github.com/tensorflow/models/blob/9b23daf9daaa1b44aee32e9f2e3b7ee5c9462b11/official/nlp/modeling/layers/self_attention_mask.py"" rel=""nofollow noreferrer"">this layer</a>. You need to edit the BERT encoder class (if this is a possibility for you).</p>\n<hr />\n<p>I came across this while trying to modify the <a href=""https://github.com/tensorflow/models/blob/c0af8f0b2d86e6d567681d86416e6f96a4c1997d/official/nlp/modeling/networks/bert_encoder.py#L273"" rel=""nofollow noreferrer"">BERT model</a> and apply the Masked Language Modeling training. I found that I was not able to load the checkpoints due to the mentioned <code>KeyError: \'name\'</code>.\nI found three issues:</p>\n<ol>\n<li>After a lot of testing I found that several layers where producing a warning during saving, the Warning stated <code>Custom mask layers require a config and must override... </code> I fixed the layers in my implementation, however the problem persisted.</li>\n<li>Later I realized that the <code>KeyError: \'name\'</code> came from the model\'s <a href=""https://github.com/tensorflow/models/blob/c0af8f0b2d86e6d567681d86416e6f96a4c1997d/official/nlp/modeling/networks/bert_encoder.py#L523"" rel=""nofollow noreferrer"">get_config implementation</a> which was not yielding the <code>tf.keras.Model</code> original config along with the <a href=""https://github.com/tensorflow/models/blob/c0af8f0b2d86e6d567681d86416e6f96a4c1997d/official/nlp/modeling/networks/bert_encoder.py#L493"" rel=""nofollow noreferrer"">new config dict</a>. In this particular case it was not due to missing layer configuration (as it is often the case). I patched the subclassed model <code>get_config</code> method in my implementation:</li>\n</ol>\n<pre><code>\ndef get_config(self):\n    # Implement get_config to enable serialization. This is NOT optional.\n    base_config = super(LayoutEncoder, self).get_config()\n    return dict(list(self._config.items()) + list(base_config.items()))\n</pre></code>\n<ol start=""3"">\n<li>Solving the <code>KeyError: \'name\'</code> (using the code in point 2.) created a new and more horrible error (also during loading/saving). More than 500 lines of errors/warnings containing <code>WARNING:tensorflow:Unresolved object in checkpoint...</code> and <code>Inconsistent references when loading the checkpoint into this object graph...</code> appeared and the loading still failed. I found that this was caused by the way that the BERT model was keeping track of the layers (lines 484-491). These layers were also serialized during save. I\'m not sure why these members are added to the encoder class, however by removing them I was able to save and load the model without any other problem.</li>\n</ol>\n<p>Sorry for the long history but, imho, this was the only way to explain it...</p>\n'}, {'owner': {'reputation': 175, 'user_id': 1042682}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1605302030, 'answer_id': 64828111, 'question_id': 62413757, 'body': '<p>I\'ve documented my experience of that <code>KeyError</code> (and the solution I found) here:</p>\n<p><a href=""https://github.com/tensorflow/models/issues/8692#issuecomment-727033061"" rel=""nofollow noreferrer"">https://github.com/tensorflow/models/issues/8692#issuecomment-727033061</a></p>\n<p>It was due to a bad implementation of a custom layer\'s <code>get_config()</code> that didn\'t use the parent\'s base config, that does contain the <code>name</code> key, necessary for keras reload.</p>\n'}, {'owner': {'reputation': 2428, 'user_id': 11235205}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1601360754, 'answer_id': 64114020, 'question_id': 62413757, 'body': ""<p>As it stated, <code>name</code> is not defined. <code>model = tf.keras.models.load_model('./saved_model/test')</code> leads to the PATH (folder) <code>./saved_model/test</code>, not the PATH of the model.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9443}"
542,58162110,"{'items': [{'owner': {'reputation': 267, 'user_id': 12198627}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1571135482, 'answer_id': 58392592, 'question_id': 58162110, 'body': '<p>The Reason might be is <code>MonitoredTrainingSession</code> is finalizing(frozen) the graph, you might require to initialize the graph on loop, you can use the function to create new graph on top of loop.</p>\n\n<pre><code>import tensorflow as tf\ntf.reset_default_graph()\ntf.Graph().as_default()\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9443}"
543,46046145,"{'items': [{'owner': {'reputation': 784, 'user_id': 4922660}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1504606294, 'answer_id': 46052415, 'question_id': 46046145, 'body': ""<p>It's a little tricky:</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\n\nseries = tf.placeholder(tf.float32, shape=[None, 5])\nseries_length = tf.placeholder(tf.int64)\n\ndef magic_slice_function(input_x, input_y):\n    array = []\n    for i in range(len(input_x)):\n        temp = [input_x[i][j] for j in range(input_y[i])]\n        array.extend(temp)\n    return [array]\n\nwith tf.Session() as sess:\n    input_x = np.array([[1, 2, 3, 0, 0],\n                        [2, 3, 0, 0, 0],\n                        [1, 0, 0, 0, 0]])\n\n    input_y = np.array([3, 2, 1], dtype=np.int64)\n\n    merged_series =  tf.py_func(magic_slice_function, [series, series_length], tf.float32, name='slice_func')\n\n    out = tf.split(merged_series, input_y)\n    print(sess.run(out, feed_dict={series: input_x, series_length: input_y}))\n</code></pre>\n\n<p>The output will be:</p>\n\n<pre><code>[array([ 1.,  2.,  3.], dtype=float32), array([ 2.,  3.], dtype=float32), array([ 1.], dtype=float32)]\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9443}"
544,71773122,"{'items': [{'owner': {'reputation': 515, 'user_id': 15848470}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1649366525, 'answer_id': 71789064, 'question_id': 71773122, 'body': '<p>Seems my installation of TF was corrupted. A full uninstall and reinstall fixed it.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9439}"
545,53787587,"{'items': [{'owner': {'reputation': 2188, 'user_id': 8468326}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1545137150, 'answer_id': 53833323, 'question_id': 53787587, 'body': '<p>First off, you should be having a really good reason to go for an increased computational overhead with Windows-based AMI.</p>\n\n<p><strong>If your CPU is at ~100%, while GPU is &lt;100%, then your CPU is likely the bottleneck.</strong> If you are on cloud, consider moving to instances with larger CPU-count <em>(CPU is cheap, GPU is scarce)</em>. If you can\'t increase CPU count, moving some parts of your graph to GPU is an option. However, <code>tf.data</code>-based input pipeline is run entirely on CPU (but highly scalable due to C++ implementation). Prefetching to GPUs might also help here, but the cost of spawning another background thread to populate the buffer for downstream might damp this effect. Another option is to do some or all pre-processing steps offline <em>(i.e. prior to training)</em>.</p>\n\n<p><strong>A word of caution on using Keras as the input pipeline.</strong> Keras relies on Pythons <code>multithreading</code> (and optionally <code>multiprocessing</code>) libraries, which may both lack performance (when doing heavy I/O or augmentations on-the-fly) and scalability (when running on multiple CPUs) compared to <a href=""https://wiki.python.org/moin/GlobalInterpreterLock"" rel=""nofollow noreferrer"">GIL</a>-free implementations. Consider performing preprocessing offline, pre-loading input data, or using alternative input pipelines (as the aforementioned TF native <a href=""https://www.tensorflow.org/guide/performance/datasets"" rel=""nofollow noreferrer""><code>tf.data</code></a>, or 3rd party ones, like <a href=""https://github.com/tensorpack/tensorpack"" rel=""nofollow noreferrer""><code>Tensorpack</code></a>).</p>\n'}, {'owner': {'reputation': 1836, 'user_id': 1097517}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1544834399, 'answer_id': 53788574, 'question_id': 53787587, 'body': '<p>The performance of any machine learning model depends on many things. Including but not limited to: How much pre-processing you do, how much data you copy from CPU to GPU, Op bottlenecks, and many more. Check out the tensorflow <a href=""https://www.tensorflow.org/guide/performance/overview"" rel=""nofollow noreferrer"">performance guide</a> as a first step. There are also a few videos from the tensorflow dev summit 2018 that talk about performance. How to properly <a href=""https://youtu.be/uIcqeP7MFH0"" rel=""nofollow noreferrer"">use tf.data</a>, and how to <a href=""https://www.youtube.com/watch?v=SxOsJPaxHME"" rel=""nofollow noreferrer"">debug performance</a> are two that I recommend.</p>\n\n<p>The only thing I can say for sure is that JSON is a bad format for this purpose. You should switch to <a href=""https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data"" rel=""nofollow noreferrer"">tfrecord format</a>, which uses protobuf (<a href=""https://auth0.com/blog/beating-json-performance-with-protobuf/"" rel=""nofollow noreferrer"">better than JSON</a>).</p>\n\n<p>Unfortunately performance and optimisation of any system takes a lot of effort and time, and can be a rabbit hole that just keeps going down.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9439}"
546,45208516,"{'items': [{'owner': {'reputation': 3596, 'user_id': 6780025}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1501717945, 'answer_id': 45472720, 'question_id': 45208516, 'body': '<p>This is done to subtract each centroid from each point. First, make sure you understand the notion of broadcasting (<a href=""https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html"" rel=""nofollow noreferrer"">https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html</a>)\n that is linked from tf.subtract (<a href=""https://www.tensorflow.org/api_docs/python/tf/subtract"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/subtract</a>). Then, you just need to draw the shapes of <code>points</code>, <code>expanded_points</code>, <code>centroids</code>, and <code>expanded_centroids</code> and understand what values get ""broadcast"" where. Once you do that you will see that broadcasting allows you to compute exactly what you want - subtract each point from each centroid.</p>\n\n<p>As a sanity check, since there are 200 points, 3 centroids, and each is 2D, we should have 200*3*2 differences. This is exactly what we get:  </p>\n\n<pre><code>In [53]: points\nOut[53]: &lt;tf.Tensor \'Const:0\' shape=(200, 2) dtype=float64&gt;\n\nIn [54]: points_expanded\nOut[54]: &lt;tf.Tensor \'ExpandDims_4:0\' shape=(1, 200, 2) dtype=float64&gt;\n\nIn [55]: centroids\nOut[55]: &lt;tf.Variable \'Variable:0\' shape=(3, 2) dtype=float64_ref&gt;\n\nIn [56]: centroids_expanded\nOut[56]: &lt;tf.Tensor \'ExpandDims_5:0\' shape=(3, 1, 2) dtype=float64&gt;\n\nIn [57]: tf.subtract(points_expanded, centroids_expanded)\nOut[57]: &lt;tf.Tensor \'Sub_5:0\' shape=(3, 200, 2) dtype=float64&gt;\n</code></pre>\n\n<p>If you are having trouble drawing the shapes, you can think of broadcasting the <code>expanded_points</code> with dimension <code>(1, 200, 2)</code> to dimension <code>(3, 200, 2)</code> as copying the 200x2 matrix 3 times along the first dimension. The 3x2 matrix in <code>centroids_expanded</code> (of shape (3, 1, 2)) get copied 200 times along the second dimension.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9439}"
547,45077445,"{'items': [{'owner': {'reputation': 10445, 'user_id': 4640905}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1499946672, 'answer_id': 45079806, 'question_id': 45077445, 'body': '<p>As mentioned by <a href=""https://stackoverflow.com/users/1946465/isarandi"">@isarandi</a> in a comment, the easiest way is to first recover all checkpoint paths using <code>get_checkpoint_state\u200c</code> followed by <code>all_model_checkpoi\u200c\u200bnt_paths</code>, which is basically an undocumented feature. You can then restore your latest state as such:</p>\n\n<pre><code>states = tf.train.get_checkpoint_state\u200c\u200b(your_checkpoint_dir\u200c\u200b)\ncheckpoint_paths = states.all_model_checkpoi\u200c\u200bnt_paths\nsaver.recover_last_checkpoints(checkpoint_paths)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9439}"
548,36295624,"{'items': [{'owner': {'reputation': 385, 'user_id': 5367279}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1479365842, 'answer_id': 40648525, 'question_id': 36295624, 'body': '<p>I faced the same problem. drop the relu activation from last dense layer. worked for me.</p>\n\n<pre><code> dense2 = tf.nn.relu(tf.matmul(dense1, _weights[\'wd2\']) + _biases[\'bd2\'], name=\'fc7\') # Relu activation\n</code></pre>\n\n<p>after this again</p>\n\n<pre><code>out = tf.nn.softmax(tf.matmul(dense2, _weights[\'out\']) + _biases[\'out\'])\n</code></pre>\n\n<p>Thus the first ""relu"" seems to be redundant to me. I did a similar thing. After dropping that line it solved the problem.</p>\n'}, {'owner': {'reputation': 11, 'user_id': 6224293}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1461061286, 'answer_id': 36715531, 'question_id': 36295624, 'body': '<p>From Tensorflow <a href=""https://www.tensorflow.org/versions/r0.8/api_docs/python/nn.html#softmax_cross_entropy_with_logits"" rel=""nofollow"">documentation</a>!</p>\n\n<p><em>WARNING: This op expects unscaled logits, since it performs a softmax on logits internally for efficiency. Do not call this op with the output of softmax, as it will produce incorrect results.</em></p>\n\n<p>With this in mind you should take out </p>\n\n<pre><code>out = tf.nn.softmax(tf.matmul(dense2, _weights[\'out\']) + _biases[\'out\'])\n</code></pre>\n\n<p>from your network definition and replace with </p>\n\n<pre><code>out = tf.matmul(dense2, _weights[\'out\']) + _biases[\'out\']\n</code></pre>\n\n<p>Since you are not fine-tuning i.e not porting weights trained on a similar problem the training would tend to be slow. Keeping in mind this could be one of many problems with the training. Hope it helps. </p>\n'}, {'owner': {'reputation': 368, 'user_id': 5732171}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1459363311, 'answer_id': 36317143, 'question_id': 36295624, 'body': ""<p>You can use a different initialization scheme by creating numpy arrays for the initial values of your variables.</p>\n\n<p>Your loss isn't changing at all, so one way to debug is to confirm that the variables are actually changing as you do updates.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9439}"
549,53003208,"{'items': [{'owner': {'reputation': 275, 'user_id': 3870291}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1540867349, 'answer_id': 53056640, 'question_id': 53003208, 'body': '<p>Another way to do this is to rewrite the model using Keras and use tf.contrib.tpu.keras_to_tpu_model(..) with tf.contrib.tpu.TPUDistributionStrategy(...). Here is small code snippet for this: </p>\n\n<pre><code>def get_model():\n  return keras.Sequential([\n    keras.layers.Dense(10, input_shape=(4,), activation=tf.nn.relu, name = ""Dense_1""),\n    keras.layers.Dense(10, activation=tf.nn.relu, name = ""Dense_2""),\n    keras.layers.Dense(3, activation=None, name = ""logits""),\n    keras.layers.Dense(3, activation=tf.nn.softmax, name = ""softmax"")\n  ])\n\ndnn_model = get_model()\n\ndnn_model.compile(optimizer=tf.train.AdagradOptimizer(learning_rate=0.1), \n              loss=\'sparse_categorical_crossentropy\',\n              metrics=[\'sparse_categorical_crossentropy\'])\n\ntpu_model = tf.contrib.tpu.keras_to_tpu_model(\n    dnn_model,\n    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))\n\n# Train the model\ntpu_model.fit(\n  train_x, train_y,\n  steps_per_epoch = steps_per_epoch,\n  epochs=epochs,\n)\n\ntpu_model.save_weights(\'./saved_weights.h5\', overwrite=True)\n</code></pre>\n'}, {'owner': {'reputation': 871, 'user_id': 10199571}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1540584396, 'answer_id': 53015637, 'question_id': 53003208, 'body': '<p>You can create a Google Cloud account under the <a href=""https://cloud.google.com/free/"" rel=""nofollow noreferrer"">free tier</a> and then create a <a href=""https://cloud.google.com/storage/"" rel=""nofollow noreferrer"">GCS bucket</a>. After doing that you can authenticate yourself in Colab to get write access to your GCS bucket from Colab by doing the following:</p>\n\n<pre><code>from google.colab import auth\nauth.authenticate_user()\n</code></pre>\n\n<p>Here is a <a href=""https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/shakespeare_with_tpuestimator.ipynb"" rel=""nofollow noreferrer"">sample Colab notebook</a> that uses Cloud TPUs and GCS.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9434}"
550,56552397,"{'items': [{'owner': {'reputation': 1088, 'user_id': 6370655}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1572560379, 'answer_id': 58651859, 'question_id': 56552397, 'body': '<p>I think that the result of a metric should be a single tensor value that represents the average of the results as described <a href=""https://keras.io/metrics/"" rel=""nofollow noreferrer"">here</a> in the Keras documentation (which I find is the better documentation than that from TensorFlow).</p>\n\n<p>You could instead use a <a href=""https://keras.io/callbacks/#callback"" rel=""nofollow noreferrer"">custom callback</a> to achieve your desired result, most probably you would want to write to disc the result on_epoch_end</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9434}"
551,55638989,"{'items': [{'owner': {'reputation': 8315, 'user_id': 5154274}, 'down_vote_count': 0, 'up_vote_count': 9, 'is_accepted': True, 'score': 9, 'creation_date': 1555010964, 'answer_id': 55639871, 'question_id': 55638989, 'body': '<p>You don\'t have a forward pass in your model. The <code>Model.predict()</code> method returns <code>numpy()</code> array without taping the forward pass. Take a look at this example:</p>\n\n<p>Given a following data and model:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\n\nx_train = tf.convert_to_tensor(np.ones((1, 2), np.float32), dtype=tf.float32)\ny_train = tf.convert_to_tensor([[0, 1]])\n\nmodel = tf.keras.models.Sequential([tf.keras.layers.Dense(2, input_shape=(2, ))])\n</code></pre>\n\n<p>First we use <code>predict()</code>:</p>\n\n<pre class=""lang-py prettyprint-override""><code>with tf.GradientTape() as tape:\n    logits = model.predict(x_train)\n    print(\'`logits` has type {0}\'.format(type(logits)))\n    # `logits` has type &lt;class \'numpy.ndarray\'&gt;\n    xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_train, logits=logits)\n    reduced = tf.reduce_mean(xentropy)\n    grads = tape.gradient(reduced, model.trainable_variables)\n    print(\'grads are: {0}\'.format(grads))\n    # grads are: [None, None]\n</code></pre>\n\n<p>Now we use model\'s input:</p>\n\n<pre class=""lang-py prettyprint-override""><code>with tf.GradientTape() as tape:\n    logits = model(x_train)\n    print(\'`logits` has type {0}\'.format(type(logits)))\n    # `logits` has type &lt;class \'tensorflow.python.framework.ops.EagerTensor\'&gt;\n    xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_train, logits=logits)\n    reduced = tf.reduce_mean(xentropy)\n    grads = tape.gradient(reduced, model.trainable_variables)\n    print(\'grads are: {0}\'.format(grads))\n    # grads are: [&lt;tf.Tensor: id=2044, shape=(2, 2), dtype=float32, numpy=\n    # array([[ 0.77717704, -0.777177  ],\n    #        [ 0.77717704, -0.777177  ]], dtype=float32)&gt;, &lt;tf.Tensor: id=2042, \n    # shape=(2,), dtype=float32, numpy=array([ 0.77717704, -0.777177  ], dtype=float32)&gt;]\n\n</code></pre>\n\n<p>So use model\'s <code>__call__()</code> (i.e. <code>model(x)</code>) for forward pass and not <code>predict()</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9434}"
552,44123088,"{'items': [{'owner': {'reputation': 7540, 'user_id': 3908170}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1495494378, 'answer_id': 44123386, 'question_id': 44123088, 'body': '<p>Also from the Docs:</p>\n\n<blockquote>\n  <p>Measures the probability error in discrete classification tasks in which the classes are mutually exclusive (each entry is in exactly one class).</p>\n</blockquote>\n\n<p><code>Softmax</code> classification <em>uses</em> <code>cross-entropy loss function</code> to train and classify data among discrete classes. There are other <strong>activation functions</strong> used like <code>ReLU</code> (Rectified Linear Units) or <code>Sigmoid</code> that are used in Linear Classification and NN; in this case <code>Softmax</code> is used. </p>\n\n<p>Activation functions are decision functions (the ones that actually classify data into categories) and cross-entropy is the function used to calculate the error during training (you could use other ways to calculate the error cost like mean squares). However, cross-entropy seems to be the currently the best way to calculate it.</p>\n\n<p>As some point out, <code>softmax cross-entropy</code> is a commonly used term in Classification for convenient notation.</p>\n\n<p><strong>Edit</strong></p>\n\n<p>Regarding the <em>logits</em>, it means that it works with its input data unscaled. In other words, the input data may not be a probability value (i.e., values may be > 1). Check <a href=""https://stackoverflow.com/questions/34240703/difference-between-tensorflow-tf-nn-softmax-and-tf-nn-softmax-cross-entropy-with"">this question</a> to know more about <code>softmax_cross_entropy_with_logits</code> and its components.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9434}"
553,50635729,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9434}"
554,67226579,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1640830083, 'answer_id': 70526803, 'question_id': 67226579, 'body': '<p>These logs might be due to looping in your code.\nYou can just turn off these logs using</p>\n<pre><code>import os\nos.environ[&quot;TF_CPP_MIN_LOG_LEVEL&quot;] = &quot;2&quot;\nimport tensorflow as tf\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9429}"
555,55122902,"{'items': [{'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1552408444, 'answer_id': 55126482, 'question_id': 55122902, 'body': '<p>As with Estimator API, you can use <code>from_generator</code></p>\n\n<pre><code>data_chunks = list(np.split(data, 1024))\nlabels_chunks = list(np.split(labels, 1024))\n\ndef genenerator():\n    for i, j in zip(data_chunks, labels_chunks):\n        yield i, j\n\ntrain_dataset = tf.data.Dataset.from_generator(genenerator, (tf.float32, tf.float32))\ntrain_dataset = train_dataset.shuffle().batch().repeat()\n</code></pre>\n\n<p>Also take a look <a href=""https://github.com/tensorflow/tensorflow/issues/24520"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/24520</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9429}"
556,58577878,"{'items': [{'owner': {'reputation': 2452, 'user_id': 11220884}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1572168102, 'answer_id': 58578062, 'question_id': 58577878, 'body': '<p>Check out TensorFlow-Addons:</p>\n\n<p><a href=""https://github.com/tensorflow/addons"" rel=""nofollow noreferrer"">https://github.com/tensorflow/addons</a>, </p>\n\n<p><a href=""https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq?hl=en"" rel=""nofollow noreferrer"">https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq?hl=en</a></p>\n\n<p>the functions you are looking for are all there.</p>\n\n<pre><code>pip install tensorflow-addons\n</code></pre>\n\n<p>Then:</p>\n\n<pre><code>import tensorflow as tf\nimport tensorflow_addons as tfa\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9429}"
557,62405592,"{'items': [{'owner': {'reputation': 1, 'user_id': 7563156}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1646016282, 'answer_id': 71290133, 'question_id': 62405592, 'body': '<p>When you use distributed strategy, the metric must be constructed and used  inside the <code>strategy.scope()</code> block. So when you want to call the <code>metric.result()</code> method, remember to put it inside the with <code>strategy.scope()</code> block.</p>\n<pre><code>with strategy.scope():\n  print(metric.result())\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9429}"
558,60398554,"{'items': [{'owner': {'reputation': 2652, 'user_id': 8831165}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1582712388, 'answer_id': 60411616, 'question_id': 60398554, 'body': ""<p>There's different ways to do what you want here, but the one I always use is: </p>\n\n<pre><code>batch_size = 32\nds = tf.Dataset()\nds = ds.shuffle(len_ds)\ntrain_ds = ds.take(0.8*len_ds)\ntrain_ds = train_ds.repeat().batch(batch_size)\nvalidation_ds = ds.skip(0.8*len_ds)\nvalidation_ds = train_ds.repeat().batch(batch_size)\nmodel.fit(train_ds,\n          steps_per_epoch = len_train_ds // batch_size,\n          validation_data = validation_ds,\n          validation_steps = len_validation_ds // batch_size,\n          epochs = 5)\n</code></pre>\n\n<p>This way you have access to all the variables after model fitting as well, for example if you want to visualize the validation set, you can. This is not really possible with <code>validation_split</code>. If you remove <code>.batch(batch_size)</code>, you should remove the <code>// batch_size</code>s, but I would leave them, as it clearer what is happening now.</p>\n\n<p>You always have to provide epochs.</p>\n\n<p>Calculating the length of your train/validation sets requires you to loop over them: </p>\n\n<pre><code>len_train_ds = 0\nfor i in train_ds:\n  len_train_ds += 1\n</code></pre>\n\n<p>if in <code>tf.Dataset</code> form.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9429}"
559,52976606,"{'items': [{'owner': {'reputation': 11, 'user_id': 10223381}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1550226743, 'answer_id': 54707391, 'question_id': 52976606, 'body': '<p>I get the same issue even without batch normalization. From what I remember, I was able to get around it by calling <code>update_ops</code> in <code>sess.run</code> along with <code>train_ops</code>, as opposed to in a <code>tf.control_dependencies</code> clause. This probably is just a bug with tensorflow.</p>\n'}, {'owner': {'reputation': 111, 'user_id': 9226290}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1541711115, 'answer_id': 53216124, 'question_id': 52976606, 'body': ""<p>I couldn't figure out why the global step was not incrementing automatically, but manually incrementing the global step as follows by adding it to the train_op with tf.group is a nice work around. </p>\n\n<pre><code>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n    with tf.control_dependencies(update_ops):\n        optimizer = tf.contrib.opt.MultitaskOptimizerWrapper(params['optimization_algorithm'](params['training_rate']))\n        train_op = optimizer.minimize(loss)\n\n        global_step = tf.train.get_global_step()\n        update_global_step = tf.assign(global_step, global_step + 1, name = 'update_global_step')\n\n        return tf.estimator.EstimatorSpec(mode, loss = loss, train_op = tf.group(train_op, update_global_step))\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9424}"
560,51706848,"{'items': [{'owner': {'reputation': 419, 'user_id': 8128643}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1533627648, 'answer_id': 51721390, 'question_id': 51706848, 'body': '<p>Tensor before and after <code>tf.reshape</code> have the <strong>same flatten order</strong>.</p>\n\n<p>In tensorflow runtime, a Tensor is consists of raw data(byte array), shape, and dtype, <code>tf.reshape</code> only change shape, with raw data and dtype not changed. <code>-1</code> or <code>None</code> in <code>tf.reshape</code> means that this value can be calculated.</p>\n\n<p>For example,</p>\n\n<pre><code># a tensor with 6 elements, with shape [3,2]\na = tf.constant([[1,2], [3,4], [5,6]]) \n# reshape tensor to [2, 3, 1], 2 is calculated by 6/3/1\nb = tf.reshape(a, [-1, 3, 1])\n</code></pre>\n\n<p>In this example, <code>a</code> and <code>b</code> have the same flatten order, namely <code>[1,2,3,4,5,6]</code>, <code>a</code> has the shape <code>[3,2]</code>, its value is <code>[[1,2], [3,4], [5,6]]</code>, <code>b</code> has the shape <code>[2,3,1]</code>, its value is <code>[[[1],[2],[3]],[[4],[5],[6]]]</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9423}"
561,50486241,"{'items': [{'owner': {'reputation': 858, 'user_id': 2594778}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1527079751, 'answer_id': 50488872, 'question_id': 50486241, 'body': '<p>The solution is to use tf.reduce_all():</p>\n\n<pre><code>i = tf.constant(0)\nc = lambda i: tf.reduce_all(tf.greater([10,10],[i,i]))\nb = lambda i: tf.add(i, 1)\nr = tf.while_loop(c, b, [i])\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9423}"
562,61875170,"{'items': [{'owner': {'reputation': 55360, 'user_id': 349130}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1589823991, 'answer_id': 61875769, 'question_id': 61875170, 'body': '<p>What is presented in the keras progress bar is a running mean of your loss/metrics over batches, since the model is being trained on batches and the weights are changing after each batch. This is why you get a floating point value.</p>\n\n<p>Your metric should also return a floating point value, maybe by taking a division over the number of elements in the batch. Then the metric values will make more sense.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9423}"
563,50500579,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9423}"
564,45202404,"{'items': [{'owner': {'reputation': 1330, 'user_id': 8315956}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1500557153, 'answer_id': 45216136, 'question_id': 45202404, 'body': '<p>Input images with size 32x32 too small for inception model. Inception_v1 try to use average pooling with kernel size 7x7, but on input to this layer came 1x1 data (with 1024 channels) after all previous pooling layers.</p>\n\n<p>Anyway i think ""inception"" is too big for task, which you describe.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9419}"
565,53760992,"{'items': [{'owner': {'reputation': 2146, 'user_id': 3086290}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': True, 'score': 11, 'creation_date': 1544704356, 'answer_id': 53761947, 'question_id': 53760992, 'body': '<p><code>tf.nn.xw_plus_b</code> is a low-level operation that only computes <code>x*W+b</code> and requires existing variables.</p>\n\n<p><code>tf.layers.dense</code> is a high-level ""layer"" that creates variables, apply activation can set constrains and apply regularization.</p>\n\n<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/dense"" rel=""noreferrer"">documentation</a> default activation is linear (no activation).</p>\n\n<blockquote>\n  <p><strong>activation</strong>: Activation function (callable). Set it to None to maintain\n  a linear activation.</p>\n</blockquote>\n\n<p><strong>Update</strong></p>\n\n<p>In Tensorflow 1.12 <code>Dense</code> layer inherits  <code>keras.layers.Dense</code> (<a href=""https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/python/layers/core.py#L32"" rel=""noreferrer"">code</a>):</p>\n\n<pre class=""lang-py prettyprint-override""><code>@tf_export(\'layers.Dense\')\nclass Dense(keras_layers.Dense, base.Layer):\n</code></pre>\n\n<p>Keras implementation of this layer does the following (<a href=""https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/python/keras/layers/core.py#L958"" rel=""noreferrer"">code</a>):</p>\n\n<pre class=""lang-py prettyprint-override""><code>  def call(self, inputs):\n    inputs = ops.convert_to_tensor(inputs, dtype=self.dtype)\n    rank = common_shapes.rank(inputs)\n    if rank &gt; 2:\n      # Broadcasting is required for the inputs.\n      outputs = standard_ops.tensordot(inputs, self.kernel, [[rank - 1], [0]])\n      # Reshape the output back to the original ndim of the input.\n      if not context.executing_eagerly():\n        shape = inputs.get_shape().as_list()\n        output_shape = shape[:-1] + [self.units]\n        outputs.set_shape(output_shape)\n    else:\n      outputs = gen_math_ops.mat_mul(inputs, self.kernel)\n    if self.use_bias:\n      outputs = nn.bias_add(outputs, self.bias)\n    if self.activation is not None:\n      return self.activation(outputs)  # pylint: disable=not-callable\n    return outputs\n</code></pre>\n\n<p>So it is not implemented using <code>tf.nn.xw_plus_b</code> but uses two separate operations.</p>\n\n<p>To answer your question: <code>Dense</code> layer without activation, constraints and regularization should do the same as <code>tf.nn.xw_plus_b</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9419}"
566,73264100,"{'items': [{'owner': {'reputation': 3244, 'user_id': 14774959}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1659882406, 'answer_id': 73268266, 'question_id': 73264100, 'body': '<p>Yes, <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/local_response_normalization"" rel=""nofollow noreferrer""><code>tf.nn.local_response_normalization</code></a> can be used in a lambda layer. See the code below:</p>\n<pre><code>...\nmodel.add(BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(10))\nmodel.add(layers.Lambda(tf.nn.local_response_normalization))\n...\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9419}"
567,67462119,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9419}"
568,52878311,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1539879888, 'answer_id': 52878532, 'question_id': 52878311, 'body': '<p>That can be done with <a href=""https://www.tensorflow.org/api_docs/python/tf/gather"" rel=""nofollow noreferrer""><code>tf.gather</code></a>, using the <code>axis</code> parameter:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\na = np.arange(18).reshape((2,3,3))\nidx = [2,0,1]\nb = a[:, idx, :]\nc = a[:, :, idx]\n\naT = tf.constant(a)\nidxT = tf.constant(idx)\nbT = tf.gather(aT, idxT, axis=1)\ncT = tf.gather(aT, idxT, axis=2)\n\nwith tf.Session() as sess:\n    b1, c1=sess.run([bT, cT])\n\nprint(np.allclose(b, b1))\nprint(np.allclose(c, c1))\n</code></pre>\n\n<p>Output:</p>\n\n<pre class=""lang-none prettyprint-override""><code>True\nTrue\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9419}"
569,68869097,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9414}"
570,51971050,"{'items': [{'owner': {'reputation': 11, 'user_id': 21391477}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1679463791, 'answer_id': 75808761, 'question_id': 51971050, 'body': ""<p>The way to go from a SavedModel to a servable after running tensorflow graph transforms is to use the SavedModel Builder API.</p>\n<p>First, you need to create a SavedModel Builder object and then rebuild the graph you have just transformed, using the SavedModel Builder API.</p>\n<p>Next, you need to add the assets, signatures, and other meta-data back into the model. Finally, you need to call the SavedModel Builder API's save() method, which will save the model as a servable.</p>\n<p>This servable can then be used with tensorflow serving.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9414}"
571,56038372,"{'items': [{'owner': {'reputation': 8315, 'user_id': 5154274}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1557313624, 'answer_id': 56039353, 'question_id': 56038372, 'body': '<p>Adding <code>@tf.function</code> does add significant speedup. Take a look at this:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\ndata = tf.random.normal((1000, 10, 10, 1))\ndataset = tf.data.Dataset.from_tensors(data).batch(10)\n\ndef iterate_1(dataset):\n    for x in dataset:\n        x = x\n\n@tf.function\ndef iterate_2(dataset):\n    for x in dataset:\n        x = x\n\n%timeit -n 1000 iterate_1(dataset) # 1.46 ms  8.2 s per loop\n%timeit -n 1000 iterate_2(dataset) # 239 s  10.2 s per loop\n</code></pre>\n\n<p>As you can see iterating with <code>@tf.function</code> is more than 6 times faster.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9414}"
572,64947184,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9414}"
573,63222770,"{'items': [{'owner': {'reputation': 19216, 'user_id': 10133797}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1596419662, 'answer_id': 63222771, 'question_id': 63222770, 'body': '<p>We\'ll need to elaborately apply <code>tf.while_loop</code>; from <a href=""https://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/python/ops/tensor_array_ops.py#L950"" rel=""nofollow noreferrer""><code>help(TensorArray)</code></a>:</p>\n<blockquote>\n<p>This class is meant to be used with dynamic iteration primitives such as <code>while_loop</code> and <code>map_fn</code>.  It  supports gradient back-propagation via special &quot;flow&quot; control flow dependencies.</p>\n</blockquote>\n<p>We thus seek to write a loop such that all outputs we are to backpropagate through are written to a <code>TensorArray</code>. Code accomplishing this, and its high-level description, below. At bottom is a validating example.</p>\n<hr>\n<p><strong>Description</strong>:</p>\n<ul>\n<li>Code borrows from <a href=""https://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/python/keras/backend.py#L3996"" rel=""nofollow noreferrer""><code>K.rnn</code></a>, rewritten for simplicity and relevance</li>\n<li>For better understanding, I suggest  inspecting <code>K.rnn</code>, <a href=""https://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/python/keras/layers/recurrent.py#L1362"" rel=""nofollow noreferrer""><code>SimpleRNNCell.call</code></a>, and <a href=""https://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/python/keras/layers/recurrent.py#L722"" rel=""nofollow noreferrer""><code>RNN.call</code></a>.</li>\n<li><code>model_rnn</code> has a few needless checks for sake of case 3; will link cleaner version</li>\n<li>The idea\'s as follows: we traverse the network <em>first</em> bottom-to-top, <em>then</em> left-to-right, and write the entire forward pass to a <em>single</em> <code>TensorArray</code> under a single <code>tf.while_loop</code>; this ensures TF caches tensor ops throughout for backpropagation.</li>\n</ul>\n<hr>\n<pre class=""lang-py prettyprint-override""><code>from tensorflow.python.util import nest\nfrom tensorflow.python.ops import array_ops, tensor_array_ops\nfrom tensorflow.python.framework import ops\n\n\ndef model_rnn(model, inputs, states=None, swap_batch_timestep=True):\n    def step_function(inputs, states):\n        out = model([inputs, *states], training=True)\n        output, new_states = (out if isinstance(out, (tuple, list)) else\n                              (out, states))\n        return output, new_states\n\n    def _swap_batch_timestep(input_t):\n        # (samples, timesteps, channels) -&gt; (timesteps, samples, channels)\n        # iterating dim0 to feed (samples, channels) slices expected by RNN\n        axes = list(range(len(input_t.shape)))\n        axes[0], axes[1] = 1, 0\n        return array_ops.transpose(input_t, axes)\n\n    if swap_batch_timestep:\n        inputs = nest.map_structure(_swap_batch_timestep, inputs)\n\n    if states is None:\n        states = (tf.zeros(model.inputs[0].shape, dtype=\'float32\'),)\n    initial_states = states\n    input_ta, output_ta, time, time_steps_t = _process_args(model, inputs)\n\n    def _step(time, output_ta_t, *states):\n        current_input = input_ta.read(time)\n        output, new_states = step_function(current_input, tuple(states))\n\n        flat_state = nest.flatten(states)\n        flat_new_state = nest.flatten(new_states)\n        for state, new_state in zip(flat_state, flat_new_state):\n            if isinstance(new_state, ops.Tensor):\n                new_state.set_shape(state.shape)\n\n        output_ta_t = output_ta_t.write(time, output)\n        new_states = nest.pack_sequence_as(initial_states, flat_new_state)\n        return (time + 1, output_ta_t) + tuple(new_states)\n\n    final_outputs = tf.while_loop(\n        body=_step,\n        loop_vars=(time, output_ta) + tuple(initial_states),\n        cond=lambda time, *_: tf.math.less(time, time_steps_t))\n\n    new_states = final_outputs[2:]\n    output_ta = final_outputs[1]\n    outputs = output_ta.stack()\n    return outputs, new_states\n\n\ndef _process_args(model, inputs):\n    time_steps_t = tf.constant(inputs.shape[0], dtype=\'int32\')\n\n    # assume single-input network (excluding states)\n    input_ta = tensor_array_ops.TensorArray(\n        dtype=inputs.dtype,\n        size=time_steps_t,\n        tensor_array_name=\'input_ta_0\').unstack(inputs)\n\n    # assume single-input network (excluding states)\n    # if having states, infer info from non-state nodes\n    output_ta = tensor_array_ops.TensorArray(\n        dtype=model.outputs[0].dtype,\n        size=time_steps_t,\n        element_shape=model.outputs[0].shape,\n        tensor_array_name=\'output_ta_0\')\n\n    time = tf.constant(0, dtype=\'int32\', name=\'time\')\n    return input_ta, output_ta, time, time_steps_t\n</code></pre>\n<hr>\n<p><strong>Examples &amp; validating</strong>:</p>\n<p>Case design: we feed the same input twice, which enables certain stateful vs stateless comparisons; results also hold for differing inputs.</p>\n<ul>\n<li><strong>Case 0</strong>: control; other cases must match this.</li>\n<li><strong>Case 1</strong>: fail; gradients don\'t match, even though outputs and loss do. Backprop fails when feeding the halved sequence.</li>\n<li><strong>Case 2</strong>: gradients match case 1. It may seem we\'ve used only one <code>tf.while_loop</code>, but SimpleRNN uses one of its own for the 3 timesteps, and writes to a <code>TensorArray</code> that\'s discarded; this won\'t do. A workaround is to implement the SimpleRNN logic ourselves.</li>\n<li><strong>Case 3</strong>: perfect match.</li>\n</ul>\n<p>Note that there\'s no such thing as a stateful RNN cell; statefulness is implemented in the <code>RNN</code> base class, and we\'ve recreated it in <code>model_rnn</code>. This is likewise how any other layer is to be handled - feeding one step slice at a time for every forward pass.</p>\n<pre class=""lang-py prettyprint-override""><code>import random\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.keras.layers import Input, SimpleRNN, SimpleRNNCell\nfrom tensorflow.keras.models import Model\n\ndef reset_seeds():\n    random.seed(0)\n    np.random.seed(1)\n    tf.compat.v1.set_random_seed(2)  # graph-level seed\n    tf.random.set_seed(3)  # global seed\n\ndef print_report(case, model, outs, loss, tape, idx=1):\n    print(&quot;\\nCASE #%s&quot; % case)\n    print(&quot;LOSS&quot;, loss)\n    print(&quot;GRADS:\\n&quot;, tape.gradient(loss, model.layers[idx].weights[0]))\n    print(&quot;OUTS:\\n&quot;, outs)\n\n\n#%%# Make data ###############################################################\nreset_seeds()\nx0 = y0 = tf.constant(np.random.randn(2, 3, 4))\nx0_2 = y0_2 = tf.concat([x0, x0], axis=1)\nx00  = y00  = tf.stack([x0, x0], axis=0)\n\n#%%# Case 0: Complete forward pass; control case #############################\nreset_seeds()\nipt = Input(batch_shape=(2, 6, 4))\nout = SimpleRNN(4, return_sequences=True)(ipt)\nmodel0 = Model(ipt, out)\nmodel0.compile(\'sgd\', \'mse\')\n#%%#############################################################\nwith tf.GradientTape(persistent=True) as tape:\n    outs = model0(x0_2, training=True)\n    loss = model0.compiled_loss(y0_2, outs)\nprint_report(0, model0, outs, loss, tape)\n\n#%%# Case 1: Two passes, stateful RNN, direct feeding ########################\nreset_seeds()\nipt = Input(batch_shape=(2, 3, 4))\nout = SimpleRNN(4, return_sequences=True, stateful=True)(ipt)\nmodel1 = Model(ipt, out)\nmodel1.compile(\'sgd\', \'mse\')\n#%%#############################################################\nwith tf.GradientTape(persistent=True) as tape:\n    outs0 = model1(x0, training=True)\n    tape.watch(outs0)  # cannot even diff otherwise\n    outs1 = model1(x0, training=True)\n    tape.watch(outs1)\n    outs = tf.concat([outs0, outs1], axis=1)\n    tape.watch(outs)\n    loss = model1.compiled_loss(y0_2, outs)\nprint_report(1, model1, outs, loss, tape)\n\n#%%# Case 2: Two passes, stateful RNN, model_rnn #############################\nreset_seeds()\nipt = Input(batch_shape=(2, 3, 4))\nout = SimpleRNN(4, return_sequences=True, stateful=True)(ipt)\nmodel2 = Model(ipt, out)\nmodel2.compile(\'sgd\', \'mse\')\n#%%#############################################################\nwith tf.GradientTape(persistent=True) as tape:\n    outs, _ = model_rnn(model2, x00, swap_batch_timestep=False)\n    outs = tf.concat(list(outs), axis=1)\n    loss = model2.compiled_loss(y0_2, outs)\nprint_report(2, model2, outs, loss, tape)\n\n#%%# Case 3: Single pass, stateless RNN, model_rnn ###########################\nreset_seeds()\nipt  = Input(batch_shape=(2, 4))\nsipt = Input(batch_shape=(2, 4))\nout, state = SimpleRNNCell(4)(ipt, sipt)\nmodel3 = Model([ipt, sipt], [out, state])\nmodel3.compile(\'sgd\', \'mse\')\n#%%#############################################################\nwith tf.GradientTape(persistent=True) as tape:\n    outs, _ = model_rnn(model3, x0_2)\n    outs = tf.transpose(outs, (1, 0, 2))\n    loss = model3.compiled_loss(y0_2, outs)\nprint_report(3, model3, outs, loss, tape, idx=2)\n</code></pre>\n<hr>\n<p><strong>Vertical flow</strong>: we\'ve validated horizontal, <em>timewise</em>-backpropagation; what about vertical?</p>\n<p>To this end, we implement a stacked stateful RNN; results below. All outputs on my machine, <a href=""https://pastebin.com/bMN6WGMt"" rel=""nofollow noreferrer"">here</a>.</p>\n<p>We\'ve hereby validated both <strong>vertical</strong> and <strong>horizontal</strong> stateful backpropagation. This can be used to implement arbitrarily complex forward-prop logic with correct backprop. Applied example <a href=""https://stackoverflow.com/a/63222778/10133797"">here</a>.</p>\n<pre class=""lang-py prettyprint-override""><code>#%%# Case 4: Complete forward pass; control case ############################\nreset_seeds()\nipt = Input(batch_shape=(2, 6, 4))\nx   = SimpleRNN(4, return_sequences=True)(ipt)\nout = SimpleRNN(4, return_sequences=True)(x)\nmodel4 = Model(ipt, out)\nmodel4.compile(\'sgd\', \'mse\')\n#%%\nwith tf.GradientTape(persistent=True) as tape:\n    outs = model4(x0_2, training=True)\n    loss = model4.compiled_loss(y0_2, outs)\nprint(&quot;=&quot; * 80)\nprint_report(4, model4, outs, loss, tape, idx=1)\nprint_report(4, model4, outs, loss, tape, idx=2)\n\n#%%# Case 5: Two passes, stateless RNN; model_rnn ############################\nreset_seeds()\nipt = Input(batch_shape=(2, 6, 4))\nout = SimpleRNN(4, return_sequences=True)(ipt)\nmodel5a = Model(ipt, out)\nmodel5a.compile(\'sgd\', \'mse\')\n\nipt  = Input(batch_shape=(2, 4))\nsipt = Input(batch_shape=(2, 4))\nout, state = SimpleRNNCell(4)(ipt, sipt)\nmodel5b = Model([ipt, sipt], [out, state])\nmodel5b.compile(\'sgd\', \'mse\')\n#%%\nwith tf.GradientTape(persistent=True) as tape:\n    outs = model5a(x0_2, training=True)\n    outs, _ = model_rnn(model5b, outs)\n    outs = tf.transpose(outs, (1, 0, 2))\n    loss = model5a.compiled_loss(y0_2, outs)\nprint_report(5, model5a, outs, loss, tape)\nprint_report(5, model5b, outs, loss, tape, idx=2)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9414}"
574,56900599,"{'items': [{'owner': {'reputation': 2669, 'user_id': 262432}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1562321403, 'answer_id': 56900992, 'question_id': 56900599, 'body': '<p><code>print</code> executes in the Python world (not in graph), so it will only print the tensors once while <code>tf.function</code> is tracing your function to construct a graph. If you want to print in-graph, use <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/print"" rel=""nofollow noreferrer""><code>tf.print</code></a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9409}"
575,52671481,"{'items': [{'owner': {'reputation': 733, 'user_id': 10458815}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1539880868, 'answer_id': 52878788, 'question_id': 52671481, 'body': '<p>Turns out this was a bug in Tensorflow between tf.keras.Model and eager execution. \nThis was not ""how the tensorflow has \'patched\' setting attributes"", as suggested by a comment.</p>\n\n<p>This is a link to the closed issue on Tensorflow:\n<a href=""https://github.com/tensorflow/tensorflow/issues/22853"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/22853</a></p>\n\n<p>If you have this problem, it should be fixed in the next Tensorflow update.\nThis bug was in version 1.11.0</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9409}"
576,49294329,"{'items': [{'owner': {'reputation': 11863, 'user_id': 241013}, 'down_vote_count': 1, 'up_vote_count': 4, 'is_accepted': True, 'score': 3, 'creation_date': 1521105960, 'answer_id': 49295627, 'question_id': 49294329, 'body': '<p>The easiest thing would be to use <code>tf.Print</code> like:</p>\n\n<pre><code>...\nglobal_step = tf.Print(global_step, [global_step], message=\'Value of global step"")\n...\n</code></pre>\n\n<p>You can replace global_step with any tensor you want printed. Then when you run the training it will print the values every time the tensor is evaluated.</p>\n\n<p>Another, more complicated way is to export the model then load it back in using your own session (not the estimator api). Once you do this you can call <code>session.run</code> for any operation defined. You can get operations with <code>tf.get_operation_by_name</code> or <code>tf.get_tensor_by_name</code>. You can also feed whatever values you want as a input.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9409}"
577,58842107,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9409}"
578,65649660,"{'items': [{'owner': {'reputation': 34678, 'user_id': 10908375}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1610286326, 'answer_id': 65653943, 'question_id': 65649660, 'body': ""<p>Here's a somewhat simpler version of the previous answer. Rather than reshaping several times, I prefer to use <code>tf.expand_dims</code> and <code>tf.stack</code>. The latter adds a dimension so that's one less call to <code>tf.reshape</code>, which can be confusing.</p>\n<pre><code>import tensorflow as tf\n\na = tf.constant([[1,2], [3,4]])\nb = [5, 6]\n\nflat_a = tf.reshape(a, [-1]) \n\nc = tf.map_fn(lambda x: tf.concat([[x], b], axis=0), flat_a)\nc = tf.stack(tf.split(c, num_or_size_splits=len(a)), axis=0)\n</code></pre>\n<pre><code>&lt;tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\narray([[[1, 5, 6],\n        [2, 5, 6]],\n       [[3, 5, 6],\n        [4, 5, 6]]])&gt;\n</code></pre>\n""}, {'owner': {'reputation': 4213, 'user_id': 13509540}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1610247832, 'answer_id': 65649773, 'question_id': 65649660, 'body': '<p>Using <code>tf.map_fn</code> with <code>tf.concat</code>, Example code:</p>\n<pre><code>import tensorflow as tf\n\na = tf.constant([ [1,2], [3,4] ])\nflat_b = [5, 6]\nflat_a = tf.reshape(a, (tf.reduce_prod(a.shape).numpy(), ))[:, tf.newaxis]\nprint(flat_a)\nc = tf.map_fn(fn=lambda t: tf.concat([t, flat_b], axis=0), elems=flat_a)\nc = tf.reshape(c, (-1, a.shape[1], c.shape[1]))\nprint(c)\n</code></pre>\n<p>Outputs:</p>\n<pre><code>tf.Tensor(\n[[1]\n [2]\n [3]\n [4]], shape=(4, 1), dtype=int32)\ntf.Tensor(\n[[[1 5 6]\n  [2 5 6]]\n\n [[3 5 6]\n  [4 5 6]]], shape=(2, 2, 3), dtype=int32)\n</code></pre>\n'}, {'owner': {'reputation': 19, 'user_id': 1585635}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1610249055, 'answer_id': 65649862, 'question_id': 65649660, 'body': ""<p>You could go through element-wise. In list form you would do something like out[i][j] = [a[i][j]]+flat_b starting from out being the same shape as a. This gets to the form you wanted. I'm not sure if there is this sort of element-wise concatenation in the tensorflow library.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9409}"
579,44753916,"{'items': [{'owner': {'reputation': 7, 'user_id': 17741553}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1640696679, 'answer_id': 70507487, 'question_id': 44753916, 'body': '<p>As how to slice a tensor is well explained above, I will show the trick about how to slice every element in the same position as <code>[3.0, 33.0]</code> in the tensor here (which is a similar problem that I met)</p>\n<pre class=""lang-py prettyprint-override""><code>batch = tf.constant([\n  [#First image\n    [[0.0,10.0],[1.0,11.0]],\n    [[3.0,33.0],[4.0,44.0]]\n  ],\n  [#Second image\n    [[5.0,55.0],[6.0,66.0]],\n    [[7.0,77.0],[8.0,88.0]]\n  ]\n])\nbatch_shape = batch.shape\nbatch_sliced = tf.slice(batch,(0,1,0,0),(batch_shape[0],1,1,batch_shape[-1]))\n</code></pre>\n<p>Then you will get <code>batch_sliced</code> as</p>\n<pre><code>&lt;tf.Tensor: shape=(2, 1, 1, 2), dtype=float32, numpy=\narray([[[[ 3., 33.]]],\n       [[[ 7., 77.]]]]```\n</code></pre>\n'}, {'owner': {'reputation': 1779, 'user_id': 3921457}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1498462775, 'answer_id': 44754984, 'question_id': 44753916, 'body': '<p>I will explain your code with examples, so I created some cases, but first of all I\'ll explain you <a href=""https://www.tensorflow.org/api_docs/python/tf/slice"" rel=""nofollow noreferrer"">tf.slice(input, begin, size)</a> parametters:</p>\n\n<ul>\n<li><code>input</code> is a ref to a Tensor.</li>\n<li><code>begin</code> is the index from the slice begins.</li>\n<li><code>size</code> is the offset of the slice.</li>\n</ul>\n\n<p>So <code>tf.slice</code> works selecting from <code>input</code> a sub-Tensor that starts at <code>begin</code> index and end at <code>begin + size</code>, treating <code>begin</code> and <code>size</code> as index vectors. The example below will clarify this:</p>\n\n<pre><code>batch = tf.constant([\n        [#First image\n            [\n                [0.0,10.0],\n                [1.0,11.0]\n            ],\n            [\n                [3.0,33.0],\n                [4.0,44.0]\n            ]\n        ],\n        [#Second image\n            [\n                [5.0,55.0],\n                [6.0,66.0]\n            ],\n            [\n                [7.0,77.0],\n                [8.0,88.0]\n            ]\n        ]\n    ])\nslice1 = tf.slice(batch,[0,0,0,0], [1,1,1,1]) \nslice2 = tf.slice(batch,[0,1,0,0], [1,1,2,2]) \nslice3 = tf.slice(batch,[1,1,1,0], [1,1,1,2]) \nslice4 = tf.slice(batch,[0,0,0,0], [2,2,2,2]) \nsess = tf.InteractiveSession()\nprint(""slice1: \\n"" + str(slice1.eval()) + ""\\n"")\nprint(""slice2: \\n"" + str(slice2.eval()) + ""\\n"")\nprint(""slice3: \\n"" + str(slice3.eval()) + ""\\n"")\nprint(""slice4: \\n"" + str(slice4.eval()) + ""\\n"")\n</code></pre>\n\n<p>The outputs in this case are:</p>\n\n<pre><code>slice1: \n[[[[ 0.]]]]\n\nslice2: \n[[[[  3.  33.]\n   [  4.  44.]]]]\n\nslice3: \n[[[[  8.  88.]]]]\n\nslice4: \n[[[[  0.  10.]\n   [  1.  11.]]\n\n  [[  3.  33.]\n   [  4.  44.]]]\n\n\n [[[  5.  55.]\n   [  6.  66.]]\n\n  [[  7.  77.]\n   [  8.  88.]]]]\n</code></pre>\n\n<ul>\n<li><code>slice1</code> selects the first element of the Tensor because of it begins on <code>[0,0,0,0]</code> and picks only one element.</li>\n<li><code>slice2</code> selects the first element of the Tensor because of it begins on <code>[0,1,0,0]</code> and picks 1 element in the two first dimensions and 2 in three and four dimensions.</li>\n<li><code>slice3</code> selects the first element of the Tensor because of it begins on <code>[1,1,1,0]</code> and picks only 1 element in the three first dimensions and 2 in the last.</li>\n<li><code>slice4</code> selects all the element of the Tensor because of it begins on <code>[0,0,0,0]</code> and two elements by dimension, so it covers all the Tensor</li>\n</ul>\n\n<p>Note that de number of dimensions are the same in all slides. If you one to remove dimensions with only one element you can use <a href=""https://www.tensorflow.org/api_docs/python/tf/squeeze"" rel=""nofollow noreferrer"">tf.squeeze</a>. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9404}"
580,61797375,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9403}"
581,39681026,"{'items': [{'owner': {'reputation': 3, 'user_id': 13438866}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1593509847, 'answer_id': 62654487, 'question_id': 39681026, 'body': '<p>Maybe not the fastest way but you could also use <code>model.train_on_batch</code> and predict these with <code>predict_on_batch</code>. Save the prediction for each batch and feed them back to your input. If your batch size is 1 you can feed y(t-1) back. You just have to loop through your dataset.</p>\n'}, {'owner': {'reputation': 85, 'user_id': 6463668}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1552309298, 'answer_id': 55102424, 'question_id': 39681026, 'body': '<p>I think one tricky way is using <code>tf.contrib.seq2seq.InferenceHelper</code> because this helper can just pass the output state to the next-time-step input as <a href=""https://github.com/tensorflow/tensorflow/issues/12065"" rel=""nofollow noreferrer"">this issue</a> and <a href=""https://stackoverflow.com/questions/49134432/how-to-use-tensorflow-seq2seq-without-embeddings"">this question</a> discuss.\nHere is my own code(inspired by <a href=""https://stackoverflow.com/questions/49134432/how-to-use-tensorflow-seq2seq-without-embeddings"">this question</a>) that works:</p>\n\n<pre><code>""""""\nconstruct Decoder\n""""""\ncell = tf.contrib.rnn.LSTMCell(rnn_size, initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n\n# should use a start token both training and inferring process\nstart_tokens = tf.tile(tf.constant([START_ARRAY], dtype=tf.float32), [BATCH_SIZE, 1], name=\'start_tokens\')\n\n# training decoder\nwith tf.variable_scope(""decoder""):\n    # below construct a helper that pass output to next timestep\n    training_helper = tf.contrib.seq2seq.InferenceHelper(\n        sample_fn=lambda outputs: outputs,\n        sample_shape=[decoder_hidden_units],\n        sample_dtype=tf.float32,\n        start_inputs=start_tokens,\n        end_fn=lambda sample_ids: False)\n\n    training_decoder = tf.contrib.seq2seq.BasicDecoder(cell, training_helper,\n                                                       initial_state=cell.zero_state(dtype=tf.float32,\n                                                                                     batch_size=[BATCH_SIZE]).\n                                                       clone(cell_state=encoder_state))\n\n    training_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n                                                                      impute_finished=True,\n                                                                      maximum_iterations=max_iters)\n</code></pre>\n\n<p>And the predicting version of decoder is identical to this training decoder, you can inference directly.</p>\n'}, {'owner': {'reputation': 2862, 'user_id': 1373669}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1521020436, 'answer_id': 49274234, 'question_id': 39681026, 'body': '<p>One way to do this is to write your own RNN cell, together with your own Multi-RNN cell. This way you can internally store the output of the last RNN cell and just access it in the next time step. Check this <a href=""https://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html"" rel=""nofollow noreferrer"">blogpost</a> for more info. You can also add e.g. encoder or decoders directly in the cell, so that you can process the data before feeding it to the cell or after retrieving it from the cell.</p>\n\n<p>Another possibility is to use the function <code>tf.nn.raw_rnn</code> which lets you control what happens before and after the calls to the RNN cells. The following code snippet shows how to use this function, credits go to <a href=""https://hanxiao.github.io/2017/08/16/Why-I-use-raw-rnn-Instead-of-dynamic-rnn-in-Tensorflow-So-Should-You-0/"" rel=""nofollow noreferrer"">this article</a>.</p>\n\n<pre><code>from tensorflow.python.ops.rnn import _transpose_batch_time\nimport tensorflow as tf\n\n\ndef sampling_rnn(self, cell, initial_state, input_, seq_lengths):\n\n    # raw_rnn expects time major inputs as TensorArrays\n    max_time = ...  # this is the max time step per batch\n    inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_time, clear_after_read=False)\n    inputs_ta = inputs_ta.unstack(_transpose_batch_time(input_))  # model_input is the input placeholder\n    input_dim = input_.get_shape()[-1].value  # the dimensionality of the input to each time step\n    output_dim = ...  # the dimensionality of the model\'s output at each time step\n\n        def loop_fn(time, cell_output, cell_state, loop_state):\n            """"""\n            Loop function that allows to control input to the rnn cell and manipulate cell outputs.\n            :param time: current time step\n            :param cell_output: output from previous time step or None if time == 0\n            :param cell_state: cell state from previous time step\n            :param loop_state: custom loop state to share information between different iterations of this loop fn\n            :return: tuple consisting of\n              elements_finished: tensor of size [bach_size] which is True for sequences that have reached their end,\n                needed because of variable sequence size\n              next_input: input to next time step\n              next_cell_state: cell state forwarded to next time step\n              emit_output: The first return argument of raw_rnn. This is not necessarily the output of the RNN cell,\n                but could e.g. be the output of a dense layer attached to the rnn layer.\n              next_loop_state: loop state forwarded to the next time step\n            """"""\n            if cell_output is None:\n                # time == 0, used for initialization before first call to cell\n                next_cell_state = initial_state\n                # the emit_output in this case tells TF how future emits look\n                emit_output = tf.zeros([output_dim])\n            else:\n                # t &gt; 0, called right after call to cell, i.e. cell_output is the output from time t-1.\n                # here you can do whatever ou want with cell_output before assigning it to emit_output.\n                # In this case, we don\'t do anything\n                next_cell_state = cell_state\n                emit_output = cell_output  \n\n            # check which elements are finished\n            elements_finished = (time &gt;= seq_lengths)\n            finished = tf.reduce_all(elements_finished)\n\n            # assemble cell input for upcoming time step\n            current_output = emit_output if cell_output is not None else None\n            input_original = inputs_ta.read(time)  # tensor of shape (None, input_dim)\n\n            if current_output is None:\n                # this is the initial step, i.e. there is no output from a previous time step, what we feed here\n                # can highly depend on the data. In this case we just assign the actual input in the first time step.\n                next_in = input_original\n            else:\n                # time &gt; 0, so just use previous output as next input\n                # here you could do fancier things, whatever you want to do before passing the data into the rnn cell\n                # if here you were to pass input_original than you would get the normal behaviour of dynamic_rnn\n                next_in = current_output\n\n            next_input = tf.cond(finished,\n                                 lambda: tf.zeros([self.batch_size, input_dim], dtype=tf.float32),  # copy through zeros\n                                 lambda: next_in)  # if not finished, feed the previous output as next input\n\n            # set shape manually, otherwise it is not defined for the last dimensions\n            next_input.set_shape([None, input_dim])\n\n            # loop state not used in this example\n            next_loop_state = None\n            return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)\n\n    outputs_ta, last_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n    outputs = _transpose_batch_time(outputs_ta.stack())\n    final_state = last_state\n\n    return outputs, final_state\n</code></pre>\n\n<p>As a side note: It is not clear if relying on the model\'s outputs during training is a good idea. Especially in the beginning, the outputs of the model can be quite bad, so your training might never converge or might not learn anything meaningful.</p>\n'}, {'owner': {'reputation': 11, 'user_id': 9533755}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1521799148, 'answer_id': 49446920, 'question_id': 39681026, 'body': '<p>Define a init_state together with your network layers:</p>\n\n<pre><code>init_state = tf.placeholder(tf.float32, [batch_size,hidden])\nbasic_cell = tf.contrib.rnn.BasicRNNCell(num_units = hidden)\nstate_series, current_state = tf.nn.dynamic_rnn(basic_cell, x, dtype=tf.float32, initial_state = init_state)\n</code></pre>\n\n<p>Then outside you training_steps_loop initialize the zero-state:</p>\n\n<pre><code> _init_state = np.zeros([batch_size,hidden], dtype=np.float32)\n</code></pre>\n\n<p>Inside your training_steps_loop run the session and put _init_state in your feed_dict and make the returned _current_state to you new _init_state for the next step:   </p>\n\n<pre><code>_training_op, _state_series, _current_state = sess.run(\n                [training_op, state_series, current_state],  feed_dict={x: xdb, y: ydb, init_state:_init_state})\n\n_init_state = _current_state\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9403}"
582,43443205,"{'items': [{'owner': {'reputation': 1605, 'user_id': 4567324}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1492390169, 'answer_id': 43443711, 'question_id': 43443205, 'body': '<p><code>in_channels</code> refers to the depth of the inputs to the constitutional layer. For example, if you are feed the layer with raw RGB images, then the depth will be 3, corresponding to the Red, Green, and Blue channels. This means that the kernels actually are 3D rather than 2D. The <code>out_channels</code> refer to the depth of output. Following picture from <a href=""http://cs231n.github.io/convolutional-networks/"" rel=""nofollow noreferrer"">here</a> illustrates an example with input depth of 3 and output depth of 5:</p>\n\n<p><a href=""https://i.stack.imgur.com/3bHh8.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3bHh8.jpg"" alt=""enter image description here""></a></p>\n\n<p><code>properly define</code> is something done based on experiments. That is a network design issue. You may read about some of the famous architectures like <a href=""http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"" rel=""nofollow noreferrer"">AlexNet</a> and <a href=""https://arxiv.org/pdf/1409.1556/"" rel=""nofollow noreferrer"">VGG-16</a> to see how network architectures are designed in practice.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9403}"
583,58338310,"{'items': [{'owner': {'reputation': 2961, 'user_id': 4373898}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1570794150, 'answer_id': 58340568, 'question_id': 58338310, 'body': '<p>From your question, I understand that you want to leverage the class-base API to define your own building-block/layer/model that encapsulate two predefined layers.</p>\n\n<pre><code>import tensorflow as tf\n\nclass MyLayer(tf.keras.Sequential):\n    def __init__(self, **kwargs):\n        super(MyLayer, self).__init__(**kwargs)\n        self.add(tf.keras.layers.Dense(1, input_shape=[10], use_bias=False))  # Use a first predefined layer\n        self.add(tf.keras.layers.Layer())  # Use a second predefined layer\n\nif __name__ == \'__main__\':\n    l = MyLayer()\n    print(l.summary())\n    print(l(tf.constant([[0] * 10])))\n</code></pre>\n\n<p>However, best solution would be to inherit the <code>tf.keras.layers.Layer</code> class and to properly override the <code>call</code> method, but it probably takes more lines.</p>\n\n<hr>\n\n<h2>Edit</h2>\n\n<p>Layer implementation is not so much difficult:</p>\n\n<pre><code>class MyLayer(tf.keras.layers.Layer):\n    def __init__(self, name=""MyLayer"", **kwargs):\n        super(MyLayer, self).__init__(name=name, **kwargs)\n        self.layer1 = tf.keras.layers.Dense(1, use_bias=False)\n        self.layer2 = tf.keras.layers.Layer()\n\n    def call(self, inputs):\n        return self.layer2(self.layer1(inputs))\n</code></pre>\n\n<p>It requires it little bit more at instanciation:</p>\n\n<pre><code>if __name__ == \'__main__\':\n    i = tf.constant([[0] *10])\n    m_input = tf.keras.Input(shape=(10,))\n    l = MyLayer()\n    m_output = l(m_input)\n    m = tf.keras.Model(inputs=m_input, outputs=m_output)\n    tf.print(m.summary())\n    tf.print(m(i))\n</code></pre>\n\n<p>I think it is the right way to implement what you ask, but I never really grasp the difference between inheriting from <code>Model</code> or from <code>Layer</code>. Take a look at the <a href=""https://www.tensorflow.org/guide/keras/custom_layers_and_models"" rel=""nofollow noreferrer"">dedicated guide</a> and give me your feedback!</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9403}"
584,54721543,"{'items': [{'owner': {'reputation': 147, 'user_id': 2624719}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1551635041, 'answer_id': 54971800, 'question_id': 54721543, 'body': '<p>You can try <a href=""https://docs.nvidia.com/deeplearning/dgx/integrate-tf-trt/index.html"" rel=""nofollow noreferrer"">TF-TRT</a> which allows to convert only the part of the graph that\'s supported by TRT, and leave the rest in TF. You can find some examples here: <a href=""https://github.com/tensorflow/tensorrt"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorrt</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9399}"
585,75555845,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9399}"
586,42095625,"{'items': [{'owner': {'reputation': 16975, 'user_id': 524436}, 'down_vote_count': 0, 'up_vote_count': 50, 'is_accepted': True, 'score': 50, 'creation_date': 1486487649, 'answer_id': 42095969, 'question_id': 42095625, 'body': '<p><code>control_dependencies</code> is not a conditional. It is a mechanism to add dependencies to whatever ops you create in the <code>with</code> block. More specifically, what you specify in the argument to <code>control_dependencies</code> is ensured to be evaluated before anything you define in the <code>with</code> block. </p>\n\n<p>In your example, you don\'t add any (TensorFlow) operations in the <code>with</code> block, so the block does nothing.</p>\n\n<p><a href=""https://stackoverflow.com/a/33950177/524436"">This answer</a> has an example of how to use <code>control_dependencies</code>, where it is used to make sure the assignments happen before the batchnorm operations are evaluated.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9399}"
587,57449484,"{'items': [{'owner': {'reputation': 23251, 'user_id': 10886420}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1565523542, 'answer_id': 57449660, 'question_id': 57449484, 'body': '<p>First of all, this function is <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"" rel=""nofollow noreferrer"">deprecated</a> and should not be used.</p>\n\n<p><code>trainable</code> arguments means that scaling factor (gamma) and offset (beta) will be trainable and it\'s true by default.</p>\n\n<p>When it comes to moving averages, those <strong>are not trainable</strong>, they are only updated after each batch pass, those are not parameters (<code>tf.Variable</code> objects).</p>\n\n<p>Please notice, you can set <code>trainable</code> to false, in such case, if <code>beta</code> and <code>gamma</code> are set to defaults (zero and one respectively), they won\'t affect the moving averages. You can turn them off by issuing <code>center</code> (for <code>beta</code>) or <code>scale</code> (for <code>gamma</code>).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9399}"
588,50560013,"{'items': [{'owner': {'reputation': 5155, 'user_id': 942774}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1644316263, 'answer_id': 71032343, 'question_id': 50560013, 'body': '<blockquote>\n<ol>\n<li>Is it possible to calculate a confusion matrix for the multi-label classification task?</li>\n</ol>\n</blockquote>\n<p>Yes and no. You can only calculate a TN (true negative), TP (true positive), FN (false negative), FP (false positive) matrix for each class and derive some <a href=""https://en.wikipedia.org/wiki/Confusion_matrix#Table_of_confusion"" rel=""nofollow noreferrer"">other metrics</a> based on this. It will not show you, how a specific class has been mis-classified as a specific other class, but only <em>that</em> is has been misclassified and <em>how</em> (FN or FP).</p>\n<p><a href=""https://i.stack.imgur.com/incuB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/incuB.png"" alt=""22 confusion matrix"" /></a>\nSource: <a href=""https://en.wikipedia.org/wiki/Confusion_matrix"" rel=""nofollow noreferrer"">Wikipedia</a></p>\n<blockquote>\n<ol start=""2"">\n<li>How would that be implemented ?</li>\n</ol>\n</blockquote>\n<p>You could simply use <a href=""https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/MultiLabelConfusionMatrix"" rel=""nofollow noreferrer"">MultiLabelConfusionMatrix</a> from the TensorFlow add-on package. It gives you just that: a 2x2 matrix <em>for each class</em>, containing TN, TP, FN and FP.</p>\n<p><em>Note that the implementation currently seems to assume that <code>y_pred</code> and <code>y_true</code> are binary tensors, i.e. consists of only <code>0</code>s and <code>1</code>s (<a href=""https://github.com/tensorflow/addons/blob/v0.15.0/tensorflow_addons/metrics/multilabel_confusion_matrix.py#L132-L133"" rel=""nofollow noreferrer"">cast to <code>int</code></a>).</em></p>\n<blockquote>\n<ol start=""3"">\n<li>How can you handle the case of failure in predicting both labels? Since it is not possible to know which confusion belongs to which prediction.</li>\n</ol>\n</blockquote>\n<p>Exactly. You can\'t.</p>\n<blockquote>\n<ol start=""4"">\n<li>What is the logic behind the sorting of the function <code>tf.nn.top_k()</code></li>\n</ol>\n</blockquote>\n<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/math/top_k"" rel=""nofollow noreferrer"">docs</a> says:</p>\n<blockquote>\n<p>If <code>true</code> the resulting <code>k</code> elements will be sorted by the values in descending order.</p>\n</blockquote>\n<p>For example, <code>tf.nn.top_k([10, 3, 1, 11], k=3)</code>, <em>could</em> return <code>[10, 3, 11]</code> (no order).</p>\n<p>When sorting, <code>tf.nn.top_k([10, 3, 1, 11], k=3)</code> returns <code>[11, 10, 3]</code> (descending order).</p>\n<p>(for clarity, please ignore for a second, that it would of course return a tensor, not a regular list)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9399}"
589,55936016,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9394}"
590,58520594,"{'items': [{'owner': {'reputation': 18649, 'user_id': 3214872}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1571826400, 'answer_id': 58520774, 'question_id': 58520594, 'body': '<p><code>positives</code> and <code>negatives</code> are defined as in the question.</p>\n\n<pre><code>positives = [(0,1),(1,1),(2,1),(3,1),(4,1)]\nnegatives = [(10,0),(11,0),(12,0),(13,0),(14,0),(15,0),(16,0)]\n\nNEGATIVE_SAMPLES = 3\n\npos_ds = tf.data.Dataset.from_tensor_slices(positives)\nneg_ds = tf.data.Dataset.from_tensor_slices(negatives).shuffle(1000)\n\nds = pos_ds.concatenate(neg_ds.take(NEGATIVE_SAMPLES)).shuffle(1000)\n\nels = [v.numpy().tolist() for v in list(ds)]\n</code></pre>\n\n<p>printing <code>els</code> for a sample execution gives:</p>\n\n<pre><code>[[0, 1], [4, 1], [12, 0], [16, 0], [1, 1], [10, 0], [3, 1], [2, 1]]\n</code></pre>\n\n<p><strong>Note:</strong> you might need to experiment with the buffer sizes for the shuffle at the end of the <code>ds</code> definition.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9394}"
591,50203668,"{'items': [{'owner': {'reputation': 5662, 'user_id': 7770781}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1525680770, 'answer_id': 50209761, 'question_id': 50203668, 'body': '<p>If you just want to test the code in the documentation, here is the way.</p>\n\n<p>The following code will give the instable <code>[nan]</code> result:</p>\n\n<pre><code>import tensorflow as tf\n\ndef log1pexp(x):\n    return tf.log(1 + tf.exp(x))\n\nx = tf.constant(100.)\ny = log1pexp(x)\ndy = tf.gradients(y, x)\n\nwith tf.Session() as sess:\n    print(sess.run(dy))\n</code></pre>\n\n<p>And the following code will give the correct result <code>[1.0]</code>:</p>\n\n<pre><code>import tensorflow as tf\n\n@tf.custom_gradient\ndef log1pexp(x):\n    e = tf.exp(x)\n    def grad(dy):\n        return dy * (1 - 1 / (1 + e))\n    return tf.log(1 + e), grad\n\nx = tf.constant(100.)\ny = log1pexp(x)\ndy = tf.gradients(y, x)\n\nwith tf.Session() as sess:\n    print(sess.run(dy))\n</code></pre>\n\n<h1>Details:</h1>\n\n<p>The main problem here is that you are trying to decorate <code>log1pexp</code> twice in your code: once with <code>@tf.custom_gradient</code> and once with <code>f = tf.custom_gradient(log1pexp)</code>. In <a href=""https://docs.python.org/3/glossary.html#term-decorator"" rel=""nofollow noreferrer"">python</a>, <code>@tf.custom_gradient</code> here is equivalent to <code>log1pexp = tf.custom_gradient(log1pexp)</code>. You should do this only once, especially here for the following reason.</p>\n\n<p><code>tf.custom_gradient</code> needs to call the function being pass to it to get both the function output and the gradient, i.e. expecting two returns. During decoration, everything works as expected because <code>log1pexp</code> returns <code>tf.log(1 + e)</code> and <code>grad</code>. After decorating <code>log1pexp</code>, <code>log1pexp</code> (returned by <code>tf.custom_gradient</code>) becomes a new function which returns only one tensor <code>tf.log(1 + e)</code>. When you do <code>f = tf.custom_gradient(log1pexp)</code> after decorating <code>log1pexp</code>, <code>tf.custom_gradient</code> can only get one return which is the single tensor <code>tf.log(1 + e)</code>. It will try to split this tensor into two by iterating this returned tensor. But it is wrong and is not allowed as the error message stated:</p>\n\n<blockquote>\n  <p>Tensor objects are not iterable when eager execution is not enabled.</p>\n</blockquote>\n\n<p>You should not decorate <code>log1pexp</code> twice anyway. But this is why you got this error. One more thing to mention, your code will trigger another error for the same reason even if you removed <code>@tf.custom_gradient</code>. After removing <code>@tf.custom_gradient</code>, the line <code>f = tf.custom_gradient(log1pexp)</code> should work as expected. But <code>f</code> is a function returning only one tensor. <code>y, dy = f(x)</code> is wrong and will not work.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9394}"
592,62620694,"{'items': [{'owner': {'reputation': 72, 'user_id': 13782959}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1593366662, 'answer_id': 62626249, 'question_id': 62620694, 'body': '<pre><code>tf.keras.models.Sequential\n</code></pre>\n<p>and</p>\n<pre><code>tf.keras.Sequential\n</code></pre>\n<p>Do the same thing but they are from different versions of tensorflow. By the documentation (TensorFlow 2.0), <code>tf.keras.Sequential</code> is the most recent way of called this function.</p>\n'}, {'owner': {'reputation': 5319, 'user_id': 5033247}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1599217945, 'answer_id': 63740060, 'question_id': 62620694, 'body': '<pre><code>&gt;&gt;&gt; tf.keras.models.Sequential==tf.keras.Sequential\nTrue\n</code></pre>\n<p>Both are same as of TFv2. You could use the later.</p>\n<p>Added in this <a href=""https://github.com/tensorflow/tensorflow/commit/36326acf6dc625014142ad9cbef665dfaf7ecbd9#"" rel=""noreferrer"">commit</a>.</p>\n'}, {'owner': {'reputation': 4013, 'user_id': 5707705}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1593342652, 'answer_id': 62621688, 'question_id': 62620694, 'body': '<p>Keras (keras.io) is a library which is available on its own. It specifies the high-level api.\ntf.keras (<a href=""https://www.tensorflow.org/guide/keras"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/keras</a>) implements the Keras API specification within TensorFlow.</p>\n<p>If you intend to stick to the Tensorflow implementation I would stick to tf.keras. Otherwise you have the advantage to be backend agnostic.</p>\n<p>=====</p>\n<p>update for updated question.</p>\n<p>The renaming of the package for <code>tf.keras.models.Sequential</code> to <code>tf.keras.Sequential</code> must have happened from <code>1.15</code> to <code>2.x</code> you can either downgrade your tensor flow version or update the code. I\'d go for the latter</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9394}"
593,63958039,"{'items': [{'owner': {'reputation': 17612, 'user_id': 5666087}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1600440943, 'answer_id': 63958140, 'question_id': 63958039, 'body': '<blockquote>\n<p>is <code>pred</code> the probability the image is a 1, and <code>1 - pred</code> the probability the image is a 0?</p>\n</blockquote>\n<p>Yes, that is correct. If you want to get hard class (i.e., 0 or 1), then you can threshold the output. 0.5 is a common threshold, but I have also seen 0.3. This is something you can tune.</p>\n<pre><code>pred = model.predict(img_array)\nclasses = pred &gt; 0.5\n</code></pre>\n<p>The predictions are between 0 and 1 most likely because the last activation of the model is a <a href=""https://en.wikipedia.org/wiki/Sigmoid_function"" rel=""nofollow noreferrer"">sigmoid function</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9394}"
594,43865115,"{'items': [{'owner': {'reputation': 3201, 'user_id': 6392807}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1494613562, 'answer_id': 43944318, 'question_id': 43865115, 'body': '<p>All the details you could ever want are in the comment describing <code>with_space_to_batch</code>\n<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn_ops.py#L149"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn_ops.py#L149</a></p>\n\n<p>Note in particular the following text:\n""In the special case that <code>dilation_rate</code> is uniformly 1, this simply returns: <code>op(input, num_spatial_dims, padding)</code>"".</p>\n\n<p>So <code>space_to_batch</code> does nothing unless you have a dilated convolution.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9389}"
595,62039068,"{'items': [{'owner': {'reputation': 11, 'user_id': 13667322}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1633846241, 'answer_id': 69512757, 'question_id': 62039068, 'body': '<p>Reference for optimizer : DiffGrad (kind of Adam like)<br />\n<a href=""https://github.com/evanatyourservice/diffGrad-tf/blob/master/diffgrad.py"" rel=""nofollow noreferrer"">https://github.com/evanatyourservice/diffGrad-tf/blob/master/diffgrad.py</a><br />\nIt is based on a paper called DiffGrad , they have good explanations and generally a good read.</p>\n<p>First of all good question, secondly TensorFlow documentation can do a lot better. Answers to various questions in no particular order:</p>\n<p>In reference to <strong>empty slot list for Adam</strong>, you have to run a model.fit once on a model for it to initialize as far as I have seen. Remember reading about it while looking up saving and loading optimizer states (check if it works on model.compile).</p>\n<p>As for <strong>_prepare_local</strong>, that line creates the momentum variable from the hyper parameter you set on creation. I suppose it makes it accessible to all the weights the optimizer is trying to update, why they use identity is deep TensorFlow graph stuff.</p>\n<p>Why they use _prepare_local generally is to create variables that are common across all weighs that are being updated like decays or learning rates or time steps and such. For every Iteration these variables are common across all variables tracked in the optimizer\'s var_list.</p>\n<p>Unlike the above _prepare_local, <strong>slots</strong> are separate variables for each weight tracked by the optimizer so you might have moments or history or cumulative sum. Anything to do with that specific individual weight.</p>\n<p><strong>Gradient compute and apply:</strong> If I understand this correctly compute gradients takes the loss does back propagation and auto differentiation and gets you the &quot;gradients&quot; for each weight. when you go to apply it is when the optimizer comes into play with its slots and variables. finally optimizer does the updating with the computed gradients as inputs.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9389}"
596,44395547,"{'items': [{'owner': {'reputation': 73, 'user_id': 8840315}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1517425549, 'answer_id': 48549654, 'question_id': 44395547, 'body': '<p>Apart from the answers from @nikpod and @Salvador Dali</p>\n\n<p>The tf.nn.dropout scaled the weights by 1./keep prob during training phase, while tf.layers.dropout scaled the weights by 1./(1-rate).</p>\n\n<p>During evaluation, You could set the keep prob to 1 which is equivalent to set training to false.</p>\n'}, {'owner': {'reputation': 71, 'user_id': 9170009}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1515013322, 'answer_id': 48085077, 'question_id': 44395547, 'body': '<p>On the training phase they are identical (as long as ""drop rate"" and ""keep rate"" are consistent). However, for evaluation (test) phase they are completely different. <code>tf.nn.dropout</code> will still do random dropping while <code>tf.layers.dropout</code> won\'t drop anything (transparent layer). In most cases it make sense to use <code>tf.layers.dropout</code>.</p>\n'}, {'owner': {'reputation': 1238, 'user_id': 2306662}, 'down_vote_count': 0, 'up_vote_count': 38, 'is_accepted': True, 'score': 38, 'creation_date': 1496814740, 'answer_id': 44404530, 'question_id': 44395547, 'body': '<p>A quick glance through \n<a href=""https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/python/layers/core.py"" rel=""noreferrer"">tensorflow/python/layers/core.py</a> and <a href=""https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/python/ops/nn_ops.py"" rel=""noreferrer"">tensorflow/python/ops/nn_ops.py</a>\nreveals that <code>tf.layers.dropout</code> is a wrapper for <code>tf.nn.dropout</code>.</p>\n\n<p>The only differences in the two functions are:</p>\n\n<ol>\n<li>The <code>tf.nn.dropout</code> has parameter <code>keep_prob</code>: ""Probability that each element is kept""<br> <code>tf.layers.dropout</code> has parameter <code>rate</code>: ""The dropout rate""<br> Thus, <code>keep_prob = 1 - rate</code> as defined <a href=""https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/python/layers/core.py#L256"" rel=""noreferrer"">here</a></li>\n<li>The <code>tf.layers.dropout</code> has <code>training</code> parameter: ""Whether to return the output in training mode (apply dropout) or in inference mode (return the input untouched).""</li>\n</ol>\n'}, {'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1496786962, 'answer_id': 44400513, 'question_id': 44395547, 'body': '<p>The idea is the same, the parameters are slightly different. In <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dropout"" rel=""nofollow noreferrer"">nn.dropout</a>, <em>keep_prob is the probability that each element is kept</em>. In <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/dropout"" rel=""nofollow noreferrer"">layers.dropout</a> <em>rate=0.1 would drop out 10% of input units</em>.</p>\n\n<p>So <code>keep_prob = 1 - rate</code>. Also layers.dropout allows <code>training</code> parameter.</p>\n\n<p>In general, just read carefully documentation about the functions you care about and you will see the differences.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9389}"
597,49701918,"{'items': [{'owner': {'reputation': 682, 'user_id': 7818309}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1523078700, 'answer_id': 49704170, 'question_id': 49701918, 'body': '<p>Q1) Initializing gamma as 1, beta as 0 means directly using the normalized inputs. Since there is no prior information about what the variance of a layer output should be, it is fair enough to assume standard Gaussian.</p>\n\n<p>Q2) During training phase (<code>training=True</code>), the batch is normalized with their own mean and var, assuming that training data are randomly sampled. During test (<code>training=False</code>), since the test data could be arbitrarily sampled, we cannot use their mean and var. Thus, we use, as you said, the moving averaging estimations from the last ""100"" training iterations.</p>\n\n<p>Q3) Yes, trainable refers to <code>beta</code> and <code>gamma</code>. There are cases to set <code>trainable=False</code>, e.g. if a novel method is used to update the parameters, or if the batch_norm layer is pre-trained and needs to be frozen. </p>\n\n<p>Q4) You may have noticed <code>reuse</code> parameters in other <code>tf.layers</code> functions as well. In general, if you wanna call a layer more than once (e.g. training and validation) and you do not wanna TensorFlow to think that you are creating a new layer, you set <code>reuse=True</code>. I prefer <code>with tf.variable_scope(..., reuse=tf.AUTO_REUSE):</code> to achieve the same purpose.</p>\n\n<p>Q5) I am not sure about this one. I guess it is for users who want to design new tricks to adjust the scale and bias.</p>\n\n<p>Q6) Yes, you are right.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9389}"
598,48981022,"{'items': [{'owner': {'reputation': 874, 'user_id': 9674919}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1548872597, 'answer_id': 54447128, 'question_id': 48981022, 'body': '<p>Functionally, <code>dilations</code> augument in <code>tf.nn.conv2d</code> is the same as <code>dilations_rate</code> in <code>tf.nn.convolution</code> as well as <code>rate</code> in <code>tf.nn.atrous_conv2d</code>.</p>\n\n<p>They all represent the rate by which we upsample the filter values by inserting zeros across the height and width dimensions. The dilation factor for each dimension of input specifying the filter upsampling/input downsampling rate otherwise known as atrous convolution.</p>\n\n<p>The usage differs slightly.\nLet rate <code>k &gt;= 1</code> represent the dilation rate,</p>\n\n<ul>\n<li><p>in <code>tf.nn.conv2d</code>, the rate <code>k</code> is passed as list of ints <code>[1, k, k,1]</code> for <code>[batch, rate_height, rate_width, channel]</code>.</p></li>\n<li><p>in <code>tf.nn.convolution</code>, rate <code>k</code> is passed as a sequence of <code>N</code> ints as <code>[k,k]</code> for <code>[rate_height, rate_width]</code>.</p></li>\n<li><p>in <code>tf.nn.atrous_conv2d</code>, rate <code>k</code> is a positive <code>int32</code>, a single value for both height and width. This library is deprecated and exists only for backwards compatibility.</p></li>\n</ul>\n\n<p>Hope it helps :)</p>\n'}, {'owner': {'reputation': 4972, 'user_id': 4752883}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1519616737, 'answer_id': 48981142, 'question_id': 48981022, 'body': '<p>To use dilated convolution, you need to use the following function:</p>\n\n<p><code>\ntf.nn.atrous_conv2d(value, filters, rate, padding, name=None)\n</code></p>\n\n<p>Reference: <a href=""https://www.tensorflow.org/versions/r0.12/api_docs/python/nn/convolution#atrous_conv2d"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r0.12/api_docs/python/nn/convolution#atrous_conv2d</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9385}"
599,51194912,"{'items': [{'owner': {'reputation': 600, 'user_id': 4573275}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1530820680, 'answer_id': 51198975, 'question_id': 51194912, 'body': '<p>You can simply run this code</p>\n\n<pre><code>from tensorflow.python import keras\nprint(keras.__version__)\n</code></pre>\n\n<p>which is compatible with TF v1.8.0.</p>\n'}, {'owner': {'reputation': 1929, 'user_id': 3076252}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1551380860, 'answer_id': 54932623, 'question_id': 51194912, 'body': '<p>This has recently been updated:</p>\n\n<pre><code>&gt;&gt;&gt; import tensorflow as tf\n&gt;&gt;&gt; print(tf.keras.__version__)\n2.1.6-tf\n&gt;&gt;&gt; print(tf.__version__)\n1.12.0\n</code></pre>\n'}, {'owner': {'reputation': 23445, 'user_id': 1735003}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1530803975, 'answer_id': 51194913, 'question_id': 51194912, 'body': '<p>You can retrieve the version of Keras implemented in <code>tf.keras</code> using</p>\n\n<pre><code>from tensorflow.python.keras._impl.keras import __version__ as tf_keras_version\nprint(tf_keras_version)\n# 2.1.5-tf (in TF 1.8)\n</code></pre>\n\n<p>It seems that from TF 1.9 on, it will actually be accessible as <code>tf.keras.__version__</code>, as it should.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9385}"
600,49619995,"{'items': [{'owner': {'reputation': 679, 'user_id': 5334585}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1548716628, 'answer_id': 54411559, 'question_id': 49619995, 'body': ""<p>From my understanding, evaluation happens using a respawned model from the latest checkpoint. In your case, you don't save a checkpoint until 2000 steps. You also indicate <code>max_steps=125</code>, which will take precedence over the data set you feed your model.</p>\n\n<p>Therefore, even though you indicate batch size of 70 and 100 epochs, your model has stopped training at 125 steps, which is well below the checkpoint limit of 2000 steps, which in turn limits evaluation, because evaluation depends on the checkpoint model.</p>\n\n<p>Note by default, evaluation happens with every checkpoint save, assuming you don't set a <code>throttle_secs</code> limit.</p>\n""}, {'owner': {'reputation': 507, 'user_id': 4833773}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1522856653, 'answer_id': 49655277, 'question_id': 49619995, 'body': '<p>One can control the repetitions by the tf.data.Dataset.repeat(num_epochs) one sets in the input_fn(). The training function will run until the number of epochs is consumed, then the evaluation function will run, then the training function will run again until the number of epochs, and so on; finally, the train_and_eval method will stop when the max_steps define in TrainSpec is reached.</p>\n\n<p>This is a conclusion I draw from a few experiments, corrections are welcome. </p>\n'}, {'owner': {'reputation': 41, 'user_id': 8398122}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1522758241, 'answer_id': 49630029, 'question_id': 49619995, 'body': '<p>In fact each 200 secs or when your training finished, the estimator will switch from the training phase to the evaluation one.</p>\n\n<p>However, we can see in your code that your are able to achieve the 125 steps before the evaluation started, it means that your training finished. The max_steps is the number of time your training will be repeated before stopping, there are any link with the number of epochs (cause it is not using in tf.estimator.train_and_evaluate).\nAnd during your training your evaluation metrics will occure each throttle_secs (=200 here).</p>\n\n<p>About the metrics you can add these inside your model with :</p>\n\n<pre><code>predict = tf.nn.softmax(logits, name=""softmax_tensor"")\nclasses = tf.cast(tf.argmax(predict, 1), tf.uint8)\n\ndef conv_model_eval_metrics(classes, labels, mode):\n    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n        return {\n            \'accuracy\': tf.metrics.accuracy(classes, labels),\n            \'precision\': tf.metrics.precision(classes, labels),\n            \'recall\': tf.metrics.recall(classes, labels),\n        }\n    else:\n        return None\n\neval_metrics = conv_model_eval_metrics(classes, labels, mode)\nwith tf.variable_scope(""performance_metrics""):\n    #Accuracy is the most intuitive performance measure and it is simply a\n        #ratio of correctly predicted observation to the total observations.\n    tf.summary.scalar(\'accuracy\', eval_metrics[\'accuracy\'][1])\n\n    #How many selected items are relevant\n    #Precision is the ratio of correctly predicted positive observations to\n        #the total predicted positive observations.\n    tf.summary.scalar(\'precision\', eval_metrics[\'precision\'][1])\n\n    #How many relevant items are selected\n    #Recall is the ratio of correctly predicted positive observations to\n        #the all observations in actual class\n    tf.summary.scalar(\'recall\', eval_metrics[\'recall\'][1])\n</code></pre>\n\n<p>It is working pretty well to follow on tensorboard the precision, recall and accuracy during your training and evaluation.</p>\n\n<p>PS : Sorry, it is my first answer, that\'s why it is quite disgusting to read it ^^</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9383}"
601,50078749,"{'items': [{'owner': {'reputation': 104, 'user_id': 9690007}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1525076004, 'answer_id': 50096463, 'question_id': 50078749, 'body': '<p>Yes, the output represents a fixed-dimensional representation of the entire sentence.</p>\n\n<p>You can also embed single words to get their vectors. In your case:</p>\n\n<pre><code>embeddings = embed({""default"": [""Cat"", ""sat"", ""on"", ""mat""]})\n</code></pre>\n\n<p>Should give you a result with shape (4, 128).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9383}"
602,46386211,"{'items': [{'owner': {'reputation': 1, 'user_id': 8824461}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1538571806, 'answer_id': 52627685, 'question_id': 46386211, 'body': '<p>There might be a situation where you send a video in chunks. That means your batch will be a sequence of frames. And assuming that close frames should be quite similar we can omit some of them by increasing batch stride. That as far as I understand. IDK about channel stride though</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9381}"
603,52814880,"{'items': [{'owner': {'reputation': 662, 'user_id': 5055862}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1539602427, 'answer_id': 52815605, 'question_id': 52814880, 'body': '<p>As clarified in the comments, you want to freeze Neurons in a tf.nn.conv2d convolution. While there is direct way of doing this in Tensorflow (as per my search), you could try slicing the Tensor and applying <code>tf.stop_gradient()</code> to it. Here is a <a href=""https://stackoverflow.com/questions/33727935/how-to-use-stop-gradient-in-tensorflow"">stackoverflow answer</a> to give you an intuition on how to use <code>tf.stop_gradient()</code></p>\n\n<p>I haven\'t tested it, but according to the <a href=""https://www.tensorflow.org/api_docs/python/tf/stop_gradient"" rel=""nofollow noreferrer"">docs</a> I think it should work. </p>\n'}, {'owner': {'reputation': 1083, 'user_id': 4055338}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1539606666, 'answer_id': 52816856, 'question_id': 52814880, 'body': '<p>A neuron in a dense neural network layer simply corresponds to a column in a weight matrix. You could therefore redefine your weight matrix as a concatenation of 2 parts/variables, one trainable and one not. Then you could either:</p>\n\n<ol>\n<li>selectively pass only the trainable part in the <code>var_list</code> argument of the <code>minimize</code> function of your optimizer, or</li>\n<li>Use <code>tf.stop_gradient</code> on the vector/column corresponding to the neuron you want to freeze.</li>\n</ol>\n\n<p>The same concept could be used for convolutional layers, although in this case the definition of a ""neuron"" becomes unclear; still, you could freeze any column(s) of a convolutional kernel.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9381}"
604,64826405,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1605294338, 'answer_id': 64826641, 'question_id': 64826405, 'body': '<p>The operation that you want to do cannot be done (in an effective way) with <a href=""https://www.tensorflow.org/api_docs/python/tf/tensordot"" rel=""nofollow noreferrer""><code>tf.tensordot</code></a>. There is, however, a dedicated function for that operation, <a href=""https://www.tensorflow.org/api_docs/python/tf/linalg/matvec"" rel=""nofollow noreferrer""><code>tf.linalg.matvec</code></a>, which will work with batches out of the box. And you can also do the same thing with <a href=""https://www.tensorflow.org/api_docs/python/tf/einsum"" rel=""nofollow noreferrer""><code>tf.einsum</code></a>, like <code>tf.einsum(\'bmn,bn-&gt;bm\', my_tensors, my_vectors)</code>.</p>\n<p>With respect to <a href=""https://www.tensorflow.org/api_docs/python/tf/tensordot"" rel=""nofollow noreferrer""><code>tf.tensordot</code></a>, in general it computes an &quot;all vs all&quot; product of the two given tensors, but matching and reducing some axes. When no axes are given (you have to explicitly pass <code>axes=[[], []]</code> to do this), it creates a tensor with the dimensions of both inputs concatenated. So, if you have <code>my_tensors</code> with shape <code>(b, m, n)</code> and <code>my_vectors</code> with shape <code>(b, n)</code> and you do:</p>\n<pre class=""lang-py prettyprint-override""><code>res = tf.tensordot(my_tensors, my_vectors, axes=[[], []])\n</code></pre>\n<p>You get <code>res</code> with shape <code>(b, m, n, b, n)</code>, such that <code>res[p, q, r, s, t] == my_tensors[p, q, r] * my_vectors[s, t]</code>.</p>\n<p>The <code>axes</code> argument is used to specify dimensions in the input tensors that are &quot;matched&quot;. Values along matched axes are multiplied and summed (like a dot product), so those matched dimensions are reduced from the output. <code>axes</code> can take two different forms:</p>\n<ul>\n<li>If it is a single integer, <code>N</code> then the last <code>N</code> dimensions of the first parameter are matched against the first <code>N</code> dimensions of <code>b</code>. In your example, that corresponds to the dimensions with <code>n</code> elements in <code>my_tensor</code> and <code>my_vector</code>.</li>\n<li>If it is a list, it must contain two sublists, <code>axes_a</code> and <code>axes_b</code>, each with the same number <code>N</code> of integers. In this form, you are explicitly indicating which dimensions of the given values are matched. So, in your example, you could have passed <code>axes=[[1], [0]]</code>, which means &quot;match the dimension <code>1</code> of the first parameter (<code>my_tensor</code>) to the dimension <code>0</code> of the second parameter (<code>my_vector</code>)&quot;.</li>\n</ul>\n<p>If you have now <code>my_tensors</code>  with shape <code>(b, m, n)</code> and <code>my_vectors</code> with shape <code>(b, n)</code>, then you would want to match the dimension <code>2</code> of the first one to the dimension <code>1</code> of the second one, so you could pass <code>axes=[[2], [1]]</code>. However, that will give you a result <code>res</code> with shape <code>(b, m, b)</code> such that <code>res[i, :, j]</code> is the product of matrix <code>my_tensors[i]</code> and vector <code>my_vectors[j]</code>. You could take then only the results that you want (those where <code>i == j</code>), with something more or less convoluted like <code>tf.transpose(tf.linalg.diag_part(tf.transpose(res, [1, 0, 2])))</code>, but you would be doing far more computation than you need to get the same result.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9381}"
605,74736678,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9381}"
606,49155119,"{'items': [{'owner': {'reputation': 6270, 'user_id': 4282745}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1520797204, 'answer_id': 49224276, 'question_id': 49155119, 'body': '<p>You can make use of the <code>tf.convert_to_tensor</code> method to convert your list of gradients to a <code>tensor</code>, and then use <code>tf.reduce_sum</code>:</p>\n\n<pre><code>train_op = optimizer.minimize(loss_op, grad_loss=tf.reduce_sum(tf.convert_to_tensor(grad_loss)))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9377}"
607,70196272,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1641361383, 'answer_id': 70588274, 'question_id': 70196272, 'body': '<p>As suggested <a href=""https://github.com/tensorflow/tensorflow/issues/34201#issuecomment-557308250"" rel=""nofollow noreferrer"">#34201</a>, Just disable the eager execution and run the rest of your code</p>\n<pre><code>import tensorflow as tf\ntf.compat.v1.disable_eager_execution()\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\nIMG_SHAPE = (160, 160) + (3,)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                                   include_top=False,\n                                                   weights=\'imagenet\')\n\nK=tf.keras.backend\nfunc = K.function([base_model.input, K.learning_phase()],[layer.output for layer in base_model.layers if layer.output is not base_model.input])\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9377}"
608,52888624,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9377}"
609,46658607,"{'items': [{'owner': {'reputation': 3551, 'user_id': 4255553}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1507644925, 'answer_id': 46669049, 'question_id': 46658607, 'body': '<p><a href=""https://github.com/tensorflow/tensorflow/blob/512d3d0868c5131a9a88ad4af0243051bdaff51c/tensorflow/core/kernels/l2loss_op.cc#L36"" rel=""nofollow noreferrer"">Here</a> is the used CPU implementation of it.</p>\n\n<p><a href=""https://github.com/tensorflow/tensorflow/blob/d2d42ee8b3e134de4c11055b695c0e16e6186b73/tensorflow/cc/gradients/nn_grad.cc#L98"" rel=""nofollow noreferrer"">Here</a> is the according gradient implementation.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9377}"
610,52872239,"{'items': [{'owner': {'reputation': 307, 'user_id': 3391030}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1587127564, 'answer_id': 61272034, 'question_id': 52872239, 'body': '<p>Refer to the Tensorflow2 documentation for tf.Variable</p>\n\n<blockquote>\n  <p><code>__getitem__</code>(\n      var, slice_spec )</p>\n  \n  <p>Creates a slice helper object given a variable.</p>\n  \n  <p>This allows creating a sub-tensor from part of the current contents of\n  a variable. See tf.Tensor.getitem for detailed examples of slicing.</p>\n  \n  <p><strong>This function in addition also allows assignment to a sliced range</strong>.\n  This is similar to <code>__setitem__</code> functionality in Python. However, the\n  syntax is different so that the user can capture the assignment\n  operation for grouping or passing to sess.run(). For example,</p>\n  \n  <p>...</p>\n</blockquote>\n\n<p>Here is a minimal working example:</p>\n\n<pre class=""lang-python3 prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\nvar = tf.Variable(np.random.rand(3,3,3))\nprint(var)\n# update the last column of the three (3x3) matrices to random integer values\n# note that the update values needs to have the same shape\n# as broadcasting is not supported as of TF2\nvar[:,:,2].assign(np.random.randint(10,size=(3,3)))\nprint(var)\n</code></pre>\n'}, {'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1539861397, 'answer_id': 52872757, 'question_id': 52872239, 'body': '<p>Here is a small demonstration of how to update rows or columns. The idea is that you specify the row and column indices of the variables where you want each element in the update to end up. That is easy to do with <a href=""https://www.tensorflow.org/api_docs/python/tf/meshgrid"" rel=""nofollow noreferrer""><code>tf.meshgrid</code></a>.</p>\n\n<pre><code>import tensorflow as tf\n\nvar = tf.get_variable(\'var\', [4, 3], tf.float32, initializer=tf.zeros_initializer())\nupdates = tf.placeholder(tf.float32, [None, None])\nindices = tf.placeholder(tf.int32, [None])\n# Update rows\nvar_update_rows = tf.scatter_update(var, indices, updates)\n# Update columns\ncol_indices_nd = tf.stack(tf.meshgrid(tf.range(tf.shape(var)[0]), indices, indexing=\'ij\'), axis=-1)\nvar_update_cols = tf.scatter_nd_update(var, col_indices_nd, updates)\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    print(\'Rows updated:\')\n    print(sess.run(var_update_rows, feed_dict={updates: [[1, 2, 3], [4, 5, 6]], indices: [3, 1]}))\n    print(\'Columns updated:\')\n    print(sess.run(var_update_cols, feed_dict={updates: [[1, 5], [2, 6], [3, 7], [4, 8]], indices: [0, 2]}))\n</code></pre>\n\n<p>Output:</p>\n\n<pre class=""lang-none prettyprint-override""><code>Rows updated:\n[[0. 0. 0.]\n [4. 5. 6.]\n [0. 0. 0.]\n [1. 2. 3.]]\nColumns updated:\n[[1. 0. 5.]\n [2. 5. 6.]\n [3. 0. 7.]\n [4. 2. 8.]]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9373}"
611,48243764,"{'items': [{'owner': {'reputation': 870, 'user_id': 1363495}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1515876074, 'answer_id': 48244117, 'question_id': 48243764, 'body': '<p>A simple example snip:</p>\n\n<pre><code>               filter = tf.zeros([3, 16, 16])\n                W = tf.Variable(tf.truncated_normal(filter, stddev=0.1), name=""W"")\n                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=""b"")\n                conv = tf.nn.conv1d(\n                    input_values,\n                    W,\n                    strides=2,\n                    padding=""VALID"",\n                    name=""conv"")\n                # nonlinearity operation\n                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=""relu"")\n                # Maxpooling over the outputs\n                pooled = tf.nn.max_pool(\n                    h,\n                    ksize=[1, sequence_length - filter_size + 1, 1, 1],\n                    strides=[1, 1, 1, 1],\n                    padding=\'VALID\',\n                    name=""pool"")\n                pooled_outputs.append(pooled)\n</code></pre>\n\n<p>Check this <a href=""https://stackoverflow.com/a/38117279/1363495"">answer</a> as well.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9373}"
612,52046902,"{'items': [{'owner': {'reputation': 59, 'user_id': 6281444}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1535536111, 'answer_id': 52074445, 'question_id': 52046902, 'body': '<p>Some answers:</p>\n\n<p>Assuming you\'ve read the documentation on cudnnLSTM + cudnnCompatibleLSTM [it\'s mostly the documentation in the code, sadly]</p>\n\n<ol>\n<li>build two graph alternatives, one for each </li>\n<li>do NOT give names to actual LSTM cells [no scoping] </li>\n<li>add a <code>with tf.variable_scope(""cudnn_lstm""):</code> scoping for the cudnnCompatible\nblock </li>\n<li>to save a checkpoint, use a saver NOT limited to trainables\n(careful control of the location of the saver construction can do\nthat, actually, if you really need it) </li>\n<li>restore: seems like you have\nto restore using the ancient method, not using meta-files.</li>\n</ol>\n\n<p>Nothing happy to say about mathematical inequivalence of the cudnnLSTM and the standard LSTM. Not sure yet how to initialise the forget gate to 1.0, although I\'m sure this can be done with some hacking.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9373}"
613,63751223,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9373}"
614,46062649,"{'items': [{'owner': {'reputation': 26, 'user_id': 9576708}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1522444477, 'answer_id': 49581528, 'question_id': 46062649, 'body': '<p>You can partition the GPU usage using the following code.</p>\n\n<p>You can set the fraction of the GPU to be used for training and evaluation separately. The code below means that the process is given 30% of the memory.\n<code>gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3000)\n  sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n  sess.run(tf.app.run())</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9369}"
615,49765437,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9369}"
616,67947583,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9369}"
617,54524992,"{'items': [{'owner': {'reputation': 5415, 'user_id': 3987085}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1549318238, 'answer_id': 54525077, 'question_id': 54524992, 'body': ""<p>It's as easy as:</p>\n\n<pre><code># Clear the default graph if any\ntf.reset_default_graph()\n# Create a saver/loader object\nloader = tf.train.Saver()\n# Build the same graph architecture (Easiest to do with a class)\nmodel = YourModel()\n# Create a session\nwith tf.Session() as sess:\n    # Initialize the variables in the graph\n    sess.run(tf.global_variables_initializer())\n    # Restore the learned weights from a saved checkpoint\n    loader.restore(sess, path_to_checkpoint_dir)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9369}"
618,63482945,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9369}"
619,74456127,"{'items': [{'owner': {'reputation': 1, 'user_id': 20517027}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1668583607, 'answer_id': 74456607, 'question_id': 74456127, 'body': '<p>refer to this answer: <a href=""https://stackoverflow.com/questions/74060508/how-to-save-a-tensorflow-dataset"">How to Save a Tensorflow Dataset</a></p>\n<p>found out tf version is 2.8.0 in the runtime environment,using <code>tf.data.experimental.save</code> works.</p>\n'}, {'owner': {'reputation': 1, 'user_id': 20517027}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1668582569, 'answer_id': 74456454, 'question_id': 74456127, 'body': ""<p>using <code>test_ds.save(path)</code> I got new problem,&quot;AttributeError: 'TensorSliceDataset' object has no attribute 'save'&quot;</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9364}"
620,61219907,"{'items': [{'owner': {'reputation': 1, 'user_id': 13160838}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1587089478, 'answer_id': 61263041, 'question_id': 61219907, 'body': '<p>It\'s solved <a href=""https://github.com/tensorflow/tensorflow/issues/38556"" rel=""nofollow noreferrer"">here</a>. Just changing <code>tf.get_variable()</code> to <code>tf.Varibble()</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9363}"
621,42787903,"{'items': [{'owner': {'reputation': 380, 'user_id': 4330168}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1489501790, 'answer_id': 42788742, 'question_id': 42787903, 'body': '<p>I guess I missed the following warning:\nSOME ARGUMENTS ARE DEPRECATED. They will be removed after 2016-12-01. Instructions for updating: Estimator is decoupled from Scikit Learn interface by moving into separate class SKCompat. Arguments x, y and batch_size are only available in the SKCompat class, Estimator will only accept input_fn. Example conversion: est = Estimator(...) -> est = SKCompat(Estimator(...))</p>\n\n<p>It is strange that the arguments are still there after 2016-12-01 though.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9363}"
622,62786629,"{'items': [{'owner': {'reputation': 161, 'user_id': 7168453}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1594179988, 'answer_id': 62787218, 'question_id': 62786629, 'body': ""<p>Your ouputs doesn't only have informations about the output of the network.\nIt includes the graph built with the the layers you have.</p>\n<p>When you create a network with the following code, you pass the complete graph with each new call:</p>\n<pre><code>inputs = tf.keras.Input(shape=(3,))\n# First step\nlayers = tf.keras.Dense(100)(inputs)\n# Second step\nlayers = tf.keras.Dense(100)(layers)\noutputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(layers)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n</code></pre>\n<p>In the first step, the graph inside layers is the following:\nInput -\xad&gt; Dense\nIn the second step, the graph inside layers is the following:\nInput -&gt; Dense -&gt; Dense\nEtc...</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9361}"
623,50222149,"{'items': [{'owner': {'reputation': 4810, 'user_id': 4320693}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1526341122, 'answer_id': 50340443, 'question_id': 50222149, 'body': '<p>You can <a href=""https://www.tensorflow.org/api_docs/python/tf/transpose"" rel=""nofollow noreferrer""><code>tf.transpose()</code></a> your tensor before the <a href=""https://www.tensorflow.org/api_docs/python/tf/scan"" rel=""nofollow noreferrer""><code>tf.scan()</code></a> and transpose back after.</p>\n\n<p>Also, if you want the variable <code>ref</code> to contain the new value after the operation, you need to <a href=""https://www.tensorflow.org/api_docs/python/tf/assign"" rel=""nofollow noreferrer""><code>tf.assign()</code></a> the value back.</p>\n\n<p>Please note your desired example value is achieved just by applying a straight-up scan, with no transpose, however. Refer to this code (tested) (see another example with transpose at the bottom of answer):</p>\n\n\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\nref = tf.Variable(tf.ones([2,3,3],tf.int32))\nref2 = tf.scan( lambda y, x: x + 1, ref )\n\nwith tf.Session() as sess:\n    sess.run( tf.global_variables_initializer() )\n    print ( sess.run( ref2 ) ) # ref2 is calculated\n    print ( ""===================="")\n    print ( sess.run( ref ) ) # the original ref is unchanged\n    print ( ""===================="")\n    sess.run( tf.assign( ref, ref2 ) ) # assign the value back to ref\n    print ( sess.run( ref ) )\n</code></pre>\n\n<p>outputs:</p>\n\n<blockquote>\n  <p>[[[1 1 1]<br>\n    [1 1 1]<br>\n    [1 1 1]]  </p>\n  \n  <p>[[2 2 2]<br>\n    [2 2 2]<br>\n    [2 2 2]]]<br>\n   ====================<br>\n  [[[1 1 1]<br>\n    [1 1 1]<br>\n    [1 1 1]]  </p>\n  \n  <p>[[1 1 1]<br>\n    [1 1 1]<br>\n    [1 1 1]]]<br>\n   ====================<br>\n  [[[1 1 1]<br>\n    [1 1 1]<br>\n    [1 1 1]]  </p>\n  \n  <p>[[2 2 2]<br>\n    [2 2 2]<br>\n    [2 2 2]]]  </p>\n</blockquote>\n\n<p>If you use <a href=""https://www.tensorflow.org/api_docs/python/tf/transpose"" rel=""nofollow noreferrer""><code>tf.transpose()</code></a>, you can achieve a scan along any dimension:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\nref = tf.Variable(tf.ones([2,3,3],tf.int32))\nref2 = tf.transpose( tf.scan( lambda y, x: x + 1,\n                              tf.transpose( ref, [ 1, 0, 2 ] ) ),\n                     [ 1, 0, 2 ] )\n\nwith tf.Session() as sess:\n    sess.run( tf.global_variables_initializer() )\n    sess.run( tf.assign( ref, ref2 ) )\n    print ( sess.run( ref ) )\n</code></pre>\n\n<p>will output:</p>\n\n<blockquote>\n  <p>[[[1 1 1]<br>\n    [2 2 2]<br>\n    [2 2 2]]  </p>\n  \n  <p>[[1 1 1]<br>\n    [2 2 2]<br>\n    [2 2 2]]]  </p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9361}"
624,50259009,"{'items': [{'owner': {'reputation': 601, 'user_id': 4987560}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1526057697, 'answer_id': 50296942, 'question_id': 50259009, 'body': '<p>This problem rooted from not clearly understand the tensor and variable in the tensorflow context. Later with more knowledge of the tensor, the solution came to my mind is:</p>\n\n<pre><code>   with tf.device(\'/cpu:0\'), tf.name_scope(""embedding""):\n        self.W = tf.Variable(\n            tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n            name=""W"")\n        self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n        for i in range(0,sequence_length - 1,2):\n            self.tslice = tf.slice(self.embedded_chars,[0,i,0],[0,1,128])\n            self.tslice2 = tf.slice(self.embedded_chars,[0,i+1,0],[0,1,128])\n            self.tslice3 = tf.slice(self.embedded_chars,[0,i+2,0],[0,1,128])\n            self.toffset1 = tf.subtract(self.tslice,self.tslice2)\n            self.toffset2 = tf.subtract(self.tslice2,self.tslice3)\n            self.tconcat = tf.concat([self.toffset1,self.toffset2],1)\n        self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n</code></pre>\n\n<p>the function used, tf.slice, tf.subtract, tf.concat all accept tensor as input. Just avoid using function like tf.scatter_nd_update that require variable as input.</p>\n'}, {'owner': {'reputation': 52739, 'user_id': 712995}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1525890709, 'answer_id': 50259941, 'question_id': 50259009, 'body': '<p><a href=""https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup"" rel=""nofollow noreferrer""><code>tf.nn.embedding_lookup</code></a> simply returns the slice of the larger matrix, so the simplest solution is to update the value of <em>that</em> matrix itself, in your case it\'s <code>self.W</code>:</p>\n\n<pre><code>self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n</code></pre>\n\n<p>Since it\'s a variable, it is compliant with <a href=""https://www.tensorflow.org/api_docs/python/tf/scatter_nd_update"" rel=""nofollow noreferrer""><code>tf.scatter_nd_update</code></a>. Note that you can\'t update just <em>any</em> tensor, only <em>variables</em>.</p>\n\n<p>Another option is to create a new variable just for the selected slice, assign <code>self.embedded_chars</code> to it and perform an update afterwards.</p>\n\n<hr>\n\n<p>Caveat: in both cases, you\'re blocking the gradients to train the embedding matrix, so double check that overwriting the learned value is really what you want.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9361}"
625,35689547,"{'items': [{'owner': {'reputation': 57117, 'user_id': 419116}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1456702758, 'answer_id': 35689728, 'question_id': 35689547, 'body': '<p>Both seem like viable approaches. Using <code>batch</code> with <code>threads=N</code> will create <code>N</code> copies of your reader op connected to your queue so that they can run in parallel, while <code>batch_join</code> you have to create the copies manually.</p>\n\n<p>In your usage with <code>batch_join</code> you are creating several copies of <code>TextLineReader</code> which (as you noticed) will only parallelize across files. To have several threads reading a single file, you could instead create one <code>TextLineReader</code> and have several <code>line_reader.read</code> ops using the same reader.</p>\n\n<p>Here\'s an example with some textfiles containing numbers</p>\n\n<p>Generate numbers:</p>\n\n<pre><code>num_files=10\nnum_entries_per_file=10\nfile_root=""/temp/pipeline""\nos.system(\'mkdir -p \'+file_root)\nfor fi in range(num_files):\n  fname = file_root+""/""+str(fi)\n  dump_numbers_to_file(fname, fi*num_entries_per_file, (fi+1)*num_entries_per_file)\n</code></pre>\n\n<p>Read those numbers in batches of size 2, with parallelism of 2</p>\n\n<pre><code>ops.reset_default_graph()\nfilename_queue = tf.train.string_input_producer([""/temp/pipeline/0"",\n                                                 ""/temp/pipeline/1""],\n                                                shuffle=False)\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\nnumeric_val1, = tf.decode_csv(value, record_defaults=[[-1]])\nnumeric_val2, = tf.decode_csv(value, record_defaults=[[-1]])\nnumeric_batch = tf.batch_join([[numeric_val1,], [numeric_val2]], 2)\n# have to create session before queue runners because they use default session\nsess = create_session()\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(coord=coord)\n\nprint \'\\n\'.join([t.name for t in threads])\nfor i in range(20):\n  print sess.run([numeric_batch])\n\ncoord.request_stop()\ncoord.join(threads)\n</code></pre>\n\n<p>You may see something like this:</p>\n\n<pre><code>QueueRunner(input_producer:input_producer/input_producer_EnqueueMany)\nQueueRunner(input_producer:input_producer/input_producer_Close_1)\nQueueRunner(batch_join/fifo_queue:batch_join/fifo_queue_enqueue)\nQueueRunner(batch_join/fifo_queue:batch_join/fifo_queue_enqueue_1)\nQueueRunner(batch_join/fifo_queue:batch_join/fifo_queue_Close_1)\n[array([0, 1], dtype=int32)]\n[array([2, 3], dtype=int32)]\n[array([4, 5], dtype=int32)]\n[array([6, 7], dtype=int32)]\n[array([8, 9], dtype=int32)]\n[array([10, 11], dtype=int32)]\n[array([12, 13], dtype=int32)]\n[array([14, 15], dtype=int32)]\n[array([16, 17], dtype=int32)]\n[array([18, 19], dtype=int32)]\n</code></pre>\n\n<p>From the list of threads, you can see that there are 2 threads corresponding to read operations (<code>fifo_queue_enqueue</code> and <code>fifo_queue_enqueue_1</code> so you can do 2 reads in parallel)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9361}"
626,54934603,"{'items': [{'owner': {'reputation': 1830, 'user_id': 6808714}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1551391682, 'answer_id': 54935035, 'question_id': 54934603, 'body': '<p><strong>As the documentation of TensorFlow you should use:</strong></p>\n\n<pre><code>v = tf.Variable(True, use_resource=True)\ntf.cond(v, lambda: v.assign(False), my_false_fn)\n</code></pre>\n\n<p><strong>See here for more information:</strong> </p>\n\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""nofollow noreferrer"">tf.Variable</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9357}"
627,66038861,"{'items': [{'owner': {'reputation': 1030, 'user_id': 3926152}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1612424480, 'answer_id': 66041240, 'question_id': 66038861, 'body': ""<p>First of all, your first question was outstanding ! Lots of info !</p>\n<p>tf.while_loop is very confusing and that is one of the reasons why tf moved to eager execution. You don't need to do that anymore.</p>\n<p>Anyway, back to your 2 questions. The answer is the same for both, you are never executing your graph, you are just building it. While building the execution graph, tensorflow needs to trace your python code and that is why you think tf.conf is running f1 and f2. It is &quot;sort of running&quot; because it needs to go inside to figure out what tensors/operations will be added to the graph.</p>\n<p>Same applies to your question regarding tf.while_loop. It is never executing that.</p>\n<p>I recommend a small change which might help you to understand what I'm saying and also fix your problem. Remove that tf.while_loop from inside the body method. Create another method, let's say run() and move the loop there. Sort of like this</p>\n<pre><code>def run(self):\n   out = tf.while_loop(cond, body, loop_vars)\n\n</code></pre>\n<p>Then, invoke run(). It will force the graph to get executed.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9357}"
628,57570385,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9357}"
629,76227668,"{'items': [{'owner': {'reputation': 21, 'user_id': 13805655}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1684741486, 'answer_id': 76303986, 'question_id': 76227668, 'body': ""<p>Here's what worked for me:</p>\n<pre><code>def resize_with_opencv_ver6(self, image):\n    image = image.numpy()\n    image = np.squeeze(image)\n    target_shape = (self._target_shape[0], self._target_shape[1])\n    resized = cv2.resize(image, target_shape, interpolation=cv2.INTER_NEAREST)\n    resized = tf.expand_dims(resized, axis=-1)\n\n    return resized\n\ndef resize_fn(self, image_path, image, label_index):\n    im_shape = image.shape\n    [image, ] = tf.py_function(self.resize_with_opencv_ver6, [image], [tf.uint8])\n    image.set_shape(im_shape)\n    return image_path, image, label_index\n</code></pre>\n<p>In general, the resize_fn is called from the tensorflow map API</p>\n<pre><code>dataset = dataset.map(self.resize_fn, num_parallel_calls=self._autotune)\n</code></pre>\n<p>A short explanation: The cv2.resize drops the channels dimension for grayscale images so you can also neglect the np.squeeze command and just stay with the tf.expand_dims to return the image as a tensor with the channels dimension. In addition, the image.shape and the image.set_shape just make sure that the channels' dimension is kept, but they aren't mandatory here.</p>\n<p>Hope it will help others.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9357}"
630,48675932,"{'items': [{'owner': {'reputation': 7520, 'user_id': 826970}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1518053005, 'answer_id': 48676014, 'question_id': 48675932, 'body': '<p>For padding images to a target shape, you can use <a href=""https://www.tensorflow.org/api_docs/python/tf/image/resize_image_with_crop_or_pad"" rel=""nofollow noreferrer"">tf.image.resize_image_with_crop_or_pad()</a>. This op crops the image if it is larger than target size, and pads (evenly on all sides) with zeros if it is smaller.</p>\n\n<pre><code>&gt;&gt;&gt; a = tf.ones([3, 4, 3])\n&gt;&gt;&gt; tf.image.resize_image_with_crop_or_pad(a, 5, 5)\n&lt;tf.Tensor \'Squeeze:0\' shape=(5, 5, 3) dtype=float32&gt;\n</code></pre>\n\n<p>If you want to use padding, you can define a function to calculate padding amount using the difference between desired size and the shape of the tensor (<a href=""https://www.tensorflow.org/api_docs/python/tf/shape"" rel=""nofollow noreferrer"">tf.shape()</a>) and pad the difference, check <a href=""https://stackoverflow.com/a/48535322/826970"">this answer</a> for padding.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9353}"
631,60314717,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9353}"
632,58561632,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9353}"
633,63226976,"{'items': [{'owner': {'reputation': 15, 'user_id': 11265981}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1596635050, 'answer_id': 63266545, 'question_id': 63226976, 'body': '<p>What I found is the .tflite converter was not running well I use another way and the output work perfectly.</p>\n<p><a href=""https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb</a></p>\n'}, {'owner': {'reputation': 4131, 'user_id': 13546426}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1596519846, 'answer_id': 63240883, 'question_id': 63226976, 'body': '<p>As per the <a href=""https://www.tensorflow.org/tutorials/images/classification#standardize_the_data"" rel=""nofollow noreferrer"">TensorFlow tutorial</a> mentioned in the comments, the images are normalized to <code>[ 0 , 1 ]</code> by dividing each pixel value by 255. This operation is included as a <code>Layer</code> in the Keras model,</p>\n<pre><code>normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n</code></pre>\n<p>Now, in your Java code, you are first subtracting 127.0 and then dividing by 255,</p>\n<pre><code>input[batchNum][x][y][0] = (Color.red(pixel) -127) / 255.0f\ninput[batchNum][x][y][1] = (Color.green(pixel) -127) / 255.0f\ninput[batchNum][x][y][2] = (Color.blue(pixel) ) -127/ 255.0f\n</code></pre>\n<p>which does not match the normalization performed in the TF tutorial. Hence, the model was not getting the images on which it was trained thereby resulting in wrong predictions.\nMake sure you perform the same normalization as in the TF tutorial,</p>\n<pre><code>input[batchNum][x][y][0] = (Color.red(pixel) / 255.0f\ninput[batchNum][x][y][1] = (Color.green(pixel) / 255.0f\ninput[batchNum][x][y][2] = (Color.blue(pixel) ) / 255.0f\n                    \n</code></pre>\n<p>That should solve your problem.</p>\n<p><strong>Tip:</strong></p>\n<p>In most cases, you perform two types of normalization,</p>\n<pre><code>( pixel_value - 128.0 ) / 128.0\n</code></pre>\n<p>Or</p>\n<pre><code>pixel_value / 255.0\n</code></pre>\n<p>The first one squishes the RGB values in <code>[ -1 , 1 ]</code> whereas the second one brings them in <code>[ 0 , 1 ]</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9353}"
634,50226274,"{'items': [{'owner': {'reputation': 636, 'user_id': 5234494}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1525767756, 'answer_id': 50229126, 'question_id': 50226274, 'body': ""<p>As I said in the comments of this question, <code>tf.rank(t)</code> creates a tensor in charge of evaluating the rank of tensor <code>t</code>. If you use the python <code>print()</code> function, it just prints information about the tensor itself.</p>\n\n<p>Let's assign the <code>tf.rank(t)</code> tensor to a variable <code>rank</code> (as suggested by @Picnix_) and evaluate its value under a <code>tf.Session()</code>:</p>\n\n<pre><code>import tensorflow as tf\n\nt = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\nrank = tf.rank(t)\n\nwith tf.Session() as sess:\n    rank_value = sess.run(rank)\n    print(rank_value)  # Outputs --&gt; 3\n</code></pre>\n\n<p>So, <code>rank_value</code> is the variable containing the value of tensor <code>rank</code>, and as documentation suggest its value is 3. Hope this puts some light on how tensorflow works.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9353}"
635,58963043,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9348}"
636,57609316,"{'items': [{'owner': {'reputation': 4131, 'user_id': 13546426}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1566558272, 'answer_id': 57625066, 'question_id': 57609316, 'body': '<p>Basically, we need the <code>converter.post_training_quantize = True</code> flag before the conversion takes place using <code>converter.convert()</code> like,</p>\n\n<pre><code>import tensorflow as tf\n\nkeras_model = ""./Trained_Models/h_vs_o_a_V1.h5""\n\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(keras_model)\nconverter.post_training_quantize = True\ntflite_model = converter.convert()\nopen(""converted_model.tflite"", ""wb"").write(tflite_model)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9348}"
637,66772069,"{'items': [{'owner': {'reputation': 16444, 'user_id': 9215780}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1616543515, 'answer_id': 66772884, 'question_id': 66772069, 'body': '<p>If you want to run the <code>predict_step</code> function in eager mode, you can do it as follows. Please note, it will set everything in eager mode.</p>\n<pre><code>import tensorflow as tf\ntf.config.run_functions_eagerly(True)\n</code></pre>\n<p>Typically <code>tf.function</code> are in <code>Graph</code> mode. Using the above statement, they can be set to <code>Eager</code> mode too, <a href=""https://www.tensorflow.org/api_docs/python/tf/config/run_functions_eagerly"" rel=""nofollow noreferrer"">src</a>.</p>\n<p>As per your comment, AFAIK, there should not be any difference if you set <code>run_eagerly</code> while compiling the model. Here is from the official statement, <a href=""https://keras.io/api/models/model_training_apis/"" rel=""nofollow noreferrer"">src - model.compile</a>.</p>\n<blockquote>\n<p><strong>run_eagerly</strong>: Bool. Defaults to False. If True, this Model\'s logic will not be wrapped in a <strong>tf. function</strong>. Recommended to leave this as None unless your Model cannot be run inside a <strong>tf. function</strong>.</p>\n</blockquote>\n<hr />\n<p>About your first query, why does <code>TensorFlow</code> disable eager execution inside the <code>predict_step</code> function of a <code>tf.keras.Model</code>?</p>\n<p>One of the main reasons is to deliver the best performance of your model. And it\'s not only with <code>predict_step</code> but also <code>train_step</code> and <code>test_step</code>. Basically <code>tf. keras</code> models are compiled to a static graph. In order to make run them in eager mode, the above approaches need to be done. But note that, using eager mode in such cases may slow down your training. For the collective of good, <code>tf. keras</code> models are compiled in graph mode.</p>\n'}, {'owner': {'reputation': 4843, 'user_id': 13726668}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1616543715, 'answer_id': 66772905, 'question_id': 66772069, 'body': '<p>You can also set <code>run_eagerly = True</code> while compiling, this will also produce the expected result.</p>\n<pre><code>model = SimpleModel()\nmodel.compile(run_eagerly = True)\npred = model.predict(x)\n</code></pre>\n<p>Results:</p>\n<pre><code>True\nTrue\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9348}"
638,65201252,"{'items': [{'owner': {'reputation': 34678, 'user_id': 10908375}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1607441603, 'answer_id': 65201907, 'question_id': 65201252, 'body': '<p>That might not answer your question directly, but I would like to address this point:</p>\n<blockquote>\n<p>can\'t shuffle all because it would cost too much memory</p>\n</blockquote>\n<p>The number 2048 in the shuffle call is the buffer size, i.e., the number of elements held in the memory buffer from which elements will be randomly selected. You can reduce this number drastically for a better memory efficiency.</p>\n<pre><code>def get_dataset(filenames, labeled=True):\n    dataset = load_dataset(filenames, labeled=labeled)\n    dataset = dataset.shuffle(32)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset\n</code></pre>\n<p>This will not be completely random, however. Even less so than having a buffer size of 2048. See <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle"" rel=""nofollow noreferrer""><code>tf.data.Dataset.shuffle</code></a>.</p>\n<blockquote>\n<p>Randomly shuffles the elements of this dataset.</p>\n</blockquote>\n<blockquote>\n<p>This dataset fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.</p>\n</blockquote>\n<blockquote>\n<p>For instance, if your dataset contains 10,000 elements but buffer_size is set to 1,000, then shuffle will initially select a random element from only the first 1,000 elements in the buffer. Once an element is selected, its space in the buffer is replaced by the next (i.e. 1,001-st) element, maintaining the 1,000 element buffer.</p>\n</blockquote>\n<blockquote>\n<p>reshuffle_each_iteration controls whether the shuffle order should be different for each epoch.</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9348}"
639,56693863,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 1, 'up_vote_count': 7, 'is_accepted': False, 'score': 6, 'creation_date': 1561098102, 'answer_id': 56697899, 'question_id': 56693863, 'body': ""<p>We get regularization losses accessing the <code>losses</code> property because these losses are created during the model definition. Since the model is a Keras model, you've built it using Keras layers. Every Keras layer (Dense, Conv3D, ...) can be regularized and this is a property of the layer itself.</p>\n\n<p>The model, being an ordered collection of layers, contains all the layers losses inside the <code>losses</code> property.</p>\n\n<p>Eager safe means you can use the <code>losses</code> property of the model during the eager training, being sure that the gradient is propagated only to the correct layers. E.g. if you added an l2 regularization only on the second layer of a model, the variables of the second layer only are influenced (and updated) by that term of the loss.</p>\n\n<p>Is named <code>losses</code> instead of <code>regularization_losses</code> because is not limited to regularization losses only; when you compile a model, a non-regularization loss is added to that property</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9348}"
640,71588962,"{'items': [{'owner': {'reputation': 663, 'user_id': 8270312}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1648058238, 'answer_id': 71591913, 'question_id': 71588962, 'body': '<p>The first dimension is the batch dimension in Tesorflow, see\n<a href=""https://www.tensorflow.org/api_docs/python/tf/linalg/solve"" rel=""nofollow noreferrer"">the docs</a>.</p>\n<pre class=""lang-py prettyprint-override""><code>mtx = tf.random.uniform(shape = (5, 4, 4))\nvec = tf.random.uniform(shape = (5, 4, 1))\nsolution = tf.linalg.solve(mtx, vec)\nprint(solution.shape)\n# TensorShape([5, 4, 1])\nprint(tf.math.reduce_max(abs(tf.matmul(mtx, solution) - vec))) \n# tf.Tensor(5.1259995e-06, shape=(), dtype=float32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9343}"
641,37979238,"{'items': [{'owner': {'reputation': 5631, 'user_id': 6490351}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1466636298, 'answer_id': 37979571, 'question_id': 37979238, 'body': '<p>Solution 1:</p>\n\n<p>You can use higher order functions tf.foldl and tf.foldr. Here is an example:</p>\n\n<pre><code>x = tf.constant([5, 2, 4, 3])\ny = tf.constant([2, 2, 1, 6])\nz = tf.constant([24, 2, 1, 6])\n\nxyz=[x,y,z]\nproduct = tf.foldl(tf.mul, xyz) \n\nwith tf.Session() as sess:\n    print product.eval()\n</code></pre>\n\n<p>Results:\n[240   8   4 108]</p>\n\n<p>Solution 2:\nYou can use tf.reduce_prod:</p>\n\n<pre><code>x = tf.constant([5, 2, 4, 3])\ny = tf.constant([2, 2, 1, 6])\nz = tf.constant([24, 2, 1, 6])\n\nx=tf.reshape(x,[1,-1])\ny=tf.reshape(y,[1,-1])\nz=tf.reshape(z,[1,-1])\nxyz=tf.concat(concat_dim=0, values=[x,y,z])\n\nproduct = tf.reduce_prod(xyz, reduction_indices=0) \n\nwith tf.Session() as sess:\n    print xyz.eval()\n    print product.eval()\n</code></pre>\n\n<p>Results:</p>\n\n<p>xyz\n[[ 5  2  4  3]</p>\n\n<p>[ 2  2  1  6]</p>\n\n<p>[24  2  1  6]]</p>\n\n<p>product\n[240   8   4 108]</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9342}"
642,51895395,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1534511328, 'answer_id': 51896151, 'question_id': 51895395, 'body': '<p>You can get an initial value from the initializer just using it as a callable:</p>\n\n<pre><code>test = tf.Variable(tf.glorot_uniform_initializer()((2, 3)))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9342}"
643,46900332,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9342}"
644,39210093,"{'items': [{'owner': {'reputation': 6384, 'user_id': 3552975}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1509327911, 'answer_id': 47007097, 'question_id': 39210093, 'body': '<p>Let\'s read the document line by line. </p>\n\n<blockquote>\n  <p>This operation pads a tensor(either placeholder or variable) according to the paddings you specify. paddings is an integer tensor with shape [n, 2](it must be two because there are only two directions in every dimension specified by n), where n is the rank of tensor(how many dimensions of the tensor).</p>\n</blockquote>\n\n<p>For example, this paddings: [[1, 2], [1, 1], [2, 2], [3, 1]], indicates the rank of the tensor is 4(4 dimensions).</p>\n\n<blockquote>\n  <p>For each dimension D of input, paddings[D, 0] indicates how many values to add before the contents of tensor in that dimension, and paddings[D, 1] indicates how many values to add after the contents of tensor in that dimension.</p>\n</blockquote>\n\n<p>Following the above example, for the 0 dimension we add 1 row ahead and 2 rows behind([1, 2]); the 1 dimension we add 1 column ahead and 1 column behind([1, 1]); the dimension 2, 2 ahead and 2 behind([2, 2]); the last dimension, 3 ahead and 1 behind([3, 1]).   </p>\n\n<blockquote>\n  <p>If mode is ""REFLECT"" then both paddings[D, 0] and paddings[D, 1] must be no greater than tensor.dim_size(D) - 1. If mode is ""SYMMETRIC"" then both paddings[D, 0] and paddings[D, 1] must be no greater than tensor.dim_size(D). </p>\n</blockquote>\n\n<p>This line is so obvious to understand with the examples there. </p>\n'}, {'owner': {'reputation': 129, 'user_id': 2865264}, 'down_vote_count': 1, 'up_vote_count': 9, 'is_accepted': False, 'score': 8, 'creation_date': 1498149842, 'answer_id': 44705154, 'question_id': 39210093, 'body': '<p>Agree that the document doesn\'t explain very well the method. Any how, </p>\n\n<p>For ""paddings"" in <code>pad(t, paddings, ""CONSTANT"");</code> let\'s start by dimension 0 (i.e., row wise), according to example, <code>paddings[0,0]=1,</code> means adding <strong>one row</strong> above, and <code>paddings[0,1]=1,</code> means adding <strong>one row</strong> at the end. </p>\n\n<p>Now, consider, dimension 1 (column wise) of paddings. <code>paddings[1,0]=2,</code> means to add <strong>two columns</strong> in the beginning, and <code>paddings[1,1]=2,</code> means to add <strong>two columns</strong> at the end. </p>\n\n<p>I hope this is helpful.</p>\n'}, {'owner': {'reputation': 3653, 'user_id': 447599}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1472503414, 'answer_id': 39214877, 'question_id': 39210093, 'body': '<p>the first pair in the padding tuple is the horizontal padding and the second pair is the vertical padding </p>\n\n<p>the reflected padding seems to quite literally reflect as if you placed a mirror on the last digit before the padding </p>\n\n<p>input: 123</p>\n\n<p>output for [2,2] horizontal:  32 123 21</p>\n\n<p>same logic for horizontal </p>\n\n<p>Symmetric seems to do the same thing, except it also repeats the boundary number first</p>\n\n<p>21 123 32</p>\n\n<p>the diagonals (corners) apply the padding scheme to the vertical padding output</p>\n\n<p>reflected with [1,1],[2,2] and input:</p>\n\n<pre><code>123\n456\n</code></pre>\n\n<p>output:</p>\n\n<pre><code>65 456 54\n32 123  23\n65  456 54\n32  123 21\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9342}"
645,45229165,"{'items': [{'owner': {'reputation': 16, 'user_id': 3612146}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1501729508, 'answer_id': 45474110, 'question_id': 45229165, 'body': '<p>Tensorflow Object Detection API has its own exporter script that is more sophisticated than the outdated examples found under Tensorflow Serving. </p>\n\n<p>While building Tensorflow Serving, make sure you pull the latest master commit of tensorflow/tensorflow (>r1.2) and tensorflow/models</p>\n\n<p><strong>Build Tensorflow Serving for GPU</strong></p>\n\n<p><code>bazel build -c opt --config=cuda tensorflow_serving/...</code></p>\n\n<p>If you face errors regarding crosstool and nccl, follow the solutions at \n<a href=""https://github.com/tensorflow/serving/issues/186#issuecomment-251152755"" rel=""nofollow noreferrer"">https://github.com/tensorflow/serving/issues/186#issuecomment-251152755</a>\n<a href=""https://github.com/tensorflow/serving/issues/327#issuecomment-305771708"" rel=""nofollow noreferrer"">https://github.com/tensorflow/serving/issues/327#issuecomment-305771708</a></p>\n\n<p><strong>Usage</strong></p>\n\n<p><code>python tf_models/object_detection/export_inference_graph.py \\\n--pipeline_config_path=/path/to/ssd_inception_v2.config \\\n--trained_checkpoint_prefix=/path/to/trained/checkpoint/model.ckpt \\\n--output_directory /path/to/output/1 \\\n--export_as_saved_model \\\n--input_type=image_tensor</code></p>\n\n<p>Note that during export all variables are converted into constants and baked into the protobuf binary. Don\'t be panicked if you don\'t find any files under saved_model/variables directory</p>\n\n<p>To start the server,</p>\n\n<p><code>bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=inception_v2 --model_base_path=/path/to/output --enable_batching=true</code></p>\n\n<p>As for the client, the examples under Tensorflow Serving work well</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9338}"
646,45290607,"{'items': [{'owner': {'reputation': 1088, 'user_id': 2130551}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1508279752, 'answer_id': 46800250, 'question_id': 45290607, 'body': '<p>The error is complaining about the <em>second</em> <code>Reshape</code>. You can see this since the <code>Reshape</code> name is <code>Reshape_1</code> in the error message. The <code>strided_slice</code> in the second reshape goes from <code>record_size+1</code> to <code>2*record_size</code> which is size <code>1682 - 842 = 840</code>. Thus the error message about the wrong size. I think you want to specify <code>record_size</code> instead of <code>record_size+1</code>.</p>\n\n<p>Hope that helps! </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9338}"
647,55141486,"{'items': [{'owner': {'reputation': 1211, 'user_id': 6862189}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1615428983, 'answer_id': 66575566, 'question_id': 55141486, 'body': '<p>You can use <code>tf.keras.utils.plot_model(model, show_shapes=True,show_dtype=True,rankdir=&quot;LR&quot;)</code> to plot a keras model graph .</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9338}"
648,55411824,"{'items': [{'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1553847529, 'answer_id': 55413120, 'question_id': 55411824, 'body': '<p>First of all, Layers API is deprecated and will be removed from TF 2.0. <code>keras.layers</code> is a direct substitute, because it will be the main high level api for future version. \nAs per official docs, <code>tf.layers</code> are wrappers around <code>tf.keras.layers</code>. Convolutional layers in Layers API inherit from <code>tf.keras.layers</code>. From <a href=""https://github.com/tensorflow/tensorflow/blob/a6d8ffae097d0132989ae4688d224121ec6d8f35/tensorflow/python/layers/convolutional.py#L28"" rel=""nofollow noreferrer"">tensorflow/python/layers/convolutional.py</a>:</p>\n\n<pre><code>@tf_export(\'layers.Conv1D\')\nclass Conv1D(keras_layers.Conv1D, base.Layer):\n  """"""1D convolution layer (e.g. temporal convolution). \n</code></pre>\n\n<p>TensorFlow layers cannot be used directly within a Keras model, as it they miss some attributes required by the Keras API. However, it is possible to use them  with Keras Lambda layer. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9335}"
649,52956268,"{'items': [{'owner': {'reputation': 813, 'user_id': 6064179}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1540322937, 'answer_id': 52956540, 'question_id': 52956268, 'body': '<p>Looks like it has to do with the way <code>map()</code> is defined by tensorflow. Take a look at the docs here: <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map</a></p>\n\n<p><code>map()</code>\'s signature:</p>\n\n<blockquote>\n  <p>map(\n      map_func,\n      num_parallel_calls=None\n  )</p>\n</blockquote>\n\n<p>The important bit is this:</p>\n\n<blockquote>\n  <p>The input signature of map_func is determined by the structure of each element in this dataset.</p>\n</blockquote>\n\n<p>So your <code>dataset</code> must somehow be arranged as elements of tuples of size 2 which makes <code>map</code> pass 2 arguments into <code>map_func</code>. However, you define your lambda function like:</p>\n\n<pre><code>lambda string: tf.string_split([string])\n</code></pre>\n\n<p>which means it expects 1 input, namely <code>string</code>. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9335}"
650,61480051,"{'items': [{'owner': {'reputation': 1576, 'user_id': 6430839}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1595266885, 'answer_id': 63001024, 'question_id': 61480051, 'body': '<p>I am having the same issue that I can\'t get AI platform to pick up tf.summary.scalar. I tried to debug it with the GCP support and AI Platform Engineering team for the last 2 months. They didn\'t manage to reproduce the issue even if we were using almost the same code. We even did one coding session but were still having different results.</p>\n<p><strong>Recommendation from the GCP AI Platform Engineering team: &quot;don\'t use tf.summary.scalar&quot;</strong> the main reason is that by using the other method:</p>\n<ul>\n<li>it works fine for everybody</li>\n<li>you can control and see what happen (not a blackbox)</li>\n</ul>\n<p>They will update the documentation to reflect this new recommendation.</p>\n<p>Setup:</p>\n<ul>\n<li>Tensoflow 2.2.0</li>\n<li>TensorBoard 2.2.2</li>\n<li>keras model is created within the tf.distribute.MirroredStrategy() scope</li>\n<li>keras callback for TensorBoard</li>\n</ul>\n<p>With the following setup the &quot;issue&quot; is observed:</p>\n<ul>\n<li>when using TensorBoard with update_freq=\'epoch\' and with 1 epoch only</li>\n</ul>\n<p>It seems to work with other setup. Anyway I will follow the recommendation from GCP and use the custom solution to avoid issue</p>\n<p><a href=""https://i.stack.imgur.com/NPsp8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NPsp8.png"" alt=""enter image description here"" /></a></p>\n'}, {'owner': {'reputation': 9507, 'user_id': 260826}, 'down_vote_count': 2, 'up_vote_count': 0, 'is_accepted': False, 'score': -2, 'creation_date': 1588109654, 'answer_id': 61490338, 'question_id': 61480051, 'body': '<p>We tested this in TF 2.1 with TF Keras and AI Platform and works succesfully:</p>\n\n<pre><code>class CustomCallback(tf.keras.callbacks.TensorBoard):\n    """"""Callback to write out a custom metric used by CAIP for HP Tuning.""""""\n\n    def on_epoch_end(self, epoch, logs=None):  # pylint: disable=no-self-use\n        """"""Write tf.summary.scalar on epoch end.""""""\n        tf.summary.scalar(\'epoch_accuracy\', logs[\'accuracy\'], epoch)\n\n# Setup TensorBoard callback.\ncustom_cb = CustomCallback(os.path.join(args.job_dir, \'metric_tb\'),\n                               histogram_freq=1)\n\n# Train model\nkeras_model.fit(\n        training_dataset,\n        steps_per_epoch=int(num_train_examples / args.batch_size),\n        epochs=args.num_epochs,\n        validation_data=validation_dataset,\n        validation_steps=1,\n        verbose=1,\n        callbacks=[custom_cb])\n</code></pre>\n\n<pre><code>trainingInput:\n  hyperparameters:\n    goal: MAXIMIZE\n    maxTrials: 4\n    maxParallelTrials: 2\n    hyperparameterMetricTag: epoch_accuracy\n    params:\n    - parameterName: batch-size\n      type: INTEGER\n      minValue: 8\n      maxValue: 256\n      scaleType: UNIT_LINEAR_SCALE\n    - parameterName: learning-rate\n      type: DOUBLE\n      minValue: 0.01\n      maxValue: 0.1\n      scaleType: UNIT_LOG_SCALE\n</code></pre>\n\n<p>Seems to be identical to your code, except I don\'t have access in how are you passing the callbacks. I remember seeing some issue when not specifying the callbacks directly.</p>\n\n<p>Code <a href=""https://github.com/GoogleCloudPlatform/ai-platform-samples/blob/master/training/tensorflow/census/tf-keras/trainer/task.py"" rel=""nofollow noreferrer"">here</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9335}"
651,61713523,"{'items': [{'owner': {'reputation': 10070, 'user_id': 9393102}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1589121936, 'answer_id': 61713869, 'question_id': 61713523, 'body': '<p>Unfortunately I cannot find a source for this right now, but generally <em>everything</em> in the scope of a decorated function will be traced/turned into a graph. That is, in your specific case, there is no need to decorate <code>x1</code> or <code>x2</code> if they are only called from inside <code>y</code>. As such, it is usually sufficient to decorate only the top-most function one wants to be traced (e.g. the function calling the model, or running a single training step, or...)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9335}"
652,45517940,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1518443569, 'answer_id': 48748092, 'question_id': 45517940, 'body': ""<p>Simply put: <code>if else</code> is how you do switch in <em>Python</em>, while <code>tf.cond</code> is how you do switch in <em>Tensorflow</em>. During running, <code>if else</code> is fixed in the compiled <em>Python</em> program, while <code>tf.cond</code> is fixed in the constructed <em>Tensorflow</em> graph. </p>\n\n<p>You can think of <code>tf.cond</code> as the <em>Tensorflow</em>'s internal way of doing <code>if else</code>.</p>\n""}, {'owner': {'reputation': 6384, 'user_id': 3552975}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1508480423, 'answer_id': 46843374, 'question_id': 45517940, 'body': ""<p>Since the graph in TensorFlow is static, you cannot modify it once built. Thus you can use if-else outside of the graph at anytime for example while preparing batches and etc., but you can also employ it while constructing the graph. That is, if the condition doesn't depend on the value of any tensor, for example the dimention(having been set) of the tensor or the shape of any tensor. In such scenarios the graph will not be changed due to the condition while excuting the graph. The graph has been fixed after you finished drawing the graph and the if-else condition would not affect the graph while excuting the graph. </p>\n\n<p>But if the condition depends on the value of the tensor in it that condition should be <strong>included in the graph</strong> and hence tf.cond should be applied. </p>\n""}, {'owner': {'reputation': 1330, 'user_id': 8315956}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1501922481, 'answer_id': 45519962, 'question_id': 45517940, 'body': '<p>Did you mean <code>if ... else</code> in Python vs. <code>tf.cond</code>?</p>\n\n<p>You can use <code>if ... else</code> for creating different graph for different external conditions. For example you can make one python script for graphs with <code>1, 2, 3</code> hidden layers, and use command line parameters for select which one use.</p>\n\n<p><code>tf.cond</code> is for add <em>condition block</em> to the graph. For example, you can define <a href=""https://en.wikipedia.org/wiki/Huber_loss"" rel=""nofollow noreferrer"">Huber function</a> by code like this:</p>\n\n<pre><code>import tensorflow as tf\ndelta = tf.constant(1.)\nx = tf.placeholder(tf.float32, shape=())\n\ndef left(x):\n    return tf.multiply(x, x) / 2.\ndef right(x):\n    return tf.multiply(delta, tf.abs(x) - delta / 2.)\n\nhubber = tf.cond(tf.abs(x) &lt;= delta,  lambda: left(x),  lambda: right(x))\n</code></pre>\n\n<p>and calculation in Graph will go by different branch for different input data.</p>\n\n<pre><code>sess = tf.Session()\nwith sess.as_default():\n    sess.run(tf.global_variables_initializer())\n    print(sess.run(hubber, feed_dict = {x: 0.5}))\n    print(sess.run(hubber, feed_dict = {x: 1.0}))\n    print(sess.run(hubber, feed_dict = {x: 2.0}))\n\n&gt; 0.125\n&gt; 0.5\n&gt; 1.5\n</code></pre>\n'}, {'owner': {'reputation': 4898, 'user_id': 1896918}, 'down_vote_count': 0, 'up_vote_count': 43, 'is_accepted': True, 'score': 43, 'creation_date': 1501922572, 'answer_id': 45519975, 'question_id': 45517940, 'body': '<p><code>tf.cond</code> is evaluated at the runtime, whereas <code>if-else</code> is evaluated at the graph construction time. </p>\n\n<p>If you want to evaluate your condition depending on the value of the tensor at the runtime, <code>tf.cond</code> is the best option.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9331}"
653,59743351,"{'items': [{'owner': {'reputation': 14062, 'user_id': 6117017}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1579073595, 'answer_id': 59746843, 'question_id': 59743351, 'body': '<p>The link to the documentation that you provided points to</p>\n<blockquote>\n<p>TensorFlow Core r2.1</p>\n</blockquote>\n<p>Updating your <code>tensorflow</code> version to version <code>2.1</code> should solve the issue;</p>\n<p>The method .<code>as_numpy_iterator()</code> is not present in TensorFlow 2.0, but only in TensorFlow &gt;= 2.1</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9331}"
654,41780344,"{'items': [{'owner': {'reputation': 57117, 'user_id': 419116}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1485020211, 'answer_id': 41782426, 'question_id': 41780344, 'body': '<p>TensorFlow uses <code>None</code> to represent <code>0</code> for implementation reasons. I don\'t think it would help you if the returned gradient was true gradient <code>0</code>, since you want to train. You could use <code>gradient_override_map</code> to substitute gradient of <code>Identity</code> op for <code>Floor</code> as follows</p>\n\n<pre><code>tf.reset_default_graph()\nx = tf.Variable(10.)\nwith tf.get_default_graph().gradient_override_map({""Floor"": ""Identity""}):\n    x2 = tf.floor(x)\nloss = tf.square(x2)\nopt = tf.train.GradientDescentOptimizer(0.1)\ntrain_op = opt.minimize(loss)\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nfor i in range(10):\n    print(sess.run([loss, train_op]))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9331}"
655,55125115,"{'items': [{'owner': {'reputation': 1268, 'user_id': 2758652}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1552404778, 'answer_id': 55125305, 'question_id': 55125115, 'body': '<p>Been a while since I last used Tensorflow, but I\'m pretty sure the latter is a wrapper for the former.</p>\n\n<p>The <code>tf.losses.softmax_cross_entropy</code> simply uses <code>tf.nn.softmax_cross_entropy_with_logits</code> for calculating the loss, while allowing you to use extra features, like class weights, label smoothing etc.</p>\n\n<p><code>tf.losses.softmax_cross_entropy</code> also adds the loss to the <code>tf.GraphKeys.LOSSES</code> collection, so that you don\'t need to ""route"" it all the way to the top, but you can simply collect your losses</p>\n\n<pre><code>  losses = tf.get_collection(tf.GraphKeys.LOSSES)\n  loss = tf.reduce_sum(reg_losses)\n</code></pre>\n\n<p>I personally liked being able to personalize my loss functions, so I used the ""nn"" one, but if you are not going to do anything outside the box, use tf.losses. </p>\n\n<p>I also like to use sparse_softmax_cross_entropy, since most often I was working with mutually exclusive classes, and this way I could avoid converting the labels to one hot encoding myself.</p>\n\n<p>The difference is that in <code>tf.nn.softmax</code> you need to use one-hot encoding for your labels, while in <code>tf.nn.sparse_softmax_cross_entropy</code>, you can use integers to specify what class number the label belongs too, ie. the difference is</p>\n\n<pre><code>labels = [\n [0, 0, 1],\n [1, 0, 0],\n [0, 1, 0],\n]\n</code></pre>\n\n<p>vs</p>\n\n<pre><code>labels = [2, 0, 1]\n</code></pre>\n\n<p>Finally, if you are not planning on doing much low-level stuff, I recommend you take a look at Keras. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9331}"
656,71019644,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1644244923, 'answer_id': 71020405, 'question_id': 71019644, 'body': '<p>Not sure what <code>PixelData</code> looks like, but here is working example with both methods:</p>\n<pre class=""lang-py prettyprint-override""><code>import numpy as np\nimport tensorflow as tf\n\nx = 2\nnp_pixel_data = np.array([[3, 4, 5, 1],\n                       [6, 4, 2, 5]], dtype=np.float32)\n\nnp_pixel_data[np_pixel_data&gt;=x] = np_pixel_data[np_pixel_data&gt;=x] - x\n\ntf_pixel_data = tf.constant([[3, 4, 5, 1],\n                       [6, 4, 2, 5]], dtype=tf.float32)\n\ntf_pixel_data = tf.where(tf.greater_equal(tf_pixel_data, x), tf_pixel_data - x, tf_pixel_data)\n\nprint(np_pixel_data)\nprint(tf_pixel_data)\n</code></pre>\n<pre><code>[[1. 2. 3. 1.]\n [4. 2. 0. 3.]]\ntf.Tensor(\n[[1. 2. 3. 1.]\n [4. 2. 0. 3.]], shape=(2, 4), dtype=float32)\n</code></pre>\n<p>You might have some minor rounding differences, but nothing significant.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9327}"
657,72184958,"{'items': [{'owner': {'reputation': 147, 'user_id': 10027860}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1652183747, 'answer_id': 72185879, 'question_id': 72184958, 'body': '<p>working code:</p>\n<pre><code>from pydantic import BaseModel\nimport tensorflow as tf\n\n\nclass MyTensor(BaseModel):\n\n    tensor: tf.Variable\n\n    class Config:\n        arbitrary_types_allowed = True\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9327}"
658,59131008,"{'items': [{'owner': {'reputation': 1846, 'user_id': 10648765}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1628196240, 'answer_id': 68673293, 'question_id': 59131008, 'body': '<p>Iterate through your generator and write the data to a TFRecord. Then use TFRecordDataset. This is the guide.</p>\n<p><a href=""https://www.tensorflow.org/tutorials/load_data/tfrecord"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/load_data/tfrecord</a></p>\n<p>TF is built to use these types of Datasets effectively with multi-gpu.</p>\n<p>Sharding the data to disk also improves shuffling.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9327}"
659,41534593,"{'items': [{'owner': {'reputation': 2713, 'user_id': 7287271}, 'down_vote_count': 0, 'up_vote_count': 45, 'is_accepted': True, 'score': 45, 'creation_date': 1483891706, 'answer_id': 41534724, 'question_id': 41534593, 'body': ""<p>Actually, I've misunderstood how <code>tf.stack</code> works. If the <code>axis</code> parameter is within the range of the existing dimensions, a new axis will be inserted at that index.</p>\n\n<p>Example:</p>\n\n<pre><code>import tensorflow as tf\n\nt1 = tf.random_normal([1, 3])\nt2 = tf.random_normal([1, 3])\n\ntf.stack([t1, t2], axis=1).shape.as_list() == [1, 2, 3]\ntf.concat([t1, t2], axis=1).shape.as_list() == [1, 6]\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9327}"
660,62643330,"{'items': [{'owner': {'reputation': 1489, 'user_id': 6101336}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1593459767, 'answer_id': 62645590, 'question_id': 62643330, 'body': '<p>if your version of tensorflow is 2.0.0 or above, you can perfectly do <code>tensor addition and substraction</code> something like:</p>\n<pre><code>import tensorflow as tf\n\na = tf.constant(2)\nprint(a)\n\nb = tf.constant(3)\nprint(b)\n\nc = a + b\nprint(c)\n</code></pre>\n<p>would print</p>\n<pre><code>tf.Tensor(2, shape=(), dtype=int32)\ntf.Tensor(3, shape=(), dtype=int32)\ntf.Tensor(5, shape=(), dtype=int32)\n</code></pre>\n'}, {'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1593459145, 'answer_id': 62645465, 'question_id': 62643330, 'body': '<p>You can use either the <code>+</code> operator or the <a href=""https://www.tensorflow.org/api_docs/python/tf/math/add"" rel=""nofollow noreferrer""><code>add</code></a> function. In most cases it is the same. The only case where <code>a + b</code> and <code>tf.add(a, b)</code> is different is if neither <code>a</code> nor <code>b</code> are TensorFlow values, e.g. if they are Python scalars or NumPy arrays. In that case, <code>a + b</code> will perform a &quot;normal&quot; addition (add the scalars, or the arrays, or whatever) and give you (in principle) a result of the same kind as <code>a</code> and <code>b</code>, whereas <code>tf.add(a, b)</code> will automatically convert <code>a</code> and <code>b</code> into tensors and compute the TensorFlow addition operation (assuming eager mode, in graph mode it would just create the graph operation), and so the result would be a TensorFlow tensor object.</p>\n<p>In some cases this makes a technical difference. For example, consider this <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""nofollow noreferrer""><code>tf.function</code></a>:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n@tf.function\ndef f(a, b):\n    return tf.math.sqrt(a + b)\n</code></pre>\n<p>If I call <code>f(2.0, 3.0)</code>, then <code>a</code> and <code>b</code> will be considered &quot;constant&quot; values (as opposed to &quot;parameters&quot; to the <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""nofollow noreferrer""><code>tf.function</code></a>), and <code>a + b</code> would be computed to be <code>5.0</code> in the first call and made into a constant in the function graphs. Subsequent calls to <code>f(2.0, 3.0)</code> would not need to recompute this value, while a different call like <code>f(1.0, 2.0)</code> would generate a new similar function graph. If the function used <code>tf.math.add(a, b)</code> instead of that, it would be more or less the same, but and <code>Add</code> operation would be added to the graph with the constant inputs <code>2.0</code> and <code>3.0</code>, so in principle the addition would be recomputed on every call to <code>f(2.0, 3.0)</code>. This is usually a very minor and unimportant technical difference, specially since these function graphs are later optimized by TensorFlow too, so probably there will be no real difference in the actual execution.</p>\n<p>The only other significant difference is that <a href=""https://www.tensorflow.org/api_docs/python/tf/math/add"" rel=""nofollow noreferrer""><code>add</code></a>, like about any other TensorFlow operation, offers a <code>name</code> parameter. This is only relevant in graph mode, and even then not in most cases, but it allows you to give a specific name to the addition operation, which the <code>+</code> operator does not.</p>\n<p>In general, I prefer to use the <code>+</code> operator, because it looks cleaner and it automatically makes the computation in the most convenient way, e.g. if the operators are NumPy arrays using the NumPy library. It also makes it easier for the same code to work with TensorFlow, NumPy or other kind of data. Only when I explicitly want to use TensorFlow operations for some reason I may use the function, and even then I will probably just pass the operators through <a href=""https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor"" rel=""nofollow noreferrer""><code>tf.convert_to_tensor</code></a> before.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9323}"
661,76319875,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9322}"
662,38962308,"{'items': [{'owner': {'reputation': 5186, 'user_id': 992489}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1489189923, 'answer_id': 42729617, 'question_id': 38962308, 'body': '<p>The <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/fixed_unigram_candidate_sampler"" rel=""nofollow noreferrer"">documentation for fixed_unigram_candidate_sampler</a> does mention that true labels can be sampled. One of the things you\'ve marked as <code>_</code> in your code is in fact the expected ratio of sampled true labels.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9322}"
663,58877056,"{'items': [{'owner': {'reputation': 2457, 'user_id': 8842694}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1573823382, 'answer_id': 58877761, 'question_id': 58877056, 'body': '<p>You can use <code>tf.data</code> and based on my experience it is better to use it with TF, although it is a bit complicated. Let\'s say you have a large amount of dataset that might be difficult to fit into the memory (RAM), with Numpy Arrays it will try to store it into the memory during training, so complete data at once, however, with <code>tf.data</code>, you can use the same amount of data for training but now only the data that is currently being used for training (such a batch) will be stored in the memory. This can let you use GBs of data without running out of memory errors. This is the major difference between them, I would say. You can read more <a href=""https://www.tensorflow.org/guide/data#basic_mechanics"" rel=""nofollow noreferrer"">here</a>. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9322}"
664,61885570,"{'items': [{'owner': {'reputation': 47089, 'user_id': 121687}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1589914787, 'answer_id': 61898718, 'question_id': 61885570, 'body': '<p>The insight of the problem is that the records are serialized using another schema: the <code>ExampleListWithContext</code> Schema, instead of the basic <code>tf.train.Example</code> schema. Updating the right deserialization solves the problem.</p>\n\n<pre><code>filenames = [\'/tmp/train.tfrecords\']\nraw_dataset = tf.data.TFRecordDataset(filenames)\nfor e in raw_dataset.take(1):\n    ELWC = input_pb2.ExampleListWithContext()\n    v = ELWC.FromString(e.numpy())\n    print(v.context)\n    for e in v.examples:\n        print(e)\n</code></pre>\n\n<p>outputs:</p>\n\n<pre><code>features {\n  feature {\n    key: ""query""\n    value {\n      bytes_list {\n        value: ""why do ...""\n      }\n    }\n  }\n  feature {\n    key: ""query_bert_encoder_outputs""\n    value {\n      float_list {\n...\n}}\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9322}"
665,49745029,"{'items': [{'owner': {'reputation': 121, 'user_id': 6289645}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1525877131, 'answer_id': 50256188, 'question_id': 49745029, 'body': '<p>My understanding is that you have to run this script on all hosts of your cluster. With</p>\n\n<p>""--job_name=ps"" arguments on parameter server and </p>\n\n<p>""--job_name=worker --task_index=[0,1]"" on workers.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9318}"
666,59870349,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9318}"
667,56286350,"{'items': [{'owner': {'reputation': 32742, 'user_id': 2099607}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1559070848, 'answer_id': 56348713, 'question_id': 56286350, 'body': '<p>The <code>num_thresholds</code> refers to the number of thresholds. But you might ask: what is a threshold (in this context)? And the answer is that the threshold, which is in the range [0,1], is actually the value which all the predictions greater than that will be considered as positive (i.e. 1) and all the prediction lower than that will be considered as negative (i.e. 0). </p>\n\n<p>For example, consider the prediction vector as <code>[0, 0.5, 0.3, 0.9]</code> which are actually confidences scores (e.g. probabilities). Now if we apply the threshold value of <code>0.1</code>, we get <code>[0, 1, 1, 1]</code>; or if we apply threshold value of <code>0.6</code> we get <code>[0, 0, 0, 1]</code> (i.e. only the confidence of last prediction is higher than <code>0.6</code>).   </p>\n\n<p>Now suppose you want to monitor the changes to specificity at a fixed sensitivity. What <code>SensitivityAtSpecificity</code> metric does is that, to compute the value of sensitivity, it would first compute the specificity at different thresholds and then chooses the threshold which has the closest specificity to the specificity value you have provided (for example, in your question you have given <code>0.4</code> as the specificity value). Then the sensitivity is computed at that threshold and will be returned as the value of this metric. The same thing applies to <code>SpecificityAtSensitivity</code> metric, just swap ""specificity"" and ""sensitivity"" in this paragraph.</p>\n\n<p>You might also ask: what are the threshold values? The answer is if <code>num_thresholds=1</code> then the only threshold is 0.5. If <code>num_thresholds &gt; 1</code> then, besides 0 and 1 as thresholds, the interval (0,1) will be split into <code>num_thresholds - 1</code> equal sub-intervals and the split points are chosen as additional threshold values. For example:</p>\n\n<pre><code>num_threshold  |  thresholds\n=============================\n1              | [0.5]\n2              | [0, 1]\n3              | [0, 0.5, 1]\n4              | [0, 0.33, 0.66, 1]\n5              | [0, 0.25, 0.5, 0.75, 1]\n...\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9318}"
668,40891533,"{'items': [{'owner': {'reputation': 5154, 'user_id': 4678222}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1480525517, 'answer_id': 40894154, 'question_id': 40891533, 'body': '<p><code>tf.get_variable</code> works with variable scope to enable variable sharing. Here is an explanation on <a href=""https://www.tensorflow.org/versions/r0.12/how_tos/variable_scope/index.html#sharing-variables"" rel=""nofollow noreferrer"">how to share variables</a>.</p>\n\n<p>Specifically, I tend to separate variable initialization with fetching variable using the following framework.</p>\n\n<pre><code>def initialize_variables(scope_name, shape):\n\'\'\'initialize variables within variable scope_name.\'\'\'\n    with tf.variable_scope(scope_name, reuse=None) as scope:\n        w = tf.get_variable(""weight"", shape, initializer = random_normal_initializer(0., 0.01)))\n        b = tf.get_variable(""biase"", shape[-1], initializer = tf.constant_initializer(0.0))\n        scope.reuse_variables()\n\ndef fetch_variables(scope_name):\n    \'\'\'fetch variables within variable scope_name\'\'\'\n    with tf.variable_scope(scope_name, reuse=True):\n        w = tf.get_variable(""weight"")\n        b = tf.get_variable(""biase"")\n        return w, b\n</code></pre>\n\n<p>Note that <code>reuse=None</code> setting in the <code>initialize_variables</code> function will make <code>w</code> and <code>b</code> recreate based on given <code>initializer</code> setting. In <code>fetch_variables</code>, <code>reuse=True</code> setting enables variable sharing.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9318}"
669,50828432,"{'items': [{'owner': {'reputation': 438, 'user_id': 5100295}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1542058901, 'answer_id': 53270513, 'question_id': 50828432, 'body': '<p>You have to specify a distribution strategy in the RunConfig of your estimator as described in this documentation: </p>\n\n<p><a href=""https://github.com/tensorflow/tensorflow/tree/r1.8/tensorflow/contrib/distribute"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/tree/r1.8/tensorflow/contrib/distribute</a>.</p>\n\n<p>However I\'m afraid that you\'re looking for a Parameter Server Strategy(as you have a \'ps\' task) which is not available in TF 1.8.</p>\n\n<p>Please take a note that in the recent versions of TF this API has been changed and documentation is much more complete:</p>\n\n<p><a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/README.md#example"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/README.md#example</a></p>\n'}, {'owner': {'reputation': 158, 'user_id': 10240511}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1537745369, 'answer_id': 52471131, 'question_id': 50828432, 'body': '<p>You need to run tf.estimator.RunConfig(). In addition, you need to set the environment variable, TF_CONFIG, to point to a json text that defines your cluster settings.</p>\n\n<p>Check out <a href=""https://github.com/GoogleCloudPlatform/cloudml-samples/blob/master/census/estimator/trainer/task.py"" rel=""nofollow noreferrer"">https://github.com/GoogleCloudPlatform/cloudml-samples/blob/master/census/estimator/trainer/task.py</a> for more details.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9318}"
670,65436819,"{'items': [{'owner': {'reputation': 34678, 'user_id': 10908375}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1608815017, 'answer_id': 65438696, 'question_id': 65436819, 'body': '<p>If your data isn\'t labeled, I don\'t think you can call it the <em>test set</em>, since you won\'t be able to evaluate the performance of your algorithm using it.</p>\n<p>The argument you\'re looking for is <code>label_mode</code>, see the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"" rel=""nofollow noreferrer""><code>documentation</code></a>. If you set it to <code>label_model=None</code>, it will not return a target;</p>\n<blockquote>\n<p><strong>label_mode</strong>: <strong>\'int\'</strong>: means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss).\n<strong>\'categorical\'</strong> means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss).\n<strong>\'binary\'</strong> means that the labels (there can be only 2) are encoded as float32 scalars with values 0 or 1 (e.g. for binary_crossentropy).\n<strong>None</strong> (no labels).</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9313}"
671,71992472,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9313}"
672,64380057,"{'items': [{'owner': {'reputation': 3739, 'user_id': 1762295}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': True, 'score': 11, 'creation_date': 1602910095, 'answer_id': 64399107, 'question_id': 64380057, 'body': ""<p>Upon some debugging and doc reading, i found there's weighted_metrics argument in .compile, which i should use instead of metrics=. I confirmed this fixed my test case in the shared colab.</p>\n<pre><code>model.compile(optimizer = Adam(learning_rate=1e-4),\n             loss = SparseCategoricalCrossentropy(),\n             weighted_metrics = [SparseCategoricalAccuracy()])\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9313}"
673,73469081,"{'items': [{'owner': {'reputation': 346, 'user_id': 11330010}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1661326431, 'answer_id': 73469117, 'question_id': 73469081, 'body': '<p>Batching only affects the CPU/GPU RAM memory needs and not the predicted values.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9313}"
674,73165980,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1659647812, 'answer_id': 73242298, 'question_id': 73165980, 'body': ""<p>Short answer is, you can define <code>output_signature</code> as follows.</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nx_train = [\n  np.array([ 6,  1,  9, 10,  7,  7,  1,  9, 10,  3, 10,  1,  4]), \n  np.array([ 2,  8,  8,  1,  1,  4,  2,  5,  1,  2,  7,  2,  1,  1, 4,  5, 10, 4])\n]\ny_train = [23, 17]\n\ndataset = tf.data.Dataset.from_generator(\n    lambda: x_train, \n    output_signature=tf.TensorSpec(\n        [None, ], \n        dtype=tf.as_dtype(x_train[0].dtype)\n    )\n)\n</code></pre>\n<p>I'll also expand and improve on some things you're doing here to improve your pipeline.</p>\n<h2>Using both inputs and labels</h2>\n<pre><code>dataset = tf.data.Dataset.from_generator(\n    lambda: zip(x_train, y_train), \n    output_signature=(\n        tf.TensorSpec([None, ], dtype=tf.as_dtype(x_train[0].dtype)),\n        tf.TensorSpec([], dtype=tf.as_dtype(y_train.dtype))\n    )\n)\n\nfor x in dataset:\n  print(x)\n</code></pre>\n<p>Which would output,</p>\n<pre><code>(&lt;tf.Tensor: shape=(13,), dtype=int64, numpy=array([ 6,  1,  9, 10,  7,  7,  1,  9, 10,  3, 10,  1,  4])&gt;, &lt;tf.Tensor: shape=(), dtype=int64, numpy=23&gt;)\n(&lt;tf.Tensor: shape=(18,), dtype=int64, numpy=\narray([ 2,  8,  8,  1,  1,  4,  2,  5,  1,  2,  7,  2,  1,  1,  4,  5, 10,\n        4])&gt;, &lt;tf.Tensor: shape=(), dtype=int64, numpy=17&gt;)\n</code></pre>\n<p><strong>Caveat</strong>: This can get slightly more complicated if you try to <code>tf.data.Dataset.batch()</code> items. Then you need to use <code>RaggedTensorSpec</code> instead of <code>TensorSpec</code>. Also, I haven't experimented too much with feeding in ragged tensors into a RNN. But I think those are out of scope for the question you've asked.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9309}"
675,41673889,"{'items': [{'owner': {'reputation': 11, 'user_id': 8112158}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1609474395, 'answer_id': 65527239, 'question_id': 41673889, 'body': '<p>I made the modification to the code from <a href=""https://github.com/tensorflow/models/blob/master/research/slim/slim_walkthrough.ipynb"" rel=""nofollow noreferrer"">https://github.com/tensorflow/models/blob/master/research/slim/slim_walkthrough.ipynb</a> and bodokaiser answer from the above post. Please note that this is from the evaluation scrip on <a href=""https://github.com/tensorflow/models/tree/master/research/slim"" rel=""nofollow noreferrer"">https://github.com/tensorflow/models/tree/master/research/slim</a>, eval_image_classifier.py. The most important modification to the eval_image_classifier.py code is to add num_epochs=1 to the DatasetDataProvider line. That way, all the images would be accessed once for inference.</p>\n<pre><code>provider = slim.dataset_data_provider.DatasetDataProvider(\n    dataset,\n    shuffle=False,\n    common_queue_capacity=2 * FLAGS.batch_size,\n    common_queue_min=FLAGS.batch_size, num_epochs=1)\n[image, label] = provider.get([\'image\', \'label\'])\nimages, labels = tf.train.batch(\n    [image, label],\n    batch_size=FLAGS.batch_size,\n    num_threads=FLAGS.num_preprocessing_threads,\n    capacity=1 * FLAGS.batch_size)\nwith tf.Session() as sess:\n     sess.run([tf.local_variables_initializer(),\n               tf.global_variables_initializer(),])\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n    try:\n        while not coord.should_stop():\n            np_image, np_label = sess.run([images, labels])\n    except:\n        coord.request_stop()\n        coord.join(threads)\n</code></pre>\n'}, {'owner': {'reputation': 1, 'user_id': 11023902}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1549469909, 'answer_id': 54558049, 'question_id': 41673889, 'body': '<p>You need to call sess.run and pass the batch to it everytime when you want to load the next batch. See the code below.</p>\n\n<pre><code>img = [0,1,2,3,4,5,6,7,8]\nlbl = [0,1,2,3,4,5,6,7,8]\nimages = tf.convert_to_tensor(img)\nlabels = tf.convert_to_tensor(lbl)\ninput_queue = tf.train.slice_input_producer([images,labels])\nsliced_img = input_queue[0]\nsliced_lbl = input_queue[1]\n\nimg_batch, lbl_batch = tf.train.batch([sliced_img,sliced_lbl], batch_size=3)\nwith tf.Session() as sess:\n    coord   = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord)\n\n    for i in range(0,3): #batch size\n        image_batch,label_batch = sess.run([img_batch,lbl_batch ])\n        print(image_batch, label_batch)\n\n    coord.request_stop()\n    coord.join(threads)\n</code></pre>\n\n<p>the answer would be something like this: </p>\n\n<p>[4,1,8] [4,1,8]</p>\n\n<p>[2,3,7] [2,3,7]</p>\n\n<p>[2,6,8] [2,6,8]</p>\n'}, {'owner': {'reputation': 15282, 'user_id': 1246987}, 'down_vote_count': 1, 'up_vote_count': 19, 'is_accepted': True, 'score': 18, 'creation_date': 1484569687, 'answer_id': 41676452, 'question_id': 41673889, 'body': '<blockquote>\n  <p>... does tf.train.batch automatically feeds in another batch of data to the session?</p>\n</blockquote>\n\n<p>No. Nothing happens automatically. You must call <code>sess.run(...)</code> again to load a new batch.</p>\n\n<blockquote>\n  <p>Does this mean even without a loop, the next batch could be automatically fed?</p>\n</blockquote>\n\n<p>No. <code>tf.train.batch(..)</code> will always load <code>batch_size</code> tensors. If you have for example 100 images and a <code>batch_size=30</code> then you will have 3*30 batches as in you can call <code>sess.run(batch)</code> three times before the input queue will start from the beginning (or stop if <code>epoch=1</code>). This means that you miss out <code>100-3*30=10</code> samples from training. In case you do not want to miss them you can do <code>tf.train.batch(..., allow_smaller_final_batch=True)</code> so now you will have 3x 30-sample-batches and 1x 10-sample-batch before the input queue will restart.</p>\n\n<p>Let me also elaborate with a code sample:</p>\n\n<pre class=""lang-py prettyprint-override""><code>queue = tf.train.string_input_producer(filenames,\n        num_epochs=1) # only iterate through all samples in dataset once\n\nreader = tf.TFRecordReader() # or any reader you need\n_, example = reader.read(queue)\n\nimage, label = your_conversion_fn(example)\n\n# batch will now load up to 100 image-label-pairs on sess.run(...)\n# most tf ops are tuned to work on batches\n# this is faster and also gives better result on e.g. gradient calculation\nbatch = tf.train.batch([image, label], batch_size=100)\n\nwith tf.Session() as sess:\n    # ""boilerplate"" code\n    sess.run([\n        tf.local_variables_initializer(),\n        tf.global_variables_initializer(),\n    ])\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n        # in most cases coord.should_stop() will return True\n        # when there are no more samples to read\n        # if num_epochs=0 then it will run for ever\n        while not coord.should_stop():\n            # will start reading, working data from input queue\n            # and ""fetch"" the results of the computation graph\n            # into raw_images and raw_labels\n            raw_images, raw_labels = sess.run([images, labels])\n    finally:\n        coord.request_stop()\n        coord.join(threads)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9309}"
676,64769187,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9309}"
677,55190692,"{'items': [{'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1552754140, 'answer_id': 55199043, 'question_id': 55190692, 'body': '<p>TensoFlow 2.0 has <code>tf.keras.layers.Conv2DTranspose</code>. Keras is the default high level API for TF 2.0, but it still have <code>tf.nn.conv2d_transpose</code> for low level applications</p>\n\n<p><a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2DTranspose"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2DTranspose</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9309}"
678,59370662,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9309}"
679,68707494,"{'items': [{'owner': {'reputation': 1380, 'user_id': 200663}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1628489795, 'answer_id': 68707577, 'question_id': 68707494, 'body': '<p>I found a solution:</p>\n<pre><code>&gt; sparse_axes = [1,4]\n&gt; sparse_data = [[1.0,2.0,3.0],[4.0,6.0,6.0]]\n&gt; dense_data = tf.IndexedSlices(\n&gt;     tf.Variable(sparse_data), sparse_axes, dense_shape=(5,3)\n&gt; )\n&gt; dense_data.dense_shape\n[5,3]\n&gt; dense_data * tf.ones((5,3))\n&lt;tf.Tensor: shape=(5, 3), dtype=float32, numpy=\narray([[0., 0., 0.],\n       [1., 2., 3.],\n       [0., 0., 0.],\n       [0., 0., 0.],\n       [4., 6., 6.]], dtype=float32)&gt;\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9304}"
680,54897832,"{'items': [{'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1551275935, 'answer_id': 54907151, 'question_id': 54897832, 'body': '<p>You can use <code>np.split</code> and <code>from_generator</code> prior to creating dataset object.</p>\n\n<pre><code>chunks = list(np.split(array, 1000))\n\ndef gen():\n    for i in chunks:\n        yield i\n\ndataset = tf.data.Dataset.from_generator(gen, tf.float32)\ndataset = dataset.shuffle(shuffle_buffer_size)\n...\n</code></pre>\n\n<p>You can control the size of dataset with shuffle. It will load only specified quantity at a time. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9303}"
681,55573670,"{'items': [{'owner': {'reputation': 73, 'user_id': 6274665}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1554731743, 'answer_id': 55575127, 'question_id': 55573670, 'body': '<p>The issue is not in the lines </p>\n\n<pre><code># If this line is uncommented I get expected value around 2.3\n# logits = tf.nn.softmax(logits)\n</code></pre>\n\n<p>Images in cifar10 dataset are in RGB, thus pixel values are in range [0, 256). If you divide your <code>x_test</code> by 255 </p>\n\n<pre><code>x_test = np.reshape(x_test, [-1, 32, 32, 3]).astype(np.float32) / 255\n</code></pre>\n\n<p>the values will be rescaled to [0,1] and <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> will return expected values</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9303}"
682,51965094,"{'items': [{'owner': {'reputation': 2924, 'user_id': 3353760}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1534936305, 'answer_id': 51965581, 'question_id': 51965094, 'body': '<ul>\n<li><p><a href=""https://www.tensorflow.org/api_docs/python/tf/feature_column/input_layer"" rel=""nofollow noreferrer""><code>tf.feature_column.input_layer</code></a> returns a dense Tensor as an input layer to the Model from an already defined <a href=""https://www.tensorflow.org/guide/feature_columns"" rel=""nofollow noreferrer"">FeatureColumn</a>. The FeatureColumn APIs <a href=""https://www.tensorflow.org/api_docs/python/tf/feature_column"" rel=""nofollow noreferrer""><code>tf.feature_column</code></a> describes the attributes from the dataset that will be fed into an Estimator for training and validation.</p></li>\n<li><p>Whereas, <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model"" rel=""nofollow noreferrer""><code>tf.layers.Input</code></a> is analogous to Keras <code>tf.keras.Input()</code> method which is used to instantiate a Keras or in this case TensorFlow Tensor for use with the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model"" rel=""nofollow noreferrer""><code>tf.keras.Model</code></a> function.</p></li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9303}"
683,44526763,"{'items': [{'owner': {'reputation': 2262, 'user_id': 7886651}, 'down_vote_count': 0, 'up_vote_count': 18, 'is_accepted': True, 'score': 18, 'creation_date': 1497377120, 'answer_id': 44528576, 'question_id': 44526763, 'body': '<p>This is how to perform this operation on a batch of images.</p>\n\n<p><code>tf.map_fn(lambda frame: tf.image.per_image_standardization(frame), frames)</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9303}"
684,66231467,"{'items': [{'owner': {'reputation': 368, 'user_id': 2406562}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1616058414, 'answer_id': 66687887, 'question_id': 66231467, 'body': '<p><code>min_resource</code>\'s explanation on <a href=""https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.SuccessiveHalvingPruner.html"" rel=""nofollow noreferrer"">the documentation</a> says</p>\n<blockquote>\n<p>A trial is never pruned until it executes <code>min_resource * reduction_factor ** min_early_stopping_rate</code> steps.</p>\n</blockquote>\n<p>So, I suppose that we need to replace the value of <code>min_resource</code> with a specific number depending on <code>reduction_factor</code> and <code>min_early_stopping_rate</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9299}"
685,57081006,"{'items': [{'owner': {'reputation': 99, 'user_id': 8188662}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1615986080, 'answer_id': 66673613, 'question_id': 57081006, 'body': '<p>maybe you can directly use a function to encapsulate your repetitive operations instead of subclassing layer, only if you think you need to play with weights or pattern of initialized weights use subclassing because that is the right method over the latter.</p>\n<p>Example:</p>\n<pre><code>def simple_conv(x):\n   x = Conv2d(x)\n   x = Bathcnorm(x)\n   return x\n\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9299}"
686,54686895,"{'items': [{'owner': {'reputation': 41, 'user_id': 5023986}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1559292356, 'answer_id': 56391638, 'question_id': 54686895, 'body': '<p>can do it like this:</p>\n\n<pre><code>def dilation2d(self, img4D):\n    \'\'\'\n    \'\'\'\n    with tf.variable_scope(\'dilation2d\'):\n        kernel = tf.ones((3, 3, img4D.get_shape()[3])) \n        output4D = tf.nn.dilation2d(img4D, filter=kernel, strides=(1,1,1,1), rates=(1,1,1,1), padding=""SAME"")\n        output4D = output4D - tf.ones_like(output4D)\n\n        return output4D\n</code></pre>\n'}, {'owner': {'reputation': 57130, 'user_id': 7328782}, 'down_vote_count': 0, 'up_vote_count': 9, 'is_accepted': True, 'score': 9, 'creation_date': 1552806856, 'answer_id': 55204699, 'question_id': 54686895, 'body': ""<p>As mentioned in the documentation page linked,</p>\n\n<blockquote>\n  <p>Computes the grayscale dilation of 4-D input and 3-D filter tensors.</p>\n</blockquote>\n\n<p>and</p>\n\n<blockquote>\n  <p>In detail, the grayscale morphological 2-D dilation is the max-sum correlation [...]</p>\n</blockquote>\n\n<p>What this means is that the kernel's values are added to the image's values at each position, then the maximum value is taken as the output value.</p>\n\n<p>Compare this to correlation, replacing the multiplication with an addition, and the integral (or sum) with the maximum:</p>\n\n<p>&nbsp; &nbsp; &nbsp; convolution: <em>g</em>(<em>t</em>) =  <em>f</em>() <em>h</em>(-<em>t</em>) d</p>\n\n<p>&nbsp; &nbsp; &nbsp; dilation: <em>g</em>(<em>t</em>) = max<sub></sub> { <em>f</em>() + <em>h</em>(-<em>t</em>) }</p>\n\n<p>Or in the discrete world:</p>\n\n<p>&nbsp; &nbsp; &nbsp; convolution: <em>g</em>[<em>n</em>] = <sub><em>k</em></sub> <em>f</em>[<em>k</em>] <em>h</em>[<em>k</em>-<em>n</em>]</p>\n\n<p>&nbsp; &nbsp; &nbsp; dilation: <em>g</em>[<em>n</em>] = max<sub><em>k</em></sub> { <em>f</em>[<em>k</em>] + <em>h</em>[<em>k</em>-<em>n</em>] }</p>\n\n<hr>\n\n<p>The dilation with a binary structuring element (kernel, what the question refers to as a conventional dilation) uses a structuring element (kernel) that contains only 1s and 0s. These indicate included and excluded. That is, the 1s determine the domain of the structuring element.</p>\n\n<p>To recreate the same behavior with a grey-value dilation, set the included pixels to 0 and the excluded pixels to minus infinity.</p>\n\n<p>For example, the 3x3 square structuring element used in the question should be a 3x3 matrix of zeros.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9299}"
687,63210672,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1600954767, 'answer_id': 64047739, 'question_id': 63210672, 'body': '<p>Linear Classifier is nothing but Logistic Regression.</p>\n<p>According to Tensorflow documentation, <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier"" rel=""nofollow noreferrer"">tf.estimator.LinearClassifier</a> is used to</p>\n<blockquote>\n<p>Train a linear model to classify instances into one of multiple\npossible classes. When number of possible classes is 2, this is binary\nclassification</p>\n</blockquote>\n<p>Linear regression predicts a value while the linear classifier predicts a class. Classification aims at predicting the probability of each class given a set of inputs.</p>\n<p>For implementation of <code>tf.estimator.LinearClassifier</code>, please follow <a href=""https://www.guru99.com/linear-classifier-tensorflow.html#7"" rel=""nofollow noreferrer"">this</a> tutorial by guru99.</p>\n<p>To know about the linear classifiers, read <a href=""https://cs231n.github.io/linear-classify/"" rel=""nofollow noreferrer"">this</a> article.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9299}"
688,61428918,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9299}"
689,50840759,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9294}"
690,70319286,"{'items': [{'owner': {'reputation': 1, 'user_id': 11470040}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1639271665, 'answer_id': 70320227, 'question_id': 70319286, 'body': '<p>Looking at the notebook more carefully, I see that the loss function is calculated as:</p>\n<pre><code>loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction=\'none\')\n</code></pre>\n<p>As explained in the link below, setting <em>from_logits</em> to <em>True</em> ensures that the Softmax is applied during the loss calculation.</p>\n<p><a href=""https://datascience.stackexchange.com/questions/73093/what-does-from-logits-true-do-in-sparsecategoricalcrossentropy-loss-function"">https://datascience.stackexchange.com/questions/73093/what-does-from-logits-true-do-in-sparsecategoricalcrossentropy-loss-function</a></p>\n<p>So the Softmax activation does not need to be applied within the Dense layer of the Transformer model.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9294}"
691,58213561,"{'items': [{'owner': {'reputation': 4277, 'user_id': 7212365}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1570085873, 'answer_id': 58213822, 'question_id': 58213561, 'body': '<p>In tensorflow 2.0, you need to set default writer via <code>.as_default()</code>. Also, <code>step</code> argument must be passed in summary ops. More details can be seen <a href=""https://www.tensorflow.org/tensorboard/migrate"" rel=""nofollow noreferrer"">here</a>. </p>\n\n<pre class=""lang-py prettyprint-override""><code>writer = tf.summary.create_file_writer(""summaries"")\n\nfor epoch in range(epochs):\n    train_loss = ...\n    val_loss = ...\n    with writer.as_default():\n      tf.summary.scalar(\'train_loss\', train_loss, step=epoch)\n      tf.summary.scalar(\'val_loss\', val_loss, step=epoch)\n    writer.flush()\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9294}"
692,71292087,"{'items': [{'owner': {'reputation': 746, 'user_id': 7848579}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1646038254, 'answer_id': 71292492, 'question_id': 71292087, 'body': '<p>I saw there is a correct answers but me also provide another way by it layer(s) that I use for my working cases:</p>\n<pre><code>X = tf.keras.layers.Concatenate(axis=1)([group_1_ShoryuKen_Left, group_1_ShoryuKen_Right])\n</code></pre>\n<p><a href=""https://i.stack.imgur.com/Q62N1.png"" rel=""nofollow noreferrer"">Working with multiple sequences</a></p>\n'}, {'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1646035774, 'answer_id': 71292121, 'question_id': 71292087, 'body': '<p>Use <code>tf.expand_dims</code> with <code>tf.concat</code>:</p>\n<pre><code>import tensorflow as tf\n\nx1 = tf.expand_dims(tf.random.normal((40, 10)), axis=0)\nx2 = tf.expand_dims(tf.random.normal((40, 10)), axis=0)\nx3 = tf.expand_dims(tf.random.normal((40, 10)), axis=0)\nx4 = tf.expand_dims(tf.random.normal((40, 10)), axis=0)\n\nx = tf.concat([x1, x2, x3, x4], axis=0)\nprint(x.shape)\n# (4, 40, 10)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9294}"
693,51883196,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9290}"
694,36508860,"{'items': [{'owner': {'reputation': 1463, 'user_id': 640898}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1460158820, 'answer_id': 36510993, 'question_id': 36508860, 'body': '<p>You have to create a new graph that has the same structure but with the <code>batch_size = 1</code> and import the saved variables with <code>tf.train.Saver.restore()</code>. You can take a look at how they define multiple models with variable batch size in ptb_word_lm.py: <a href=""https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/models/rnn/ptb/ptb_word_lm.py"" rel=""nofollow"">https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/models/rnn/ptb/ptb_word_lm.py</a></p>\n\n<p>So you can have a separate file for instance, where you instantiate the graph with the batch_size that you want, then restore the saved variables. Then you can execute your graph.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9290}"
695,61717694,"{'items': [{'owner': {'reputation': 1, 'user_id': 13714103}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1591711426, 'answer_id': 62284510, 'question_id': 61717694, 'body': '<p>I bumped into this issue as well. It seems to be caused by the incompatibility issues between TFP and TF 2.0 (a couple relevant issues <a href=""https://github.com/tensorflow/probability/issues/355"" rel=""nofollow noreferrer"">https://github.com/tensorflow/probability/issues/355</a> and <a href=""https://github.com/tensorflow/probability/issues/946"" rel=""nofollow noreferrer"">https://github.com/tensorflow/probability/issues/946</a>).</p>\n\n<p>As a workaround, you need to add the (trainable) variables of your transformed distribution / bijector as an attribute to your Keras Model:</p>\n\n<pre><code>class Flows(tf.keras.Model):\n\n    def __init__(self, d=2, shape=(100, 2), n_flows=10, ):\n        super(Flows, self).__init__()\n        # Parameters\n        self.d = d\n        self.shape = shape\n        self.n_flows = n_flows\n        # Base distribution - MF = Multivariate normal diag\n        base_distribution = tfd.MultivariateNormalDiag(\n            loc=tf.zeros(shape=shape, dtype=tf.float32)\n        )\n        # Flows as chain of bijector\n        flows = []\n        for n in range(n_flows):\n            flows.append(Flow(self.d, name=f""flow_{n + 1}""))\n        bijector = tfb.Chain(list(reversed(flows)))\n        self.flow = tfd.TransformedDistribution(\n            distribution=base_distribution,\n            bijector=bijector\n        )\n        # issue: https://github.com/tensorflow/probability/issues/355, https://github.com/tensorflow/probability/issues/946\n        # need to add bijector\'s trainable variables as an attribute (name does not matter)\n        # otherwise this layer has zero trainable variables\n        self._variables = self.flow.variables # https://github.com/tensorflow/probability/issues/355\n\n    def call(self, *inputs):\n        return self.flow.bijector.forward(*inputs)\n\n    def log_prob(self, *inputs):\n        return self.flow.log_prob(*inputs)\n\n    def sample(self, num):\n        return self.flow.sample(num)\n</code></pre>\n\n<p>After adding this your model should have trainable variables and weights to optimize.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9290}"
696,42675391,"{'items': [{'owner': {'reputation': 78826, 'user_id': 395857}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1488988262, 'answer_id': 42675889, 'question_id': 42675391, 'body': '<p>The  keyword argument <code>labels</code>  <a href=""https://web.archive.org/web/20170308155130/https://github.com/carpedm20/DCGAN-tensorflow/issues/84"" rel=""nofollow noreferrer"">only exists</a> in TensorFlow 1.0.0 and above. I guess you\'re using 0.12 or below. Use <code>pip freeze</code> or <code>print(\'TensorFlow version: {0}\'.format(tf.__version__))</code> to check.</p>\n\n<hr>\n\n<p>The documentation for prior versions can be found at <a href=""https://www.tensorflow.org/versions/"" rel=""nofollow noreferrer"">https://www.tensorflow.org/versions/</a></p>\n\n<p>To search for some information in the documentation of a previous version you can use: <a href=""https://www.google.com/search?q=site:https://www.tensorflow.org/versions/r0.12+sigmoid_cross_entropy_with_logits()"" rel=""nofollow noreferrer"">https://www.google.com/search?q=site:https://www.tensorflow.org/versions/r0.12+sigmoid_cross_entropy_with_logits()</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9290}"
697,57529534,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9290}"
698,58608838,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9285}"
699,57881799,"{'items': [{'owner': {'reputation': 55, 'user_id': 5026962}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1568214719, 'answer_id': 57892130, 'question_id': 57881799, 'body': '<p>Nevermind, I was supposed to use GradientReversal layer after the Dense to get the result I want.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9285}"
700,53167302,"{'items': [{'owner': {'reputation': 1373, 'user_id': 8909870}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1541497955, 'answer_id': 53169453, 'question_id': 53167302, 'body': '<p>Convolution does generally does not need an input shape. Actually you can feed the same network different input shapes, but it is much faster, when you give tensorflow an input shape. I think that the reason, why its stated in the docs. </p>\n\n<p>The original method of tensorflow does not even have an argument for input shapes.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9283}"
701,62850250,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1594901901, 'answer_id': 62934515, 'question_id': 62850250, 'body': '<p>This is a good observation.</p>\n<p><strong>TLDR</strong>, different <code>Input Shapes</code> can be passed for <code>Models</code> of <code>tf.keras.applications</code> with the argument, <code>include_top = False</code> but that is not possible when we use <code>tf.keras.applications</code> with the argument, <code>include_top = True</code> and when we use <code>Models</code> of <code>Tensorflow Hub</code>.</p>\n<p><strong>Detailed Explanation</strong>:</p>\n<p>This <a href=""https://www.tensorflow.org/hub/common_signatures/images#image_input"" rel=""nofollow noreferrer"">Tensorflow Hub Documentation</a> states</p>\n<pre><code>&gt; The height and width dimensions are fixed to the expected size of\n&gt; input images. (Future work may remove that restriction for fully\n&gt; convolutional modules.)\n</code></pre>\n<p>That\'s the reason, if we pass the <code>Image Shape</code> other than the Expected Shape, it raises an error,</p>\n<pre><code> Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=\'inputs\')\n        * True\n        * False\n        * TensorSpec(shape=(), dtype=tf.float32, name=\'batch_norm_momentum\')\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=\'inputs\')\n        * True\n        * True\n        * TensorSpec(shape=(), dtype=tf.float32, name=\'batch_norm_momentum\')\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=\'inputs\')\n        * False\n        * True\n        * TensorSpec(shape=(), dtype=tf.float32, name=\'batch_norm_momentum\')\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=\'inputs\')\n        * False\n        * False\n        * TensorSpec(shape=(), dtype=tf.float32, name=\'batch_norm_momentum\')\n      Keyword arguments: {}\n</code></pre>\n<p>Similarly, when we pass different <code>Input Shape</code> while using the <code>Pre-Trained Models</code> of <code>tf.keras.applications</code> with the argument, <strong><code>include_top = True</code></strong> (including the Dense Layers at the Top as well), it raises an error,</p>\n<pre><code>ValueError: When setting `include_top=True` and loading `imagenet` \nweights, `input_shape` should be (224, 224, 3).\n</code></pre>\n<p>But if we set the value of argument, <strong><code>include_top = False</code></strong> while using the <code>Pre-Trained Models</code> from <code>tf.keras.applications</code>, the <code>Input_Shape</code> can be <strong>flexible</strong> i.e., for MobileNetV2, we can pass any of the shapes from the list, <code>[96, 128, 160, 192, 224]</code>) and for Models like <code>ResNet</code> or <code>VGGNet</code>, we can pass any <code>Input Shape</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9283}"
702,43885770,"{'items': [{'owner': {'reputation': 3201, 'user_id': 6392807}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1494617257, 'answer_id': 43945143, 'question_id': 43885770, 'body': ""<p>This simply checks that <code>values</code> are Tensors built as part of the same <code>tf.Graph()</code> object. You can have more than one <code>tf.Graph()</code> in your program, and confusing things can happen if you mix nodes from two graphs. Most programs don't do this though, but often it is a good thing to check when writing library code.</p>\n\n<p>There is no additional value to the <code>values</code> parameter than providing this error checking.</p>\n\n<p>Hope this helps!</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9283}"
703,56972492,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9283}"
704,43472077,"{'items': [{'owner': {'reputation': 3156, 'user_id': 1217998}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1512911467, 'answer_id': 47739184, 'question_id': 43472077, 'body': '<p>I am using Tensorflow 1.4</p>\n\n<p>I cannot find any straightforward way to use text summaries as I cannot find any example of how to convert number-like tensors into strings. However, using <a href=""https://stackoverflow.com/questions/45593967/convert-tensorflow-tensor-of-ascii-codes-to-string"">this</a> post we can write a makeshift function using <a href=""https://www.tensorflow.org/api_docs/python/tf/py_func"" rel=""nofollow noreferrer"">tf.py_func</a> to achieve the result.</p>\n\n<pre><code>import tensorflow as tf\n\n# Input tensor\na = tf.constant([ord(\'a\'),ord(\'b\')])\n\n# Function in python\ndef asciiToString(x):\n    s = """"\n    for c in x:\n        s += chr(c)\n    return s\n\nprint(asciiToString([97,98]))\n\nb = tf.py_func(asciiToString,[a],tf.string)\n\n# Save summary\ntf.summary.text(\'my_text\',b)\n\nsummaries = tf.summary.merge_all()  \n\nwith tf.Session() as sess:\n    summaryWriter = tf.summary.FileWriter(\'./logs\',sess.graph) \n    sess.run(tf.global_variables_initializer())\n    print(sess.run(a))\n    print(sess.run(b))\n    summary_output = sess.run(summaries)\n    summaryWriter.add_summary(summary_output,0)\n</code></pre>\n'}, {'owner': {'reputation': 5620, 'user_id': 4082104}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1496279332, 'answer_id': 44296934, 'question_id': 43472077, 'body': '<p><a href=""https://github.com/tensorflow/tensorflow/releases"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/releases</a></p>\n\n<p>Patch notes says that it was only added in v1.2.0</p>\n\n<p>Perhaps the code is there in previous versions, but when it\'s installed/built, it\'s not included?</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9279}"
705,73794766,"{'items': [{'owner': {'reputation': 5156, 'user_id': 11659881}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1663729822, 'answer_id': 73794945, 'question_id': 73794766, 'body': '<p>Per the <a href=""https://keras.io/api/layers/preprocessing_layers/numerical/normalization/"" rel=""nofollow noreferrer"">documentation</a> this layer is:</p>\n<blockquote>\n<p>A preprocessing layer which normalizes continuous <strong>features</strong>.</p>\n</blockquote>\n<p>Then, under the description of <code>axis</code>:</p>\n<blockquote>\n<p>Defaults to -1, where the last axis of the input is assumed to be a <strong>feature dimension</strong> and is normalized per index.</p>\n</blockquote>\n<p>From these two statements, we can see that <code>-1</code> in this context just means the last axis. This is actually fairly common in Python, for example you can index for the last element in a list using <code>-1</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9279}"
706,69526735,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9279}"
707,57316557,"{'items': [{'owner': {'reputation': 1984, 'user_id': 8762113}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1565576267, 'answer_id': 57455003, 'question_id': 57316557, 'body': '<p>@Stewart_R clearly shows the solution to the problem :)</p>\n<p>Let me just put a simple code with the solution.</p>\n<pre class=""lang-py prettyprint-override""><code>loaded_model = keras.models.load_model(fname)\n    \n# remove the last 2 layers\nsliced_loaded_model = Sequential(loaded_model.layers[:-2])\n    \n# set trainable=False for the layers from loaded_model\nfor layer in sliced_loaded_model.layers:\n    layer.trainable = False\n    \n# add new layers\nsliced_loaded_model.add(Dense(32, activation=\'relu\'))  # trainable=True is default\nsliced_loaded_model.add(Dense(1))\n    \n# compile\nsliced_loaded_model.compile(loss=\'mse\', optimizer=\'adam\', metrics=[])\n    \n# fit\n...\n</code></pre>\n'}, {'owner': {'reputation': 13934, 'user_id': 2455494}, 'down_vote_count': 0, 'up_vote_count': 10, 'is_accepted': True, 'score': 10, 'creation_date': 1564727800, 'answer_id': 57321117, 'question_id': 57316557, 'body': '<p>I agree this is confusing. The reason is that <code>model.layers</code> returns a shallow copy of the layers list so:</p>\n\n<p>The tldr is dont use <code>model.layers.pop()</code> to remove the last layer. Instead we should create a new model with all but the last layer. Perhaps something like this:</p>\n\n<pre class=""lang-py prettyprint-override""><code>new_model = tf.keras.models.Sequential(base_model.layers[:-1])\n</code></pre>\n\n<p>Checkout this <a href=""https://github.com/tensorflow/tensorflow/issues/22479"" rel=""noreferrer"">github issue</a> for more details</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9279}"
708,38646996,"{'items': [{'owner': {'reputation': 1699, 'user_id': 5990514}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1469797047, 'answer_id': 38659510, 'question_id': 38646996, 'body': '<p><code>dynamic_rnn</code> does not appear to be listed in the <a href=""https://www.tensorflow.org/versions/r0.7/api_docs/python/nn.html"" rel=""nofollow noreferrer"">api docs</a> of tensorflow 0.7.</p>\n\n<p>As a next step, you could try one of the following options:</p>\n\n<ul>\n<li>Deploy a newer version of Datalab. This is the recommended option. The latest version uses tensorflow 0.9.0.</li>\n<li>Upgrade tensorflow to version 0.9.0 by running the command below in a Datalab notebook. See my explanation in the following <a href=""https://stackoverflow.com/questions/37464668/tensorflow-upgrade-failed-on-google-datalab/37604626#37604626"">stackoverflow post</a> explaining why this is not recommended (but it may work). </li>\n</ul>\n\n<p>Note for tensorflow version 0.9.0 use: </p>\n\n<pre><code>%%bash\nwget https://storage.googleapis.com/cloud-datalab/deploy/tf/tensorflow-0.9.0-cp27-none-linux_x86_64.whl &amp;&amp; pip install --ignore-installed --no-deps tensorflow-0.9.0-cp27-none-linux_x86_64.whl &amp;&amp; rm tensorflow-0.9.0-cp27-none-linux_x86_64.whl\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9275}"
709,62670041,"{'items': [{'owner': {'reputation': 14062, 'user_id': 6117017}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1593580556, 'answer_id': 62670148, 'question_id': 62670041, 'body': '<p>You do not need to pass the <code>batch_size</code> parameter in <code>model.fit()</code> in this case. It will automatically use the BATCH_SIZE that you use in <code>tf.data.Dataset().batch()</code>.</p>\n<p>As for your other question : the batch size hyperparameter indeed needs to be carefully tuned. On the other hand, if you see OOM errors, you should decrease it until you do not get OOM (normally (but not necessarily) in this manner 32 --&gt; 16 --&gt; 8 ...). In fact you can try non-power of two batch sizes for the decrease purposes.</p>\n<p>In your case I would start with a batch_size of 2 an increase it gradually (<code>3-4-5-6...</code>).</p>\n<p>You do not need to provide the <code>batch_size</code> parameter if you use the <code>tf.data.Dataset().batch()</code> method.</p>\n<p>In fact, even the official <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">documentation</a> states this:</p>\n<blockquote>\n<p>batch_size : Integer or None. Number of samples per gradient update.\nIf unspecified, batch_size will default to 32. Do not specify the\nbatch_size if your data is in the form of datasets, generators, or\nkeras.utils.Sequence instances (since they generate batches).</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9275}"
710,45030619,"{'items': [{'owner': {'reputation': 23445, 'user_id': 1735003}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1499766720, 'answer_id': 45031123, 'question_id': 45030619, 'body': ""<p>You could use tensorflow's python slicing operator, which is slightly more powerful than <code>tf.slice</code> and in particular does some bound checking to behave similarly to <code>numpy</code>.</p>\n\n<pre><code>x = tf.zeros((10,))\ny = tf.slice(x, [5], [15])\nprint(y.shape)\n# (15,)\nz = x[5:42]\nprint(z.shape)\n# (5,)\n</code></pre>\n""}, {'owner': {'reputation': 6144, 'user_id': 7456923}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1499765983, 'answer_id': 45030831, 'question_id': 45030619, 'body': '<p>You could use <a href=""https://www.tensorflow.org/api_docs/python/tf/clip_by_value"" rel=""nofollow noreferrer"">tf.clip_by_value</a>:</p>\n\n<pre><code>def robust_slice( t, begin, size, name=None ):\n    with tf.name_scope(\'robust_slice\'):\n        new_size = tf.clip_by_value(size + begin, clip_value_min = 0, clip_value_max = t.shape()) - begin\n        return tf.slice(t, begin, new_size, name)\n</code></pre>\n\n<p>(not tested but somthing like that should do the job)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9275}"
711,52219099,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1536317714, 'answer_id': 52221056, 'question_id': 52219099, 'body': '<p>There is not a provided way to read a <code>.npy</code> file into a <code>tensorflow::Tensor</code>. First you would need to read the file, which is not trivial but it is not too hard either, checkout the <a href=""https://www.numpy.org/devdocs/reference/generated/numpy.lib.format.html"" rel=""nofollow noreferrer"">NPY format documentation</a>. Once you have that, the easiest thing would be to copy the data to a tensor:</p>\n\n<pre><code>// Existing NPY reading function, assuming float type\nbool read_npy(const char* file, std::vector&lt;float&gt;&amp; npy_values, std::vector&lt;int64_t&gt;&amp; shape);\n// Read file\nstd::vector&lt;float&gt; npy_values;\nstd::vector&lt;int64_t&gt; shape;\nif (!read_npy(""data.npy"", npy_values, shape))\n{\n    // error...\n}\n// Make tensor\ntensorflow::TensorShape tensorShape;\nfor (int64_t dim : shape)\n{\n    tensorShape.AddDim(dim);\n}\ntensorflow::Tensor tensor(DT_FLOAT, tensorShape);\n// Copy data\nstd::copy(npy_values.begin(), npy_values.end(), tensor.flat&lt;float&gt;().data());\n// Or with memcpy\nstd::memcpy(tensor.flat&lt;float&gt;().data(), npy_values.data(), tensor.NumElements() * sizeof(float));\n</code></pre>\n\n<p>Note that this assumes that the NPY data buffer is in row-major order like TensorFlow tensors, and I suppose <a href=""https://www.tensorflow.org/api_docs/cc/class/tensorflow/tensor#classtensorflow_1_1_tensor_1aec1fa00d85d569b344a55ad89f915ce9"" rel=""nofollow noreferrer""><code>IsAligned()</code></a> should be true for the tensor, although afaik that should always be true for new tensors.</p>\n\n<p>Another option would be to first create the tensor and then use its buffer (<code>tensor.flat&lt;float&gt;().data()</code>) to write the read values. This however requires a bit more of work, because you would need to first read the shape of the tensor in the file (or fix it beforehand), create the tensor and then read the file into its buffer (in this case the reading function would receive a pointer and not allocate any memory).</p>\n\n<p>EDIT: I just realised you said ""Assuming I have a utility function to read the .npy file and it returns a float pointer to the array"", not a vector. Well the idea should be the same, you can still use <code>memcpy</code> or <code>copy</code> like:</p>\n\n<pre><code>std::copy(npy_ptr, npy_ptr + tensor.NumElements(), tensor.flat&lt;float&gt;().data());\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9275}"
712,75478235,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9275}"
713,58631390,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 16, 'is_accepted': True, 'score': 16, 'creation_date': 1572459768, 'answer_id': 58631589, 'question_id': 58631390, 'body': '<p><a href=""https://www.tensorflow.org/api_docs/python/tf/compat"" rel=""noreferrer""><code>tf.compat</code></a> allows you to write code that works both in TensorFlow 1.x and 2.x. For example, the following piece of code:</p>\n\n<pre><code>import tensorflow as tf\n\ntf.compat.v1.disable_v2_behavior()\nwith tf.compat.v1.Session() as sess:\n    x = tf.compat.v1.placeholder(tf.float32, [2])\n    x2 = tf.square(x)\n    print(sess.run(x2, feed_dict={x: [2, 3]}))\n    # [4. 9.]\n</code></pre>\n\n<p>Runs the same on TensorFlow 1.15.0 and 2.0.0, even though session and placeholders were deprecated in 2.x. Likewise, <a href=""https://www.tensorflow.org/api_docs/python/tf/compat/v2"" rel=""noreferrer""><code>tf.compat.v2</code></a> allows you to use things introduced in 2.x from 1.x. Also, these APIs provide also backwards compatibility for the future too, so if at some point a 3.x version is released, the mechanism to write version-independent code will already be there since the first version of 2.x.</p>\n\n<p>EDIT: The documentation for the module about Python should actually be changed. Originally, <code>tf.compat</code> only held functions for that purpose (and it was like that until 1.13, <a href=""https://www.tensorflow.org/versions/r1.13/api_docs/python/tf/compat"" rel=""noreferrer"">see all module documentation</a>). However, it was later repurposed for TensorFlow version compatibility.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9270}"
714,45401311,"{'items': [{'owner': {'reputation': 16941, 'user_id': 8143158}, 'down_vote_count': 0, 'up_vote_count': 20, 'is_accepted': True, 'score': 20, 'creation_date': 1501430633, 'answer_id': 45401846, 'question_id': 45401311, 'body': '<p>Lets say you have a image of size <code>64x64</code>. It is composed of <code>R-G-B</code> of <code>64x64</code> each, so the input size is <code>64x64x3</code> and <code>3</code> is the input channel in this case. Now you want to convolve this input with a <code>kernel</code> of <code>5x5x3</code>, you get an output of <code>64x64x1</code> (with padding). Suppose you have <code>100</code> such kernels and convolve each one of them with the input, you get <code>64x64x100</code>. Here the output channels are <code>100</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9270}"
715,62086367,"{'items': [{'owner': {'reputation': 1233, 'user_id': 401884}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1591247431, 'answer_id': 62187234, 'question_id': 62086367, 'body': '<p><code>tf.data</code> does not use <code>tf.placeholders</code> under the hood. <code>tf.data.Dataset</code> uses the same mechanisms as other Tensorflow ops. The graph it creates in graph mode is not separate.</p>\n\n<p>Check out the below video to learn more about how <code>tf.data</code> works under the hood. I linked to the part that explains what happens when you call <code>next()</code> on a dataset iterator.</p>\n\n<p><a href=""https://youtu.be/kVEOCfBy9uY?t=1404"" rel=""nofollow noreferrer"">https://youtu.be/kVEOCfBy9uY?t=1404</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9270}"
716,44315874,"{'items': [{'owner': {'reputation': 6420, 'user_id': 5080995}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1496348156, 'answer_id': 44316366, 'question_id': 44315874, 'body': '<p>As you mentioned in the comments, <code>b</code>, <code>bb</code> are both valid forms of broadcasting. As mentioned in the <code>numpy</code> <a href=""https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html#general-broadcasting-rules"" rel=""nofollow noreferrer"">documentation</a>,</p>\n\n<blockquote>\n  <p>Arrays do not need to have the same number of dimensions.</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9270}"
717,67241187,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9270}"
718,46976226,"{'items': [{'owner': {'reputation': 1080, 'user_id': 1454804}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1510161328, 'answer_id': 47185807, 'question_id': 46976226, 'body': '<p>Please prefer core version, i.e. <code>tf.estimator.RunConfig</code>. \n<code>tf.contrib.learn.*</code> will be deprecated soon.\nBTW, you can do <code>tf.estimator.RunConfig(save_check...)</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9265}"
719,43422949,"{'items': [{'owner': {'reputation': 5186, 'user_id': 992489}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': True, 'score': 7, 'creation_date': 1492446025, 'answer_id': 43455251, 'question_id': 43422949, 'body': '<p>In this case <code>b</code> is each example in a minibatch. <code>sequence_length(b)</code> is the number of time stamps you have for that example. This is specified in the <code>sequence_length</code> argument passed to <code>tf.nn.ctc_loss</code> which is a 1-d tensor of sequence lengths.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9265}"
720,51762406,"{'items': [{'owner': {'reputation': 3784, 'user_id': 8334261}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1533805290, 'answer_id': 51762880, 'question_id': 51762406, 'body': '<p>No, the implementation of the <code>binary_crossentropy</code> with tensorflow backend is defined <a href=""https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/keras/backend.py"" rel=""nofollow noreferrer"">here</a> as</p>\n\n<pre class=""lang-py prettyprint-override""><code>@tf_export(\'keras.backend.binary_crossentropy\')\ndef binary_crossentropy(target, output, from_logits=False):\n    """"""Binary crossentropy between an output tensor and a target tensor.\n    Arguments:\n      target: A tensor with the same shape as `output`.\n      output: A tensor.\n      from_logits: Whether `output` is expected to be a logits tensor.\n          By default, we consider that `output`\n          encodes a probability distribution.\n    Returns:\n      A tensor.\n    """"""\n    # Note: nn.sigmoid_cross_entropy_with_logits\n    # expects logits, Keras expects probabilities.\n    if not from_logits:\n        # transform back to logits\n        epsilon_ = _to_tensor(epsilon(), output.dtype.base_dtype)\n        output = clip_ops.clip_by_value(output, epsilon_, 1 - epsilon_)\n        output = math_ops.log(output / (1 - output))\n    return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n</code></pre>\n\n<p>Therefore, it uses <code>sigmoid_crossentropy</code> and not <code>softmax_crossentropy</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9263}"
721,68422887,"{'items': [{'owner': {'reputation': 1, 'user_id': 16470540}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1626553585, 'answer_id': 68424035, 'question_id': 68422887, 'body': ""<p>Per NONONONONO's comment, my solution was</p>\n<pre><code># 'model' is a tensorflow.keras.models.Sequential\n\nn_scores = 10000\n\ninputs = np.zeros((n_scores, 8, 10), dtype=np.bool)\noutputs = np.zeros((n_scores, 10), dtype=np.bool)\n\n# [populate inputs and outputs]\n\npredictions = model.predict(inputs)\n\nfrom tensorflow.keras.losses import CategoricalCrossentropy\ncce = CategoricalCrossentropy()\n\nscores = []\nfor i in range(n_scores):\n    score = cce(predictions[i], outputs[i])\n    scores.append(score)\n\nreturn scores\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9263}"
722,38114534,"{'items': [{'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1495320995, 'answer_id': 44091550, 'question_id': 38114534, 'body': '<p>In the new versions of TF (starting from 0.11) you have <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv1d"" rel=""nofollow noreferrer"">conv1d</a>, so there is no need to use 2d convolution to do 1d convolution. Here is a simple example of how to use conv1d:</p>\n\n<pre><code>import tensorflow as tf\ni = tf.constant([1, 0, 2, 3, 0, 1, 1], dtype=tf.float32, name=\'i\')\nk = tf.constant([2, 1, 3], dtype=tf.float32, name=\'k\')\n\ndata   = tf.reshape(i, [1, int(i.shape[0]), 1], name=\'data\')\nkernel = tf.reshape(k, [int(k.shape[0]), 1, 1], name=\'kernel\')\n\nres = tf.squeeze(tf.nn.conv1d(data, kernel, stride=1, padding=\'VALID\'))\nwith tf.Session() as sess:\n    print sess.run(res)\n</code></pre>\n\n<p>To understand how conv1d is calculates, take a look at <a href=""http://www.riptutorial.com/tensorflow/example/30750/math-behind-1d-convolution-with-advanced-examples-in-tf"" rel=""nofollow noreferrer"">various examples</a></p>\n'}, {'owner': {'reputation': 28028, 'user_id': 5098368}, 'down_vote_count': 0, 'up_vote_count': 36, 'is_accepted': True, 'score': 36, 'creation_date': 1467273751, 'answer_id': 38117279, 'question_id': 38114534, 'body': '<p>I am sorry to say that, but your first code was almost right. You just inverted <code>x</code> and <code>phi</code> in <code>tf.nn.conv2d</code>:</p>\n\n<pre class=""lang-py prettyprint-override""><code>g = tf.Graph()\nwith g.as_default():\n    # data shape is ""[batch, in_height, in_width, in_channels]"",\n    x = tf.Variable(np.array([0.0, 0.0, 0.0, 0.0, 1.0]).reshape(1, 1, 5, 1), name=""x"")\n    # filter shape is ""[filter_height, filter_width, in_channels, out_channels]""\n    phi = tf.Variable(np.array([0.0, 0.5, 1.0]).reshape(1, 3, 1, 1), name=""phi"")\n    conv = tf.nn.conv2d(\n        x,\n        phi,\n        strides=[1, 1, 1, 1],\n        padding=""SAME"",\n        name=""conv"")\n</code></pre>\n\n<hr>\n\n<p><strong>Update:</strong> TensorFlow now supports 1D convolution since version r0.11, using <a href=""https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv1d"" rel=""noreferrer""><code>tf.nn.conv1d</code></a>. I previously made a guide to use them in the stackoverflow documentation (now extinct) that I\'m pasting here:</p>\n\n<hr>\n\n<h2>Guide to 1D convolution</h2>\n\n<p>Consider a basic example with an input of length <code>10</code>, and dimension <code>16</code>. The batch size is <code>32</code>. We therefore have a placeholder with input shape <code>[batch_size, 10, 16]</code>.</p>\n\n<pre class=""lang-py prettyprint-override""><code>batch_size = 32\nx = tf.placeholder(tf.float32, [batch_size, 10, 16])\n</code></pre>\n\n<p>We then create a filter with width 3, and we take <code>16</code> channels as input, and output also <code>16</code> channels.</p>\n\n<pre class=""lang-py prettyprint-override""><code>filter = tf.zeros([3, 16, 16])  # these should be real values, not 0\n</code></pre>\n\n<hr>\n\n<p>Finally we apply <code>tf.nn.conv1d</code> with a stride and a padding:\n- <strong>stride</strong>: integer <code>s</code>\n- <strong>padding</strong>: this works like in 2D, you can choose between <code>SAME</code> and <code>VALID</code>. <code>SAME</code> will output the same input length, while <code>VALID</code> will not add zero padding.</p>\n\n<p>For our example we take a stride of 2, and a valid padding.\n</p>\n\n<pre><code>output = tf.nn.conv1d(x, filter, stride=2, padding=""VALID"")\n</code></pre>\n\n<p>The output shape should be <code>[batch_size, 4, 16]</code>.<br>\nWith <code>padding=""SAME""</code>, we would have had an output shape of <code>[batch_size, 5, 16]</code>.</p>\n'}, {'owner': {'reputation': 5279, 'user_id': 1601580}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1470766517, 'answer_id': 38857776, 'question_id': 38114534, 'body': '<p>I think I got it to work with the requirements that I needed. The comments/details of how it works are on the code:</p>\n\n<pre><code>import numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\ntask_name = \'task_MNIST_flat_auto_encoder\'\nmnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)\nX_train, Y_train = mnist.train.images, mnist.train.labels # N x D\nX_cv, Y_cv = mnist.validation.images, mnist.validation.labels\nX_test, Y_test = mnist.test.images, mnist.test.labels\n\n# data shape is ""[batch, in_height, in_width, in_channels]"",\n# X_train = N x D\nN, D = X_train.shape\n# think of it as N images with height 1 and width D.\nX_train = X_train.reshape(N,1,D,1)\nx = tf.placeholder(tf.float32, shape=[None,1,D,1], name=\'x-input\')\n#x = tf.Variable( X_train , name=\'x-input\')\n# filter shape is ""[filter_height, filter_width, in_channels, out_channels]""\nfilter_size, nb_filters = 10, 12 # filter_size , number of hidden units/units\n# think of it as having nb_filters number of filters, each of size filter_size\nW = tf.Variable( tf.truncated_normal(shape=[1, filter_size, 1,nb_filters], stddev=0.1) )\nstride_convd1 = 2 # controls the stride for 1D convolution\nconv = tf.nn.conv2d(input=x, filter=W, strides=[1, 1, stride_convd1, 1], padding=""SAME"", name=""conv"")\n\nwith tf.Session() as sess:\n    sess.run( tf.initialize_all_variables() )\n    sess.run(fetches=conv, feed_dict={x:X_train})\n</code></pre>\n\n<p>thanks to Olivier for the help (see the discussion in his comments for further clarification). </p>\n\n<hr>\n\n<p>Manually check it:</p>\n\n<pre><code>X_train_org = np.array([[0,1,2,3]])\nN, D = X_train_org.shape\nX_train_1d = X_train_org.reshape(N,1,D,1)\n#X_train = tf.constant( X_train_org )\n# think of it as N images with height 1 and width D.\nxx = tf.placeholder(tf.float32, shape=[None,1,D,1], name=\'xx-input\')\n#x = tf.Variable( X_train , name=\'x-input\')\n# filter shape is ""[filter_height, filter_width, in_channels, out_channels]""\nfilter_size, nb_filters = 2, 2 # filter_size , number of hidden units/units\n# think of it as having nb_filters number of filters, each of size filter_size\nfilter_w = np.array([[1,3],[2,4]]).reshape(1,filter_size,1,nb_filters)\n#W = tf.Variable( tf.truncated_normal(shape=[1,filter_size,1,nb_filters], stddev=0.1) )\nW = tf.Variable( tf.constant(filter_w, dtype=tf.float32) )\nstride_convd1 = 2 # controls the stride for 1D convolution\nconv = tf.nn.conv2d(input=xx, filter=W, strides=[1, 1, stride_convd1, 1], padding=""SAME"", name=""conv"")\n\n#C = tf.constant( (np.array([[4,3,2,1]]).T).reshape(1,1,1,4) , dtype=tf.float32 ) #\n#tf.reshape( conv , [])\n#y_tf = tf.matmul(conv, C)\n\n\n##\nx = tf.placeholder(tf.float32, shape=[None,D], name=\'x-input\') # N x 4\nW1 = tf.Variable( tf.constant( np.array([[1,2,0,0],[3,4,0,0]]).T, dtype=tf.float32 ) ) # 2 x 4\ny1 = tf.matmul(x,W1) # N x 2 = N x 4 x 4 x 2\nW2 = tf.Variable( tf.constant( np.array([[0,0,1,2],[0,0,3,4]]).T, dtype=tf.float32 ))\ny2 = tf.matmul(x,W2) # N x 2 = N x 4 x 4 x 2\nC1 = tf.constant( np.array([[4,3]]).T, dtype=tf.float32 ) # 1 x 2\nC2 = tf.constant( np.array([[2,1]]).T, dtype=tf.float32 )\n\np1 = tf.matmul(y1,C1)\np2 = tf.matmul(y2,C2)\ny = p1 + p2\nwith tf.Session() as sess:\n    sess.run( tf.initialize_all_variables() )\n    print \'manual conv\'\n    print sess.run(fetches=y1, feed_dict={x:X_train_org})\n    print sess.run(fetches=y2, feed_dict={x:X_train_org})\n    #print sess.run(fetches=y, feed_dict={x:X_train_org})\n    print \'tf conv\'\n    print sess.run(fetches=conv, feed_dict={xx:X_train_1d})\n    #print sess.run(fetches=y_tf, feed_dict={xx:X_train_1d})\n</code></pre>\n\n<p>outputs:</p>\n\n<pre><code>manual conv\n[[ 2.  4.]]\n[[  8.  18.]]\ntf conv\n[[[[  2.   4.]\n   [  8.  18.]]]]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9263}"
723,73213159,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1659506319, 'answer_id': 73216861, 'question_id': 73213159, 'body': ""<p>Try using a ragged structure:</p>\n<pre><code>import tensorflow as tf\nimport pandas as pd\n\ndf = pd.DataFrame(data={'reports': [[2.0, 3.0, 4.0], [2.0, 3.0], [2.0]]})\n\ndataset = tf.data.Dataset.from_tensor_slices(tf.ragged.constant(df['reports']))\n\nfor x in dataset:\n  print(x)\n</code></pre>\n<pre><code>tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\ntf.Tensor([2. 3.], shape=(2,), dtype=float32)\ntf.Tensor([2.], shape=(1,), dtype=float32)\n</code></pre>\n""}, {'owner': {'reputation': 3244, 'user_id': 14774959}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1659471835, 'answer_id': 73213382, 'question_id': 73213159, 'body': ""<p>You can try forcing your <code>df[&quot;reports&quot;]</code> to a specific type. Assuming that you want to convert this column to numbers you can easily do it like this:</p>\n<pre><code>df['reports'] = pd.to_numeric(df['reports'])\n</code></pre>\n<p>Anyway, I suggest you to investigate the cause of your non-uniform <code>dtype('O')</code>. You could have some mistake in your data.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9263}"
724,41467115,"{'items': [{'owner': {'reputation': 63, 'user_id': 3009947}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1483549129, 'answer_id': 41469347, 'question_id': 41467115, 'body': '<p>I was looking for a code something like this. I wasn\'t aware of the class attributes of <code>w</code> - couldn\'t find them in the gensim website.</p>\n\n<pre><code>s = ""hello, how are you?""\ntokens = tokenize(s)//function that returns a list of the tokens in a sentence\n\nids = []\nfor key in tokens:\n  try:\n    ids.append(w.vocab[key].index)\n  except:\n    ids.append(w.vocab[\'UNK\'].index)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9259}"
725,63558891,"{'items': [{'owner': {'reputation': 1446, 'user_id': 13720565}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1598277416, 'answer_id': 63562528, 'question_id': 63558891, 'body': '<p>You could use <code>numpy.convolve()</code> for this.</p>\n<pre><code>import numpy as np\n\nkernel = [1.0,2.0,1.0]  # weighted moving average\nx = [   # history_size=5, num_features=10\n  [1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\n  [2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0],\n  [3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0],\n  [4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0],\n  [5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0],\n]\n\noutput = []\nfor i in range(len(x)):\n    output.append(list(np.convolve(x[i], kernel, mode = \'same\')))\noutput\n\n\'\'\'\n[[3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0],\n [6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0],\n [9.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 9.0],\n [12.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 12.0],\n [15.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.0]]\n\'\'\'\n</code></pre>\n<p>You could try changing the <code>mode</code> whichever fits best to you according to the <a href=""https://numpy.org/doc/stable/reference/generated/numpy.convolve.html"" rel=""nofollow noreferrer"">documentation</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9259}"
726,64017646,"{'items': [{'owner': {'reputation': 861, 'user_id': 5546244}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1600846897, 'answer_id': 64023226, 'question_id': 64017646, 'body': '<pre><code>self.total = tf.Variable((np.empty((0, 3), dtype=np.float64)), shape=[None, 3])\n</code></pre>\n'}, {'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1600817076, 'answer_id': 64018952, 'question_id': 64017646, 'body': '<p>You can do the following (only tested in TF 2.x),</p>\n<pre><code>import tensorflow as tf\n\nv = tf.Variable([[0,0,0],[0,0,0]], shape=[None, 3])\n</code></pre>\n<p>As you can see, you <strong>must</strong> provide an initial value to a <code>tf.Variable</code>. But you can have <code>None</code> dimensions as shown. If you need to change the size of the first dimension (which we defined as <code>None</code>), you can do the following.</p>\n<pre><code>v = v.assign([[0,0,0],[0,0,0],[0,0,0]])\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9259}"
727,57914611,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9259}"
728,59299060,"{'items': [{'owner': {'reputation': 2532, 'user_id': 9579075}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1576245067, 'answer_id': 59323903, 'question_id': 59299060, 'body': '<p><code>parallel_iterations</code> doesn\'t mean anything when running in eager mode, but you can always use <code>tf.function</code> decorator and gain significant speedups. This can be seen in this picture: <a href=""https://i.stack.imgur.com/nz3GL.png"" rel=""nofollow noreferrer"">running times</a></p>\n\n<p>You can wrap your <code>tf.while_loop</code> with <code>tf.function</code> like this </p>\n\n<pre><code>@tf.function\ndef run_graph():\n    iteration = tf.constant(0)\n    r = tf.while_loop(c, print_fun, [iteration], parallel_iterations=4)\n</code></pre>\n\n<p>and then call <code>run_graph</code> when required.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9259}"
729,47119604,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9254}"
730,68439286,"{'items': [{'owner': {'reputation': 72, 'user_id': 16423798}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1643090947, 'answer_id': 70844112, 'question_id': 68439286, 'body': '<p>Change it to tf.io.gfile.GFile.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9254}"
731,62264567,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1591700237, 'answer_id': 62280983, 'question_id': 62264567, 'body': '<p>Yes it saves GPU Memory. From the documentation of <code>tf.stop_gradient</code>, it states <strong><em>When building ops to compute gradients, this op prevents the contribution of its inputs to be taken into account.</em></strong></p>\n\n<p>One more explanation about <code>tf.stop_gradient()</code>: It is an operation that acts as the <code>identity function</code> in the <code>forward direction</code>, but stops the accumulated <code>gradient</code> from flowing through that operator in the <code>backward direction</code>. It does not prevent <code>backpropagation</code> altogether, but instead prevents an individual tensor from contributing to the <code>gradients</code> that are computed for an expression.</p>\n\n<p>It means that the Weights included in the Operation which is passed to <code>tf.stop_gradient</code> are not updated during Back Propagation. </p>\n\n<p>Normally, during Back Propagation, Weights are updated using the Formula,</p>\n\n<pre><code>W(i+1) = W(i) - Learning Rate * Gradient\n</code></pre>\n\n<p>When we use <code>tf.stop_gradient</code>, the Weights which are passed as Inputs to this Op are maintained as Constants. Since the Computations during <code>Back Propagation</code> are reduced, <strong>Memory Consumption also decreases</strong>.</p>\n\n<p>For more information regarding <code>tf.stop_gradient</code>, please refer <a href=""https://www.tensorflow.org/api_docs/python/tf/stop_gradient"" rel=""nofollow noreferrer"">Tensorflow documentation</a>, <a href=""https://stackoverflow.com/a/39356229/13465258"">Abhishek\'s Stack Overflow Answer</a>, <a href=""https://stackoverflow.com/a/33729320/13465258"">mrry\'s Stack Overflow Answer</a> and <a href=""https://scelesticsiva.github.io/2018/01/22/stop-gradients/"" rel=""nofollow noreferrer"">this article</a>.</p>\n\n<p>Hope this helps. Happy Learning!</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9254}"
732,52720886,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9254}"
733,66997498,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9250}"
734,59723003,"{'items': [{'owner': {'reputation': 506, 'user_id': 3397173}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1579358863, 'answer_id': 59801677, 'question_id': 59723003, 'body': ""<p>Unfortunately I was only able to find a workaround instead of an outright solution.  Because <code>tf.stack</code> will only work on items of the same data type, I need to transform all data into floats during processing of the Examples (including one-hot encoding for all strings), and then use <code>tf.stack</code> on the resulting tensor:</p>\n\n<pre><code>def proces_example(serialized_example):\n    feature_description = get_feature_desc()  # dictionary describing features and dtypes\n    target_name = get_target_name()  # so we don't include the target in our feature vector\n    parsed_example = tf.io.parse_single_example(serialized_example, feature_description)\n    tensor_list = []\n    for tensor in parsed_example:\n        if tensor != target_name:\n            parsed_example[tensor] = tf.dtypes.cast(parsed_example[tensor], tf.float32)\n            tensor_list.append(parsed_example[tensor])\n    X = tf.stack(tensor_list)\n    y = parsed_example[target_name]\n    return X, y\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9250}"
735,54211834,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1547635294, 'answer_id': 54215289, 'question_id': 54211834, 'body': ""<p>In order to use <code>tf.print</code> in graph mode, that's how <code>tf.estimator</code> works, you can just use <code>tf.print</code> as a drop-in replacement for <code>tf.Print</code>, you just have to force the execution of the <code>tf.print</code> operation before the execution of a tensor in your model_fn, hence, given the input tensor, <code>input_</code> of your model_fn, you can just:</p>\n\n<pre><code>    print_op = tf.print(tensor_to_log)\n    with tf.control_dependencies([print_op]):\n        first_layer_output = first_inpyt_layer(input_)\n</code></pre>\n\n<p>or even</p>\n\n<pre><code>    print_op = tf.print(tensor_to_log)\n    with tf.control_dependencies([print_op]):\n        input_ = tf.identity(input_)\n    # define your model using input_ as usual\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9250}"
736,57171197,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9250}"
737,72041726,"{'items': [{'owner': {'reputation': 128, 'user_id': 13049396}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1682408059, 'answer_id': 76098659, 'question_id': 72041726, 'body': '<p>Yes, there is a difference between creating a tf.Variable and using keras.layers.Layer.add_weights().</p>\n<p>A <code>tf.Variable</code> is a general-purpose variable that can be used to store any data type.</p>\n<p>While a <code>keras.layers.Layer.add_weights()</code> method is used to add weights to a layer. The weights are stored in a dictionary, where the keys are the names of the weights and the values are the tensors that represent the weights.</p>\n<p>For example, you could create a <code>tf.Variable</code> and use it to store the number of times a user has visited a website. You could then use that variable to calculate the probability that the user will visit the website again.</p>\n<p>However, you could not use <code>keras.layers.Layer.add_weight()</code> to store the number of times a user has visited a website. This is because <code>keras.layers.Layer.add_weight()</code> can only be used to create weights for layers.</p>\n<p>In general, you should use <code>tf.Variable</code> if you need to create a variable that can be used in any context. You should use <code>keras.layers.Layer.add_weight()</code> if you need to create a weight for a layer.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9246}"
738,74622205,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9246}"
739,52473088,"{'items': [{'owner': {'reputation': 1146, 'user_id': 9865225}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1537772213, 'answer_id': 52474060, 'question_id': 52473088, 'body': ""<p>In <code>tensorflow</code>, anything that is created using <code>tf.Variable()</code>, will get updated during training in back-propagation, for example, a weight matrix.</p>\n\n<p>Ideally, by default, every <code>tf.Variable()</code> becomes trainable unless you specify it <code>non-trainable</code> explicitly.</p>\n\n<p>If you do this <code>initial = tf.truncated_normal([5,10], mean=0, stddev=0.1)</code>, then tensorflow will not know that it's a trainable variable and hence it will not be trained. It will stay constant throughout the training.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9246}"
740,63186177,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1601140132, 'answer_id': 64080452, 'question_id': 63186177, 'body': '<p>There is not much difference in both cases.</p>\n<p>In <code>tf.data.experimental.parse_example_dataset</code> the below apply function is retuned.</p>\n<pre><code>def _apply_fn(dataset):\n    &quot;&quot;&quot;Function from Dataset to Dataset that applies the transformation.&quot;&quot;&quot;\n    out_dataset = _ParseExampleDataset(dataset, features, num_parallel_calls,\n                                       deterministic)\n    if any(\n        isinstance(feature, parsing_ops.SparseFeature) or\n        (isinstance(feature, parsing_ops.RaggedFeature) and feature.partitions)\n        for feature in features.values()):\n      # pylint: disable=protected-access\n      # pylint: disable=g-long-lambda\n      out_dataset = out_dataset.map(\n          lambda x: parsing_ops._construct_tensors_for_composite_features(\n              features, x),\n          num_parallel_calls=num_parallel_calls)\n    return out_dataset\n\n  return _apply_fn  \n</code></pre>\n<p>Where in <code>tf.io.parse_single_example</code>   Parses a serialized Example protos given in serialized which is similar to <code>tf.io.parse_example</code>, except <code>tf.io.parse_example</code> is serialized in batches.</p>\n<p>You can use <code>tf.io.parse_example</code> for performance advantage over batching samples.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9243}"
741,58680578,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9243}"
742,42818819,"{'items': [{'owner': {'reputation': 1248, 'user_id': 1255535}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': False, 'score': 0, 'creation_date': 1496551465, 'answer_id': 44350837, 'question_id': 42818819, 'body': '<p>Plese see this <a href=""https://stackoverflow.com/a/44350789/1255535"">answer</a> for a detailed example of how <code>tf.nn.conv2d_backprop_input</code> and <code>tf.nn.conv2d_backprop_filter</code> in an example.</p>\n\n<p>A short answer to your question:</p>\n\n<p>In <code>tf.nn</code>, there are 4 closely related 2d conv functions:</p>\n\n<ul>\n<li><code>tf.nn.conv2d</code></li>\n<li><code>tf.nn.conv2d_backprop_filter</code></li>\n<li><code>tf.nn.conv2d_backprop_input</code></li>\n<li><code>tf.nn.conv2d_transpose</code></li>\n</ul>\n\n<p>Given <code>out = conv2d(x, w)</code> and the output gradient <code>d_out</code>:</p>\n\n<ul>\n<li>Use <code>tf.nn.conv2d_backprop_filter</code> to compute the filter gradient <code>d_w</code></li>\n<li>Use <code>tf.nn.conv2d_backprop_input</code> to compute the filter gradient <code>d_x</code></li>\n<li><code>tf.nn.conv2d_backprop_input</code> can be implemented by <code>tf.nn.conv2d_transpose</code></li>\n<li>All 4 functions above can be implemented by <code>tf.nn.conv2d</code></li>\n<li>Actually, use TF\'s autodiff is the fastest way to compute gradients</li>\n</ul>\n'}, {'owner': {'reputation': 5134, 'user_id': 6416660}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1489606068, 'answer_id': 42818980, 'question_id': 42818819, 'body': '<p>For an explanation of conv2d_transpose I would look at other stack overflow questions such as this one: <a href=""https://stackoverflow.com/questions/39373230/what-does-tensorflows-conv2d-transpose-operation-do"">conv2d_transpose</a></p>\n\n<p>As for conv2d_backprop_filter:\nthis is what is computed during backpropagation to be passed to the previous layer.  It has been used for things such as Deep Dream and creation of adversarial examples.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9243}"
743,57453826,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': False, 'score': 7, 'creation_date': 1565596305, 'answer_id': 57457401, 'question_id': 57453826, 'body': '<p>You could use <a href=""https://www.tensorflow.org/datasets"" rel=""noreferrer"">TensorFlow Datasets (tfds)</a>: this library is not only a collection of ready to use <code>tf.data.Dataset</code> objects, but it is also a toolchain for the transformation of raw data to TFRecords.</p>\n\n<p>Following the <a href=""https://github.com/tensorflow/datasets/blob/master/docs/add_dataset.md"" rel=""noreferrer"">official guide</a> is straightforward adding a new dataset. In short, you only have to implement the methods <code>_info</code> and <code>_generate_examples</code>.</p>\n\n<p>In particular, the <code>_generate_examples</code> is the method that is used by tfds to create rows inside the TFRecords.\nEvery element that <code>_generate_examples</code> yields is a dictionary; every dictionary is a row in a TFRecord file.</p>\n\n<p>For example (kept from the official documentation) the <code>generate_examples</code> below is used by tfds to save TFRecords, each one with the records ""image_description"", ""image"", ""label"".</p>\n\n<pre class=""lang-py prettyprint-override""><code>def _generate_examples(self, images_dir_path, labels):\n  # Read the input data out of the source files\n  for image_file in tf.io.gfile.listdir(images_dir_path):\n    ...\n  with tf.io.gfile.GFile(labels) as f:\n    ...\n\n  # And yield examples as feature dictionaries\n  for image_id, description, label in data:\n    yield image_id, {\n        ""image_description"": description,\n        ""image"": ""%s/%s.jpeg"" % (images_dir_path, image_id),\n        ""label"": label,\n    }\n</code></pre>\n\n<p>In your case, you can just use the <code>tf.data.Dataset</code> object you already have, and loop through it (in the generate_examples method), and yielding the rows of the TFRecord.</p>\n\n<p>In this way, tfds will take care for you of the serialization and you\'ll find in the <code>~/tensorflow_datasets</code> folder the TFRecord created for your dataset.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9240}"
744,58225926,"{'items': [{'owner': {'reputation': 4277, 'user_id': 7212365}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': True, 'score': 0, 'creation_date': 1570138969, 'answer_id': 58227265, 'question_id': 58225926, 'body': '<p>You need to watch x. For the operations inside this context manager, it\'s required at least one of their inputs is being watched. </p>\n\n<pre class=""lang-py prettyprint-override""><code>with tf.GradientTape() as g:\n    g.watch(x)\n    value = tf.reduce_sum(scales * (x - minimum) ** 2)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9240}"
745,49497353,"{'items': [{'owner': {'reputation': 30867, 'user_id': 4790871}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1522087523, 'answer_id': 49497857, 'question_id': 49497353, 'body': ""<p>It's always annoying when these kinds of functions don't support batches. Use <code>tf.map_fn</code> to map the batch onto the function. Though note that this breaks your problem into many small operations which aren't as efficient on the GPU as they could be if <code>random_flip_left_right</code> supported batch operations.</p>\n\n<pre><code>imgs = tf.map_fn(tf.image.random_flip_left_right, imgs_4d_tensor)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9240}"
746,76012810,"{'items': [{'owner': {'reputation': 555, 'user_id': 4463330}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1681778436, 'answer_id': 76040265, 'question_id': 76012810, 'body': '<p>Finally got it working. Casting <code>output</code> to <code>tf.Tensor</code> and then using <code>dataSync()</code> on it did the trick.</p>\n<pre><code>const input = tf.tensor2d([\n    [financialInfo.age, financialInfo.riskTolerance, financialInfo.currentNetWorth, financialInfo.annualIncome, financialInfo.debt],\n  ]) as tf.Tensor;\n  \n  const output = net.predict(input) as tf.Tensor;\n  const probabilities = Array.from(output.dataSync());\n  const maxProbIndex = probabilities.indexOf(Math.max(...probabilities));\n  const suggestedPortfolio = Object.keys(portfolios)[maxProbIndex];\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9240}"
747,56204555,"{'items': [{'owner': {'reputation': 13, 'user_id': 8289138}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1559011116, 'answer_id': 56334340, 'question_id': 56204555, 'body': '<h1>Another method use <code>tf.gather_nd</code>:</h1>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\n\na = tf.cast(tf.constant(np.reshape(np.arange(60), (3,2,2,5))), tf.int32)\nidx = tf.range(tf.shape(a)[0])\nidx2 = tf.constant([0,1,0])\nindices = tf.stack([idx, idx2], axis=1)\na = tf.transpose(a, [0,3,1,2])\nmasks = tf.gather_nd(a, indices)\n\nwith tf.Session() as sess:\n    print(sess.run(a))\n    print(sess.run(tf.shape(masks)))\n    print(sess.run(masks))\n</code></pre>\n'}, {'owner': {'reputation': 6098, 'user_id': 7389608}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1558245718, 'answer_id': 56205181, 'question_id': 56204555, 'body': ""<p><strong>1.Another method</strong></p>\n\n<p>I'm not sure if it's the best way, but it's faster. You can use <code>tf.boolean_mask</code> instead of <code>tf.map_fn</code>. </p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\na = tf.cast(tf.constant(np.reshape(np.arange(60), (3,2,2,5))), tf.int32)\nidx2 = tf.constant([0, 1, 0])\n\nfn = lambda i: a[i,:,:][:,:,idx2[i]]\nidx = tf.range(tf.shape(a)[0])\nmasks = tf.map_fn(fn, idx)\n\n# new method\nidx = tf.one_hot(idx2,depth=a.shape[-1])\nmasks2 = tf.boolean_mask(tf.transpose(a,[0,3,1,2]), idx)\n\nwith tf.Session() as sess:\n    print('tf.map_fn version:\\n',sess.run(masks))\n    print('tf.boolean_mask version:\\n',sess.run(masks2))\n\n# print\ntf.map_fn version:\n [[[ 0  5]\n  [10 15]]\n\n [[21 26]\n  [31 36]]\n\n [[40 45]\n  [50 55]]]\ntf.boolean_mask version:\n [[[ 0  5]\n  [10 15]]\n\n [[21 26]\n  [31 36]]\n\n [[40 45]\n  [50 55]]]\n</code></pre>\n\n<p><strong>2.Performance comparison</strong></p>\n\n<p>The vectorization method 1000 iterations takes <code>0.07s</code> and the <code>tf.map_fn</code>method 1000 iterations takes <code>0.85s</code> on my 8GB GPU memory. The vectorization method will be significantly faster than the <code>tf.map_fn()</code>.</p>\n\n<pre><code>import datetime\n...\nwith tf.Session() as sess:\n    start = datetime.datetime.now()\n    for _ in range(1000):\n        sess.run(masks)\n    end = datetime.datetime.now()\n    print('tf.map_fn version cost time(seconds) : %.2f' % ((end - start).total_seconds()))\n\n    start = datetime.datetime.now()\n    for _ in range(1000):\n        sess.run(masks2)\n    end = datetime.datetime.now()\n    print('tf.boolean_mask version cost time(seconds) : %.2f' % ((end - start).total_seconds()))\n\n# print\ntf.map_fn version cost time(seconds) : 0.85\ntf.boolean_mask version cost time(seconds) : 0.07\n</code></pre>\n\n<p>I believe that the performance difference will become more obvious as the shape of <code>a</code> increases.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9240}"
748,57279754,"{'items': [{'owner': {}, 'down_vote_count': 1, 'up_vote_count': 7, 'is_accepted': True, 'score': 6, 'creation_date': 1565270571, 'answer_id': 57413676, 'question_id': 57279754, 'body': '<p>These are the data types of the <code>output Tensor</code> of the function, <code>tf.quantization.quantize()</code>. This corresponds to the Argument, <code>T</code> of the function.</p>\n\n<p>Mentioned below is the underlying code, which converts/quantizes a Tensor from one Data Type (e.g. <code>float32</code>) to another (<code>tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16</code>).</p>\n\n<pre><code>out[i] = (in[i] - min_range) * range(T) / (max_range - min_range)\nif T == qint8: out[i] -= (range(T) + 1) / 2.0\n</code></pre>\n\n<p>Then, they can be passed to functions like <code>tf.nn.quantized_conv2d</code>, etc.., whose input is a Quantized Tensor, explained above. </p>\n\n<p><strong>TLDR</strong>, to answer your question in short, they are actually stored 8 bits (for <code>qint8</code>) in memory. </p>\n\n<p>You can find more information about this topic in the below links:</p>\n\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/quantization/quantize"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/quantization/quantize</a></p>\n\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/nn/quantized_conv2d"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/quantized_conv2d</a></p>\n\n<p><a href=""https://www.tensorflow.org/lite/performance/post_training_quantization"" rel=""noreferrer"">https://www.tensorflow.org/lite/performance/post_training_quantization</a></p>\n\n<p>If you feel this answer is useful, kindly accept this answer and/or up vote it. Thanks.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9235}"
749,55868686,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9235}"
750,64687375,"{'items': [{'owner': {'reputation': 401, 'user_id': 4183916}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1627539569, 'answer_id': 68571006, 'question_id': 64687375, 'body': '<p>the short solution for reading labels from <code>image_dataset_from_directory</code> function:</p>\n<pre><code>train_label = np.concatenate([y for x, y in train_data], axis=0)\n\ntest_label = np.concatenate([y for x, y in test_data], axis=0) \n</code></pre>\n'}, {'owner': {'reputation': 11, 'user_id': 15083817}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1646819154, 'answer_id': 71407288, 'question_id': 64687375, 'body': '<p>The tf.data.Dataset object is batch-like object so you need to take a single and loop through it.\nFor the first batch, you do:</p>\n<pre><code>for image, label in test_ds.take(1):\n    print (label)\n</code></pre>\n<p>I used <code>test_ds</code> from your code above because it has the data and labels all in one object.\nSo the take away is that tf.data.Dataset object is a batch-like object.</p>\n'}, {'owner': {'reputation': 9, 'user_id': 6600615}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1626403045, 'answer_id': 68402769, 'question_id': 64687375, 'body': ""<pre><code># Neah it does not, some debugging revealed:\n# Credit: (with corrections and debugging)\n# https://stackoverflow.com/questions/64687375/get-labels-from-dataset-when-using-tensorflow-image-dataset-from-directory\n# predictions = np.array([])\n\ntest_labels =  np.array([])\n# counter = 0\nfor x, y in test_unshuffled:\n#   predictions = np.argmax(model.predict(x), axis = -1)  #np.concatenate([predictions, np.argmax(model.predict(x), axis = -1)])\n#   print(f'prediction: {predictions}, size of {len(predictions)}')\n#   print(f'y label:    {y.numpy()}, size of {len(y.numpy())}') #labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n  test_labels = np.concatenate([test_labels, y.numpy()])\n#   counter += 1\n#   if counter &gt; 1:\n#     break\n\n# with the final code:\ntest_predicted_labels = np.argmax(classes_predicted_unshuffled, axis=1)\ntest_predicted_labels.shape # sanity check\n\ntest_labels =  np.array([])\nfor x, y in test_unshuffled:\n  test_labels = np.concatenate([test_labels, y.numpy()])\ntest_labels.shape # sanity check better match test_predicted_labels\n</code></pre>\n""}, {'owner': {'reputation': 81, 'user_id': 6233183}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': False, 'score': 8, 'creation_date': 1610834003, 'answer_id': 65755128, 'question_id': 64687375, 'body': ""<p>Modified from Alexandre Catalano's post:</p>\n<pre><code>predictions = np.array([])\nlabels =  np.array([])\nfor x, y in test_ds:\n  predictions = np.concatenate([predictions, **np.argmax**(model.predict(x), axis = -1)])\n  labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n</code></pre>\n<p>You need to take the <code>np.argmax</code> for both sets</p>\n<p>This works in 2021 now.</p>\n""}, {'owner': {'reputation': 764, 'user_id': 4994352}, 'down_vote_count': 0, 'up_vote_count': 15, 'is_accepted': True, 'score': 15, 'creation_date': 1604531531, 'answer_id': 64689000, 'question_id': 64687375, 'body': ""<p>If I were you, I'll iterate over the entire testData, I'll save the predictions and labels along the way and I'll build the confusion matrix at the end.</p>\n<pre><code>testData = tf.keras.preprocessing.image_dataset_from_directory(\n    dataDirectory,\n    labels='inferred',\n    label_mode='categorical',\n    seed=324893,\n    image_size=(height,width),\n    batch_size=32)\n\n\npredictions = np.array([])\nlabels =  np.array([])\nfor x, y in testData:\n  predictions = np.concatenate([predictions, model.predict_classes(x)])\n  labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n\ntf.math.confusion_matrix(labels=labels, predictions=predictions).numpy()\n</code></pre>\n<p>and the result is</p>\n<pre><code>Found 4 files belonging to 2 classes.\narray([[2, 0],\n       [2, 0]], dtype=int32)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9235}"
751,64734480,"{'items': [{'owner': {'reputation': 20575, 'user_id': 2790047}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1604809671, 'answer_id': 64734827, 'question_id': 64734480, 'body': '<p>AFAIK there is no equivalent <code>in_top_k</code> function built into pytorch. It\'s relatively straightforward to write one. For example</p>\n<pre class=""lang-py prettyprint-override""><code>def in_top_k(targets, preds, k):\n    topk = preds.topk(k)[1]\n    return (targets.unsqueeze(1) == topk).any(dim=1)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9235}"
752,63376657,"{'items': [{'owner': {'reputation': 17612, 'user_id': 5666087}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1597239948, 'answer_id': 63377877, 'question_id': 63376657, 'body': '<p>An <a href=""https://datascience.stackexchange.com/a/60408"">answer on the Datascience Stack Exchange site</a> seems to answer this question.</p>\n<p>Franois Chollet, the creator of Keras, recommends that users switch to <code>tf.keras</code> (<a href=""https://twitter.com/fchollet/status/1174018651449544704?s=19"" rel=""nofollow noreferrer"">source</a>)</p>\n<blockquote>\n<p>New release of multi-backend Keras: 2.3.0</p>\n<p>https://github.com/keras-team/keras/releases/tag/2.3.0</p>\n<ul>\n<li>First release of multi-backend Keras with full TF 2 support</li>\n<li>Continued support for Theano/CNTK</li>\n<li>Will be the last major release of multi-backend Keras</li>\n</ul>\n<p>We recommend you switch your Keras code to tf.keras.</p>\n</blockquote>\n<p>And in two replies:</p>\n<blockquote>\n<p>Both Theano and CNTK are out of development. Meanwhile, as Keras backends they represent less than 4% of Keras usage. The other 96% of users (of which more than half are already on tf.keras) are better served with tf.keras.</p>\n<p>Keras development will focus on tf.keras going forward.</p>\n</blockquote>\n<blockquote>\n<p>Importantly, we will seek to start developing tf.keras in its own standalone GitHub repository at keras-team/keras in order to make it much easier for 3rd party folks to contribute.</p>\n<p>Keras has never been moving faster than now :)</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9235}"
753,43367697,"{'items': [{'owner': {'reputation': 8853, 'user_id': 262271}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1499621696, 'answer_id': 44999183, 'question_id': 43367697, 'body': '<p>If you were dealing with <code>Example</code>s rather than <code>SequenceExample</code>s, it would be as easy as adding a call to <a href=""https://www.tensorflow.org/api_docs/python/tf/train/shuffle_batch"" rel=""nofollow noreferrer""><code>tf.train.shuffle_batch</code></a> on your decoded tensors.</p>\n\n<pre><code>_, value = reader.read(queue)\ninput_, output = decode(value)\nbatch_input, batch_output = tf.train.shuffle_batch([input_, output],\n    batch_size=BATCH_SIZE, capacity=CAPACITY,\n    min_after_sequeue=MIN_AFTER_DEQUEUE)\n</code></pre>\n\n<p>However, shuffle-batch requires that the tensors you pass in have a static shape, which is not true here. For variable shape tensors, you can instead use <a href=""https://www.tensorflow.org/api_docs/python/tf/train/batch"" rel=""nofollow noreferrer""><code>tf.train.batch</code></a> with <code>dynamic_pad=True</code>. This will take care of the batching (and padding) for you, but will not shuffle your examples. Unfortunately, <code>shuffle_batch</code> does not take a <code>dynamic_pad</code> argument. </p>\n\n<p>There\'s a workaround <a href=""https://github.com/tensorflow/tensorflow/issues/5147#issuecomment-271086206"" rel=""nofollow noreferrer"">described here</a> where you can add a <code>RandomShuffleQueue</code> before the call to <code>tf.train.batch</code>:</p>\n\n<pre><code>inputs = decode(value)\ndtypes = list(map(lambda x: x.dtype, inputs))\nshapes = list(map(lambda x: x.get_shape(), inputs))\nqueue = tf.RandomShuffleQueue(CAPACITY, MIN_AFTER_DEQUEUE, dtypes)\nenqueue_op = queue.enqueue(inputs)\nqr = tf.train.QueueRunner(queue, [enqueue_op] * NUM_THREADS)\ntf.add_to_collection(tf.GraphKeys.QUEUE_RUNNERS, qr)\ninputs = queue.dequeue()\nfor tensor, shape in zip(inputs, shapes):\n    tensor.set_shape(shape)\n\n# Now you can use tf.train.batch with dynamic_pad=True, and the order in which\n# it enqueues elements will be permuted because of RandomShuffleQueue.\nbatch_input, batch_output = tf.train.batch(inputs, batch_size, capacity=capacity,\n                              dynamic_pad=True, name=name)\n</code></pre>\n\n<p>There\'s an example of this pattern implemented <a href=""https://github.com/tensorflow/magenta/blob/master/magenta/common/sequence_example_lib.py#L47"" rel=""nofollow noreferrer"">here</a> (in Google\'s Magenta project). </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9230}"
754,53523729,"{'items': [{'owner': {'reputation': 4469, 'user_id': 3009130}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1543422017, 'answer_id': 53523873, 'question_id': 53523729, 'body': '<p>Here <a href=""https://www.tensorflow.org/guide/performance/overview#rnn_performance"" rel=""nofollow noreferrer"">RNN Performance</a> are some recommendations for TensorFlow. A couple of important points from the doc:</p>\n\n<ul>\n<li>use <code>tf.contrib.cudnn_rnn()</code> on NVIDIA GPUs;</li>\n<li>use <code>tf.nn.dynamic_rnn()</code> instead of <code>tf.nn.static_rnn()</code>. Probably they mean, that we need to add <code>sequence_length</code> to avoid extra computations.</li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9230}"
755,52731151,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9230}"
756,60130582,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9230}"
757,45917464,"{'items': [{'owner': {'reputation': 46, 'user_id': 10764959}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1544300790, 'answer_id': 53686652, 'question_id': 45917464, 'body': '<p>I think dropout can only mask one end, like what you did with rnn_inputs.\nDropoutWrapper can mask multi end, like a lstm cell.</p>\n'}, {'owner': {'reputation': 1094, 'user_id': 2179162}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1503924226, 'answer_id': 45919372, 'question_id': 45917464, 'body': '<p>The idea behind both is the same and it is dropout: the network ""drops"" (i.e does not use) some of its nodes in the prediction. This means reducing during training the capacity of the model to prevent overfitting. Thanks to dropout, the network learns not to rely exclusively on particular nodes for its prediction.</p>\n\n<p>The difference between the two methods is that:</p>\n\n<ul>\n<li><p><code>tf.nn.droput</code>is a generic function to perform droput to a given input tensor. Looking at the documentation:</p>\n\n<blockquote>\n  <p>Computes dropout.</p>\n  \n  <p>With probability <code>keep_prob</code>, outputs the input element scaled up by 1 /\n  <code>keep_prob</code>, otherwise outputs 0. The scaling is so that the expected\n  sum is unchanged.</p>\n</blockquote></li>\n<li><p><code>tf.contrib.rnn.DropoutWrapper</code> or <code>tf.nn.rnn_cell.DropoutWrapper</code> is a specific class to define Recurrent Neural Network cells with dropout applied both at the input and the output of the cell. Looking at the documentation: </p>\n\n<blockquote>\n  <p>Operator adding dropout to inputs and outputs of the given cell.</p>\n</blockquote>\n\n<p>In particular, it <a href=""https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/ops/rnn_cell_impl.py#L770"" rel=""nofollow noreferrer"">uses</a> <code>tf.nn.droput</code> to mask the input to the cell, the state and the output.</p></li>\n</ul>\n\n<p>The difference between your two pieces of code is that when you are using <code>tf.nn.dropout</code> you are masking the inputs of the first layer only. In the wrapper case, layer per layer, you are masking the outputs of the cells (since you are providing only the output probabilities )</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9226}"
758,61355289,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1589286144, 'answer_id': 61751625, 'question_id': 61355289, 'body': '<p><code>tf.print</code> works almost in every case.</p>\n\n<p>Mentioned below is the code which demonstrates that <code>tf.print</code> works as expected inside <code>init</code> Method of <code>Custom Layer</code> and inside a <code>Method</code> called from <code>init</code> Method of a <code>Custom Layer</code>.</p>\n\n<pre><code>import tensorflow as tf\n\nclass MyLayer(tf.keras.layers.Layer):\n    def __init__(self, units, **kwargs): \n        self.units = units\n        tf.print(\'units\', tf.convert_to_tensor(units)) # Inside init method\n        self.call(10) # Method called from init Method\n        super().__init__(**kwargs)\n    def call(self, inputs):        \n        tf.print(\'inputs\', tf.convert_to_tensor(inputs)) #Inside Method of Custom Layer\n        return inputs\n\n\ndef get_model():\n    inp = tf.keras.layers.Input(shape=(1,))\n    out = MyLayer(8)(inp)\n    model = tf.keras.Model(inputs=inp, outputs=out)\n    #model.summary()\n    return model\n\n\ndef train():\n    model = get_model()\n    model.compile(optimizer=""adam"", loss=""mae"")\n    x_train = [2, 3, 4, 1, 2, 6]\n    y_train = [1, 0, 1, 0, 1, 1]\n    model.fit(x_train, y_train)\n\n\nif __name__ == \'__main__\':\n    train()\n</code></pre>\n\n<p>Output of the <code>tf.print</code> statements used in the code above is shown below:</p>\n\n<pre><code>units 8\n\ninputs 10\n\ninputs [[2]\n [6]\n [3]\n [2]\n [1]\n [4]]\n</code></pre>\n\n<p>If you see that <code>tf.print</code> is not working as expected in any other case, please share the reproducible code so that the <code>Tensorflow Community</code> can take a look.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9226}"
759,66659610,"{'items': [{'owner': {'reputation': 24, 'user_id': 18970738}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': True, 'score': 0, 'creation_date': 1651116323, 'answer_id': 72037668, 'question_id': 66659610, 'body': ""<p>TopKCategoricalAccuracy and Precison at k , these two metrics are different from each other. let us see one example.</p>\n<p>For instance in the recommendation usecase , we predict 5 movies [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;,&quot;D&quot;,&quot;F&quot;] for a user and the user viewed Movie 'A' and rejected the rest.</p>\n<ol>\n<li>Then precision at 1 = 1/1= 1</li>\n<li>Then precision at 5 = 1/5(among 5 movies user select only one)</li>\n<li>Top1CategoricalAccuracy(K=1)= 1 or 100%(Because in the prediction list the First movie 'A' was seen by the user)</li>\n<li>Top5CategoricalAccuracy(K=5)= 1 or 100%(the right answer appears in your top five guesses)</li>\n</ol>\n""}, {'owner': {'reputation': 742, 'user_id': 3266253}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1644100750, 'answer_id': 71002778, 'question_id': 66659610, 'body': '<p>No. you are totally right.\nThey both are the same metric.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9226}"
760,74861849,"{'items': [{'owner': {'reputation': 364, 'user_id': 13648950}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1671534836, 'answer_id': 74862243, 'question_id': 74861849, 'body': ""<p>One way of dealing with your parameters indirectly (when there's no reach to it) is using <code>tf.keras.backend</code> access. In this case, tf defines the input format through call function:</p>\n<pre><code>def call(self, inputs):\n    z_mean, z_log_var = inputs\n    batch = tf.shape(z_mean)[0]\n    dim = tf.shape(z_mean)[1]\n    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n</code></pre>\n<p>And then iterates over each batch</p>\n<pre><code>for step, x_batch_train in enumerate(train_dataset):\n    with tf.GradientTape() as tape:\n        reconstructed = vae(x_batch_train)\n        # Compute reconstruction loss\n        loss = mse_loss_fn(x_batch_train, reconstructed)\n        loss += sum(vae.losses)  # Add KLD regularization loss\n\n    grads = tape.gradient(loss, vae.trainable_weights)\n    optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n\n    loss_metric(loss)\n\n    if step % 100 == 0:\n        print(&quot;step %d: mean loss = %.4f&quot; % (step, loss_metric.result())\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9223}"
761,66084126,"{'items': [{'owner': {'reputation': 18097, 'user_id': 5069957}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1612696898, 'answer_id': 66087303, 'question_id': 66084126, 'body': '<p><code>tf.image.grayscale_to_rgb</code> convert a 3d tensor with a single channel to a 3d tensor with 3 channels where the 3 channels have the same intensity. The result is still a grayscale image. This can be done with the following</p>\n<pre><code>const transformed = tensor.mul([1, 1, 1])\n</code></pre>\n<p>The above uses broadcasting to augment the size of the last dimension to 3</p>\n<p>Converting a grayscale image to a colorful image on the other hand is not a trivial task. To achieve it, some models have been trained only for that purpose</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9223}"
762,65260831,"{'items': [{'owner': {'reputation': 6543, 'user_id': 13337635}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1607743510, 'answer_id': 65261310, 'question_id': 65260831, 'body': ""<p>MNIST returns a grayscale image which is in 2D, SSIM requires the image to be in 3D. So just expand the dims of the returned image that you want to compare and apply SSIM on it.</p>\n<pre><code>import numpy as np\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(\n    path='mnist.npz'\n)\n\nx_train_expanded = np.expand_dims(x_train[0], axis=2)\nprint(tf.image.ssim(x_train_expanded, x_train_expanded, 255))\n</code></pre>\n<p>It returns the following:</p>\n<pre><code>tf.Tensor(1.0, shape=(), dtype=float32)\n</code></pre>\n<p>The returned tensor contains an MS-SSIM value for each image in batch. The values are in the range [0, 1] and the example returns a value of 1 indicating both images are identical.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9221}"
763,68162847,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9221}"
764,53677345,"{'items': [{'owner': {'reputation': 7125, 'user_id': 3986320}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1544445303, 'answer_id': 53705775, 'question_id': 53677345, 'body': '<p>The solution that worked for me was using</p>\n\n<pre><code>tf.estimator.inputs.numpy_input_fn(x_train, y_train, num_epochs=EPOCHS,\n                                   batch_size=BATCH_SIZE, shuffle=True)\n</code></pre>\n\n<p>instead of <code>input_fn</code>. The only problem is that <code>tf.estimator.inputs.numpy_input_fn</code> raises deprecation warnings, so unfortunately this will stop working as well.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9221}"
765,53828895,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9221}"
766,46394659,"{'items': [{'owner': {'reputation': 11, 'user_id': 20585051}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1669236740, 'answer_id': 74552869, 'question_id': 46394659, 'body': '<p>If someone is looking for a solution:</p>\n<p>As Stephen mentioned, a histogram isn\'t a continuous function (or even mostly continuous), so it\'s not differentiable. However, what you\'re probably looking for is actually a density estimate for the distribution of intensities. You can calculate one using kernel density estimation (KDE). It\'s similar to a histogram, except the intensity values are interpolated so a continuous change in intensity will correspond to a continuous change in the density estimate.</p>\n<p>The easiest way to do this in Tensorflow currently is using Tensorflow Probability. There\'s an example in their original <a href=""https://arxiv.org/pdf/1711.10604.pdf"" rel=""nofollow noreferrer"">paper</a> (see section 5.1):</p>\n<pre><code>f = lambda x: tfd.Independent(tfd.Normal( loc=x, scale=1.))\nn = x.shape[0].value\nkde = tfd.MixtureSameFamily(\nmixture_distribution=tfd.Categorical( probs=[1 / n] * n),\ncomponents_distribution=f(x))\n</code></pre>\n<p>Note you\'ll have to install tensorflow_probability (pip works) and import tensorflow_probability as tfp and/or import tensorflow_probability.Distributions as tfd.</p>\n<p>It\'s also possible to roll your own, although working out a way to do it without writing a custom op is a bit tricky. For the adventurous, a good place to start is this <a href=""https://courses.cs.washington.edu/courses/cse577/17au/notes/mattes.pdf"" rel=""nofollow noreferrer"">paper</a> (see eq. 6; you only need the second term for a 1d histogram/distribution).</p>\n<p>My (lightly tested) effort:</p>\n<pre><code>import tensorflow as tf\n\ndef cubicSplineFunction(arg):\n    &quot;&quot;&quot; Applies the cubic spline basis function to the argument &quot;&quot;&quot;\n    absX = tf.math.abs(arg)\n    sqrX = tf.math.square(arg)\n    coef1 = (4.0 - 6.0*sqrX + 3.0*sqrX*absX) / 6.0              # |arg| &lt; 1.0\n    coef2 = (8.0 - 12.0*absX + 6.0*sqrX - sqrX*absX) / 6.0      # |arg| &lt; 2.0\n    lt1 = tf.cast(tf.where(absX &lt;= 1,1,0),tf.float32)\n    lt2 = tf.cast(tf.where(absX &lt; 2,1,0),tf.float32) * (1-lt1)\n    out = coef1 * lt1 + coef2 * lt2\n    return out\n    \ndef bincountWithWeights(h,bins,weights):\n    &quot;&quot;&quot; Adds weights[i] into h[bins[i]] for all i&quot;&quot;&quot;\n    return tf.tensor_scatter_nd_add(h,tf.reshape(tf.cast(bins,tf.int32),[-1,1]),weights)\n\ndef parzenDensityEstimate(x,histN):\n    &quot;&quot;&quot; Returns a cubic spline interpolated probability density estimate for x &quot;&quot;&quot;\n    padding = 2\n    minOb = tf.reduce_min(x)-1e-4; maxOb = tf.reduce_max(x)+1e-4; \n    delta = (maxOb-minOb) / (histN-2*padding)\n    min = minOb / delta - padding\n    max = maxOb / delta + padding\n    xs = tf.range(minOb-2*delta,maxOb+2*delta,delta)\n    h = tf.zeros_like(xs)\n    xn = x/delta - min\n    xb = tf.math.floor(xn,tf.int32)\n    for offset in range(-2,3):\n        splineArg = (xb+offset)-xn+0.5        # 0.5 is to find the distance from the bin centre\n        v = cubicSplineFunction(splineArg)\n        h = bincountWithWeights(h=h,bins=xb+offset,weights=v)\n    h = h / tf.reduce_sum(h)\n    return h,xs\n\n\ndensity, bins = parzenDensityEstimate([0.,10.,10.,10.,20.],histN=20)\n</code></pre>\n'}, {'owner': {'reputation': 19, 'user_id': 5451157}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1627157126, 'answer_id': 68513454, 'question_id': 46394659, 'body': '<p>I had the similar problem. There are two ways you can try: 1. After the output layer, add an extra layer to produce the histogram; 2. Use something like <code>tf.RegisterGradient</code> or <code>tf.custom_gradient</code> to define your own gradients for the operations.</p>\n'}, {'owner': {'reputation': 121, 'user_id': 6431737}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1525305620, 'answer_id': 50145134, 'question_id': 46394659, 'body': '<p><code>tf.histogram_fixed_width()</code> does not support autogradient functionality since histogram is not a continuous differential function. You can look at the following example which returns gradient None.</p>\n\n<pre><code>import keras.backend as K\nimport tensorflow as tf\n\nvalue_range = [0.0, 5.0]\na = np.array([-1.0, 0.0, 1.5, 2.0, 5.0, 15])\n\nx = K.variable(a)\nhist = tf.histogram_fixed_width(x, value_range, nbins=5, dtype=tf.float32)\ngradient = K.gradients(hist, x)\n\n# output is [None]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9221}"
767,47389988,"{'items': [{'owner': {'reputation': 18649, 'user_id': 3214872}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': True, 'score': 8, 'creation_date': 1511174887, 'answer_id': 47390223, 'question_id': 47389988, 'body': '<p>When you create an <code>Estimator</code> instance, you can pass in the constructor\'s <code>config</code> a <a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig"" rel=""noreferrer""><code>tf.estimator.RunConfig</code></a> instance.\nThe <code>RunConfig</code> has a <code>session_config</code> attribute you can use to set a <code>tf.ConfigProto</code> with the session\'s parameters.</p>\n\n\n\n<p>In code, this translates to:</p>\n\n<pre class=""lang-python prettyprint-override""><code>session_config = tf.ConfigProto()\nsession_config.gpu_options.per_process_gpu_memory_fraction = 0.5\nestimator_config = tf.estimator.RunConfig(session_config=session_config)\nmy_estimator = tf.estimator.Estimator(..., config=estimator_config)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9216}"
768,58748202,"{'items': [{'owner': {'reputation': 9218, 'user_id': 867889}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1573145027, 'answer_id': 58753403, 'question_id': 58748202, 'body': ""<p>After reviewing source code for both operations here is what I found:</p>\n\n<ul>\n<li>both operations rely on <code>tensorflow.python.ops.embedding_ops</code> funcitonality;</li>\n<li>keras.layers.Embedding uses <strong>dense</strong> representations and contains generic keras code for fiddling with shapes, init variables etc;</li>\n<li>feature_column.embedding_column relies on <strong>sparse</strong> and contains functionality to cache results.</li>\n</ul>\n\n<p>So, your guess seems to be right: these 2 are doing similar things, rely on distinct input representations, contain some logic that doesn't change the essense of what they do.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9216}"
769,76244268,"{'items': [{'owner': {'reputation': 16444, 'user_id': 9215780}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1684094078, 'answer_id': 76249422, 'question_id': 76244268, 'body': '<p>In your case, you may need to write your model definition in the following way in order to build class activation mapping network. Know more details in this <a href=""https://github.com/keras-team/keras/issues/16355"" rel=""nofollow noreferrer"">ticket</a>.</p>\n<pre class=""lang-py prettyprint-override""><code>def vgg_sequential():\n    inputs = keras.Input(shape=(224, 224, 3,))\n    pretrained_model = keras.applications.VGG16(\n            weights=\'imagenet\', \n            include_top=False, \n            input_tensor=inputs,\n        )\n    x = keras.layers.GlobalAveragePooling2D()(pretrained_model.output)\n    outputs = keras.layers.Dense(1)(x)\n    model = keras.Model(inputs, outputs)\n    return model\n</code></pre>\n<p>And then you can do</p>\n<pre class=""lang-py prettyprint-override""><code>cam_model = keras.Model(\n    inputs=seq_vgg.layers[0].input, \n    outputs=(\n        seq_vgg.layers[-3].output, \n        seq_vgg.layers[-1].output\n    )\n)\n\na, b = cam_model(tf.ones((1, 224, 224, 3)))\na.shape, b.shape\n(TensorShape([1, 7, 7, 512]), TensorShape([1, 1]))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9216}"
770,57857325,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1568048093, 'answer_id': 57858229, 'question_id': 57857325, 'body': '<p>While there does not seem to be a public API for that in C++, the library loading functions are exposed in the <a href=""https://www.tensorflow.org/install/lang_c"" rel=""nofollow noreferrer"">TensorFlow API for C</a> (which is the API that <a href=""https://www.tensorflow.org/api_docs/python/tf/load_library"" rel=""nofollow noreferrer""><code>tf.load_library</code></a> uses). There is no ""nice"" documentation for it, but you can find them in <a href=""https://github.com/tensorflow/tensorflow/blob/v1.14.0/tensorflow/c/c_api.h#L1626-L1655"" rel=""nofollow noreferrer""><code>c/c_api.h</code></a>:</p>\n\n<pre class=""lang-c prettyprint-override""><code>// --------------------------------------------------------------------------\n// Load plugins containing custom ops and kernels\n\n// TF_Library holds information about dynamically loaded TensorFlow plugins.\ntypedef struct TF_Library TF_Library;\n\n// Load the library specified by library_filename and register the ops and\n// kernels present in that library.\n//\n// Pass ""library_filename"" to a platform-specific mechanism for dynamically\n// loading a library. The rules for determining the exact location of the\n// library are platform-specific and are not documented here.\n//\n// On success, place OK in status and return the newly created library handle.\n// The caller owns the library handle.\n//\n// On failure, place an error status in status and return NULL.\nTF_CAPI_EXPORT extern TF_Library* TF_LoadLibrary(const char* library_filename,\n                                                 TF_Status* status);\n\n// Get the OpList of OpDefs defined in the library pointed by lib_handle.\n//\n// Returns a TF_Buffer. The memory pointed to by the result is owned by\n// lib_handle. The data in the buffer will be the serialized OpList proto for\n// ops defined in the library.\nTF_CAPI_EXPORT extern TF_Buffer TF_GetOpList(TF_Library* lib_handle);\n\n// Frees the memory associated with the library handle.\n// Does NOT unload the library.\nTF_CAPI_EXPORT extern void TF_DeleteLibraryHandle(TF_Library* lib_handle);\n</code></pre>\n\n<p>These functions do actually call C++ code (see source in <a href=""https://github.com/tensorflow/tensorflow/blob/v1.14.0/tensorflow/c/c_api.cc#L977-L995"" rel=""nofollow noreferrer""><code>c/c_api.cc</code></a>). However, the called functions, defined in <a href=""https://github.com/tensorflow/tensorflow/blob/v1.14.0/tensorflow/core/framework/load_library.cc"" rel=""nofollow noreferrer""><code>core/framework/load_library.cc</code></a> does not have a header to include. The workaround to use it in C++ code, which they use in <a href=""https://github.com/tensorflow/tensorflow/blob/v1.14.0/tensorflow/c/c_api.cc#L751-L753"" rel=""nofollow noreferrer""><code>c/c_api.cc</code></a>, is to declare the function yourself, and link the TensorFlow library.</p>\n\n<pre class=""lang-cpp prettyprint-override""><code>namespace tensorflow {\n// Helpers for loading a TensorFlow plugin (a .so file).\nStatus LoadLibrary(const char* library_filename, void** result,\n                   const void** buf, size_t* len);\n}\n</code></pre>\n\n<p>As far as I can tell there is no API to unload the library. The C API allows you only to delete the library handle object. This done just by freeing the pointer, but if you want to avoid trouble you should probably use the freeing function given by TensorFlow, <code>tensorflow::port:free</code>, declared in <a href=""https://github.com/tensorflow/tensorflow/blob/v1.14.0/tensorflow/core/platform/mem.h#L34"" rel=""nofollow noreferrer""><code>core/platform/mem.h</code></a>. Again, if you cannot not or don\'t want to include that, you can declare the function yourself and it should work as well.</p>\n\n<pre class=""lang-cpp prettyprint-override""><code>namespace tensorflow {\nnamespace port {\nvoid Free(void* ptr);\n}\n}\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9216}"
771,61994285,"{'items': [{'owner': {'reputation': 11, 'user_id': 15769899}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1619535416, 'answer_id': 67285551, 'question_id': 61994285, 'body': '<p>Chiming in a year later to report that I had the same problem and &quot;solved&quot; it by eliminating any examples with zero weights. Might be an issue with Tensorflow converting something to a Sparse representation and omitting the zeros.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9212}"
772,76244271,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9212}"
773,57175343,"{'items': [{'owner': {'reputation': 1040, 'user_id': 493767}, 'down_vote_count': 0, 'up_vote_count': 9, 'is_accepted': False, 'score': 9, 'creation_date': 1591633062, 'answer_id': 62266578, 'question_id': 57175343, 'body': '<p>I had a similar issue, and it took me many tries to get the structure right for those inputs.   Here\'s an example of a network with 3 inputs and 2 outputs, complete to the <code>.fit</code> call.  </p>\n\n<p>The following works in tensorflow  <code>2.1.0</code></p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\n\ndef generator(N=10):\n    """"""\n    Returns tuple of (inputs,outputs) where\n    inputs  = (inp1,inp2,inp2)\n    outputs = (out1,out2)\n    """"""\n    dt=np.float32\n    for i in range(N):\n        inputs  = (np.random.rand(N,3,3,1).astype(dt), \n                   np.random.rand(N,3,3,1).astype(dt), \n                   np.random.rand(N,3,3,1).astype(dt))\n        outputs = (np.random.rand(N,3,3,1).astype(dt),\n                   np.random.rand(N,3,3,1).astype(dt))\n        yield inputs,outputs\n\n# Create dataset from generator\ntypes = ( (tf.float32,tf.float32,tf.float32),\n          (tf.float32,tf.float32) )\nshapes = (([None,3,3,1],[None,3,3,1],[None,3,3,1]),\n          ([None,3,3,1],[None,3,3,1]))\ndata = tf.data.Dataset.from_generator(generator,\n                                      output_types=types,\n                                      output_shapes=shapes\n                                     )\n# Define a model\ninp1 = tf.keras.Input(shape=(3,3,1),name=\'inp1\')\ninp2 = tf.keras.Input(shape=(3,3,1),name=\'inp2\')\ninp3 = tf.keras.Input(shape=(3,3,1),name=\'inp3\')\nout1 = tf.keras.layers.Conv2D(1,kernel_size=3,padding=\'same\')(inp1)\nout2 = tf.keras.layers.Conv2D(1,kernel_size=3,padding=\'same\')(inp2)\nmodel = tf.keras.Model(inputs=[inp1,inp2,inp3],outputs=[out1,out2])\nmodel.compile(loss=[\'mse\',\'mse\'])\n\n# Train\nmodel.fit(data)\n\n\n</code></pre>\n'}, {'owner': {'reputation': 21, 'user_id': 13633037}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': False, 'score': 0, 'creation_date': 1591552775, 'answer_id': 62249537, 'question_id': 57175343, 'body': '<pre><code>model.fit([input_1, input_2, input_3], y, epochs=EPOCHS)\n</code></pre>\n\n<p>You got to have n(3 in the case above) input layers in your model.</p>\n'}, {'owner': {'reputation': 13934, 'user_id': 2455494}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1563949656, 'answer_id': 57176547, 'question_id': 57175343, 'body': '<p>So assuming you have a generator that is similar to this mock:</p>\n\n<pre class=""lang-py prettyprint-override""><code>def dummy_generator():\n  number_of_records = 100\n\n  for i in range(100):\n    an_image = tf.random.uniform((200,200,3))\n    some_numbers = tf.random.uniform((50,))\n    signal1 = tf.random.uniform((50000,))\n    signal2 = tf.random.uniform((100000,))\n    signal3 = tf.random.uniform((100000,))\n    yield an_image, some_numbers, signal1, signal2, signal3\n</code></pre>\n\n<p>each record is of datatype <code>float32</code> so the output types are easy:</p>\n\n<pre class=""lang-py prettyprint-override""><code>out_types = (tf.float32, tf.float32, tf.float32, tf.float32, tf.float32)\n</code></pre>\n\n<p>for the output shapes we just list the shapes in the same order:</p>\n\n<pre class=""lang-py prettyprint-override""><code>out_shapes = ((200,200,3), (50,), (50000,), (100000,), (100000,))\n</code></pre>\n\n<p>so now we can just call <code>from_generator</code>:</p>\n\n<pre class=""lang-py prettyprint-override""><code>ds = tf.data.Dataset.from_generator(dummy_generator, \n                                    output_types=out_types,\n                                    output_shapes=out_shapes)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9212}"
774,64095538,"{'items': [{'owner': {'reputation': 19216, 'user_id': 10133797}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1601978968, 'answer_id': 64223667, 'question_id': 64095538, 'body': ""<p>Most of the time, yes. To learn of the difference, do:</p>\n<ol>\n<li><code>tf.ones?</code> or <code>tf.ones??</code> if your IDE supports it; this'll show docs + source code + file location</li>\n<li><code>from inspect import getsource; print(getsource(tf.ones))</code> will show source code</li>\n</ol>\n<p>I'd not <em>replace</em> <code>K</code> with <code>tf</code>, though; stuff gets moved around between versions, and functionality may break. Each has its own list of imports: <code>tensorflow/__init__.py</code> and <code>tensorflow/python/keras/backend.py</code>.</p>\n""}, {'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1601978372, 'answer_id': 64223517, 'question_id': 64095538, 'body': '<p>Yes, you can use tf but there might be minor difference in the results as both of them have different repo maintained.</p>\n<p>For example the <a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/backend.py#L4795-L4831"" rel=""nofollow noreferrer"">tf.keras.backend.binary_crossentropy</a> and <a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/losses.py#L1570-L1605"" rel=""nofollow noreferrer"">tf.keras.losses.binary_crossentropy</a> have different code repo maintained but objective should remain the same.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9212}"
775,50054453,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1525373158, 'answer_id': 50161964, 'question_id': 50054453, 'body': '<p>The reason for the absence of static shape information is that TensorFlow doesn\'t understand enough about the <code>example_generator</code> function to determine the shapes of the arrays it yields, and so it assumes the shapes can be completely different from one element to the next. The best way to constrain this is to specify the optional <code>output_shapes</code> argument to <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator"" rel=""nofollow noreferrer""><code>tf.data.Dataset.from_generator()</code></a>, which accepts a nested structure of shapes matching the structure of the yielded elements (and the <code>output_types</code> argument).</p>\n\n<p>In this case you\'d pass a tuple of two shapes, which can be partially specified. For example, if the <code>x</code> elements are <code>900 x 1000</code> arrays and the <code>y</code> elements are scalars:</p>\n\n<pre><code>sequence_dataset = tf.data.Dataset.from_generator(\n    example_generator, (tf.int32, tf.int32),\n    output_shapes=([900, 1000], []))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9208}"
776,52073782,"{'items': [{'owner': {'reputation': 28407, 'user_id': 1233251}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1535535543, 'answer_id': 52074249, 'question_id': 52073782, 'body': '<p>There is nothing wrong with <code>tf.greater</code> or <code>tf.cond</code>. But since the two have been executed in different session runs, the values sampled from <code>x</code> and <code>y</code> will be different in each one. This can be noticed by fetching <code>x</code> and <code>y</code> alongside the output:</p>\n\n<pre><code>x = tf.random_uniform([])\ny = tf.random_uniform([])\ng = tf.greater(x, y)      # you can also do `x &gt; y`, same TF op\nc = tf.cond(g, lambda: x + y, lambda: x - y)\nsess = tf.Session()\nsess.run([x, y, g])\nsess.run([x, y, c])\n</code></pre>\n\n<p>The output:</p>\n\n<pre class=""lang-none prettyprint-override""><code>[0.11019015, 0.028247476, True]\n[0.29905212, 0.9846852, -0.68563306]\n</code></pre>\n\n<p>In order to ensure that these operations use the same value, you can perform both operations in the same run:</p>\n\n<pre><code>sess.run([x, y, g, c])\n</code></pre>\n\n<pre class=""lang-none prettyprint-override""><code>[0.74283457, 0.8982569, False, -0.15542233]\n</code></pre>\n\n<p>Or turn <code>x</code> and <code>y</code> into TensorFlow variables, which would retain the same numbers from the distribution until the next reassignment.</p>\n\n<pre><code>x = tf.get_variable(\'x\', shape=[], initializer=tf.random_uniform_initializer())\ny = tf.get_variable(\'y\', shape=[], initializer=tf.random_uniform_initializer())\n\ng = x &gt; y\nc = tf.cond(g, lambda: x + y, lambda: x - y)\n\nreset_vars = tf.variables_initializer([x, y])\n\nsess = tf.Session()\nsess.run(reset_vars) # this must be called once\nsess.run([x, y, g])\nsess.run([x, y, c])\n</code></pre>\n\n<pre class=""lang-none prettyprint-override""><code>[0.4862318, 0.48253357, True]\n[0.4862318, 0.48253357, 0.9687654]\n</code></pre>\n'}, {'owner': {'reputation': 2593, 'user_id': 6470853}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1535535477, 'answer_id': 52074233, 'question_id': 52073782, 'body': ""<p>The tricky part with <code>tensorflow</code> is that the code is used to build a graph of computations, which can then be ran/evaluated in a <code>tf.Session</code>.</p>\n\n<p>In your example, at each evaluation, random tensors <code>x</code> and <code>y</code> are generated.</p>\n\n<ul>\n<li><p>So, your call <code>x.eval()</code> generates random tensors <code>x</code> and <code>y</code>.</p></li>\n<li><p>Your call <code>y.eval()</code> regenerates random tensors <code>x</code> and <code>y</code>.</p></li>\n<li><p>And so do <code>sess.run(tf.greater(x, y))</code> and <code>sess.run(out)</code>.</p></li>\n</ul>\n\n<p>Therefore, your prints of <code>x</code> and <code>y</code> do not reflect the actual <code>x</code> and <code>y</code> used in <code>sess.run(tf.greater(x, y))</code> and <code>sess.run(out)</code> (which by the way also explains why your result <code>0.3438499</code> do not correspond to neither <code>x+y</code> or <code>x-y</code>).</p>\n\n<p>By freezing tensors <code>x</code> and <code>y</code> to <code>tf.constant</code>, you get the expected behaviour:</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\n\nwith tf.Session() as sess:\n   x = tf.constant(np.random.uniform())\n   y = tf.constant(np.random.uniform())\n   print('x: '+str(x.eval()))\n   print('y: '+str(y.eval()))\n   out = tf.cond(tf.greater(x, y), lambda: x + y, lambda: x - y)\n   print(sess.run(tf.greater(x, y)))\n   print(sess.run(out))\n</code></pre>\n\n<p><em>prints (on one run on my side)</em></p>\n\n<pre><code>x: 0.75513345\ny: 0.04605962\nTrue\n0.80119306\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9208}"
777,57527609,"{'items': [{'owner': {'reputation': 31, 'user_id': 10779975}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1584299722, 'answer_id': 60696673, 'question_id': 57527609, 'body': '<p>Create the ops inside a function and decorate it with tf.function</p>\n\n<pre><code>import tensorflow as tf\ndef _parse_function(x):\n    return x * 2\n\n@tf.function\ndef foo():\n    x = tf.constant([0 , 1])\n    dataset = tf.data.Dataset.from_tensor_slices(x)\n    dataset = dataset.map(_parse_function)\n\nlogdir = \'logs\'\nwriter = tf.summary.create_file_writer(logdir)\n\ntf.summary.trace_on(graph=True, profiler=True)\nfoo()\nwith writer.as_default():\n    tf.summary.trace_export(\n      name=""trace"",\n      step=0,\n      profiler_outdir=logdir)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9208}"
778,51248442,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9208}"
779,64496955,"{'items': [{'owner': {'reputation': 86, 'user_id': 13685500}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1612334097, 'answer_id': 66022388, 'question_id': 64496955, 'body': '<p>img_shape should be (224, 224, 3) not [224, 224, 3]</p>\n<p>for example:</p>\n<pre><code>def set_shapes(img, label, img_shape=(120,120,3)):\n    img.set_shape(img_shape)\n    label.set_shape([])\n    return img, label\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9208}"
780,36631868,"{'items': [{'owner': {'reputation': 2354, 'user_id': 2878004}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1460677724, 'answer_id': 36635964, 'question_id': 36631868, 'body': '<p>Weights and biases are the weight matrix and bias vector for the output layer of your language model.</p>\n\n<p><a href=""https://www.tensorflow.org/versions/r0.8/api_docs/python/nn.html#nce_loss"" rel=""nofollow"">https://www.tensorflow.org/versions/r0.8/api_docs/python/nn.html#nce_loss</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9203}"
781,62348605,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1591982071, 'answer_id': 62349239, 'question_id': 62348605, 'body': '<p>EDIT:</p>\n\n<p>I worked out a kind of ""hacky"" solution that can read tensors from different types, casting them to a given type, and works with <code>@tf.function</code> (interestingly, it does <em>not</em> work without <code>@tf.function</code>). The idea is to read the second byte of the <code>TensorProto</code> message, which <em>should</em> indicate the data type, and then make a <code>tf.switch_case</code> to convert from a range of possible source data types. Here is how it could work:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\n# Different sets of data types you could use\nINTEGER_DTYPES = frozenset({tf.bool, tf.uint8, tf.uint16, tf.uint32, tf.uint64,\n                            tf.int8, tf.int16, tf.int32, tf.int64})\nFLOAT_DTYPES = frozenset({tf.float16, tf.bfloat16, tf.float32, tf.float64})\nCOMPLEX_DTYPES = frozenset({tf.complex64, tf.complex128})\nREAL_DTYPES = INTEGER_DTYPES | FLOAT_DTYPES\nNUMERICAL_DTYPES = REAL_DTYPES | COMPLEX_DTYPES\n\n@tf.function\ndef parse_tensor_cast(tensor_proto, out_dtype, possible_dtypes=REAL_DTYPES):\n    # Prepare branches\n    branches = {}\n    dtype_idx = [0] * 128\n    for i, dtype in enumerate(possible_dtypes):\n        dtype_idx[dtype.as_datatype_enum] = i\n        branches[i] = lambda: tf.dtypes.cast(\n            tf.io.parse_tensor(tensor_proto, dtype), out_dtype)\n    dtype_idx = tf.constant(dtype_idx, tf.int32)\n    # Extract dtype byte (""hacky"" part of the solution)\n    dtype_code = tf.strings.substr(tensor_proto, 1, 1)\n    dtype_num = tf.io.decode_raw(dtype_code, tf.uint8)[0]\n    dtype_num_idx = dtype_idx[tf.dtypes.cast(dtype_num, tf.int32)]\n    # Switch operation\n    return tf.switch_case(dtype_num_idx, branches)\n\n# Test\nserialized_tensors = [\n    tf.io.serialize_tensor(tf.constant([1, 2, 3], tf.int32)),\n    tf.io.serialize_tensor(tf.constant([1, 2, 3], tf.float64))\n]\nfor t in serialized_tensors:\n    tf.print(parse_tensor_cast(t, tf.float32))\n# [1 2 3]\n# [1 2 3]\n</code></pre>\n\n<hr>\n\n<p>Unfortunately you cannot skip this argument. If there was only eager mode it wouldn\'t be necessary, but if you want to ""graph"" this operation (e.g. within a <code>@tf.function</code>) then the data type needs to be known in advance, before the actual parsing happens.</p>\n\n<p>If you are only interested in eager mode, then it is not difficult to work around this:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import numpy as np\nimport tensorflow as tf\n\ninput_tensor = tf.constant([1, 2, 3], tf.int32)\n\n# A scalar tf.string tensor containing the serialized input_tensor\nserialized_tensor = tf.io.serialize_tensor(input_tensor)\n\n# Create a TensorProto from serialized_tensor content\ntensor_proto = tf.core.framework.tensor_pb2.TensorProto()\ntensor_proto.ParseFromString(serialized_tensor.numpy())\n\n# At this point, this is equivalent to tf.make_tensor_proto\ntf.make_tensor_proto(input_tensor)\n\n# Read data back from tensor_proto\ntensor_parsed = tf.io.parse_tensor(serialized_tensor.numpy(),\n                                   tf.dtypes.as_dtype(tensor_proto.dtype))\ntf.debugging.assert_equal(input_tensor, tensor_parsed)\n\n# You can also just directly create the tensor from the extracted message\nnumpy_parsed = tf.make_ndarray(tensor_proto)\nnp.testing.assert_array_equal(input_tensor.numpy(), numpy_parsed)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9203}"
782,69942590,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9203}"
783,40090943,"{'items': [{'owner': {'reputation': 897, 'user_id': 523503}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1497607142, 'answer_id': 44586368, 'question_id': 40090943, 'body': '<p>For your last question:</p>\n\n<p>""Can two different sessions share the same tf.Variable?""</p>\n\n<ol>\n<li>For distributed sessions(e.g. Session(""grpc://.."")), they can. </li>\n<li>For direct sessions, they can\'t.</li>\n</ol>\n\n<p>In distributed training, variables are managed by tf.Server(), persistent across sessions. Remember? Server are created before sessions. It lives longer than tf.Sessions.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9203}"
784,54175038,"{'items': [{'owner': {'reputation': 7061, 'user_id': 5495381}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1547455226, 'answer_id': 54178060, 'question_id': 54175038, 'body': '<p>You are probably training your model with actual image files, while it is best to send images as encoded byte-string to a model hosted on CloudML. Therefore you\'ll need to specify a <code>ServingInputReceiver</code> function when exporting the model, as you mention. Some boilerplate code to do this for a Keras model:</p>\n\n<pre><code># Convert keras model to TF estimator\ntf_files_path = \'./tf\'\nestimator =\\\n    tf.keras.estimator.model_to_estimator(keras_model=model,\n                                          model_dir=tf_files_path)\n\n# Your serving input function will accept a string\n# And decode it into an image\ndef serving_input_receiver_fn():\n    def prepare_image(image_str_tensor):\n        image = tf.image.decode_png(image_str_tensor,\n                                    channels=3)\n        return image  # apply additional processing if necessary\n\n    # Ensure model is batchable\n    # https://stackoverflow.com/questions/52303403/\n    input_ph = tf.placeholder(tf.string, shape=[None])\n    images_tensor = tf.map_fn(\n        prepare_image, input_ph, back_prop=False, dtype=tf.float32)\n\n    return tf.estimator.export.ServingInputReceiver(\n        {model.input_names[0]: images_tensor},\n        {\'image_bytes\': input_ph})\n\n# Export the estimator - deploy it to CloudML afterwards\nexport_path = \'./export\'\nestimator.export_savedmodel(\n    export_path,\n    serving_input_receiver_fn=serving_input_receiver_fn)\n</code></pre>\n\n<p>You can refer to <a href=""https://stackoverflow.com/questions/51432589/how-do-i-get-a-tensorflow-keras-model-that-takes-images-as-input-to-serve-predic"">this very helpful answe</a>r for a more complete reference and other options for exporting your model. </p>\n\n<p><strong>Edit:</strong> If this approach throws a <code>ValueError: Couldn\'t find trained model at ./tf.</code> error, you can try it the workaround solution that I documented in <a href=""https://stackoverflow.com/questions/54615708/exporting-a-keras-model-as-a-tf-estimator-couldnt-find-trained-model"">this answer</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9199}"
785,75572543,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9199}"
786,74442047,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1671002260, 'answer_id': 74794753, 'question_id': 74442047, 'body': '<p>Before you convert your model to tflite model you have to enable TF ops to work in tflite by using the below code</p>\n<pre><code>converter.target_spec.supported_ops = [\n    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n    tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n]\n</code></pre>\n<p>For more details please refer to this <a href=""https://www.tensorflow.org/lite/guide/ops_select#convert_a_model"" rel=""nofollow noreferrer"">document</a>. Thank You.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9199}"
787,55514435,"{'items': [{'owner': {'reputation': 10946, 'user_id': 2846923}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1572804952, 'answer_id': 58683231, 'question_id': 55514435, 'body': '<p>CuDNNLSTM has a hardcoded tanh activation. As far as I am aware, there is no way for this to be changed. If you need some other activation, you\'re stuck using a regular LSTM layer.</p>\n\n<p>Alternately, if you only need a specific output activation for your model, e.g. softmax, you can stick on a Dense layer and then put the activation after that. Here\'s a snippet of how I\'m doing that for my particular case:</p>\n\n<pre><code>x = CuDNNLSTM(256, return_sequences=True)(x)\nx = TimeDistributed(Dense(8))(x)\nx = Softmax(axis=2)(x)\n</code></pre>\n\n<p>Further reading:</p>\n\n<ul>\n<li><a href=""https://github.com/keras-team/keras/issues/8510"" rel=""nofollow noreferrer"">https://github.com/keras-team/keras/issues/8510</a></li>\n<li><a href=""https://devblogs.nvidia.com/optimizing-recurrent-neural-networks-cudnn-5/"" rel=""nofollow noreferrer"">https://devblogs.nvidia.com/optimizing-recurrent-neural-networks-cudnn-5/</a></li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9199}"
788,53966148,"{'items': [{'owner': {'reputation': 1857, 'user_id': 10484131}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1546049994, 'answer_id': 53966179, 'question_id': 53966148, 'body': '<p>Your expectation may not be logically sound, as pointed out further <a href=""https://github.com/tensorflow/tensorflow/issues/18238#issuecomment-378646160"" rel=""nofollow noreferrer"">in this feature request</a> that resembles your question. You would need to have dynamic shapes for tensors, which has only limited support in TensorFlow (e.g. <a href=""https://www.tensorflow.org/guide/ragged_tensors"" rel=""nofollow noreferrer"">Ragged Tensors</a>).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9199}"
789,41125183,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9194}"
790,41602374,"{'items': [{'owner': {'reputation': 57117, 'user_id': 419116}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1484184442, 'answer_id': 41603661, 'question_id': 41602374, 'body': '<p>Your ""5"" parameter has shape <code>()</code> but needs to have rank 1</p>\n\n<pre><code>original_tensor = tf.constant([1,2,3,4,5])\nmade_copies_tensor = tf.tile(original_tensor, [5])\nsess.run(made_copies_tensor)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9194}"
791,44887367,"{'items': [{'owner': {'reputation': 6144, 'user_id': 7456923}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': True, 'score': 11, 'creation_date': 1499091358, 'answer_id': 44887860, 'question_id': 44887367, 'body': '<p><code>tf.one_hot()</code> transforms a list of indices (e.g. <code>[0, 2, 1]</code>) and transforms it into a list of one-hot vectors of length <code>depth</code>.</p>\n\n<p>For instance, if <code>depth = 3</code>, </p>\n\n<ul>\n<li>index 0 in the input will be replaced by [1, 0, 0]</li>\n<li>index 1 in the input will be replaced by [0, 1, 0]</li>\n<li>index 2 in the input will be replaced by [0, 0, 1]</li>\n</ul>\n\n<p>So <code>[0, 2, 1]</code> would be encoded as <code>[[1, 0, 0], [0, 0, 1], [0, 1, 0]]</code></p>\n\n<p>As you can see, the output has one more dimension than the input (since each index is replaced by a vector). </p>\n\n<p>By default (<strong>and what you usually need</strong>), the new dimension is created as the last one, so if your input is of shape <code>(d1, d2, .., dn)</code>, your output will be of shape <code>(d1, d2, .., dn, depth)</code>. But if you change the input parameter <em>axis</em>, you may choose to put the new dimension elsewhere, for instance if <code>axis=0</code> your output will be of shape <code>(depth, d1, d2, .., dn)</code>.</p>\n\n<p>Changing the order of the dimensions is basically the n-dimensional version of transposing: you have the same data, but switch the order of the indices to access them (equivalent to switching the columns and the rows in a 2D matrix).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9194}"
792,61513032,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9194}"
793,45313351,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9190}"
794,49605958,"{'items': [{'owner': {'reputation': 463, 'user_id': 9375901}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1522649819, 'answer_id': 49606249, 'question_id': 49605958, 'body': '<p>tf.layers.dropout uses tf.nn.dropout function internally.</p>\n\n<p>tf.nn.dropout might be useful if you just want to use a higher level abstraction and do not want to control many facets of the dropout.</p>\n\n<p>Look at the api docs:\n1)<a href=""https://www.tensorflow.org/api_docs/python/tf/layers/dropout"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/layers/dropout</a></p>\n\n<p>2)<a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dropout"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/nn/dropout</a></p>\n\n<p>tf.layers.dropout is a wrapper around tf.nn.dropout and there\'s a slight difference in terms that tf.layers uses ""rate of dropout"" while tf.nn ""uses the probability to keep the inputs"". Though a direct relation can be established between them. </p>\n\n<p>Also there\'s an extra argument ""Training"" in tf.layers.dropout which is used to control Whether to return the output in training mode (apply dropout) or in inference mode (return the input untouched).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9190}"
795,55160136,"{'items': [{'owner': {'reputation': 373, 'user_id': 8397234}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1556573201, 'answer_id': 55911034, 'question_id': 55160136, 'body': '<p>Many of the image processing functions that were historically housed in <code>tf.contrib</code> have been migrated to other locations in TensorFlow 2.0. <code>dense_image_warp</code> and <code>rotate</code> are now part of the <a href=""https://github.com/tensorflow/addons/tree/master/tensorflow_addons/image"" rel=""nofollow noreferrer""><code>tfa.image</code></a> module in TensorFlow Addons.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9190}"
796,55414091,"{'items': [{'owner': {'reputation': 143, 'user_id': 6597035}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1553854487, 'answer_id': 55415113, 'question_id': 55414091, 'body': ""<p>I believe that can't be done. As the main aim for <code>tf.get_variable()</code> is to search for a variable with the same name first and if it didn't find it it creates a new one. So if you just want to create a new variable use <code>tf.Variable()</code> instead</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9190}"
797,50967885,"{'items': [{'owner': {'reputation': 3596, 'user_id': 6780025}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1529628029, 'answer_id': 50979176, 'question_id': 50967885, 'body': '<p><code>grad_ys</code> is only needed for advanced use cases. Here is how you can think about it.</p>\n\n<p><code>tf.gradients</code> allows you to compute <code>tf.gradients(y, x, grad_ys) = grad_ys * dy/dx</code>. In other words, <code>grad_ys</code> is the multiplier of each <code>y</code>. In this notation, it seems silly to provide this argument because one should be able to just multiple himself, i.e. <code>tf.gradients(y, x, grad_ys) = grad_ys * tf.gradients(y, x)</code>. Unfortunately, this equality does not hold because when computing gradients backwards, we perform reduction (typically summation) after each step to get ""intermediate loss"".</p>\n\n<p>This functionality can be useful in many cases. One is mentioned in the doc string. Here is another. Remember the chain rule - <code>dz/dx = dz/dy * dy/dx</code>. Let\'s say that we wanted to compute <code>dz/dx</code> but <code>dz/dy</code> is not differentiable and we can only approximate it. Let\'s say we compute the approximation somehow and call it <code>approx</code>. Then, <code>dz/dx = tf.gradients(y, x, grad_ys=approx)</code>.</p>\n\n<p>Another use case can be when you have a model with a ""huge fan-in"". Let\'s say you have 100 input sources that go through a few layers (call these ""100 branches""), get combined at <code>y</code>, and go through 10 more layers until you get to a <code>loss</code>. It might be that computing all the gradients (which requires remembering many activations) for the whole model at once does not fit in memory. One way to do this would be to compute <code>d(loss)/dy</code> first. Then, compute the gradients for variables in <code>branch_i</code> with respect to <code>loss</code> using <code>tf.gradients(y, branch_i_variables, grad_ys=d(loss)/dy)</code>. Using this (and a few more details I am skipping) you can reduce the peak memory requirement.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9186}"
798,63919438,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1600338037, 'answer_id': 63935993, 'question_id': 63919438, 'body': ""<blockquote>\n<p>Is it correct to use these parameters in order to get more frequent\nfeedback on performance?</p>\n</blockquote>\n<p>Yes, it is correct to use these parameters. Here is the code that i used to fit the model.</p>\n<pre><code>model.fit(\ntrain_data,\nsteps_per_epoch = train_samples//batch_size,\nepochs = epochs,\nvalidation_data = test_data,\nverbose = 1,\nvalidation_steps = test_samples//batch_size)\n</code></pre>\n<blockquote>\n<p>does it use all 100k images or does it use the same first 10k images of my\ntraining set at every 'epoch'?</p>\n</blockquote>\n<p>It use all images in your training data.</p>\n<p>For better understanding <code>Epoch</code> is the number times the learning algorithm will work through the entire training data set.</p>\n<p>Where as <code>steps_per_epoch</code> is the total number of samples in your training data set divided by the batch size.</p>\n<p>For example, if you have 100000 training samples and use a batch size of 100, one epoch will be equivalent to 1000 steps_per_epoch.</p>\n<p><em>Note: We generally observe batch size to be the power of 2, this is because of the effective work of optimized matrix operation libraries.</em></p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9186}"
799,70880589,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1643296261, 'answer_id': 70880952, 'question_id': 70880589, 'body': '<p>The cardinality, in your case, is simply the rounded number of batches:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport pathlib\n\ndataset_url = &quot;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&quot;\ndata_dir = tf.keras.utils.get_file(\'flower_photos\', origin=dataset_url, untar=True)\ndata_dir = pathlib.Path(data_dir)\n\nbatch_size = 32\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=&quot;training&quot;,\n  seed=123,\n  image_size=(180, 180),\n  batch_size=batch_size)\n\nprint(train_ds.cardinality())\n</code></pre>\n<pre><code>Found 3670 files belonging to 5 classes.\nUsing 2936 files for training.\ntf.Tensor(92, shape=(), dtype=int64)\n</code></pre>\n<p>The equation is: <code>2936/32 = cardinality</code>, so it depends on your batch size.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9186}"
800,57138511,"{'items': [{'owner': {'reputation': 106, 'user_id': 8474650}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1563948231, 'answer_id': 57176224, 'question_id': 57138511, 'body': '<p>The following steps add a custom plugin layer in C++ for TensorFlow networks: </p>\n\n<ol>\n<li>Implement the IPluginV2 and IPluginCreator classes as shown in: <a href=""https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#example1_add_custlay_c"" rel=""nofollow noreferrer"">Adding A Custom Layer Using C++ For Caffe</a>.</li>\n<li>Map the TensorFlow operation to the plugin operation. You can use <a href=""https://docs.nvidia.com/deeplearning/sdk/tensorrt-api/python_api/graphsurgeon/graphsurgeon.html"" rel=""nofollow noreferrer"">GraphSurgeon</a> for this. </li>\n<li><p>Call the <a href=""https://docs.nvidia.com/deeplearning/sdk/tensorrt-api/python_api/uff/uff.html"" rel=""nofollow noreferrer"">UFF converter</a> with the preprocess -p flag set. This will generate a UFF file with the TensorFlow operations replaced by TensorRT plugin nodes.<code>\nconvert-to-uff frozen_inference_graph.pb -p config.py -t</code></p></li>\n<li><p>Run the pre-processed and converted UFF file with TensorRT using the UFF parser. For details, see <a href=""https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#using_custom_layer"" rel=""nofollow noreferrer"">Using Custom Layers When Importing A Model From A Framework</a>. <a href=""https://docs.nvidia.com/deeplearning/sdk/tensorrt-sample-support-guide/index.html#uffssd_sample"" rel=""nofollow noreferrer"">The Object Detection With A TensorFlow SSD Network</a> sample illustrates how to add a custom layer that is not supported in UFF using C++. See config.py in the sample folder for a demonstration of how to pre-process the graph.</p></li>\n</ol>\n\n<p>Although the C++ API is the preferred language to implement custom layers; due to easily accessing libraries like CUDA and cuDNN, you can also work with custom layers in Python applications. You can follow <a href=""https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#add_custom_layer_python"" rel=""nofollow noreferrer"">Adding Custom Layers Using The Python API</a> guide. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9183}"
801,56419668,"{'items': [{'owner': {'reputation': 1848, 'user_id': 1140684}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1559520171, 'answer_id': 56419842, 'question_id': 56419668, 'body': '<p>I recently looked at <code>tf probability</code>, the new place for <code>tf distributions</code>. This is my understanding:</p>\n\n<p>They are not the same. <code>tf.distributions.Normal</code> will give you a distribution object from which you can sample (this will be same as evaluating the tensor returned by <code>tf.random.normal</code> function call for the same mean and loc values). But, a distribution additionally allows you to evaluate probability of a sample that you provide and all the aspects of having access to a distribution.</p>\n\n<p>For example, you could do the following:</p>\n\n<pre><code>&gt;&gt;&gt; import tensorflow as tf\n&gt;&gt;&gt; dist = tf.distributions.Normal(loc=0., scale=1.)\n&gt;&gt;&gt; dist.log_prob(tf.random.normal(shape=(3,3)))\n&lt;tf.Tensor: id=58, shape=(3, 3), dtype=float32, numpy=\narray([[-0.9486696 , -0.95645994, -1.1610177 ],\n       [-1.244764  , -1.416851  , -1.1236244 ],\n       [-0.9292835 , -0.98901427, -0.9705758 ]], dtype=float32)&gt;\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9183}"
802,56386901,"{'items': [{'owner': {'reputation': 6124, 'user_id': 5561472}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1635661874, 'answer_id': 69784443, 'question_id': 56386901, 'body': ""<p>I've changed @Illuminati0x5B, @VigneshKumar code to calculate the average with tf2.0.</p>\n<pre><code>ids = [1, 2, 3, 1, 2, 3]\nfeatures = [1, 2.2, 7, 3.0, 2, 3]\n\n# Define reducer\n# Reducer requires 3 functions - init_func, reduce_func, finalize_func. \n# init_func - to define initial value\n# reducer_func - operation to perform on values with same key\n# finalize_func - value to return in the end.\ndef init_func(_):\n    return (0.0, 0.0)\n\ndef reduce_func(state, value):\n    return (state[0] + value['features'], state[1] + 1)\n\ndef finalize_func(s, n):\n    return s / n\n\nreducer = tf.data.experimental.Reducer(init_func, reduce_func, finalize_func)\n\n# Group by reducer\n# Group the data by id\ndef key_f(row):\n  return tf.dtypes.cast(row['ids'], tf.int64)\n\nt = tf.data.experimental.group_by_reducer(\n        key_func = key_f,\n        reducer = reducer)\n\nds = tf.data.Dataset.from_tensor_slices({'ids':ids, 'features' : features})\nds = ds.apply(t)\nds = ds.batch(6)\n\niterator = tf.compat.v1.data.make_one_shot_iterator(ds)\ndata = iterator.get_next()\nprint(data)\n</code></pre>\n""}, {'owner': {'reputation': 11, 'user_id': 10986595}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1591587892, 'answer_id': 62254681, 'question_id': 56386901, 'body': ""<p>I tweaked @Illuminati0x5B code to work with tf2.0. Thanks @Illuminati0x5B, your sample code is really helpful.</p>\n\n<p>TensorFlow Code(tweaked):</p>\n\n<pre><code>ids = [1, 2, 3, 1, 2, 3]\nfeatures = [1, 2.2, 7, 3.0, 2, 3]\n\n# Define reducer\n# Reducer requires 3 functions - init_func, reduce_func, finalize_func. \n# init_func - to define initial value\n# reducer_func - operation to perform on values with same key\n# finalize_func - value to return in the end.\ndef init_func(_):\n    return 0.0\n\ndef reduce_func(state, value):\n    return state + value['features']\n\ndef finalize_func(state):\n    return state\n\nreducer = tf.data.experimental.Reducer(init_func, reduce_func, finalize_func)\n\n# Group by reducer\n# Group the data by id\ndef key_f(row):\n  return tf.dtypes.cast(row['ids'], tf.int64)\n\nt = tf.data.experimental.group_by_reducer(\n        key_func = key_f,\n        reducer = reducer)\n\nds = tf.data.Dataset.from_tensor_slices({'ids':ids, 'features' : features})\nds = ds.apply(t)\nds = ds.batch(6)\n\niterator = tf.compat.v1.data.make_one_shot_iterator(ds)\ndata = iterator.get_next()\nprint(data)\n</code></pre>\n""}, {'owner': {'reputation': 602, 'user_id': 3016483}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1559277048, 'answer_id': 56388689, 'question_id': 56386901, 'body': ""<p>Say we are provided with a dataset with <code>['ids', 'features']</code> and we want to group the data by adding <code>'features'</code> corresponding to same <code>'ids'</code>. We can use <code>tf.group_by_reducer(key_func, reducer)</code> to achieve this. </p>\n\n<p>Raw data</p>\n\n<pre><code>ids | features\n--------------\n1   | 1\n2   | 2.2\n3   | 7\n1   | 3.0\n2   | 2\n3   | 3\n</code></pre>\n\n<p>Desired data</p>\n\n<pre><code>ids | features\n--------------\n1   | 4\n2   | 4.2\n3   | 10\n</code></pre>\n\n<p>TensorFlow Code:</p>\n\n<pre><code>import tensorflow as tf\ntf.enable_eager_execution()\n\nids = [1, 2, 3, 1, 2, 3]\nfeatures = [1, 2.2, 7, 3.0, 2, 3]\n\n# Define reducer\n# Reducer requires 3 functions - init_func, reduce_func, finalize_func. \n# init_func - to define initial value\n# reducer_func - operation to perform on values with same key\n# finalize_func - value to return in the end.\ndef init_func(_):\n    return 0.0\n\ndef reduce_func(state, value):\n    return state + value['features']\n\ndef finalize_func(state):\n    return state\n\nreducer = tf.contrib.data.Reducer(init_func, reduce_func, finalize_func)\n\n# Group by reducer\n# Group the data by id\ndef key_f(row):\nreturn tf.to_int64(row['ids'])\n\nt = tf.contrib.data.group_by_reducer(\n        key_func = key_f,\n        reducer = reducer)\n\nds = tf.data.Dataset.from_tensor_slices({'ids':ids, 'features' : features})\nds = ds.apply(t)\nds = ds.batch(6)\n\niterator = ds.make_one_shot_iterator()\ndata = iterator.get_next()\nprint(data)\n</code></pre>\n\n<p>Consider ids == 1. We set our initial value to 0 using <code>init_func</code>. The <code>reducer_func</code> will perform <code>0 + 1</code> and <code>1 + 3.0</code> operation and <code>finalize_func</code> will return 4.0.</p>\n\n<p>In group_by_reducer function, <code>key_func</code> is a function which returns a key for that data row. Key should be Int64. In our case, we use 'ids' as our key.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9181}"
803,34870614,"{'items': [{'owner': {'reputation': 35, 'user_id': 19155489}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1661518992, 'answer_id': 73501463, 'question_id': 34870614, 'body': ""<p>The existing explanations are not enough.\nThe main purpose of this function is to efficiently retrieve the vectors for each word in a given sequence of word indices. Suppose we have the following matrix of embeddings:</p>\n<pre><code>embds = np.array([[0.2, 0.32,0.9],\n        [0.8, 0.62,0.19],\n        [0.0, -0.22,-1.9],\n        [1.2, 2.32,6.0],\n        [0.11, 0.10,5.9]])\n</code></pre>\n<p>Let's say we have the following sequences of word indices:</p>\n<pre><code>data=[[0,1],\n     [3,4]]\n</code></pre>\n<p>Now to get the corresponding embedding for each word in our data:</p>\n<pre><code>tf.nn.embedding_lookup(\n    embds, data\n)\n</code></pre>\n<p>out:</p>\n<pre><code>array([[[0.2 , 0.32, 0.9 ],\n        [0.8 , 0.62, 0.19]],\n\n       [[1.2 , 2.32, 6.  ],\n        [0.11, 0.1 , 5.9 ]]])&gt;\n</code></pre>\n<p><strong>Note</strong> If embds are not an array or tensor, the output will not be like this (I won't go into details). For example, if embds were a list, the output would be:</p>\n<pre><code>array([[0.2 , 0.32],\n       [0.8 , 0.62]], dtype=float32)&gt;\n</code></pre>\n""}, {'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 18, 'is_accepted': False, 'score': 18, 'creation_date': 1533469593, 'answer_id': 51694027, 'question_id': 34870614, 'body': '<p>Here\'s an image depicting the process of embedding lookup. </p>\n\n<p><img src=""https://i.stack.imgur.com/5wFii.jpg"" alt=""Image: Embedding lookup process"">\n<br/>\n<br/>\nConcisely, it gets the corresponding rows of a embedding layer, specified by a list of IDs and provide that as a tensor. It is achieved through the following process.</p>\n\n<ol>\n<li>Define a placeholder <code>lookup_ids = tf.placeholder([10])</code></li>\n<li>Define a embedding layer <code>embeddings = tf.Variable([100,10],...)</code></li>\n<li>Define the tensorflow operation <code>embed_lookup = tf.embedding_lookup(embeddings, lookup_ids)</code></li>\n<li>Get the results by running <code>lookup = session.run(embed_lookup, feed_dict={lookup_ids:[95,4,14]})</code></li>\n</ol>\n'}, {'owner': {'reputation': 58189, 'user_id': 2956066}, 'down_vote_count': 0, 'up_vote_count': 49, 'is_accepted': False, 'score': 49, 'creation_date': 1516868047, 'answer_id': 48438325, 'question_id': 34870614, 'body': '<p>Yes, the purpose of <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup"" rel=""noreferrer""><strong><code>tf.nn.embedding_lookup()</code></strong></a> function is to perform a <em>lookup</em> in the <em>embedding matrix</em> and return the embeddings (or in simple terms the vector representation) of words.</p>\n<p>A simple embedding matrix (of shape: <strong><code>vocabulary_size x embedding_dimension</code></strong>) would look like below. (i.e. each <em>word</em> will be represented by a <em>vector</em> of numbers; hence the name <em>word2vec</em>)</p>\n<hr />\n<p><strong>Embedding Matrix</strong></p>\n<pre><code>the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862\nlike 0.36808 0.20834 -0.22319 0.046283 0.20098 0.27515 -0.77127 -0.76804\nbetween 0.7503 0.71623 -0.27033 0.20059 -0.17008 0.68568 -0.061672 -0.054638\ndid 0.042523 -0.21172 0.044739 -0.19248 0.26224 0.0043991 -0.88195 0.55184\njust 0.17698 0.065221 0.28548 -0.4243 0.7499 -0.14892 -0.66786 0.11788\nnational -1.1105 0.94945 -0.17078 0.93037 -0.2477 -0.70633 -0.8649 -0.56118\nday 0.11626 0.53897 -0.39514 -0.26027 0.57706 -0.79198 -0.88374 0.30119\ncountry -0.13531 0.15485 -0.07309 0.034013 -0.054457 -0.20541 -0.60086 -0.22407\nunder 0.13721 -0.295 -0.05916 -0.59235 0.02301 0.21884 -0.34254 -0.70213\nsuch 0.61012 0.33512 -0.53499 0.36139 -0.39866 0.70627 -0.18699 -0.77246\nsecond -0.29809 0.28069 0.087102 0.54455 0.70003 0.44778 -0.72565 0.62309 \n</code></pre>\n<hr />\n<p>I split the above embedding matrix and loaded only the <em>words</em> in <code>vocab</code> which will be our vocabulary and the corresponding vectors in <code>emb</code> array.</p>\n<pre><code>vocab = [\'the\',\'like\',\'between\',\'did\',\'just\',\'national\',\'day\',\'country\',\'under\',\'such\',\'second\']\n\nemb = np.array([[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -0.044457, -0.49688, -0.17862],\n   [0.36808, 0.20834, -0.22319, 0.046283, 0.20098, 0.27515, -0.77127, -0.76804],\n   [0.7503, 0.71623, -0.27033, 0.20059, -0.17008, 0.68568, -0.061672, -0.054638],\n   [0.042523, -0.21172, 0.044739, -0.19248, 0.26224, 0.0043991, -0.88195, 0.55184],\n   [0.17698, 0.065221, 0.28548, -0.4243, 0.7499, -0.14892, -0.66786, 0.11788],\n   [-1.1105, 0.94945, -0.17078, 0.93037, -0.2477, -0.70633, -0.8649, -0.56118],\n   [0.11626, 0.53897, -0.39514, -0.26027, 0.57706, -0.79198, -0.88374, 0.30119],\n   [-0.13531, 0.15485, -0.07309, 0.034013, -0.054457, -0.20541, -0.60086, -0.22407],\n   [ 0.13721, -0.295, -0.05916, -0.59235, 0.02301, 0.21884, -0.34254, -0.70213],\n   [ 0.61012, 0.33512, -0.53499, 0.36139, -0.39866, 0.70627, -0.18699, -0.77246 ],\n   [ -0.29809, 0.28069, 0.087102, 0.54455, 0.70003, 0.44778, -0.72565, 0.62309 ]])\n\n\nemb.shape\n# (11, 8)\n</code></pre>\n<hr />\n<p><strong>Embedding Lookup in TensorFlow</strong></p>\n<p>Now we will see how can we perform <em>embedding lookup</em> for some arbitrary input sentence.</p>\n<pre><code>In [54]: from collections import OrderedDict\n\n# embedding as TF tensor (for now constant; could be tf.Variable() during training)\nIn [55]: tf_embedding = tf.constant(emb, dtype=tf.float32)\n\n# input for which we need the embedding\nIn [56]: input_str = &quot;like the country&quot;\n\n# build index based on our `vocabulary`\nIn [57]: word_to_idx = OrderedDict({w:vocab.index(w) for w in input_str.split() if w in vocab})\n\n# lookup in embedding matrix &amp; return the vectors for the input words\nIn [58]: tf.nn.embedding_lookup(tf_embedding, list(word_to_idx.values())).eval()\nOut[58]: \narray([[ 0.36807999,  0.20834   , -0.22318999,  0.046283  ,  0.20097999,\n         0.27515   , -0.77126998, -0.76804   ],\n       [ 0.41800001,  0.24968   , -0.41242   ,  0.1217    ,  0.34527001,\n        -0.044457  , -0.49687999, -0.17862   ],\n       [-0.13530999,  0.15485001, -0.07309   ,  0.034013  , -0.054457  ,\n        -0.20541   , -0.60086   , -0.22407   ]], dtype=float32)\n</code></pre>\n<p>Observe how we got the <em>embeddings</em> from our original embedding matrix (with words) using the <em>indices of words</em> in our vocabulary.</p>\n<p>Usually, such an embedding lookup is performed by the first layer (called <em>Embedding layer</em>) which then passes these embeddings to RNN/LSTM/GRU layers for further processing.</p>\n<hr />\n<p><em>Side Note</em>: Usually the vocabulary will also have a special <code>unk</code> token. So, if a token from our input sentence is not present in our vocabulary, then the index corresponding to <strong><code>unk</code></strong> will be looked up in the embedding matrix.</p>\n<hr />\n<p><strong>P.S.</strong> Note that <code>embedding_dimension</code> is a hyperparameter that one has to tune for their application but popular models like <strong><a href=""https://en.wikipedia.org/wiki/Word2vec"" rel=""noreferrer"">Word2Vec</a></strong> and <strong><a href=""https://nlp.stanford.edu/projects/glove/"" rel=""noreferrer"">GloVe</a></strong> uses <code>300</code> dimension vector for representing each word.</p>\n<p><strong>Bonus Reading</strong> <a href=""http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/"" rel=""noreferrer"">word2vec skip-gram model</a></p>\n'}, {'owner': {'reputation': 37, 'user_id': 4585592}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1517524112, 'answer_id': 48572802, 'question_id': 34870614, 'body': ""<p>Since I was also intrigued by this function, I'll give my two cents.</p>\n\n<p>The way I see it in the 2D case is just as a matrix multiplication (it's easy to generalize to other dimensions).</p>\n\n<p>Consider a vocabulary with N symbols.\nThen, you can represent a symbol <strong><em>x</em></strong> as a vector of dimensions Nx1, one-hot-encoded.</p>\n\n<p>But you want a representation of this symbol not as a vector of Nx1, but as one with dimensions Mx1, called <strong><em>y</em></strong>.</p>\n\n<p>So, to transform <strong><em>x</em></strong> into <strong><em>y</em></strong>, you can use and embedding matrix <strong>E</strong>, with dimensions MxN: </p>\n\n<p><strong><em>y</em></strong> = <strong>E</strong> <strong><em>x</em></strong>.</p>\n\n<p>This is essentially what tf.nn.embedding_lookup(params, ids, ...) is doing, with the nuance that <em>ids</em> are just one number that represents the position of the 1 in the one-hot-encoded vector <strong><em>x</em></strong>.</p>\n""}, {'owner': {'reputation': 459, 'user_id': 8185944}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': False, 'score': 7, 'creation_date': 1511579707, 'answer_id': 47482287, 'question_id': 34870614, 'body': ""<p>When the params tensor is in high dimensions, the ids only refers to top dimension. Maybe it's obvious to most of people but I have to run the following code to understand that:</p>\n\n<pre><code>embeddings = tf.constant([[[1,1],[2,2],[3,3],[4,4]],[[11,11],[12,12],[13,13],[14,14]],\n                          [[21,21],[22,22],[23,23],[24,24]]])\nids=tf.constant([0,2,1])\nembed = tf.nn.embedding_lookup(embeddings, ids, partition_strategy='div')\n\nwith tf.Session() as session:\n    result = session.run(embed)\n    print (result)\n</code></pre>\n\n<p>Just trying the 'div' strategy and for one tensor, it makes no difference.</p>\n\n<p>Here is the output:</p>\n\n<pre><code>[[[ 1  1]\n  [ 2  2]\n  [ 3  3]\n  [ 4  4]]\n\n [[21 21]\n  [22 22]\n  [23 23]\n  [24 24]]\n\n [[11 11]\n  [12 12]\n  [13 13]\n  [14 14]]]\n</code></pre>\n""}, {'owner': {'reputation': 6215, 'user_id': 5543198}, 'down_vote_count': 3, 'up_vote_count': 153, 'is_accepted': True, 'score': 150, 'creation_date': 1453208706, 'answer_id': 34877590, 'question_id': 34870614, 'body': '<p><code>embedding_lookup</code> function retrieves rows of the <code>params</code> tensor. The behavior is similar to using indexing with arrays in numpy. E.g.</p>\n\n<pre><code>matrix = np.random.random([1024, 64])  # 64-dimensional embeddings\nids = np.array([0, 5, 17, 33])\nprint matrix[ids]  # prints a matrix of shape [4, 64] \n</code></pre>\n\n<p><code>params</code> argument can be also a list of tensors in which case the <code>ids</code> will be distributed among the tensors. For example, given a list of 3 tensors <code>[2, 64]</code>, the default behavior is that they will represent <code>ids</code>: <code>[0, 3]</code>, <code>[1, 4]</code>, <code>[2, 5]</code>. </p>\n\n<p><code>partition_strategy</code> controls the way how the <code>ids</code> are distributed among the list. The partitioning is useful for larger scale problems when the matrix might be too large to keep in one piece.</p>\n'}, {'owner': {'reputation': 2486, 'user_id': 4949974}, 'down_vote_count': 0, 'up_vote_count': 233, 'is_accepted': False, 'score': 233, 'creation_date': 1485705781, 'answer_id': 41922877, 'question_id': 34870614, 'body': ""<p>Yes, this function is hard to understand, until you get the point.</p>\n\n<p>In its simplest form, it is similar to <code>tf.gather</code>. It returns the elements of <code>params</code> according to the indexes specified by <code>ids</code>.</p>\n\n<p>For example (assuming you are inside <code>tf.InteractiveSession()</code>)</p>\n\n<pre><code>params = tf.constant([10,20,30,40])\nids = tf.constant([0,1,2,3])\nprint tf.nn.embedding_lookup(params,ids).eval()\n</code></pre>\n\n<p>would return <code>[10 20 30 40]</code>, because the first element (index 0) of params is <code>10</code>, the second element of params (index 1) is <code>20</code>, etc.</p>\n\n<p>Similarly, </p>\n\n<pre><code>params = tf.constant([10,20,30,40])\nids = tf.constant([1,1,3])\nprint tf.nn.embedding_lookup(params,ids).eval()\n</code></pre>\n\n<p>would return <code>[20 20 40]</code>.</p>\n\n<p>But <code>embedding_lookup</code> is more than that. The <code>params</code> argument can be a <strong>list</strong> of tensors, rather than a single tensor.</p>\n\n<pre><code>params1 = tf.constant([1,2])\nparams2 = tf.constant([10,20])\nids = tf.constant([2,0,2,1,2,3])\nresult = tf.nn.embedding_lookup([params1, params2], ids)\n</code></pre>\n\n<p>In such a case, the indexes, specified in <code>ids</code>, correspond to elements of tensors according to a <strong>partition strategy</strong>, where the default partition strategy is 'mod'.</p>\n\n<p>In the 'mod' strategy, index 0 corresponds to the first element of the first tensor in the list. Index 1 corresponds to the <strong>first</strong> element of the <strong>second</strong> tensor. Index 2 corresponds to the <strong>first</strong> element of the <strong>third</strong> tensor, and so on. Simply index <code>i</code> corresponds to the first element of the (i+1)th tensor , for all the indexes <code>0..(n-1)</code>, assuming params is a list of <code>n</code> tensors.</p>\n\n<p>Now, index <code>n</code> cannot correspond to tensor n+1, because the list <code>params</code> contains only <code>n</code> tensors. So index <code>n</code> corresponds to the <strong>second</strong> element of the first tensor. Similarly, index <code>n+1</code> corresponds to the second element of the second tensor, etc.</p>\n\n<p>So, in the code</p>\n\n<pre><code>params1 = tf.constant([1,2])\nparams2 = tf.constant([10,20])\nids = tf.constant([2,0,2,1,2,3])\nresult = tf.nn.embedding_lookup([params1, params2], ids)\n</code></pre>\n\n<p>index 0 corresponds to the first element of the first tensor: 1</p>\n\n<p>index 1 corresponds to the first element of the second tensor: 10</p>\n\n<p>index 2 corresponds to the second element of the first tensor: 2</p>\n\n<p>index 3 corresponds to the second element of the second tensor: 20</p>\n\n<p>Thus, the result would be:</p>\n\n<pre><code>[ 2  1  2 10  2 20]\n</code></pre>\n""}, {'owner': {'reputation': 31, 'user_id': 6126756}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1509062757, 'answer_id': 46965588, 'question_id': 34870614, 'body': '<p>Another way to look at it is , assume that you flatten out the tensors to one dimensional array, and then you are performing a lookup</p>\n\n<p>(eg) Tensor0=[1,2,3], Tensor1=[4,5,6], Tensor2=[7,8,9]</p>\n\n<p>The flattened out tensor will be as follows\n[1,4,7,2,5,8,3,6,9]</p>\n\n<p>Now when you do a lookup of [0,3,4,1,7] it will yeild [1,2,5,4,6]</p>\n\n<p>(i,e) if lookup value is 7 for example , and we have 3 tensors (or a tensor with 3 rows) then, </p>\n\n<p>7 / 3 : (Reminder is 1, Quotient is 2) So 2nd element of Tensor1 will be shown, which is 6 </p>\n'}, {'owner': {'reputation': 21007, 'user_id': 3907250}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1502926273, 'answer_id': 45724451, 'question_id': 34870614, 'body': ""<p>Adding to Asher Stern's answer,\n <code>params</code> is\n  interpreted as a <strong>partitioning</strong> of a large embedding tensor. It can be a  single tensor representing the complete embedding tensor,\n      or a list of X tensors all of same shape except for the first dimension,\n      representing sharded embedding tensors. </p>\n\n<p>The function <code>tf.nn.embedding_lookup</code> is written considering the fact that embedding (params) will be large. Therefore we need <code>partition_strategy</code>.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9181}"
804,59729239,"{'items': [{'owner': {'reputation': 14062, 'user_id': 6117017}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1578987823, 'answer_id': 59729350, 'question_id': 59729239, 'body': '<p>I think that what you are looking for is here: <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM2D?version=stable"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM2D?version=stable</a></p>\n\n<p>You can import it in your code like: </p>\n\n<pre><code>import tensorflow as tf\nconv_lstm_layer = tf.keras.layers.ConvLSTM2D(my_parameters)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9181}"
805,52827483,"{'items': [{'owner': {'reputation': 31, 'user_id': 7547975}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1539669975, 'answer_id': 52828877, 'question_id': 52827483, 'body': ""<p>One potential solution I realized is <code>tf.where</code>:</p>\n\n<pre><code>import tensorflow as tf\n\nseq_len = 10\nbatch_size = 4\n\noutput_ta = tf.TensorArray(\n    dtype=tf.float32,\n    size=seq_len,\n    tensor_array_name='example_1')\n\ncond_tensor = tf.constant([3, 4, 5, 6])\n\nt1 = tf.ones(shape=[batch_size, seq_len])\nt2 = tf.zeros(shape=[batch_size, seq_len])\n\n\ndef _step(time, arrays):\n    time_tensor = tf.tile(tf.expand_dims(time, -1), multiples=[batch_size])\n    # arrays = arrays\n\n    bool_cond = tf.less(time_tensor, cond_tensor)\n    output_array = tf.where(bool_cond, t1, t2)\n    # arrays_write = tf.cond(bool_cond, true_fn=_true_function, false_fn=_false_function)\n    arrays = arrays.write(time, output_array)\n    return time + 1, arrays\n\n\ntrace_time, outputs_tensor_arrays = tf.while_loop(\n    cond=lambda time, *_: time &lt; seq_len,\n    body=_step,\n    loop_vars=[0, output_ta],\n    parallel_iterations=32,\n    swap_memory=True)\n\naxes = [1, 0, 2]\noutput = outputs_tensor_arrays.stack()\noutput = tf.transpose(output, axes)\n\nwith tf.Session() as sess:\n    r_output = sess.run(output)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9181}"
806,67308892,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9177}"
807,55731549,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9177}"
808,64474463,"{'items': [{'owner': {'reputation': 14062, 'user_id': 6117017}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1603352845, 'answer_id': 64477588, 'question_id': 64474463, 'body': ""<p>You can use <code>tensorflow-addons</code> which has a built-in method for F1-Score. (don't forget to <code>pip install tensorflow-addons</code>)</p>\n<p>Have a look below:</p>\n<pre><code>  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n                  loss=tf.keras.losses.CategoricalCrossentropy(),\n                  metrics=[tf.keras.metrics.CategoricalAccuracy(),\n                           tfa.metrics.F1Score(num_classes=n_classes, average='macro'),\n                           tfa.metrics.FBetaScore(beta=2.0, num_classes=n_classes, average='macro')])\n</code></pre>\n<p>If you do have a multi-label classification problem, you can change it to:</p>\n<pre><code>  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n                      loss=tf.keras.losses.BinaryCrossentropy(),\n                      metrics=[tf.keras.metrics.BinaryAccuracy(),\n                               tfa.metrics.F1Score(num_classes=1, average='macro',threshold=0.5),\n                               tfa.metrics.FBetaScore(beta=2.0, num_classes=1, average='macro',threshold=0.5)])\n</code></pre>\n""}, {'owner': {'reputation': 1, 'user_id': 4855112}, 'down_vote_count': 2, 'up_vote_count': 0, 'is_accepted': False, 'score': -2, 'creation_date': 1607375209, 'answer_id': 65189399, 'question_id': 64474463, 'body': ""<p>This is my code scoring f1 for Tensorflow 2.0:</p>\n<pre><code>class F1Score(tf.keras.metrics.Metric):\n  def __init__(self, name='F1Score', **kwargs):\n    super(F1Score, self).__init__(name=name, **kwargs)\n    self.f1score = self.add_weight(name='F1Score', initializer='zeros')\n    self.count = self.add_weight(name='F1ScoreCount', initializer='zeros')\n\n  def update_state(self, y_true, y_pred, sample_weight=None):\n    y_true = tf.cast(y_true, tf.bool)\n    y_pred = tf.cast(y_pred, tf.bool)\n\n    true_positives = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n    true_positives = tf.cast(true_positives, self.dtype)\n    count_true_positives = tf.reduce_sum(true_positives)\n\n    possible_positives = tf.cast(y_true, self.dtype)\n    count_possible_positives = tf.reduce_sum(possible_positives)\n\n    predicted_positives = tf.cast(y_pred, self.dtype)\n    count_predicted_positives = tf.reduce_sum(predicted_positives)\n\n    precision = count_true_positives / (count_predicted_positives + K.epsilon())\n    recall = count_true_positives / (count_possible_positives + K.epsilon())\n    f1_cal = 2*(precision*recall)/(precision + recall + K.epsilon())\n\n    self.count.assign_add(1)\n    a = 1.0 / self.count\n    b = 1.0 - a\n    self.f1score.assign(a*f1_cal+b*self.f1score)\n\n  def result(self):\n    return self.f1score\n</code></pre>\n""}, {'owner': {'reputation': 10889, 'user_id': 7370153}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1603352631, 'answer_id': 64477522, 'question_id': 64474463, 'body': '<p>You get this error because you want to instantiate some <code>tf.Variable</code>s during the update_state function. When instantiate object from the class Precision and Recall, you are creating some <code>tf.Variable</code>s.</p>\n<p>Instantiate the objects in the constructor, and call them in the update_state function:</p>\n<pre class=""lang-py prettyprint-override""><code>class F1_Score(tf.keras.metrics.Metric):\n\n    def __init__(self, name=\'f1_score\', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.f1 = self.add_weight(name=\'f1\', initializer=\'zeros\')\n        self.precision_fn = Precision(thresholds=0.5)\n        self.recall_fn = Recall(thresholds=0.5)\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        p = self.precision_fn(y_true, y_pred)\n        r = self.recall_fn(y_true, y_pred)\n        # since f1 is a variable, we use assign\n        self.f1.assign(2 * ((p * r) / (p + r + 1e-6)))\n\n    def result(self):\n        return self.f1\n\n    def reset_states(self):\n        # we also need to reset the state of the precision and recall objects\n        self.precision_fn.reset_states()\n        self.recall_fn.reset_states()\n        self.f1.assign(0)\n</code></pre>\n<hr />\n<p><strong>Explanation of the behavior :</strong></p>\n<p>Tensorflow allow to create Variable only on the first call of a <code>tf.function</code>, see the <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""nofollow noreferrer"">documentation</a> :</p>\n<blockquote>\n<p>tf.function only allows creating new tf.Variable objects when it is called for the first time</p>\n</blockquote>\n<p>Keras metrics are wrapped in a tf.function to allow compatibility with tensorflow v1. You can find this comment in the <a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/metrics.py#L81-L314"" rel=""nofollow noreferrer"">code</a></p>\n<blockquote>\n<p>If <code>update_state</code> is not in eager/tf.function and it is not from a\nbuilt-in metric, wrap it in <code>tf.function</code>. This is so that users writing\ncustom metrics in v1 need not worry about control dependencies and\nreturn ops.</p>\n</blockquote>\n<p>You also have another bug in your class, is that you override the <code>f1 tf.Variable</code> that you created with the calculation of your f1 score. To update the value of a variable, you need to use <code>assign</code>. And we must not forget to reset the states of the Precision and Recall Metrics objects in use!</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9177}"
809,42933599,"{'items': [{'owner': {'reputation': 1605, 'user_id': 4567324}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1490116119, 'answer_id': 42933837, 'question_id': 42933599, 'body': '<p>Here is how you do it:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nt = t = tf.pack(np.random.randint(1,10,[32,32,32,1]))\nhalf1 = tf.slice(t,[0,0,0,0],[16,32,32,1])\nhalf2 = tf.slice(t,[16,0,0,0],[16,32,32,1])\n</code></pre>\n\n<p><code>[0,0,0,0]</code> means start from the very first element in each dimension, [<code>16,32,32,1]</code> means size in first dimension is 16 and for the others 32, 32, 1. It basically means get the first half with regard to first dimension and for all other dimensions get all elements.</p>\n'}, {'owner': {'reputation': 4261, 'user_id': 5016028}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1490115971, 'answer_id': 42933789, 'question_id': 42933599, 'body': '<p>Turns out tensorflow does not require you to use tf.slice since you can simply use numpy slicing:</p>\n\n<pre><code>first_half = input[:16]\nsecond_half = input[16:]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9177}"
810,65547615,"{'items': [{'owner': {'reputation': 1030, 'user_id': 3926152}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1609660765, 'answer_id': 65547742, 'question_id': 65547615, 'body': '<p>To be more precise, you can create variables inside a @tf.function decorated method, as long as your variable is created only once.\nHere is an example:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nclass YourClass:\n    def __init__(self):\n        self.first = True\n\n    @tf.function\n    def your_function(self):\n\n        if self.first == True:\n            self.first = False\n            self.your_variable = tf.Variable([0]) \n\nc = YourClass()\nc.your_function()\n</code></pre>\n<p>******** UPDATED ************</p>\n<p>Since you mentioned you just want to update, not actually create, you could use tf.assign</p>\n<p>Code below</p>\n<pre><code>import tensorflow as tf\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nclass YourClass:\n    def __init__(self):\n        self.your_variable = tf.Variable([0])\n\n    @tf.function\n    def your_function(self):\n\n        tf.compat.v1.assign(self.your_variable,value=[1]) \n\nc = YourClass()\nc.your_function()\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9177}"
811,63096162,"{'items': [{'owner': {'reputation': 63, 'user_id': 12238214}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1671712615, 'answer_id': 74888622, 'question_id': 63096162, 'body': '<p>You could also make use reshape:</p>\n<pre><code>tf.reshape(y, shape=tf.concat([tf.shape(y),  tf.ones(tf.rank(x) - 2)], 0))\n</code></pre>\n'}, {'owner': {'reputation': 11, 'user_id': 18288541}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1645617207, 'answer_id': 71236459, 'question_id': 63096162, 'body': '<p>I had a similar issue and the following solution worked for me:</p>\n<pre><code>rank_diff = tf.rank(x) - tf.rank(y)\ny = y[(...,) + rank_diff * (tf.newaxis,)]\n</code></pre>\n'}, {'owner': {'reputation': 3156, 'user_id': 1217998}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1595821527, 'answer_id': 63108395, 'question_id': 63096162, 'body': '<p>After much headbanging this is what I came up with. Not the most performant, but it does the job. I wish tensorflow had inbuilt support for this. Numpy already does.</p>\n<pre class=""lang-py prettyprint-override""><code>@tf.function\ndef match_shapes(x, y):\n    # Find which one needs to be broadcasted\n    low, high = (y, x) if tf.rank(x) &gt; tf.rank(y) else (x, y)\n    l_rank, l_shape = tf.rank(low), tf.shape(low)\n    h_rank, h_shape = tf.rank(high), tf.shape(high)\n    \n    # Find the difference in ranks\n    common_shape = h_shape[:l_rank]\n    tf.debugging.assert_equal(common_shape, l_shape, \'No common shape to broadcast\')\n    padding = tf.ones(h_rank - l_rank, dtype=tf.int32)\n    \n    # Pad the difference with ones and reshape\n    new_shape = tf.concat((common_shape, padding),axis=0)\n    low = tf.reshape(low, new_shape)\n\n    return high, low\n\n@tf.function\ndef broadcast_multiply(x, y):\n    x, y = match_shapes(x, y)\n    return x * y\n    \nx = tf.ones((3, 3, 2)) * 3\ny = tf.ones((3, 3)) * 2\nbroadcast_multiply(x, y)\n</code></pre>\n<p>Result</p>\n<pre><code>&lt;tf.Tensor: shape=(3, 3, 2), dtype=float32, numpy=\narray([[[6., 6.],\n        [6., 6.],\n        [6., 6.]],\n\n       [[6., 6.],\n        [6., 6.],\n        [6., 6.]],\n\n       [[6., 6.],\n        [6., 6.],\n        [6., 6.]]], dtype=float32)&gt;\n</code></pre>\n'}, {'owner': {'reputation': 3689, 'user_id': 5533928}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1595794138, 'answer_id': 63105166, 'question_id': 63096162, 'body': '<p>You should check out <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/broadcast_to"" rel=""nofollow noreferrer""><code>tf.broadcast_to</code></a></p>\n<pre><code>def broadcast_multiply(x, y):\n    y = tf.broadcast_to(y, tf.shape(x))\n    return x * y\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9172}"
812,61273445,"{'items': [{'owner': {'reputation': 1233, 'user_id': 401884}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1587141253, 'answer_id': 61276402, 'question_id': 61273445, 'body': '<p>The error occurs because <code>get_label</code> performs an out-of-bounds list access</p>\n\n<pre><code>def get_label(file_path):\n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path)\n\n    # The second to last is the class-directory\n    return parts[-2] == CLASS_NAMES\n</code></pre>\n\n<p><code>parts</code> has size <code>1</code>. This is because <code>tf.strings.split</code> will split by whitespace unless you specify what delimiter to use. To split into path components, it should be <code>parts = tf.strings.split(file_path, ""/"")</code></p>\n\n<p>To debug this sort of issue, you can add <code>tf.print</code> statements to your functions, e.g. </p>\n\n<pre><code>def get_label(file_path):\n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path)\n\n    # The second to last is the class-directory\n    tf.print(file_path)\n    tf.print(len(parts))\n    return parts[-2] == CLASS_NAMES\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9172}"
813,66942311,"{'items': [{'owner': {'reputation': 741, 'user_id': 11245475}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1617577823, 'answer_id': 66946641, 'question_id': 66942311, 'body': '<pre><code>import tensorflow as tf\nx = tf.Variable([3.0, 2.0])\nwith tf.GradientTape() as g:\n  g.watch(x)\n  y = x * x\ndy_dx = g.gradient(y, x)\nprint(dy_dx)\nprint(y)\n\nResult: \ntf.Tensor([6. 4.], shape=(2,), dtype=float32)\ntf.Tensor([9. 4.], shape=(2,), dtype=float32)\n</code></pre>\n<p>As described in the figure above, <code>tf.GradientTape.gradient</code> simply calculates the gradient dy/dx. In your case with multiple variables, tf seems to calculate the derivative of the corresponding tensor instead of automatically summing them.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9172}"
814,43175272,"{'items': [{'owner': {'reputation': 5134, 'user_id': 6416660}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1491328907, 'answer_id': 43214452, 'question_id': 43175272, 'body': '<p>You can create a third placeholder variable of type boolean to select which branch to use and feed that in at run time.</p>\n\n<p>The logic behind it is that since you are feeding in the placholders at runtime anyways you can determine outside of tensorflow which placeholders will be fed.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9172}"
815,46759271,"{'items': [{'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1508098880, 'answer_id': 46759611, 'question_id': 46759271, 'body': ""<p>Values are into [0,1] because is what <code>tf.image.decode_*</code> methods do.</p>\n\n<p>In general, when a method returns a float tensor, its values are supposed to be in the [0,1] range, whilst if the returned tensor is a uint8 the values are supposed to be in the [0,255] range.</p>\n\n<p>Also, when you use the <code>tf.image.convert_image_dtype</code> method, to convert the dtype of the input image, you're applying that conversion rules.</p>\n\n<p>If your input image is a uint8 image and you convert it to a float32, the values are scaled in the [0,1] range. If your image is already a float, its values are supposed to be in that range and nothing is done.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9172}"
816,67523944,"{'items': [{'owner': {'reputation': 1, 'user_id': 8320002}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1664223325, 'answer_id': 73859511, 'question_id': 67523944, 'body': ""<p>The code works but is slow and GPU is under utilized. There is extra column to prevent windows that contains two different files, which for many problems could be removed. There are 3 columns feature1, feature2, feature3. The code returns windows of feature1 and feature2 and single point from feature3 but that could be easily adjusted. It is to predict value of feature3 based on feature1 and feature2.</p>\n<pre><code>def pack_features_vector(features):\n    features = tf.stack([tf.cast(x,tf.float32) for x in list(features.values())], axis=1)\n    return features\n\n\ndef read_dataset(file_path, min_array, max_array, shuffle_enabled=False, batch_size = 512, window_size=50, for_forecast=False,make_sequences=True):\n    \n    if min_array is None or max_array is None:\n        scaling_on = False\n    else:\n        scaling_on = True\n    \n    \n    if scaling_on:\n        # This is required for Normalization X-Min_X/(Max_X-Min_X) the first element is unique file id that we don't need to normalize as it\n        # is use for filtering and removing sequences that have mixed file ids so we do not cross data from different units\n        max_np = np.insert(max_array,0,1)\n        min_np = np.insert(min_array,0,0)\n        min_list = list(min_np)\n\n        denominator_list = list(max_np-min_np) # Need list that will be used to divide element wise for Normalization\n    \n    # Shuffle files\n    if shuffle_enabled:\n        shuffle(file_path)\n    \n    # Read csv files (cannot use parallel as it would mix samples, we can shuffle\n    building_dataset = tf.data.experimental.make_csv_dataset(file_pattern=file_path,\n                                                        batch_size=1024,num_epochs=1, shuffle=False,\n                                                        select_columns=['file_id','feature1','feature2','feature3'],\n                                                        num_parallel_reads=1)\n    \n   \n    building_dataset = building_dataset.map(pack_features_vector)\n    building_dataset = building_dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x))\n\n    if scaling_on:\n        building_dataset = building_dataset.map(lambda x: (x-min_list)/denominator_list)#/(np.array[1,105,1005,10005]-np.array[0,100,1000,10000]))\n     \n    # Make overlapping sequences and filter some that go over different files\n    if make_sequences:\n        building_dataset = building_dataset.window(window_size, shift=1, drop_remainder=True)\n        building_dataset = building_dataset.flat_map(lambda window: window.batch(window_size))\n\n        building_dataset = building_dataset.filter(lambda window: tf.reduce_sum(window[:-1,0]-window[1:,0])==0) # Check if windows is for single file_id (no crossing allowed) (column 0)\n\n        \n        if not for_forecast:\n            building_dataset = building_dataset.map(lambda window: (window[:,1:-1], window[-((window_size)//2),-1]))   #building_dataset = building_dataset.map(lambda window: (window[:,:-1], window[-1:,-1]))\n        else:\n            building_dataset = building_dataset.map(lambda window: window[:,1:-1])\n    else:\n        building_dataset = building_dataset.map(lambda x: x[1:])\n\n    if shuffle_enabled:\n        building_dataset = building_dataset.shuffle(1000)\n    \n    building_dataset = building_dataset.batch(batch_size)\n    \n    building_dataset = building_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    \n    return building_dataset\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9167}"
817,58113387,"{'items': [{'owner': {'reputation': 2457, 'user_id': 8842694}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': True, 'score': 8, 'creation_date': 1569493292, 'answer_id': 58114679, 'question_id': 58113387, 'body': '<p>You can replace it with, <code>tf.keras.optimizers.SGD()</code> defined <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers/SGD"" rel=""noreferrer"">here</a>.\n<a href=""https://www.tensorflow.org/beta/guide/migration_guide#keras_optimizers"" rel=""noreferrer"">Here</a> (skip to third point) is the official message, where TF team mentioned to use this keras optimizer. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9167}"
818,70747499,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1642453983, 'answer_id': 70747569, 'question_id': 70747499, 'body': '<p>You should make sure you are returning a tensor. Maybe concatenate or stack the list of values:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\ntensaki=tf.constant([[1., 2., 3.], [4., 5., 6.]])\n\ndef my_fun(x):\n    x = tf.stack([x[0], x[1]], axis=0)\n    return x\n\nprint(tf.map_fn(my_fun,tensaki))\n</code></pre>\n<pre><code>tf.Tensor(\n[[1. 2.]\n [4. 5.]], shape=(2, 2), dtype=float32)\n</code></pre>\n<p>Of course, it all depends on the output you are expecting.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9167}"
819,70219114,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1638780066, 'answer_id': 70242776, 'question_id': 70219114, 'body': '<p>You could just define a normal <code>Tensor</code> and update it with <code>tf.tensor_scatter_nd_update</code> like this:</p>\n<pre class=""lang-py prettyprint-override""><code>%tensorflow_version 1.x\n\nimport tensorflow as tf\n\ndata = tf.constant([1, 1, 1, 0, 1, 0, 1, 1, 0, 0], dtype=tf.float32)\ndata_tensor = tf.zeros_like(data)\ntensor_size = data_tensor.shape[0]\n\ninit_state = (0, data_tensor)\ncondition = lambda i, _: i &lt; tensor_size\n\ndef custom_body(i, tensor):\n  special_index = 3 # index for which a value should be changed\n  new_value = 8\n  tensor = tf.where(tf.equal(i, special_index), \n                    tf.tensor_scatter_nd_update(tensor, [[special_index]], [new_value]),\n                    tf.tensor_scatter_nd_update(tensor, [[i]], [data[i]*2]))\n\n  return i + 1, tensor\n\n\nbody = lambda i, tensor: (custom_body(i, tensor))\n_, final_result = tf.while_loop(condition, body, init_state)\n\nwith tf.Session() as sess:\n  final_result_values = final_result.eval()\n\nprint(final_result_values)\n</code></pre>\n<pre><code>[2. 2. 2. 8. 2. 0. 2. 2. 0. 0.]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9167}"
820,41764199,"{'items': [{'owner': {'reputation': 525, 'user_id': 5350761}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1646322934, 'answer_id': 71340043, 'question_id': 41764199, 'body': '<p>With the advent of tf.math.bincount, I believe the problem has become much simpler.</p>\n<p>Something like this should work:</p>\n<pre><code>def hist_fixed_width(x,st,en,nbins):\n  x=(x-st)/(en-st)\n  x=tf.cast(x*nbins,dtype=tf.int32)\n  x=tf.clip_by_value(x,0,nbins-1)\n  return tf.math.bincount(x,minlength=nbins,axis=-1)\n</code></pre>\n'}, {'owner': {'reputation': 1, 'user_id': 13102415}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1584843966, 'answer_id': 60795351, 'question_id': 41764199, 'body': '<p>answers above is still slow running in GPU. Here i give an another option, which is faster(at least in my running envirment), but it is limited to 0~1 (you can normalize the value first). the train_equal_mask_nbin can be defined once in advance </p>\n\n<pre class=""lang-py prettyprint-override""><code>def histogram_v3_nomask(tensor, nbins, row_num, col_num):\n    #init mask\n    equal_mask_list = []\n    for i in range(nbins):\n        equal_mask_list.append(tf.ones([row_num, col_num], dtype=tf.int32) * i)\n    #[nbins, row, col]\n    #[0, row, col] is tensor of shape [row, col] with all value 0\n    #[1, row, col] is tensor of shape [row, col] with all value 1\n    #....\n    train_equal_mask_nbin = tf.stack(equal_mask_list, axis=0)\n\n    #[inst, doc_len] float to int(equaly seg float in bins)\n    int_input = tf.cast(tensor * (nbins), dtype=tf.int32)\n    #input [row,col] -&gt; copy N times, [nbins, row_num, col_num]\n    int_input_nbin_copy = tf.reshape(tf.tile(int_input, [nbins, 1]), [nbins, row_num, col_num])\n    #calculate histogram\n    histogram = tf.transpose(tf.count_nonzero(tf.equal(train_equal_mask_nbin, int_input_nbin_copy), axis=2))\n    return histogram\n</code></pre>\n'}, {'owner': {'reputation': 6683, 'user_id': 2230045}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1547393656, 'answer_id': 54170386, 'question_id': 41764199, 'body': '<p>I would like to propose another implementation.\nThis implementation can also handle multi axes and unknown dimensions (batching).</p>\n\n<pre><code>def histogram(tensor, nbins=10, axis=None):\n    value_range = [tf.reduce_min(tensor), tf.reduce_max(tensor)]\n\n    if axis is None:\n        return tf.histogram_fixed_width(tensor, value_range, nbins=nbins)\n    else:\n        if not hasattr(axis, ""__len__""):\n            axis = [axis]\n\n        other_axis = [x for x in range(0, len(tensor.shape)) if x not in axis]\n        swap = tf.transpose(tensor, [*other_axis, *axis])\n        flat = tf.reshape(swap, [-1, *np.take(tensor.shape.as_list(), axis)])\n\n        count = tf.map_fn(lambda x: tf.histogram_fixed_width(x, value_range, nbins=nbins), flat, dtype=(tf.int32))\n\n        return tf.reshape(count, [*np.take([-1 if a is None else a for a in tensor.shape.as_list()], other_axis), nbins])\n</code></pre>\n\n<p>The only slow part here is <code>tf.map_fn</code> but it is still faster than the other solutions mentioned.</p>\n\n<p>If someone knows a even faster implementation please comment since this operation is still very expensive.</p>\n'}, {'owner': {'reputation': 8368, 'user_id': 482601}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1485161684, 'answer_id': 41802308, 'question_id': 41764199, 'body': ""<p>Inspired by keveman's answer and because the number of rows of <code>t</code> is fixed and rather small, I chose to use a combination of <code>tf.gather</code> to split rows and <code>tf.pack</code> to join rows. It looks simple and works, will see if it is efficient...</p>\n\n<pre><code>t_histo_rows = [\n        tf.histogram_fixed_width(\n            tf.gather(t, [row]),\n            vals, nbins)\n        for row in range(t_num_rows)]\n\nt_histo = tf.pack(t_histo_rows, axis=0)\n</code></pre>\n""}, {'owner': {'reputation': 8427, 'user_id': 691733}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1484931522, 'answer_id': 41768777, 'question_id': 41764199, 'body': '<p><a href=""https://www.tensorflow.org/api_docs/python/histogram_ops/histograms#histogram_fixed_width"" rel=""nofollow noreferrer""><code>tf.histogram_fixed_width</code></a> works on the entire tensor indeed. You have to loop through the rows explicitly to compute the per-row histograms. Here is a complete working example using TensorFlow\'s <a href=""https://www.tensorflow.org/api_docs/python/control_flow_ops/control_flow_operations#while_loop"" rel=""nofollow noreferrer""><code>tf.while_loop</code></a> construct :</p>\n\n<pre><code>import tensorflow as tf\n\nt = tf.random_uniform([2, 2])\n\ni = 0\nhist = tf.constant(0, shape=[0, 5], dtype=tf.int32)\n\ndef loop_body(i, hist):\n  h = tf.histogram_fixed_width(t[i, :], [0.0, 1.0], nbins=5)\n  return i+1, tf.concat_v2([hist, tf.expand_dims(h, 0)], axis=0)\n\ni, hist = tf.while_loop(\n              lambda i, _: i &lt; 2, loop_body, [i, hist],\n              shape_invariants=[tf.TensorShape([]), tf.TensorShape([None, 5])])\n\nsess = tf.InteractiveSession()\nprint(hist.eval())\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9163}"
821,46370159,"{'items': [{'owner': {'reputation': 3596, 'user_id': 6780025}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1506982281, 'answer_id': 46534458, 'question_id': 46370159, 'body': '<p>""local step"" is incremented on every call to <code>sess.run()</code>. You are calling <code>sess.run()</code> twice within your while loop.</p>\n\n<p>Here are some pointers to relevant code:\n<a href=""https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/training/basic_session_run_hooks.py#L255"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/training/basic_session_run_hooks.py#L255</a> - increment _iter_count after every call to <code>sess.run()</code>.</p>\n\n<p><a href=""https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/training/basic_session_run_hooks.py#L228"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/training/basic_session_run_hooks.py#L228</a> - If <code>_iter_count</code> should trigger logging, add the current tensors to be run in the following call to <code>sess.run()</code> so that their values can be logged next.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9162}"
822,76334449,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9162}"
823,56970612,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9162}"
824,54701429,"{'items': [{'owner': {'reputation': 2768, 'user_id': 10953776}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1550200241, 'answer_id': 54702197, 'question_id': 54701429, 'body': '<p>If you try to follow the chain of function calls, you will find that <code>tf.layers.conv2D()</code> makes calls to <code>tf.nn.conv2D()</code> so no matter what you use, <code>tf.nn.conv2d()</code> will be called, it will be just faster if you call it yourself. You can use <code>traceback.print_stack()</code> method to verify that for yourself.</p>\n\n<p><strong>NOTE</strong> This does not mean that they are one and the same, select the function based on your need as there are various other tasks undertaken by <code>tf.layers.conv2D()</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9162}"
825,61986166,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9158}"
826,62571896,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9158}"
827,55778682,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9158}"
828,35958139,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': True, 'score': 7, 'creation_date': 1457802275, 'answer_id': 35960657, 'question_id': 35958139, 'body': '<p>The <a href=""https://www.tensorflow.org/versions/r0.7/api_docs/python/math_ops.html#reduce_sum"" rel=""noreferrer""><code>tf.reduce_sum()</code></a> op works on 3-D tensors and variables (and in general any rank or tensor or variable). However, if you have a <strong>list</strong> of 2-D tensors (or variables), you should use the <a href=""https://www.tensorflow.org/versions/r0.7/api_docs/python/math_ops.html#add_n"" rel=""noreferrer""><code>tf.add_n()</code></a> op to add together the values in the list:</p>\n\n<pre><code>var_3Dlist = ...  # List of 3-D variables.\nsum_list = [tf.reduce_sum(mat) for mat in var_3Dlist]\nsum = tf.add_n(sum_list)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9158}"
829,72707453,"{'items': [{'owner': {'reputation': 866, 'user_id': 425281}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1681940920, 'answer_id': 76059051, 'question_id': 72707453, 'body': '<p>Not useful for your question, but if someone just wants to create shards, lets mention that it is possible to use random:</p>\n<pre><code>tf.data.experimental.save(trainingdata, &quot;./tmpTrainingData&quot;,\n                          shard_func=lambda x, y:  np.int64(random.randint(0,99)) )\n</code></pre>\n<p>Now I wonder if your goal could be obtained by calling hash and producing a int64. Even if it can, I guess there is some risk of collision.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9154}"
830,57392510,"{'items': [{'owner': {'reputation': 22581, 'user_id': 521776}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1565174681, 'answer_id': 57392590, 'question_id': 57392510, 'body': '<p><code>apply_gradients</code> returns an operation that you can use to apply the gradients. In other words, you just do <code>train = optimizer.apply_gradients(grads_and_vars)</code> and the rest will work as in the first snippet. I,e.:</p>\n\n<pre><code>optimizer = tf.train.GradientDescentOptimizer(0.55)\ngrads_and_vars = calc_grad(x,y)\ntrain = optimizer.apply_gradients(grads_and_vars)\n\ninit = tf.global_variables_initializer()\n\ndef optimize():\n  with tf.Session() as session:\n    session.run(init)\n    print(""starting at"", ""x:"", session.run(x), ""y:"", session.run(y), ""z:"", session.run(z))\n    for step in range(10):  \n      session.run(train)\n      print(""step"", step, ""x:"", session.run(x), ""y:"", session.run(y), ""z:"", session.run(z))\n\n\noptimize()\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9154}"
831,44162432,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 30, 'is_accepted': True, 'score': 30, 'creation_date': 1495640878, 'answer_id': 44163122, 'question_id': 44162432, 'body': '<p><a href=""https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"" rel=""noreferrer""><code>tf.dynamic_rnn</code></a> provides two outputs, <code>outputs</code> and <code>state</code>.</p>\n\n<ul>\n<li><code>outputs</code> contains the output of the RNN cell at every time instant. Assuming the default <code>time_major == False</code>, let\'s say you have an input composed of 10 examples with 7 time steps each and a feature vector of size 5 for every time step. Then your input would be 10x7x5 (<code>batch_size</code>x<code>max_time</code>x<code>features</code>). Now you give this as an input to a RNN cell with output size 15. Conceptually, each time step of each example is input to the RNN, and you would get a 15-long vector for each of those. So that is what <code>outputs</code> contains, a tensor in this case of size 10x7x15 (<code>batch_size</code>x<code>max_time</code>x<code>cell.output_size</code>) with the output of the RNN cell at each time step. If you are only interested in the last output of the cell, you can just slice the time dimension to pick just the last element (e.g. <code>outputs[:, -1, :]</code>).</li>\n<li><code>state</code> contains the state of the RNN after processing all the inputs. Note that, unlike <code>outputs</code>, this doesn\'t contain information about every time step, but only about the last one (that is, the state <em>after</em> the last one). Depending on your case, the state may or may not be useful. For example, if you have very long sequences, you may not want/be able to processes them in a single batch, and you may need to split them into several subsequences. If you ignore the <code>state</code>, then whenever you give a new subsequence it will be as if you are beginning a new one; if you remember the state, however (e.g. outputting it or storing it in a variable), you can feed it back later (through the <code>initial_state</code> parameter of <code>tf.nn.dynamic_rnn</code>) in order to correctly keep track of the state of the RNN, and only reset it to the initial state (generally all zeros) after you have completed the whole sequences. The shape of <code>state</code> can vary depending on the RNN cell that you are using, but, in general, you have some state for each of the examples (one or more tensors with size <code>batch_size</code>x<code>state_size</code>, where <code>state_size</code> depends on the cell type and size).</li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9154}"
832,43681154,"{'items': [{'owner': {'reputation': 5778, 'user_id': 6824418}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1493407889, 'answer_id': 43687652, 'question_id': 43681154, 'body': ""<p>It was written very early in TensorFlow's development, at a point where shape information was not associated with Tensors. Since it's not useful in model code, updating it for usability was never a priority.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9154}"
833,53466500,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9154}"
834,59555206,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1577916670, 'answer_id': 59556499, 'question_id': 59555206, 'body': '<p>There\'s few issues with your code. Fix them and you should be good to go,</p>\n\n<h2>Issue 1: Use <code>Input</code> instead of <code>InputLayer</code></h2>\n\n<p>The standard is to use <code>Input</code> layer instead of <code>InputLayer</code> (which infact uses <code>InputLayer</code> internally). You also need to change <code>input_shape</code> to <code>shape</code> if you are using <code>Input</code> layer.</p>\n\n<pre><code>input_layer = tf.keras.layers.Input(shape=(100,))\n</code></pre>\n\n<h2>Issue 2: 2 <code>None</code> dimensions in the output</h2>\n\n<p>When you execute the following line, you get two <code>None</code> dimensions in your output. </p>\n\n<pre><code>reshape_layer = tf.keras.layers.Reshape((-1, 100, 1))(input_layer)\n</code></pre>\n\n<p>Which is why you are getting the above error. When defining the <code>Reshape</code> layer you don\'t define the <code>batch</code> dimension, which will be None. And that\'s the only dimension you can have as <code>None</code> if you want to use a <code>Dense</code> layer. Otherwise, the <code>Dense</code> layer cannot infer the shape of its weights (which is why you get the error). So change that to,</p>\n\n<pre><code>reshape_layer = tf.keras.layers.Reshape((1, 100, 1))(input_layer)\n</code></pre>\n\n<p>The rest stays the same.</p>\n\n<pre><code>conv_layer_1 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(10, 1), strides=(1, 1), padding=""same"", activation=""relu"")(reshape_layer)\nconv_layer_2 = tf.keras.layers.Convolution2D(filters=30, kernel_size=(8, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_1)\nconv_layer_3 = tf.keras.layers.Convolution2D(filters=40, kernel_size=(6, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_2)\nconv_layer_4 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_3)\nconv_layer_5 = tf.keras.layers.Convolution2D(filters=50, kernel_size=(5, 1), strides=(1, 1), padding=""same"", activation=""relu"")(conv_layer_4)\nflatten_layer = tf.keras.layers.Flatten()(conv_layer_5)\nlabel_layer = tf.keras.layers.Dense(200, activation=""relu"")(flatten_layer)\noutput_layer = tf.keras.layers.Dense(1, activation=""linear"")(label_layer)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=output_layer)\nmodel.summary()\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9149}"
835,58912135,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9149}"
836,39282060,"{'items': [{'owner': {'reputation': 2471, 'user_id': 4844184}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1472823285, 'answer_id': 39293770, 'question_id': 39282060, 'body': ""<p>The COST that is often used is simply the squared difference:</p>\n\n<pre><code>def squared_error(y1,y2):\n  return tf.square(y1-y2)\n</code></pre>\n\n<p>Plus an L1 or L2 penalty if you feel like it.  </p>\n\n<p>However it seems to me that you need a hidden layer in your neural network if you want something remotely interesting. Plus if you squash your output and your target is the squared function you might not be able to do much.\nI would do:</p>\n\n<pre><code>x = tf.placeholder(tf.float32, [None, 1]) \n#Hidden layer with ten neurons\nW1 = tf.Variable(tf.zeros([1,10]))\nb1 = tf.Variable(tf.zeros([10]))\nh1 = some_nonlinear_activation_function(tf.matmul(x,W) + b)\nW2 = tf.Variable(tf.zeros([10,1]))\nb2 = tf.Variable(tf.zeros([1]))\n#I am not squashing the output\ny=tf.matmul(h1,W2)+b\ncost = tf.reduce_mean(squared_error(y, y_))\n</code></pre>\n\n<p>Also I would not use 0 weights but a more clever initialization scheme like Xavier's or He's which really come down to starting with practically zero weights but not exactly zeros for various reasons.\nFor activations you might use tanh, sigmoid or ReLU or anything really.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9149}"
837,55213452,"{'items': [{'owner': {'reputation': 10580, 'user_id': 8300135}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1552871394, 'answer_id': 55213544, 'question_id': 55213452, 'body': '<p>You can use <code>tf.transpose()</code>:</p>\n\n<pre><code># t\n# array([[[ 1,  2,  3],\n#         [ 3,  4,  5]],\n\n#        [[11, 22, 33],\n#         [33, 44, 55]]])\n\ntf.transpose(t, perm=[0, 2, 1])\n# array([[[ 1,  3],\n#         [ 2,  4],\n#         [ 3,  5]],\n\n#        [[11, 33],\n#         [22, 44],\n#         [33, 55]]])\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9149}"
838,45553038,"{'items': [{'owner': {'reputation': 5186, 'user_id': 992489}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1502139263, 'answer_id': 45555558, 'question_id': 45553038, 'body': ""<p>There is no officially supported extension point to pull in your own ops other than dynamically loading them.</p>\n\n<p>If you build tensorflow from source and are willing to hack it it's not hard to pretend your ops are core ops, but it's not supported.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9149}"
839,65779087,"{'items': [{'owner': {'reputation': 41, 'user_id': 11450679}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1676873713, 'answer_id': 75505826, 'question_id': 65779087, 'body': '<p>I think you are trying to use both eager and graph execution modes simultaneously. Try using <code>tf.config.run_functions_eagerly(False)</code> at the start...</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9144}"
840,40879504,"{'items': [{'owner': {'reputation': 488, 'user_id': 8156023}, 'down_vote_count': 0, 'up_vote_count': 12, 'is_accepted': False, 'score': 12, 'creation_date': 1501595657, 'answer_id': 45439859, 'question_id': 40879504, 'body': '<p>The key point here is that:</p>\n\n<pre><code>    layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights_hiden), biases_hidden))\n    # apply DropOut to hidden layer\n    keep_prob = tf.placeholder(tf.float32)  # DROP-OUT here\n    drop_out = tf.nn.dropout(layer_1, keep_prob)  # DROP-OUT here\n    # output layer with linear activation\n    out_layer = tf.matmul(layer_1, weights_out) + biases_out\n</code></pre>\n\n<p>Becomes:</p>\n\n<pre><code>    layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights_hiden), biases_hidden))\n    # apply DropOut to hidden layer\n    drop_out = tf.nn.dropout(layer_1, keep_prob)  # DROP-OUT here\n    # output layer with linear activation\n    out_layer = tf.matmul(drop_out, weights_out) + biases_out\n</code></pre>\n\n<p>Where drop_out is being used in the final line as oppose to layer_1. As this would otherwise ignore the dropout line. </p>\n'}, {'owner': {'reputation': 5154, 'user_id': 4678222}, 'down_vote_count': 0, 'up_vote_count': 57, 'is_accepted': True, 'score': 57, 'creation_date': 1480487157, 'answer_id': 40881670, 'question_id': 40879504, 'body': '<p>In the graph, I\'d suggest to move <code>keep_prob = tf.placeholder(tf.float32)</code> outside of the <code>model</code> function to make it global.</p>\n\n<pre class=""lang-py prettyprint-override""><code>with graph.as_default():\n    ...\n    x = tf.placeholder(""float"", [None, n_input])\n    y = tf.placeholder(""float"", [None, n_classes])\n    keep_prob = tf.placeholder(tf.float32)\n\n    def model(x, weights_hiden, weights_out, biases_hidden, biases_out, keep_prob):\n        # hidden layer with RELU activation\n        layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights_hiden), biases_hidden))\n        # apply DropOut to hidden layer\n        drop_out = tf.nn.dropout(layer_1, keep_prob)  # DROP-OUT here\n        # output layer with linear activation\n        out_layer = tf.matmul(drop_out, weights_out) + biases_out\n        return out_layer\n    ...\n</code></pre>\n\n<p>When running <code>session</code>, feed a desired <code>keep_prob</code> value during training time, and feed 1.0 to <code>keep_prob</code> during reference (validation and/or testing) time.</p>\n\n<pre class=""lang-py prettyprint-override""><code># run the graph\nwith tf.Session(graph=graph) as sess:\n    tf.initialize_all_variables().run()\n    ...\n    for epoch in range(training_epochs):\n        ...\n        for i in range(total_batch):\n            batch_x = ...\n            batch_y = ...\n            # Run optimization op (backprop) and cost op (to get loss value)\n            # Feed a value &lt; 1.0 for keep prob during training\n            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y, keep_prob : 0.5})\n    ...\n    # Feed 1.0 for keep prob during testing\n    print(""Test data accuracy:"", accuracy.eval({x: test_dataset, y: test_labels, keep_prob : 1.0}))\n    print(""Valid data accuracy:"", accuracy.eval({x: valid_dataset, y: valid_labels, keep_prob : 1.0}))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9143}"
841,63495568,"{'items': [{'owner': {'reputation': 747, 'user_id': 4496896}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1597890089, 'answer_id': 63497425, 'question_id': 63495568, 'body': '<p>No, there is no difference between two. You can check the Keras document of functional API here: <a href=""https://keras.io/guides/functional_api/"" rel=""nofollow noreferrer"">https://keras.io/guides/functional_api/</a></p>\n<p>or here the same tf.keras version: <a href=""https://www.tensorflow.org/guide/keras/functional"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/keras/functional</a></p>\n<p>They both are the same and will give you a model that works in exactly same way.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9143}"
842,53079436,"{'items': [{'owner': {'reputation': 992, 'user_id': 10111931}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1540992466, 'answer_id': 53084507, 'question_id': 53079436, 'body': '<p>This is because you are evaluating again in a new sess.run. \nSince you are generating a random number for deterministic_action, the result turns out to be the next random number after 4, which is 1.\nHere is the result of your code, when I extract the value of deterministic_action as well in the last step.</p>\n\n<p>Modification:</p>\n\n<pre><code>print (""s_ph = "", stochastic_ph)\nd_action = sess.run(deterministic_action)\nprint (""det_action= "", d_action)\nr_action = sess.run(random_action)\nprint (""rand_action= "", r_action)\ne = sess.run(eps)\nc_action = sess.run(chose_random)\nprint (""chose_rand= "", c_action)\ns_action, d_action = sess.run([stochastic_action, deterministic_action])\nprint (""s_action= "", s_action)\nprint (""det_action= "", d_action)\n</code></pre>\n\n<p>Result:</p>\n\n<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)\ndet_action=  4\nrand_action=  11\nchose_rand=  False\ns_action=  1\ndet_action=  1\n</code></pre>\n\n<p>Now all you need to do is run everything in one sess.run</p>\n\n<pre><code>d_action, r_action, e,  c_action, s_action = sess.run([deterministic_action, random_action, eps, chose_random, stochastic_action])\nprint (""det_action= "", d_action)\nprint (""rand_action= "", r_action)\nprint (""chose_rand= "", c_action)\nprint (""s_action= "", s_action)\n</code></pre>\n\n<p>Result:</p>\n\n<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)\ndet_action=  4\nrand_action=  11\nchose_rand=  False\ns_action=  4\n</code></pre>\n\n<p>Update:</p>\n\n<p>I was not clear on why the random_uniform generates different values when seed is set. This is because the code is running with the same session object that it initialized the variables with.\nModifying the code with a new session object, this is what happens:</p>\n\n<pre><code>print (""s_ph = "", stochastic_ph)\nd_action = sess.run(deterministic_action)\nprint (""det_action= "", d_action)\nsess.close()\nsess = tf.Session()\nsess.run(init, feed_dict={stochastic_ph: True})\ns_action = sess.run(stochastic_action)\nprint (""s_action= "", s_action)\n</code></pre>\n\n<p>Result:</p>\n\n<pre><code>s_ph =  Tensor(""stochastic:0"", shape=(), dtype=bool, device=/device:CPU:0)\ndet_action=  4\ns_action=  4\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9143}"
843,74182037,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9143}"
844,63600026,"{'items': [{'owner': {'reputation': 31, 'user_id': 5798275}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1609833651, 'answer_id': 65575041, 'question_id': 63600026, 'body': '<p>mixed1, mixed2, ... are layers of type <strong>tf.keras.layers.Concatenate</strong>.\nYou can read more about these layers here :\n<a href=""https://keras.io/api/layers/merging_layers/concatenate/"" rel=""nofollow noreferrer"">https://keras.io/api/layers/merging_layers/concatenate/</a></p>\n'}, {'owner': {'reputation': 544, 'user_id': 11083136}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1598453605, 'answer_id': 63600286, 'question_id': 63600026, 'body': '<p>Refer to <a href=""https://arxiv.org/abs/1512.00567"" rel=""nofollow noreferrer"">InceprtionV3 paper</a>.</p>\n<p>You can see that the mixed layers are made of four parallel connections with single input and we get the output by concatenating all parallel outputs into one. Note that to contatenate all the outputs, all parallel feature maps have to have identical first two dimensions (number of feature maps can differ) and this is achieved by strides and pooling.</p>\n<p><a href=""https://i.stack.imgur.com/H4pFo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/H4pFo.png"" alt=""Inception layer"" /></a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9139}"
845,51586459,"{'items': [{'owner': {'reputation': 145, 'user_id': 3331276}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1532936287, 'answer_id': 51589094, 'question_id': 51586459, 'body': '<pre><code>i0 = tf.constant(1)\nm0 = tf.zeros([1, 2], dtype=tf.int32)\nf0 = tf.constant(True)\ndef cond_true_fn(i, m):\n    return [i + 1, tf.concat([m, [[6, 6]]], axis=0), False]\n\n\ndef cond_false_fn(i, m):\n    return [i + 1, tf.concat([m, [[3, 3]]], axis=0), False]\n\n\ndef body(i, m, f):\n    return tf.cond(f, lambda:cond_true_fn(i,m), lambda:cond_false_fn(i,m))\n\ndef condi(i, m, f):\n    return tf.less_equal(i, 3)\n\n_, r = tf.while_loop(condi, body, loop_vars=[i0, m0, f0], shape_invariants=[i0.get_shape(), tf.TensorShape([None, 2]), f0.get_shape()], back_prop=False)\n\nwith tf.Session() as sess:\n    tf.global_variables_initializer().run()\n    _r = sess.run([r])\n    print(_r)\n</code></pre>\n\n<p><strong>This works! but WHY?</strong></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9139}"
846,59772316,"{'items': [{'owner': {'reputation': 458, 'user_id': 3241790}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1579188524, 'answer_id': 59772937, 'question_id': 59772316, 'body': '<p>You need to put a name for the output layers, then used the name to connect the output to the right loss function like this:</p>\n\n<pre><code>output_1 = SoftmaxLayer(X, name=""output_1"")\noutput_2 = SoftmaxLayer(X, name=""output_2"")    \nmodel = Model(inputs=input, outputs=[output_1, output_2])    \nlosses = {\n        ""output_1"": fun_1,\n        ""output_2"": fun_2\n    }\n\nlossWeights = {""output_1"": alpha, ""output_2"": beta}\n\nmodel.compile(optimizer=opt, loss=losses, metrics=[""acc""], loss_weights=lossWeights)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9139}"
847,60013980,"{'items': [{'owner': {'reputation': 16962, 'user_id': 5046896}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1580538803, 'answer_id': 60014627, 'question_id': 60013980, 'body': '<p>The most easier way to do so is to make the sparse tensor as a 2D tensor and get the weights of the embedding matrix and then reshape.</p>\n\n<pre class=""lang-py prettyprint-override""><code># First make the z as a 2D arr and create a sparse tensor \nz = np.array([\n        [0, 1, 2, 3],  # get the row 0,1,2,3 of the embedding matrix w and get the sum\n        [2, 3],\n        [1, 3],\n        [2],\n        [0, 1, 3],\n        [1, 2]\n      ])\n\nsp = tf.SparseTensor(values=[0, 1, 2, 3, 2, 3, 1, 3, 2, 0, 1, 3, 1, 2],\n                     indices=[[0,0],[0,1],[0,2],[0,3],[1,2],[1,3],[2,1],\n                              [2,3],[3,2],[4,0],[4,1],[4,3],[5,1],[5,2]],\n                     dense_shape=[6, 4])\n\nres = tf.nn.embedding_lookup_sparse(w, sp, None, combiner=\'sum\')\n\nres.numpy()\n# the output\narray([[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],\n       [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ],\n       [ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],\n       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],\n       [-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],\n       [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]],\n\n# reshape\ntf.reshape(res, [-1, 2, 4])\n# that is exacly what I want.\narray([[[-3.6457794 , -1.5215762 ,  1.7455802 , -2.5802398 ],\n        [-2.227188  ,  0.13151208, -0.9329706 , -0.5421516 ]],\n\n       [[ 0.2612    , -0.6687883 ,  1.7068193 , -0.03506255],\n        [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532]],\n\n       [[-2.3057768 , -1.0579524 ,  3.1107986 , -2.8524451 ],\n        [-0.19161725, -1.7275481 , -0.0906471 ,  1.0514997 ]]])\n\n# print w, and the above result is right\nw.numpy()\n\narray([[-2.5669768 , -0.38916406,  1.4039794 , -2.8173826 ],\n       [ 1.1483854 , -1.2639242 ,  1.2745714 ,  0.7792944 ],\n       [-1.3400027 , -0.46362385, -1.3652185 ,  0.27220532],\n       [-0.8871854 ,  0.5951359 ,  0.43224794, -0.8143569 ]],\n      dtype=float32)\n</code></pre>\n\n<p>So, forget the 3D sparse tensor, simply convert it to 2D tensor. Because you only care about the values (index of rows, which are used to get the corresponding rows of the embedding matrix) in the sparse tensor.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9139}"
848,73778590,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9139}"
849,57460127,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9134}"
850,61293983,"{'items': [{'owner': {'reputation': 47089, 'user_id': 121687}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1598751777, 'answer_id': 63653251, 'question_id': 61293983, 'body': '<p>It says it in the documentation: Coercion.\nThe amount of bytes are the same. How to interpret those bytes the difference is.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9134}"
851,59458980,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9134}"
852,45247909,"{'items': [{'owner': {'reputation': 151, 'user_id': 7476324}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1500936453, 'answer_id': 45291251, 'question_id': 45247909, 'body': ""<p>Okay, so I figured it out.  If I want to compute the gradients of the output with respect to the variables of the network it goes like this.</p>\n\n<pre><code>import keras\nimport tensorflow as tf\n\n# Dummy input\ntest = np.random.rand(1, 32, 32, 1)\n\nx = tf.placeholder(tf.float32, shape=(None, 32, 32, 1))\n\nmodel = keras.layers.Conv2D(16, 5, padding = 'same', activation='elu') (x)\nmodel = keras.layers.Flatten() (model)\nmodel = keras.layers.Dense(128, activation='relu') (model)\npredictions = keras.layers.Dense(1) (model)\n\n# This was the part that I was missing.\n============================================================\nopt = tf.train.GradientDescentOptimizer(learning_rate=0.01)\ngradient_step = opt.compute_gradients(predictions, tf.trainable_variables())\n============================================================\n\nwith tf.Session() as sess:\n    init_op = tf.global_variables_initializer()\n    sess.run(init_op)\n\n    # This part changed too.\n    ==========================================================\n    gradients = sess.run(gradient_step, feed_dict={x: test})\n    ==========================================================\n</code></pre>\n\n<p>I had to define an optimizer <code>tf.train.GradientDescentOptimizer</code> and then feed the <code>predictions</code> to the <code>gradient_step</code> operation to find the gradient for my output. It was actually pretty simple!  </p>\n\n<p>Thank you all for your help ^.^ </p>\n""}, {'owner': {'reputation': 323, 'user_id': 4012272}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1500694803, 'answer_id': 45250404, 'question_id': 45247909, 'body': ""<p>Two things here.</p>\n\n<ol>\n<li>Theta corresponds to the weights in the layers. </li>\n<li><p>To get weights in Keras, use <code>get_weights()</code>. Do something like following:   </p>\n\n<pre><code>m1 = keras.layers.Conv2D(16, 5, padding = 'same', activation='elu')  \nmodel = m1 (x)  \nW1 = m1.get_weights()\n</code></pre></li>\n</ol>\n\n<p>Now you can see W1 constains the weights.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9134}"
853,73049510,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1658311725, 'answer_id': 73049712, 'question_id': 73049510, 'body': ""<p>Maybe something like this:</p>\n<pre><code>class MovieModel(tf.keras.Model):\n\n  def __init__(self):\n    super().__init__()\n\n    max_tokens = 10_000_00\n\n    self.title_vectorizer = tf.keras.layers.TextVectorization(\n        max_tokens=max_tokens)\n\n    self.title_text_embedding = tf.keras.Sequential([\n      # tf.keras.layers.Flatten(),\n      self.title_vectorizer,\n      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n    ])\n    self.title_vectorizer.adapt(movies)\n\n  def call(self, titles, pool_size):\n    avg_layer = tf.keras.layers.AveragePooling2D(pool_size=pool_size,strides=1,padding='valid',)\n    return avg_layer(self.title_text_embedding(titles))\n</code></pre>\n<pre><code>test_movie_titles = [[&quot;M*A*S*H (1970)&quot;, &quot;Dances with Wolves (1990)&quot;, &quot;Speed (1994)&quot;,&quot;Dances with Wolves (1990)&quot;, &quot;Speed (1994)&quot;]]\nmd = MovieModel()\ntest_ratings = md(tf.constant(tf.reshape(test_movie_titles,[1,5,1])),  pool_size = (1, 4))  \ntest_ratings\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9130}"
854,57116074,"{'items': [{'owner': {'reputation': 83, 'user_id': 4954882}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1570105951, 'answer_id': 58219202, 'question_id': 57116074, 'body': '<p><strong>Without preserving Order</strong></p>\n\n<p>You can use <code>tf.py_function</code> and call <code>np.unique</code> to return unique multidimensional tensors along axis=0. Note that this finds the unique rows but does not preserve the order.</p>\n\n<pre><code>def distinct(a):\n    _a =  np.unique(a, axis=0)\n    return _a\n\n&gt;&gt; input = tf.constant([\n[0,3],\n[0,1],\n[0,4],\n[0,1],\n[1,5],\n[3,9],\n[3,2],\n[3,6],\n[3,5],\n[3,3]])\n\n&gt;&gt; tf.py_function(distinct, [input], tf.int32)\n&lt;tf.Tensor: id=940, shape=(9, 2), dtype=int32, numpy=\narray([[0, 1],\n   [0, 3],\n   [0, 4],\n   [1, 5],\n   [3, 2],\n   [3, 3],\n   [3, 5],\n   [3, 6],\n   [3, 9]], dtype=int32)&gt;\n</code></pre>\n\n<p><strong>With Orders preserved</strong></p>\n\n<pre><code>def distinct_with_order_preserved(a):\n    _a = a.numpy()\n    return pd.DataFrame(_a).drop_duplicates().values\n\n&gt;&gt; tf.py_function(distinct_with_order_preserved, [input], tf.int32)\n&lt;tf.Tensor: id=950, shape=(9, 2), dtype=int32, numpy=\narray([[0, 3],\n   [0, 1],\n   [0, 4],\n   [1, 5],\n   [3, 9],\n   [3, 2],\n   [3, 6],\n   [3, 5],\n   [3, 3]], dtype=int32)&gt;\n</code></pre>\n'}, {'owner': {'reputation': 121, 'user_id': 3582363}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1563552231, 'answer_id': 57116075, 'question_id': 57116074, 'body': '<p>One approach would be to look for elements for which a previous sub-<code>Tensor</code> along the axis 0 is equal, then filter those out:</p>\n\n<ol>\n<li>Use <code>tf.equal</code> to get the pairwise equality of the individual axis -1 elements of the input crossed with itself along axis 0.</li>\n<li>Use <code>tf.math.reduce_all</code> to aggregate the pairwise equalities until you have a 2-D equality matrix for the axis 0 elements of the input.</li>\n<li>Generate an upper-triangular matrix of False values</li>\n<li>Use that triangular matrix to restrict our equality comparisons to one direction along axis 0.</li>\n<li>Use <code>tf.reduce_any</code> to find which axis 0 elements are equal to any later elements; they are the duplicates that will be removed.</li>\n<li>Use <code>tf.math.logical_not</code> and <code>tf.boolean_mask</code> to obtain only the non-duplicate elements of axis 0.</li>\n</ol>\n\n<p>This process is implement in the following Python code, tested in TensorFlow 2.0 beta:</p>\n\n<pre><code>def distinct(input:tf.Tensor) -&gt; tf.Tensor:\n    """"""Returns only the distinct sub-Tensors along the 0th dimension of the provided Tensor""""""\n    is_equal = tf.equal(input[:,tf.newaxis], input[tf.newaxis,:])\n    while len(is_equal.shape) &gt; 2:\n        is_equal = tf.math.reduce_all(is_equal, axis=2)\n    all_true = tf.constant(True, shape=is_equal.shape)\n    true_upper_tri = tf.linalg.band_part(all_true, 0, -1)\n    false_upper_tri = tf.math.logical_not(true_upper_tri)\n    is_equal_one_way = tf.math.logical_and(is_equal, false_upper_tri)\n    is_duplicate = tf.reduce_any(is_equal_one_way, axis=1)\n    is_distinct = tf.math.logical_not(is_duplicate)\n    distinct_elements = tf.boolean_mask(input, is_distinct, 0)\n    return distinct_elements\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9130}"
855,43396525,"{'items': [{'owner': {'reputation': 1115, 'user_id': 5401777}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1492098345, 'answer_id': 43396603, 'question_id': 43396525, 'body': ""<p><code>tf.image.decode_png</code> accepts a Tensor of type string, so you need to read the png with Tensorflow before passing it to the function:</p>\n\n<pre><code>import tensorflow as tf\nimage1 = tf.image.decode_png(tf.read_file('/usr/src/pycharm-2017.1/bin/pycharm.png'))\nprint(image1.shape)\nwith tf.Session() as sess:\n    img = sess.run(image1)\n    print(img.shape, img)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9130}"
856,41780655,"{'items': [{'owner': {'reputation': 49880, 'user_id': 336527}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1522615611, 'answer_id': 49602463, 'question_id': 41780655, 'body': ""<p>Just adding a few minor points to @Yaroslav-Bulatov answer.</p>\n\n<p>As you can see from Yaroslav's answer:</p>\n\n<ul>\n<li><code>tf.control_depenencies</code> creates no ops by itself, and adds dependencies to whatever ops your create inside its scope</li>\n<li><code>tf.group</code> creates a single op (of type <code>NoOp</code>), adds dependencies to that op.</li>\n</ul>\n\n<p>More importantly, if <code>tf.group</code> arguments belong to multiple devices, <code>tf.group</code> will insert an intermediate layer between its inputs and the node it returns. That layer will contain one node per device, so that the dependencies are organized by device. This could reduce the cross-device data flow.</p>\n\n<p>So if your dependencies are on multiple devices, <code>tf.group</code> adds a (possibly critical) optimization.</p>\n\n<p>On the other hand, <code>tf.control_dependencies</code> supports nesting: the inner context will add dependencies to the union of all the ops in the outer contexts.</p>\n""}, {'owner': {'reputation': 57117, 'user_id': 419116}, 'down_vote_count': 0, 'up_vote_count': 16, 'is_accepted': True, 'score': 16, 'creation_date': 1485019792, 'answer_id': 41782361, 'question_id': 41780655, 'body': ""<p>If you look at the graphdef, the <code>c=tf.group(a, b)</code> produces the same graph as </p>\n\n<pre><code>with tf.control_dependencies([a, b]):\n    c = tf.no_op() \n</code></pre>\n\n<p>There's no specific order in which ops will run, TensorFlow tries to execute operations as soon as it can (i.e. in parallel).</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9130}"
857,60222896,"{'items': [{'owner': {'reputation': 2446, 'user_id': 7946792}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1581674358, 'answer_id': 60224010, 'question_id': 60222896, 'body': '<p>The function <code>tf.nn.weighted_cross_entropy_with_logits</code> is implementing binary cross entropy loss. The loss you are looking for is a ""categorical"" cross entropy. And if you are looking for a concrete behaviour I recommend you to implement it from scratch.\nHere you have what you are asking for:</p>\n\n<pre><code>&gt;&gt;&gt; import tensorflow as tf\n&gt;&gt;&gt; from sklearn.utils.class_weight import compute_class_weight\n&gt;&gt;&gt; # Weighted categorical cross entropy\n&gt;&gt;&gt; def ce(y_pred, y_true, weights):\n...   y_pred = tf.clip_by_value(y_pred, 1e-6, 1 - 1e-6)\n...   loss = -tf.math.log(y_pred)\n...   loss = y_true * loss\n...   loss = weights * loss\n...   return tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n&gt;&gt;&gt;\n# A B C just refers to your classes\n&gt;&gt;&gt; weights = compute_class_weight(\'balanced\', [A, B, C], y_true)\n&gt;&gt;&gt; y_true = tf.one_hot(y_true, NUM_CLASSES)\n&gt;&gt;&gt; y_pred = tf.random.uniform((3, 3)) # Mock predictions (Should be activated by a softmax)\n&gt;&gt;&gt; print(y_true.shape, y_pred.shape)\n(3, 3) (3, 3)\n&gt;&gt;&gt; ce(y_pred, y_true, weights)\n&lt;tf.Tensor: id=23, shape=(), dtype=float32, numpy=2.8649616&gt;\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9130}"
858,72668593,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9125}"
859,50988466,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9125}"
860,67882420,"{'items': [{'owner': {'reputation': 10889, 'user_id': 7370153}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1623134962, 'answer_id': 67882683, 'question_id': 67882420, 'body': '<p>Those two statements are the result of two helper functions used by <code>tf.keras.preprocessing.image_dataset_from_directory</code>.</p>\n<p>See the relevant part of those functions below:</p>\n<ul>\n<li><p><a href=""https://github.com/tensorflow/tensorflow/blob/401dc1b3db4e7412f4fc50f96c25fd564d593f4c/tensorflow/python/keras/preprocessing/dataset_utils.py#L28"" rel=""nofollow noreferrer"">dataset_utils.index_directory</a>.</p>\n<pre><code>if labels is None:\n print(\'Found %d files.\' % (len(filenames),))\n else:\n   print(\'Found %d files belonging to %d classes.\' %\n       (len(filenames), len(class_names)))\n</code></pre>\n</li>\n<li><p><a href=""https://github.com/tensorflow/tensorflow/blob/401dc1b3db4e7412f4fc50f96c25fd564d593f4c/tensorflow/python/keras/preprocessing/dataset_utils.py#L166"" rel=""nofollow noreferrer"">dataset_utils.get_training_or_validation_split</a></p>\n<pre><code>if subset == \'training\':\n    print(\'Using %d files for training.\' % (len(samples) - num_val_samples,))\n    samples = samples[:-num_val_samples]\n    labels = labels[:-num_val_samples]\n</code></pre>\n</li>\n</ul>\n<p>Those two helper functions simply print those messages in the standard output as a way to provide information to the developer.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9123}"
861,49845685,"{'items': [{'owner': {'reputation': 3673, 'user_id': 4023951}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1523821242, 'answer_id': 49846037, 'question_id': 49845685, 'body': '<h1>Answer</h1>\n\n<p><code>tf.exp(s)</code> easily overflows for large <strong>s</strong>.  That\'s the main reason that <code>tf.nn.softmax</code> doesn\'t actually use that equation but does <em>something equilivent</em> to it (according to the docs).</p>\n\n<h1>Discussion</h1>\n\n<p>When I rewrote your softmax function to </p>\n\n<pre><code>p = tf.exp(s) / tf.reshape( tf.reduce_sum(tf.exp(s), axis=1), [-1,1] )\n</code></pre>\n\n<p>It worked without a problem.</p>\n\n<p>Here is a fully working python 2.7 implementation that uses a hand-crafted softmax and works (using the reshape function)</p>\n\n<pre><code># -- imports --\nimport tensorflow as tf\nimport numpy as np\n\n# np.set_printoptions(precision=1) reduces np precision output to 1 digit\nnp.set_printoptions(precision=2, suppress=True)\n\n# -- constant data --\nx = [[0., 0.], [1., 1.], [1., 0.], [0., 1.]]\ny_ = [[1., 0.], [1., 0.], [0., 1.], [0., 1.]]\n\n# -- induction --\n# 1x2 input -&gt; 2x3 hidden sigmoid -&gt; 3x1 sigmoid output\n\n# Layer 0 = the x2 inputs\nx0 = tf.constant(x, dtype=tf.float32)\ny0 = tf.constant(y_, dtype=tf.float32)\n\n# Layer 1 = the 2x3 hidden sigmoid\nm1 = tf.Variable(tf.random_uniform([2, 3], minval=0.1, maxval=0.9, dtype=tf.float32))\nb1 = tf.Variable(tf.random_uniform([3], minval=0.1, maxval=0.9, dtype=tf.float32))\nh1 = tf.sigmoid(tf.matmul(x0, m1) + b1)\n\n# Layer 2 = the 3x2 softmax output\nm2 = tf.Variable(tf.random_uniform([3, 2], minval=0.1, maxval=0.9, dtype=tf.float32))\nb2 = tf.Variable(tf.random_uniform([2], minval=0.1, maxval=0.9, dtype=tf.float32))\nh2 = tf.matmul(h1, m2) + b2\ny_out = tf.exp(h2) / tf.reshape( tf.reduce_sum(tf.exp(h2), axis=1) , [-1,1] )\n\n\n# -- loss --\n\n# loss : sum of the squares of y0 - y_out\nloss = tf.reduce_sum(tf.square(y0 - y_out))\n\n# training step : gradient decent (1.0) to minimize loss\ntrain = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n\n\n# -- training --\n# run 500 times using all the X and Y\n# print out the loss and any other interesting info\n#with tf.Session() as sess:\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nprint ""\\nloss""\nfor step in range(500):\n    sess.run(train)\n    if (step + 1) % 100 == 0:\n        print sess.run(loss)\n\nresults = sess.run([m1, b1, m2, b2, y_out, loss])\nlabels = ""m1,b1,m2,b2,y_out,loss"".split("","")\nfor label, result in zip(*(labels, results)):\n    print """"\n    print label\n    print result\n\nprint """"\n</code></pre>\n\n<p>Perhaps your initial values for M and b are too <em>large</em>.  I tried re-running my above code but with with weights initialized to large numbers and I was able to reproduce your NaN issue.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9123}"
862,49862069,"{'items': [{'owner': {'reputation': 1691, 'user_id': 6627660}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1528386128, 'answer_id': 50745304, 'question_id': 49862069, 'body': '<p>Maybe, <code>tf.disposeVariables()</code> is what you want.</p>\n\n<p>this command is available after 0.11.1 version.</p>\n\n<p><a href=""https://js.tensorflow.org/api/0.11.1/#disposeVariables"" rel=""nofollow noreferrer"">https://js.tensorflow.org/api/0.11.1/#disposeVariables</a></p>\n'}, {'owner': {'reputation': 1615, 'user_id': 226509}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1523967935, 'answer_id': 49878101, 'question_id': 49862069, 'body': '<p>If you wrap your entire block in a <code>tf.tidy()</code> it will dispose of all tensors except for those returned by the block.</p>\n\n<p><a href=""https://js.tensorflow.org/api/0.9.0/#tidy"" rel=""nofollow noreferrer"">https://js.tensorflow.org/api/0.9.0/#tidy</a></p>\n'}, {'owner': {'reputation': 73, 'user_id': 9646255}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1523896308, 'answer_id': 49862145, 'question_id': 49862069, 'body': '<p>The closest thing i can think of is <code>tf.reset_default_graph()</code>, although it blows away all ops and tensors, as well as all variables.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9123}"
863,55264696,"{'items': [{'owner': {'reputation': 1912, 'user_id': 1836044}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1560936461, 'answer_id': 56664386, 'question_id': 55264696, 'body': '<p>I needed an answer to this too, and figured out what I needed through the link at the bottom of your question.</p>\n\n<p>In short, you do as the answer in the link says, but you \'simply\' leave out the embedding layer if you\'re not interested in using one. I\'d highly recommend reading and understanding the <a href=""https://stackoverflow.com/questions/54989442/rnn-in-tensorflow-vs-keras-depreciation-of-tf-nn-dynamic-rnn"">linked answer</a> as it goes into more detail, and the docs on <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking"" rel=""nofollow noreferrer"">Masking</a>, but here\'s a modified version which uses a masking layer over the sequence inputs to replace \'sequence_length\':</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\n\npad_value = 0.37\n# This is our input to the RNN, in [batch_size, max_sequence_length, num_features] shape\ntest_input = np.array(\n[[[1.,   1.  ],\n  [2,    2.  ],\n  [1.,   1.  ],\n  [pad_value, pad_value], # &lt;- a row/time step which contains all pad_values will be masked through the masking layer\n  [pad_value, pad_value]],\n\n [[pad_value, pad_value],\n  [1.,   1.  ],\n  [2,    2.  ],\n  [1.,   1.  ],\n  [pad_value, pad_value]]])\n\n# Define the mask layer, telling it to mask all time steps that contain all pad_value values\nmask = tf.keras.layers.Masking(mask_value=pad_value)\nrnn = tf.keras.layers.GRU(\n    1,\n    return_sequences=True,\n    activation=None, # &lt;- these values and below are just used to initialise the RNN in a repeatable way for this example\n    recurrent_activation=None,\n    kernel_initializer=\'ones\',\n    recurrent_initializer=\'zeros\',\n    use_bias=True,\n    bias_initializer=\'ones\'\n)\n\nx = tf.keras.layers.Input(shape=test_input.shape[1:])\nm0 = tf.keras.Model(inputs=x, outputs=rnn(x))\nm1 = tf.keras.Model(inputs=x, outputs=mask(x))\nm2 = tf.keras.Model(inputs=x, outputs=rnn(mask(x)))\n\nprint(\'raw inputs\\n\', test_input)\nprint(\'raw rnn output (no mask)\\n\', m0.predict(test_input).squeeze())\nprint(\'masked inputs\\n\', m1.predict(test_input).squeeze())\nprint(\'masked rnn output\\n\', m2.predict(test_input).squeeze())\n</code></pre>\n\n<p>out:</p>\n\n<pre><code>raw inputs\n [[[1.   1.  ]\n  [2.   2.  ]\n  [1.   1.  ]\n  [0.37 0.37]\n  [0.37 0.37]]\n\n [[0.37 0.37]\n  [1.   1.  ]\n  [2.   2.  ]\n  [1.   1.  ]\n  [0.37 0.37]]]\nraw rnn output (no mask)\n [[  -6.        -50.       -156.       -272.7276   -475.83362 ]\n [  -1.2876     -9.862801  -69.314    -213.94202  -373.54672 ]]\nmasked inputs\n [[[1. 1.]\n  [2. 2.]\n  [1. 1.]\n  [0. 0.]\n  [0. 0.]]\n\n [[0. 0.]\n  [1. 1.]\n  [2. 2.]\n  [1. 1.]\n  [0. 0.]]]\nmasked rnn output\n [[  -6.  -50. -156. -156. -156.]\n [   0.   -6.  -50. -156. -156.]]\n</code></pre>\n\n<p>Notice how with the mask applied, the calculations are not performed on a time step where the mask is active (i.e. where the sequence is padded out). Instead, state from the previous time step is carried forward.</p>\n\n<p>A few other points to note:</p>\n\n<ul>\n<li>In the linked (and this) example, the RNN is created with various activation and initializer parameters. I assume this is to initialize the RNN to a known state for repeatability for the example. In practice, you would initialize the RNN how you would like.</li>\n<li>The pad value can be any value you specify. Typically, padding using zeros is used. In the linked (and this) example, a value of 0.37 is used. I can only assume it is an arbitrary value to show the difference in the raw and masked RNN outputs, as a zero input value with this example RNN initialisation gives little/no difference in output, therefore \'some\' value (i.e. 0.37) demonstrates the effect of the masking.</li>\n<li>The <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking"" rel=""nofollow noreferrer"">Masking</a> docs state that rows/time steps are masked only if <em>all</em> of the values for that time step contain the mask value. For example, in the above, a time step of <code>[0.37, 2]</code> would still be fed to the network with those values, however, a time step of <code>[0.37, 0.37]</code> would be skipped over.</li>\n<li>An alternative approach  to this problem instead of masking would be to train several times by batching the different sequence lengths together. For example, if you have a mix of sequence lengths of 10, 20, and 30, instead of padding them all out to 30 and masking, train using all your 10 sequence lengths, then your 20s, then 30s. Or if you have say lots of 100 sequence lengths, and also lots of 3, 4, 5 sequence lengths, you may want to pad your smaller ones to all 5 length and train twice using 100s and padded/masked 5s. You will likely gain training speed, but at the trade-off of less accuracy as you won\'t be able to shuffle between batches of different sequence lengths.</li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9120}"
864,48825785,"{'items': [{'owner': {'reputation': 992, 'user_id': 14642180}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1612421770, 'answer_id': 66040707, 'question_id': 48825785, 'body': ""<p>Reading, filtering a dataset is very easy and there is no need to unstack anything.</p>\n<p>to read the dataset:</p>\n<pre><code>print(my_dataset, '\\n\\n')\n##let us print the first 3 records\nfor record in my_dataset.take(3):\n    ##below could be large in case of image\n    print(record)\n    ##let us print a specific key\n    print(record['key2'])\n</code></pre>\n<p>To filter is equally simple:</p>\n<pre><code>my_filtereddataset = my_dataset.filter(_filtcond1)\n</code></pre>\n<p>where you define _filtcond1 however you want. Let us say there is a 'true' 'false' boolean flag in your dataset, then:</p>\n<pre><code>@tf.function\ndef _filtcond1(x):\n    return x['key_bool'] == 1\n</code></pre>\n<p>or even a lambda function:</p>\n<pre><code>my_filtereddataset = my_dataset.filter(lambda x: x['key_int']&gt;13)\n</code></pre>\n<p>If you are reading a dataset which you havent created or you are unaware of the keys (as seems to be the OPs case), you can use this to get an idea of the keys and structure first:</p>\n<pre><code>import json\nfrom google.protobuf.json_format import MessageToJson\n\nfor raw_record in noidea_dataset.take(1):\n    example = tf.train.Example()\n    example.ParseFromString(raw_record.numpy())\n    ##print(example) ##if image it will be toooolong\n    m = json.loads(MessageToJson(example))\n    print(m['features']['feature'].keys())\n</code></pre>\n<p>Now you can proceed with the filtering</p>\n""}, {'owner': {'reputation': 43, 'user_id': 8638404}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1525719435, 'answer_id': 50220751, 'question_id': 48825785, 'body': ""<p>I think you don't need to make label a 1-dimensional array in the first place.</p>\n\n<p>with:</p>\n\n<pre><code>feature = {'label': tf.FixedLenFeature((), tf.string)}\n</code></pre>\n\n<p>you won't need to unstack the label in your filter_func</p>\n""}, {'owner': {'reputation': 7100, 'user_id': 4137497}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1519056609, 'answer_id': 48869963, 'question_id': 48825785, 'body': ""<p>I am answering my own question. I found the issue!</p>\n\n<p>What I needed to do is <code>tf.unstack()</code> the label like this:</p>\n\n<pre><code>label = tf.unstack(features['label'])\nlabel = label[0]\n</code></pre>\n\n<p>before I give it to <code>tf.equal()</code>:</p>\n\n<pre><code>result = tf.reshape(tf.equal(label, 'some_label_value'), [])\n</code></pre>\n\n<p>I suppose the problem was that the label is defined as an array with one element of type string <code>tf.FixedLenFeature([1], tf.string)</code>, so in order to get the first and single element I had to unpack it (which creates a list) and then get the element with index 0, correct me if I'm wrong.</p>\n""}, {'owner': {'reputation': 83, 'user_id': 7986124}, 'down_vote_count': 5, 'up_vote_count': 0, 'is_accepted': False, 'score': -5, 'creation_date': 1518783367, 'answer_id': 48826574, 'question_id': 48825785, 'body': '<p>You should try to use the apply function from \ntf.data.TFRecordDataset <a href=""https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset"" rel=""nofollow noreferrer"">tensorflow documentation</a></p>\n\n<p>Otherwise... read this article about TFRecords to get a better knowledge about TFRecords  <a href=""https://planspace.org/20170323-tfrecords_for_humans/"" rel=""nofollow noreferrer"">TFRecords for humans </a></p>\n\n<p>But the most likely situation is that you can not access neither modify a TFRecord...there is a request on github about this topic <a href=""https://github.com/tensorflow/tensorflow/issues/7482"" rel=""nofollow noreferrer"">TFRecords request</a></p>\n\n<p>My advice is to make the things as easy as you can...you have to know that you are you working with graph and sessions...</p>\n\n<p>In any case...if everything fail try the part of the code that does not work in a tensorflow session as simple as you can do it...probably all these operations should be done when tf.session is running...</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9120}"
865,67698111,"{'items': [{'owner': {'reputation': 56, 'user_id': 13915440}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1622020559, 'answer_id': 67701963, 'question_id': 67698111, 'body': '<p>This one seems to be working for me:</p>\n<p><code>tf.__version__</code></p>\n<p>Run with Python 3.7.10 and Tensorflow 2.4.1 in a Colab Notebook</p>\n<p>Alternatively, if you used pip to install Tensorflow, you could also use:</p>\n<pre><code>pip show tensorflow\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9120}"
866,37234114,"{'items': [{'owner': {'reputation': 47089, 'user_id': 121687}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1463287523, 'answer_id': 37234653, 'question_id': 37234114, 'body': ""<p>To lock the ones that you don't want to train you can use <code>tf.Variable(..., trainable=False)</code></p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9120}"
867,53951941,"{'items': [{'owner': {'reputation': 198, 'user_id': 9671423}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1551261856, 'answer_id': 54902812, 'question_id': 53951941, 'body': '<p>Tensorflow detection API supports different input formats during exporting as discribed in documentation of file <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py"" rel=""noreferrer"">export_inference_graph.py</a>:</p>\n\n<ul>\n<li><code>image_tensor</code>: Accepts a uint8 4-D tensor of shape [None, None, None, 3]</li>\n<li><code>encoded_image_string_tensor</code>: Accepts a 1-D string tensor of shape [None]\ncontaining encoded PNG or JPEG images. Image resolutions are expected to be\nthe same if more than 1 image is provided.</li>\n<li><code>tf_example</code>: Accepts a 1-D string tensor of shape [None] containing\nserialized TFExample protos. Image resolutions are expected to be the same\nif more than 1 image is provided.</li>\n</ul>\n\n<p>So you should check that you use <code>image_tensor</code> input_type. The chosen input node will be named as ""inputs"" in exported model. So I suppose that replacing <code>image_tensor:0</code> with <code>inputs</code> (or maybe <code>inputs:0</code>) will solve your problem. </p>\n\n<p>Also I would like to recommend a useful tool to run exported models with several lines of code: <code>tf.contrib.predictor.from_saved_model</code>. Here is example of how to use it:</p>\n\n<pre><code>import tensorflow as tf\nimport cv2\n\nimg = cv2.imread(""test.jpg"")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_rgb = np.expand_dims(img, 0)\n\npredict_fn = tf.contrib.predictor.from_saved_model(""./saved_model"")\noutput_data = predict_fn({""inputs"": img_rgb})\nprint(output_data)  # detector output dictionary\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9116}"
868,53915078,"{'items': [{'owner': {'reputation': 187, 'user_id': 4058766}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1545665147, 'answer_id': 53915191, 'question_id': 53915078, 'body': '<p>I am unable to comment due to reputation. </p>\n\n<p>But I think the variables are referencing the position and size of the Max Pooling window. x and y are the x and y position of the kernel as it moves along the input matrix and b and c are the width and height of the kernel. You would set b and c in kernel size.  </p>\n\n<p>If you are having a problem implementing max pooling with argmax it has little to do with these variables. You might want to specify the issue you are having with Max Pooling. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9116}"
869,63399368,"{'items': [{'owner': {'reputation': 31, 'user_id': 8727547}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1597930262, 'answer_id': 63506221, 'question_id': 63399368, 'body': ""<p>I had the same issue and I found the answer creating a custom layer with the lookup transformation and then addin that layer to my model. Somebody else put the answer here on stackoverflow but I cannot find this again so I will put it for you. The reason is that the variables and the other elements from outside must be trackeable and I didn't find other way to make them trackeable but to create a Custom layer because those are trackeable and don't need to add aditional assets when exporting.</p>\n<p>This is the code:</p>\n<p>Here is the custom layer specific to make the transformation before the model (includes the tokenizer as a lookup from a static table, and then the padding:</p>\n<pre><code>class VocabLookup(tf.keras.layers.Layer):\n    def __init__(self, word_index, **kwargs):\n        self.word_index = word_index\n        self.vocab = list(word_index.keys())\n        self.indices = tf.convert_to_tensor(list(word_index.values()), dtype=tf.int64)\n        vocab_initializer = tf.lookup.KeyValueTensorInitializer(self.vocab, self.indices)\n        self.table = tf.lookup.StaticHashTable(vocab_initializer, default_value=1)\n        super(VocabLookup, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.built = True\n\n    def sentences_transform(self,tx):\n        x = tf.strings.lower(tx)\n        x = tf.strings.regex_replace(x,&quot;[,.:;]&quot;, &quot; &quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;a&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;e&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;i&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;i&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;u&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;u&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;a&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;e&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;i&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;o&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;u&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;u&quot;)\n        x = tf.strings.regex_replace(x,&quot;&quot;, &quot;u&quot;)\n        x = tf.strings.regex_replace(x,&quot;[?!@#$-_\\?+{}*/]&quot;, &quot;&quot;)\n        x = tf.strings.regex_replace(x,&quot; +&quot;, &quot; &quot;)\n        x = tf.strings.strip(x)\n        x = tf.strings.split(x)\n        x = self.table.lookup(x)\n        x_as_vector = tf.reshape(x, [-1])\n        zero_padding = tf.zeros([191] - tf.shape(x_as_vector), dtype=x.dtype)\n        x = tf.concat([x_as_vector, zero_padding], 0)\n        return x\n        \n\n    def call(self, inputs):\n        x = tf.map_fn(lambda tx: self.sentences_transform(tx), elems = inputs,dtype=tf.int64)\n        return x\n\n    def get_config(self):\n        return {'word_index': self.word_index}\n</code></pre>\n<p>In my case I create the layer to receive the word_index from a tokenizer as an Input. Then, you can use a Layer like this one inside your model:</p>\n<pre><code>with open(&lt;tokenizer_path&gt;) as f:\n    data = json.load(f)\n    tokenizer = tokenizer_from_json(data)\n\nmoderator = load_model(&lt;final model path ('.h5')&gt;)\nword_index = tokenizer.word_index\ntext_bytes = tf.keras.Input(shape=(), name='image_bytes', dtype=tf.string)\nx = VocabLookup(word_index)(text_bytes)\noutput = moderator(x)\nmodel = tf.keras.models.Model(text_bytes, output)\n</code></pre>\n<p>If you make the summary you will have something like this:</p>\n<pre><code>model.summary()\nModel: &quot;functional_57&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nimage_bytes (InputLayer)     [(None,)]                 0         \n_________________________________________________________________\nvocab_lookup_60 (VocabLookup (None, None)              0         \n_________________________________________________________________\nsequential_1 (Sequential)    (None, 1)                 1354369   \n=================================================================\nTotal params: 1,354,369\nTrainable params: 1,354,369\nNon-trainable params: 0\n</code></pre>\n<p>With this steps you finally can save as a TF2 serving model</p>\n<pre><code>save_path = &lt;your_serving_model_path&gt;\ntf.saved_model.save(model,  save_path)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9116}"
870,51858891,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9116}"
871,55199181,"{'items': [{'owner': {'reputation': 2128, 'user_id': 2364295}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1552769043, 'answer_id': 55201328, 'question_id': 55199181, 'body': ""<p>It turns out that the error is a result of having tensorflow eager execution enabled.  I'm not quite sure why the string notation doesn't work, as opposed to:</p>\n\n<pre><code>optimizer=tf.train.AdamOptimizer()\n</code></pre>\n\n<p>But this solved the problem.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9116}"
872,61355474,"{'items': [{'owner': {'reputation': 21, 'user_id': 4799312}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1668807896, 'answer_id': 74495646, 'question_id': 61355474, 'body': '<p>You might be running in a Colab. If so, try the following immediately after importing Tensorflow:</p>\n<pre><code>tf.compat.v1.enable_v2_behavior()\n</code></pre>\n<p>More generally, check the docs at <a href=""https://www.tensorflow.org/api_docs/python/tf/executing_eagerly"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/executing_eagerly</a> for more information on eager execution.</p>\n'}, {'owner': {'reputation': 3098, 'user_id': 9936228}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1587826016, 'answer_id': 61427471, 'question_id': 61355474, 'body': '<p>As far as I know, when an input to a custom layer is symbolic input, then the layer is executed in graph (non-eager) mode. However, if your input to the custom layer is an eager tensor (as in the following example #1, then the custom layer is executed in the eager mode. So your model\'s output <code>tf.executing_eagerly() = False</code> is expected.</p>\n\n<p>Example #1</p>\n\n<pre><code>from tensorflow.keras import layers\n\n\nclass Linear(layers.Layer):\n\n  def __init__(self, units=32, input_dim=32):\n    super(Linear, self).__init__()\n    w_init = tf.random_normal_initializer()\n    self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units),\n                                              dtype=\'float32\'),\n                         trainable=True)\n    b_init = tf.zeros_initializer()\n    self.b = tf.Variable(initial_value=b_init(shape=(units,),\n                                              dtype=\'float32\'),\n                         trainable=True)\n\n  def call(self, inputs):\n    print(""tf.executing_eagerly() ="", tf.executing_eagerly())\n    return tf.matmul(inputs, self.w) + self.b\n\nx = tf.ones((1, 2)) # returns tf.executing_eagerly() = True\n#x = tf.keras.layers.Input(shape=(2,)) #tf.executing_eagerly() = False\nlinear_layer = Linear(4, 2)\ny = linear_layer(x)\nprint(y) \n#output in graph mode: Tensor(""linear_9/Identity:0"", shape=(None, 4), dtype=float32)\n#output in Eager mode: tf.Tensor([[-0.03011466  0.02563028  0.01234017  0.02272708]], shape=(1, 4), dtype=float32)\n</code></pre>\n\n<p>Here is another example with Keras functional API where custom layer was used (similar to you). This model is executed in graph mode and prints <code>tf.executing_eagerly() = False</code> as in your case.</p>\n\n<pre><code>from tensorflow import keras\nfrom tensorflow.keras import layers\nclass CustomDense(layers.Layer):\n  def __init__(self, units=32):\n    super(CustomDense, self).__init__()\n    self.units = units\n\n  def build(self, input_shape):\n    self.w = self.add_weight(shape=(input_shape[-1], self.units),\n                             initializer=\'random_normal\',\n                             trainable=True)\n    self.b = self.add_weight(shape=(self.units,),\n                             initializer=\'random_normal\',\n                             trainable=True)\n\n  def call(self, inputs):\n    print(""tf.executing_eagerly() ="", tf.executing_eagerly())\n    return tf.matmul(inputs, self.w) + self.b\n\n\ninputs = keras.Input((4,))\noutputs = CustomDense(10)(inputs)\n\nmodel = keras.Model(inputs, outputs) \n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9111}"
873,64081367,"{'items': [{'owner': {'reputation': 1159, 'user_id': 5235528}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1601580504, 'answer_id': 64162020, 'question_id': 64081367, 'body': '<p>You can use :</p>\n<pre><code>downsampled_activations =tf.gather(activations , tf.squeeze(ids) ,axis = 1)\ndownsampled_activations.shape #  [1,120,4]\n</code></pre>\n<p>In most cases, the tf.gather method needs 1d indices, and that is right in your case, instead of indices with 3d (1,1,120), a 1d is sufficient (120,). The method tf.gather will look at the axis( = 1)  and return the element at each index provided by the indices tensor.</p>\n'}, {'owner': {'reputation': 1546, 'user_id': 6767390}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1601580581, 'answer_id': 64162041, 'question_id': 64081367, 'body': '<blockquote>\n<p><code>tf.gather</code> Gather slices from <code>params</code> axis <code>axis</code> according to indices.</p>\n</blockquote>\n<p>Granted that the documentation is not the most expressive, and the emphasis should be placed on the <strong>slices</strong> (since you index slices from the <code>axis</code> and not elements, which is what I suppose you mistakenly took it for).</p>\n<p><strong>Let\'s take a much smaller example:</strong></p>\n<pre class=""lang-py prettyprint-override""><code>activations_small = tf.convert_to_tensor([[[1, 2, 3, 4], [11, 22, 33, 44]]])\nprint(activations_small.shape) # [1, 2, 4]\n</code></pre>\n<p>Let\'s picture this tensor:</p>\n<pre><code>    XX 4  XX 44 XX XX\n  XX  3 XX  33 X  XX\nXXX 2 XX   22XX  XX\nX-----X-----+X  XX\n|  1  |  11 | XX\n+-----+-----+X\n</code></pre>\n<p><code>tf.gather(activations1, [0, 0], axis=1)</code> will return</p>\n<pre><code>&lt;tf.Tensor: shape=(1, 2, 4), dtype=int32, numpy=\narray([[[1, 2, 3, 4],\n        [1, 2, 3, 4]]], dtype=int32)&gt;\n</code></pre>\n<p>What <code>tf.gather</code> did was to <em>look from</em> axis 1, and picks up index 0 (ofc, two times i.e. <code>[0, 0]</code>). If you were to run <code>tf.gather(activations1, [0, 0, 0, 0, 0], axis=1).shape</code>, you\'d get <code>TensorShape([1, 5, 4])</code>.</p>\n<p><strong>Your Error</strong>\nNow let\'s try to trigger the error that you\'re getting.</p>\n<p><code>tf.gather(activations1, [0, 2], axis=1)</code></p>\n<blockquote>\n<p>InvalidArgumentError: indices[1] = 2 is not in [0, 2) [Op:GatherV2]</p>\n</blockquote>\n<p>What happened here was that when <code>tf.gather</code> looks from axis 1 perspective, there\'s no item (column if you will) with index = 2.</p>\n<p>I guess this is what the <a href=""https://www.tensorflow.org/api_docs/python/tf/gather#args"" rel=""nofollow noreferrer"">documentation</a> is hinting at by</p>\n<blockquote>\n<p><code>param:&lt;indices&gt;</code> The index Tensor. Must be one of the following types: int32, int64. Must be in range [0, params.shape[axis]).</p>\n</blockquote>\n<p><strong>Your (potential) solution</strong></p>\n<p>From the dimensions of <code>indices</code>, and that of the expected result from your question, I am not sure if the above was very obvious to you.</p>\n<p><code>tf.gather(activations, indices=[0, 1, 2, 3], axis=2)</code> or anything with indices within the range of indices in <code>[0, activations.shape[2])</code> i.e. <code>[0, 4)</code> would work. Anything else would give you the error that you\'re getting.</p>\n<p>There\'s a verbatim answer below in case that\'s your expected result.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9111}"
874,60610007,"{'items': [{'owner': {'reputation': 63, 'user_id': 12910437}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1584327630, 'answer_id': 60699823, 'question_id': 60610007, 'body': '<p>Please refer working code Build tf.estimator.DNNClassifier from Mnist Dataset.</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nlearn = tf.contrib.learn\ntf.logging.set_verbosity(tf.logging.ERROR)\nprint(tf.__version__)\n##import the dataset\nmnist = learn.datasets.load_dataset(\'mnist\')\ndata = mnist.train.images\nlabels = np.asarray(mnist.train.labels, dtype=np.int32)\ntest_data = mnist.test.images\ntest_labels = np.asarray(mnist.test.labels, dtype = np.int32)\ndef input(dataset):\n    return dataset.images, dataset.labels.astype(np.int32)\n\n# Specify feature\nfeature_columns = [tf.feature_column.numeric_column(""""x"""", shape=[28, 28])]\n# Build 2 layer DNN classifier\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=feature_columns,\n    hidden_units=[256, 32],\n    optimizer=tf.train.AdamOptimizer(1e-4),\n    n_classes=10,\n    dropout=0.1,\n    model_dir=""""./tmp/mnist_model""""\n)\n\n# Define the training inputs\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={""""x"""": input(mnist.train)[0]},\n    y=input(mnist.train)[1],\n    num_epochs=None,\n    batch_size=50,\n    shuffle=True\n)\n\nclassifier.train(input_fn=train_input_fn, steps=100)\n# Evaluate accuracy\naccuracy_score = classifier.evaluate(input_fn=train_input_fn)[""""accuracy""""]\nprint(""""\\nTrain Accuracy: {0:f}%\\n"""".format(accuracy_score*100))\n\n# Define the test inputs\ntest_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={""""x"""": input(mnist.test)[0]},\n    y=input(mnist.test)[1],\n    num_epochs=1,\n    shuffle=False\n)\n\n# Evaluate accuracy\naccuracy_score = classifier.evaluate(input_fn=test_input_fn)[""""accuracy""""]\nprint(""""\\nTest Accuracy: {0:f}%\\n"""".format(accuracy_score*100))""\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9111}"
875,65408472,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9111}"
876,46298583,"{'items': [{'owner': {'reputation': 416, 'user_id': 4341842}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1506509178, 'answer_id': 46445911, 'question_id': 46298583, 'body': '<p>Alright! anyway, I have found the answer to this question and I am posting it so that others might benefit from it. <br></p>\n\n<p>The first link is more of a tutorial that steps you through the process of exactly how the embeddings are learnt. <br></p>\n\n<p>In practical cases, such as training seq2seq models or Any other encoder-decoder models, we use the second approach where the embedding matrix gets tuned appropriately while the model gets trained.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9107}"
877,40195549,"{'items': [{'owner': {'reputation': 3149, 'user_id': 6791223}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1477162525, 'answer_id': 40195859, 'question_id': 40195549, 'body': ""<p>Firstly, <code>tf.rank</code> returns the dimension of a tensor, not the number of elements. For instance, the output from <code>tf.rank</code> called for the 2x2 matrix would be 2. </p>\n\n<p>To print the rank of a tensor, create an appropriate node, e.g. <code>rank = tf.rank(x)</code> and then evaluate this node using a <code>Session.run()</code>, as you've done for weights and x. Execution of <code>print (tf.rank(x), tf.rank(weights))</code> expectedly prints out description of tensors, as <code>tf.rank(x), tf.rank(weights)</code> are nodes of the graph, not the variables with defined values.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9107}"
878,57875937,"{'items': [{'owner': {'reputation': 36, 'user_id': 7416201}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1568140236, 'answer_id': 57876450, 'question_id': 57875937, 'body': '<p>I think what\'s happening is you\'re creating a race between w1 and v_op2, and they\'re both being executed simultaneously. (with theses lines)</p>\n\n<pre class=""lang-py prettyprint-override""><code>with tf.control_dependencies([w1, v_op2]):\n</code></pre>\n\n<p>for example if v_op2 is executed before w1 then 2 is added to <code>v</code> then when w1 is executed it adds 1 to it making msg_1 print 3. However when w1 is able to be completed before v_op2 is executed then 2 is added to <code>v</code> after.</p>\n\n<p>e.g. case 1</p>\n\n<pre><code>v_op2 executed:\nv = 2\nw1 executed:\nv = 3\nprint(v)\n</code></pre>\n\n<p>case 2</p>\n\n<pre><code>w1 executed\nv = 1\nprint(v)\nv_op2 executed\nv=3\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9107}"
879,75996642,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9107}"
880,53233123,"{'items': [{'owner': {'reputation': 47103, 'user_id': 38626}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1628249441, 'answer_id': 68680868, 'question_id': 53233123, 'body': '<p>Stateful RNNs in TensorFlow require the batch size to be fixed, so your desired output would not work: the batch size changes from 3 to 2.</p>\n<p>So you need to have something like this instead:</p>\n<pre class=""lang-py prettyprint-override""><code>[[[ 0. inf inf inf]   # batch 1\n  [ 0.  1.  2. inf]\n  [ 0.  1.  2.  3.]]\n\n [[inf]               # batch 2 - the leftover timestep from a padded \n  [inf]               # batch of the first 3 generators\n  [4. ]]\n\n [[ 0.  1.  2.  3.]   # batch 3 - only two generators are left\n  [ 0.  1.  2.  3.]   # but we still need the same batch size\n  [ inf inf inf inf]] # so this row of `inf` is needed\n\n [[ 4.  5.  6. inf]   # batch 4\n  [ 4.  5.  6.  7.]\n  [ inf inf inf inf]]\n\n [[inf]               # batch 5\n  [ 8.]\n  [inf]]]\n</code></pre>\n<p>I don\'t believe it\'s possible to do this using your <code>interleave</code> + <code>padded_batch</code> approach.</p>\n<p>However, one approach that does work is to pad all the sequences to the same length. Here\'s a working example using TensorFlow 2.4.1 (it should work with other TF 2 versions):</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\n\nlengths = list(range(1,12,2)) # [1, 3, 5, 7, 9, 11]\nmax_length = max(lengths)\n\ndef stepwise_generator(length):\n    for i in range(max_length):\n        if i &lt; length:\n            yield float(i)\n        else:\n            yield np.inf\n\nwindow_length = 4\nbatch_size = 3\n\ndataset = tf.data.Dataset.from_tensor_slices(lengths)\n\ngen = lambda length: tf.data.Dataset.from_generator(\n    stepwise_generator, tf.float32, args=(length,)\n).batch(window_length) # this batching saves window_length timesteps per generator\n\ndataset = dataset.interleave(gen, cycle_length=batch_size)\ndataset = dataset.batch(batch_size)\n\nfor batch in dataset:\n    print(batch)\n</code></pre>\n<p>This gives the following output:</p>\n<pre><code>tf.Tensor(\n[[ 0. inf inf inf]\n [ 0.  1.  2. inf]\n [ 0.  1.  2.  3.]], shape=(3, 4), dtype=float32)\ntf.Tensor(\n[[inf inf inf inf]\n [inf inf inf inf]\n [ 4. inf inf inf]], shape=(3, 4), dtype=float32)\ntf.Tensor(\n[[inf inf inf]\n [inf inf inf]\n [inf inf inf]], shape=(3, 3), dtype=float32)\ntf.Tensor(\n[[0. 1. 2. 3.]\n [0. 1. 2. 3.]\n [0. 1. 2. 3.]], shape=(3, 4), dtype=float32)\ntf.Tensor(\n[[ 4.  5.  6. inf]\n [ 4.  5.  6.  7.]\n [ 4.  5.  6.  7.]], shape=(3, 4), dtype=float32)\ntf.Tensor(\n[[inf inf inf]\n [ 8. inf inf]\n [ 8.  9. 10.]], shape=(3, 3), dtype=float32)\n</code></pre>\n<p>Notes:</p>\n<ul>\n<li>the generator now handles the padding, so we use <code>batch()</code> instead of <code>padded_batch()</code></li>\n<li>the number of sequences must be a multiple of the batch size</li>\n<li>the <code>tf.contrib</code> package was removed in TF 2, but <code>tf.contrib.data.parallel_interleave()</code> was promoted to the core API: you can now use <code>dataset.interleave()</code></li>\n<li>since this is TF 2, there\'s no need for <code>dataset.make_one_shot_iterator()</code>, or <code>iterator.get_next()</code> or <code>tf.Session()</code>, etc. It\'s much simpler.</li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9103}"
881,57277926,"{'items': [{'owner': {'reputation': 1108, 'user_id': 6253183}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1582793005, 'answer_id': 60429294, 'question_id': 57277926, 'body': '<h3>Use <code>my_model.output_names</code></h3>\n\n<p>Given</p>\n\n<pre class=""lang-py prettyprint-override""><code>my_model = tf.keras.models.Model(inputs=my_inputs_dict, outputs=my_outputs_dict)\n</code></pre>\n\n<p>create the <code>dict</code> yourself from <code>my_model.output_names</code>, which is a list of <code>name</code> attributes of your output layers in the order of prediction</p>\n\n<pre class=""lang-py prettyprint-override""><code>prediction_list = my_model.predict(my_test_input_dict)\nprediction_dict = {name: pred for name, pred in zip(my_model.output_names, prediction_list)}\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9103}"
882,75148775,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9103}"
883,62086633,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9103}"
884,44963306,"{'items': [{'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1499407519, 'answer_id': 44963595, 'question_id': 44963306, 'body': '<p>Most of TF functions take tensors as parameters. This applies to <a href=""https://www.tensorflow.org/api_docs/python/tf/concat"" rel=""nofollow noreferrer"">tf.concat</a>. As you can see from the documentation:</p>\n\n<blockquote>\n  <p>values: A list of Tensor objects or a single Tensor.</p>\n</blockquote>\n\n<p>And you provide numpy arrays and not tensors. Here is a working example.</p>\n\n<pre><code>import tensorflow as tf \nimport numpy as np \n\na=np.zeros([3,3])\nb=np.ones([3,3])\n\nA = tf.constant(a)\nB = tf.constant(b)\nconcatenated=tf.concat([A, B], axis=0) \n\nwith tf.Session() as sess:\n    print sess.run(concatenated)\n</code></pre>\n\n<p>Not related to your question, but separate a graph definition from a graph execution (you do everything in <code>tf.session</code>, I define everything outside and only execute in the session</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9099}"
885,74143214,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9099}"
886,49997294,"{'items': [{'owner': {'reputation': 18649, 'user_id': 3214872}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1524560626, 'answer_id': 49997528, 'question_id': 49997294, 'body': '<p><strong>Note:</strong> While writing the question I eventually realised my mistake (i.e., being blind and not seeing code and documentation that by now I think I looked at 20 times at least), but I believe the question and matching answer might be useful to others so I decided to finish the question and self-answer it.</p>\n\n<p><strong>If I were to read the whole <a href=""https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/estimator/train_and_evaluate"" rel=""nofollow noreferrer"">docs</a> as they are written</strong>, I would have noticed the following: </p>\n\n<blockquote>\n  <p>Example of TF_CONFIG for evaluator task. Evaluator is a special task\n  that is not part of the training cluster. There could be only one. It\n  is used for model evaluation.</p>\n</blockquote>\n\n<pre><code># This should be a JSON string, which is set as environment variable. Usually\n# the cluster manager handles that.\nTF_CONFIG=\'{\n    ""cluster"": {\n        ""chief"": [""host0:2222""],\n        ""worker"": [""host1:2222"", ""host2:2222"", ""host3:2222""],\n        ""ps"": [""host4:2222"", ""host5:2222""]\n    },\n    ""task"": {""type"": ""evaluator"", ""index"": 0}\n}\'\n</code></pre>\n\n<p>As it turns out, yes, there is indeed support for the evaluation task <em>and using it is a lot easier than I expected</em>.</p>\n\n<p>Just set the <code>""task""</code>part of <code>TF_CONFIG</code> to <code>{""type"": ""evaluator"", ""index"": 0}</code> as shown above and there you have evaluation running. The confusing part for me was <em>""Evaluator is a special task that is not part of the training cluster""</em>. This is, I believe, because the chief worker waits for all workers to register with him when starting the distributed session, so leaving the evaluator out of the cluster keeps training and evaluation independent of each other and makes training agnostic of evaluation.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9099}"
887,67747314,"{'items': [{'owner': {'reputation': 4737, 'user_id': 2423278}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1622275570, 'answer_id': 67749140, 'question_id': 67747314, 'body': ""<p>Since <strong>Precision</strong> and <strong>Recall</strong> are naturally binary metrics, you can not use them for a multi class prediction.</p>\n<p>The error indicates that you have 10 classes for prediction and this is incompatible with 1 class classification metric you have provided.</p>\n<p>However, you can implement a <strong>Custom Metric</strong> and pass it as an argument to your <code>metrics</code>.</p>\n<p><strong>1. Define a custom metric:</strong></p>\n<pre><code>class MulticlassTruePositives(tf.keras.metrics.Metric):\n    def __init__(self, name='multiclass_true_positives', **kwargs):\n        super(MulticlassTruePositives, self).__init__(name=name, **kwargs)\n        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n        values = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')\n        values = tf.cast(values, 'float32')\n        if sample_weight is not None:\n            sample_weight = tf.cast(sample_weight, 'float32')\n            values = tf.multiply(values, sample_weight)\n        self.true_positives.assign_add(tf.reduce_sum(values))\n\n    def result(self):\n        return self.true_positives\n\n    def reset_states(self):\n        # The state of the metric will be reset at the start of each epoch.\n        self.true_positives.assign(0.)\n</code></pre>\n<p><strong>2. Then pass it to your <code>metrics</code>:</strong></p>\n<pre><code>metrics=[tf.keras.metrics.SparseCategoricalAccuracy(), MulticlassTruePositives()]\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9099}"
888,57056756,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9095}"
889,75838967,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9095}"
890,63624699,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9095}"
891,61175291,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9095}"
892,60782077,"{'items': [{'owner': {'reputation': 6067, 'user_id': 4358570}, 'down_vote_count': 1, 'up_vote_count': 4, 'is_accepted': False, 'score': 3, 'creation_date': 1590801642, 'answer_id': 62096717, 'question_id': 60782077, 'body': '<blockquote>\n<p>First, what are the input_length and label_length parameters?</p>\n</blockquote>\n<p><code>input_length</code> is the length of the input sequence in time steps. <code>label_length</code> is the length of the text label.</p>\n<p>For example, if you are trying to recognize:</p>\n<p><a href=""https://i.stack.imgur.com/VjGu2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VjGu2.png"" alt=""John Hancock"" /></a></p>\n<p>and you are doing it in 32 time steps, then your <code>input_length</code> is 32 and your <code>label_length</code> is 12 (<code>len(&quot;John Hancock&quot;)</code>).</p>\n<blockquote>\n<p>Shouldn\'t the function already know the input_length and label_length from the shape of the first two parameters (y_true and y_pred)?</p>\n</blockquote>\n<p>You usually process input data in batches, which have to be padded to the largest element in the batch, so this information is lost. In your case the <code>input_length</code> is always the same, but the <code>label_length</code> varies.</p>\n<p>When dealing with speech recognition, for example, <code>input_length</code> can vary as well.</p>\n<blockquote>\n<p>Secondly, do I need to encode my training data? Is this all done automatically?</p>\n</blockquote>\n<p>Not sure I understand what you are asking, but here is a good example written in Keras:</p>\n<p><a href=""https://keras.io/examples/image_ocr/"" rel=""nofollow noreferrer"">https://keras.io/examples/image_ocr/</a></p>\n<blockquote>\n<p>I know tensorflow also has a function called <code>tf.keras.backend.ctc_decode</code>. Is this only used when making predictions?</p>\n</blockquote>\n<p>In general, yes. You can also try to use it make you breakfast in the morning, but it\'s not very good at it ;)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9095}"
893,73657854,"{'items': [{'owner': {'reputation': 3541, 'user_id': 5157515}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1669140018, 'answer_id': 74537167, 'question_id': 73657854, 'body': '<p><code>tf.keras.Sequential</code> model is usable. However, not all other keras submodules are available yet. This may have changed over the subsequent version releases v1.4 and v1.5</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9090}"
894,70303232,"{'items': [{'owner': {'reputation': 386, 'user_id': 11849563}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1639663913, 'answer_id': 70380453, 'question_id': 70303232, 'body': '<p>In your case warning happens because of <code>(2) passing tensors with different shapes</code>. And you get tensors of different shape because of PIL.\n<code>img.thumbnail</code> resizes some of your images in a wrong way. It keeps the aspect ratio of the image, so you get 160x160 image only if your source image had 1:1 aspect ratio.</p>\n<p>Use Tensorflow or OpenCV to process images, not PIL it\'s very slow...</p>\n<pre class=""lang-py prettyprint-override""><code>def process_image(img_name, output_size=(160,160)):\n    img = cv2.imread(directory+img_name)\n    img = img[..., ::-1] # convert BGR to RGB\n    img = cv2.resize(img, output_size)\n    results = detector.detect_faces(img)\n    ...\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9090}"
895,71294464,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9090}"
896,73461248,"{'items': [{'owner': {'reputation': 696, 'user_id': 1676589}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1661280980, 'answer_id': 73463853, 'question_id': 73461248, 'body': ""<p>If you don't want to use <code>ImageDataGenerator</code></p>\n<pre><code>from tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n\ndef make_dataset(x, y):\n    imgs = []\n    labels = []\n    img_size = # set to whatever you need\n\n    for i, j in zip(x, y):\n        img = load_img(i, target_size=img_size)\n        img = img_to_array(img)\n        imgs.append(img)\n        labels.append(j)\n    imgs, labels = np.array(imgs), np.array(labels)\n    return imgs, labels\n\n\nx_train, y_train = make_dataset(list_imagepath_train, list_corresponding_classlabels_train)\nx_val, y_val = make_dataset(list_imagepath_val, list_corresponding_classlabels_val)\nmodel.fit(x_train, y_train, ...)\n</code></pre>\n""}, {'owner': {'reputation': 321, 'user_id': 19121443}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1661280289, 'answer_id': 73463747, 'question_id': 73461248, 'body': '<p>You could use ImageDataGenerator() class and then its function flow_from_dataframe(); so before create dataframe with two columns; x_col as files path and y_col as the labels, then define parameters in flow_from_dataframe() and for this case set directory to None.</p>\n<p>Also you could use os library and create dirs and subdirs and then move images based on the labels into its subdirs; if you wanna only use image_data_from_directory()</p>\n<p>And even tf.data.Dataset.from_tensor_slices((path_list, label_list)) and then map it by a function which load image by tf.io.read_file() and then decode image, resize and reshape and then return both image and label. then batch and shuffle after map the dataset.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9090}"
897,51265030,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9086}"
898,73645574,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9086}"
899,73336326,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9086}"
900,48051722,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9083}"
901,47775244,"{'items': [{'owner': {'reputation': 1058, 'user_id': 6032016}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1513095366, 'answer_id': 47777046, 'question_id': 47775244, 'body': '<p><code>tf.nn.conv2d</code> computes a <strong>2-D</strong> convolution given 4-D input and filter tensors, while <code>tf.nn.convolution</code> computes sums of <strong>N-D</strong> convolutions. Both return a <code>Tensor</code> with same type of input. </p>\n\n<p>See <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/convolution"" rel=""nofollow noreferrer"">tt.nn.convolution</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv2d"" rel=""nofollow noreferrer"">tt.nn.con2d</a> for further understanding.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9082}"
902,64046604,"{'items': [{'owner': {'reputation': 41, 'user_id': 1860294}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1668179945, 'answer_id': 74404607, 'question_id': 64046604, 'body': '<p>Use <code>tf.data.Dataset.cache()</code> to limit <code>map()</code> to the first epoch. Call after any transformations you only want applied once, but before transformations you want applied every epoch.</p>\n<p>For example:</p>\n<pre><code>ds = ds.map(lambda x, y: (my_first_epoch_only_transformation(x), y)).cache()\nds = ds.map(lambda x, y: (my_every_epoch_transformation(x), y))\n</code></pre>\n<p>From the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#cache"" rel=""nofollow noreferrer"">tf.data.Dataset.cache() docs</a>:</p>\n<blockquote>\n<p>Caches the elements in this dataset.</p>\n<p>The first time the dataset is iterated over, its elements will be\ncached either in the specified file or in memory. Subsequent\niterations will use the cached data.</p>\n</blockquote>\n'}, {'owner': {'reputation': 34678, 'user_id': 10908375}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1600954775, 'answer_id': 64047741, 'question_id': 64046604, 'body': ""<p>You can just use different datasets. That's easy in a custom training loop. Just like that:</p>\n<pre><code>def transformation(inputs, labels):\n    tf.print('With transformation!')\n    return inputs, labels\n\ndef no_transformation(inputs, labels):\n    tf.print('No transformation!')\n    return inputs, labels\n\ndata_with_transform = data.take(4).map(transformation).batch(4)\ndata_no_transform = data.take(4).map(no_transformation).batch(4)\n</code></pre>\n<p>And then later:</p>\n<pre><code>if epoch &lt; 1:\n    ds = data_with_transform\nelse:\n    ds = data_no_transform\n\nfor X_train, y_train in ds:\n    train_step(X_train, y_train)\n</code></pre>\n<p>Full example:</p>\n<pre><code>import tensorflow_datasets as tfds\nimport tensorflow as tf\n\ndata, info = tfds.load('iris', split='train', as_supervised=True,\n                       with_info=True)\n\ndef transformation(inputs, labels):\n    tf.print('With transformation!')\n    return inputs, labels\n\ndef no_transformation(inputs, labels):\n    tf.print('No transformation!')\n    return inputs, labels\n\ndata_with_transform = data.take(4).map(transformation).batch(4)\ndata_no_transform = data.take(4).map(no_transformation).batch(4)\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(8, activation='relu'),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(info.features['label'].num_classes)\n])\n\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\ntrain_loss = tf.keras.metrics.Mean()\ntrain_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n\nopt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n\n\n@tf.function\ndef train_step(inputs, labels):\n    with tf.GradientTape() as tape:\n        logits = model(inputs)\n        loss = loss_object(labels, logits)\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n    opt.apply_gradients(zip(gradients, model.trainable_variables))\n    train_loss(loss)\n    train_acc(labels, logits)\n\n\ndef main(epochs=5):\n\n    for epoch in range(epochs):\n\n        train_loss.reset_states()\n        train_acc.reset_states()\n\n        if epoch &lt; 1:\n            ds = data_with_transform\n        else:\n            ds = data_no_transform\n\n        for X_train, y_train in ds:\n            train_step(X_train, y_train)\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n<pre><code>With transformation!\nWith transformation!\nWith transformation!\nWith transformation!\n\nNo transformation!\nNo transformation!\nNo transformation!\nNo transformation!\n\nNo transformation!\nNo transformation!\nNo transformation!\nNo transformation!\n\nNo transformation!\nNo transformation!\nNo transformation!\nNo transformation!\n\nNo transformation!\nNo transformation!\nNo transformation!\nNo transformation!\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9082}"
903,48311823,"{'items': [{'owner': {'reputation': 682, 'user_id': 7818309}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1516242134, 'answer_id': 48312871, 'question_id': 48311823, 'body': '<p>Well, <code>conv1d</code> is actually <code>conv2d</code> with <code>in_height=1</code>. The <a href=""https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/ops/nn_ops.py"" rel=""nofollow noreferrer"">nn_ops.py.conv1d</a> states:</p>\n\n<pre><code>Internally, this op reshapes the input tensors and invokes `tf.nn.conv2d`. \nFor example, if `data_format` does not start with ""NC"", a tensor of shape\n  [batch, in_width, in_channels]\nis reshaped to\n  [batch, 1, in_width, in_channels],\nand the filter is reshaped to\n  [1, filter_width, in_channels, out_channels].\nThe result is then reshaped back to\n  [batch, out_width, out_channels]\n\\(where out_width is a function of the stride and padding as in conv2d\\) and\n returned to the caller.\n</code></pre>\n\n<p>Thus, <code>tf.nn.conv2d_transpose</code> can do the job.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9082}"
904,76324368,"{'items': [{'owner': {'reputation': 5, 'user_id': 18338104}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1685016928, 'answer_id': 76332168, 'question_id': 76324368, 'body': '<p>After some experimentation I realized that the <code>kernel</code> for the dense layer needs to be of <code>shape=(10,5)</code> as apposed to <code>(5,10)</code> as in the code from the original question above. This is implicit because <code>units=5</code> so a vector of size <code>10</code> needs to be passed (hence why <code>input_shape=(10,)</code> is commented out as a reminder). Below is the corrected code:</p>\n<pre class=""lang-py prettyprint-override""><code>tf.random.set_seed(1)\n\nbias   = tf.Variable(tf.random.uniform(shape=(5,1)), dtype=tf.float32)\nkernel = tf.Variable(tf.random.uniform(shape=(10,5)), dtype=tf.float32)\nx = tf.constant(tf.random.uniform(shape=(10,1), dtype=tf.float32))\n\nresult = tf.nn.relu(tf.linalg.matmul(a=weights, b=x, transpose_a=True) + biases)\ntf.print(result)\n\ntest = tf.keras.layers.Dense(units = 5, \n                            # input_shape=(10,),\n                            activation = \'relu\',\n                            use_bias = True, \n                            kernel_initializer = tf.keras.initializers.Constant(value=kernel), \n                            bias_initializer = tf.keras.initializers.Constant(value=bias), \n                            dtype=tf.float32)\n\nresult1 = test(tf.transpose(x))\n\nprint()\ntf.print(result1)\n\n</code></pre>\n<pre class=""lang-py prettyprint-override""><code>[[2.38769]\n [3.63470697]\n [2.62423944]\n [3.31286287]\n [2.91121125]]\n\n[[2.38769 3.63470697 2.62423944 3.31286287 2.91121125]]\n</code></pre>\n<p>Ultimately, I am not entirely sure what was happening under the hood and why <code>keras</code> did not raise an error. I will check with the <code>tf.keras.layers.Dense()</code> implementation but any thoughts or suggestions by someone who knows the code already are highly appreciated!</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9082}"
905,50763281,"{'items': [{'owner': {'reputation': 5778, 'user_id': 6824418}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1528753308, 'answer_id': 50806440, 'question_id': 50763281, 'body': '<p>This may be a bit more clear if you look at <a href=""https://stackoverflow.com/a/37922210/6824418"">what a TensorFlow <code>Optimizer</code> actually computes</a>. There are two steps: it fetches gradients for variables, then it applies updates. So yes, only variables are optimized.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9078}"
906,55602703,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9078}"
907,52319765,"{'items': [{'owner': {'reputation': 18649, 'user_id': 3214872}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1536922199, 'answer_id': 52330445, 'question_id': 52319765, 'body': '<p>Since you already have a trained graph saved in a checkpoint, <strong>in theory</strong> the simplest solution for you is to export the inference graph via <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py"" rel=""noreferrer""><code>optimize_for_inference</code></a>.</p>\n\n<p>This tool works both for already-frozen graphs and, as is your case, for graphs with variables still defined.\nAssuming you go for the frozen graph way, the first step is to transform your graph\'s variables in constants via:</p>\n\n<pre><code>python freeze_graph.py \\\n--input_graph=temp/path/graph.pbtxt \\\n--input_checkpoint=temp/path/your_model_name.ckpt \\\n--output_graph=frozen_model.pb \\\n--output_node_names=name_of_the_output_tensor_you_want_to_use\n</code></pre>\n\n<p>This will generate a new binary file called <code>frozen_model.pb</code> that has the <code>Variable</code> operations replaced with <code>Const</code> ops with the values loaded from the checkpoint file.</p>\n\n<p>Then, you need to generate the inference graph with:</p>\n\n<pre><code>python optimize_for_inference.py \\\n--input=frozen_model.pb \\\n--output=inference.pb \\\n--frozen_graph=True \\\n--input_names=IteratorGetNext\n--output_names=name_of_the_output_tensor_you_want_to_use\n</code></pre>\n\n<p>This will replace the <code>IteratorGetNext</code> node with a float placeholder. You might want to choose another node, in which case just change the name. You can also change the type of the generated placeholder via the <code>--placeholder_type_enum</code> option. In that case, you need to provide an integer value matching the datatype you want from the <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/types.proto"" rel=""noreferrer""><code>DataType</code> enum</a>.</p>\n\n<p><strong>NOTE:</strong> I said ""in theory"" because actually inspecting the generated inception graph from a test I made it seems there are still some weird ops in there that are not really necessary for inference. You might have to further process your graph via nvidia\'s <a href=""https://docs.nvidia.com/deeplearning/sdk/tensorrt-api/python_api/graphsurgeon/graphsurgeon.html"" rel=""noreferrer"">Graph Surgeon</a> or TF\'s <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md"" rel=""noreferrer"">graph transform tool</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9078}"
908,60384790,"{'items': [{'owner': {'reputation': 4380, 'user_id': 3279603}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1582588851, 'answer_id': 60385714, 'question_id': 60384790, 'body': '<p>They are basically the same. <code>tf.keras</code> is TensorFlow\'s high-level API for building and training deep learning models. It\'s used for fast prototyping, state-of-the-art research, and production. <code>tf.Keras</code> basically uses Tensorflow in its backend. By looking at <code>tf.Keras</code> source code <a href=""https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/backend.py#L3772-L3784"" rel=""nofollow noreferrer"">here</a>, we can see that <code>tf.keras.backend.gradients</code> indeed uses <code>tf.gradients</code>: </p>\n\n<pre class=""lang-py prettyprint-override""><code># Part of Keras.backend.py\n\nfrom tensorflow.python.ops import gradients as gradients_module\n\n@keras_export(\'keras.backend.gradients\')\ndef gradients(loss, variables):\n  """"""Returns the gradients of `loss` w.r.t. `variables`.\n  Arguments:\n      loss: Scalar tensor to minimize.\n      variables: List of variables.\n  Returns:\n      A gradients tensor.\n  """"""\n   # ========\n   # Uses tensorflow\'s gradient function\n   # ========\n  return gradients_module.gradients(\n      loss, variables, colocate_gradients_with_ops=True)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9078}"
909,71130645,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1644946384, 'answer_id': 71130875, 'question_id': 71130645, 'body': '<p>You should be able to solve this with <code>tf.keras.layers.Multiply()</code> and <code>tf.reshape</code>:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\nrepeated_query_vector = tf.constant([\n  [[1, 2], [1, 2]],\n  [[3, 4], [3, 4]]\n])\n\ndocument_vectors = tf.constant([\n  [[5, 6], [7, 8]],\n  [[9, 10], [11, 12]],\n])\n\nmultiply_layer = tf.keras.layers.Multiply()\nresult = multiply_layer([repeated_query_vector, document_vectors])\nshape = tf.shape(result)\nresult = tf.reduce_sum(tf.reshape(result, (shape[0], shape[1] * shape[2])), axis=1, keepdims=True)\n</code></pre>\n<pre><code>tf.Tensor(\n[[ 40]\n [148]], shape=(2, 1), dtype=int32)\n</code></pre>\n<p>Or with <code>tf.keras.layers.Dot</code> and <code>tf.reshape</code>:</p>\n<pre><code>import tensorflow as tf\n\nrepeated_query_vector = tf.constant([\n  [[1, 2], [1, 2]],\n  [[3, 4], [3, 4]]\n])\n\ndocument_vectors = tf.constant([\n  [[5, 6], [7, 8]],\n  [[9, 10], [11, 12]],\n])\n\ndot_layer = tf.keras.layers.Dot(axes=1)\nresult = dot_layer([tf.reshape(repeated_query_vector, (repeated_query_vector.shape[0], repeated_query_vector.shape[1] * repeated_query_vector.shape[2])),\n                         tf.reshape(document_vectors, (document_vectors.shape[0], document_vectors.shape[1] * document_vectors.shape[2]))])\n</code></pre>\n<pre><code>tf.Tensor(\n[[ 40]\n [148]], shape=(2, 1), dtype=int32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9074}"
910,71933464,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9074}"
911,46650905,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9074}"
912,51858970,"{'items': [{'owner': {'reputation': 606, 'user_id': 3325672}, 'down_vote_count': 1, 'up_vote_count': 2, 'is_accepted': True, 'score': 1, 'creation_date': 1534349015, 'answer_id': 51862290, 'question_id': 51858970, 'body': ""<p>If y and x have the same shape then the sum over the dy/dx is the sum over exactly one value. However, if you have more than one y for each x, then the gradients are summed.</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\n\nx_dims = 3\nbatch_size = 4\n\nx = tf.placeholder(tf.float32, (None, x_dims))\ny = 2*(x**2)\nz = tf.stack([y, y]) # There are twice as many z's as x's\n\ndy_dx = tf.gradients(y,x)\ndz_dx = tf.gradients(z,x)\n\nsess = tf.Session()\n\nx_val = np.random.randint(0, 10, (batch_size, x_dims))\ny_val, z_val, dy_dx_val, dz_dx_val = sess.run([y, z, dy_dx, dz_dx], {x:x_val})\n\nprint('x.shape =', x_val.shape)\nprint('x = \\n', x_val)\nprint('y.shape = ', y_val.shape)\nprint('y = \\n', y_val)\nprint('z.shape = ', z_val.shape)\nprint('z = \\n', z_val)\nprint('dy/dx = \\n', dy_dx_val[0])\nprint('dz/dx = \\n', dz_dx_val[0])\n</code></pre>\n\n<p>Produces the following output:</p>\n\n<pre><code>x.shape = (4, 3)\nx = \n [[1 4 8]\n [0 2 8]\n [2 8 1]\n [4 5 2]]\n\ny.shape =  (4, 3)\ny = \n [[  2.  32. 128.]\n [  0.   8. 128.]\n [  8. 128.   2.]\n [ 32.  50.   8.]]\n\nz.shape =  (2, 4, 3)\nz = \n [[[  2.  32. 128.]\n  [  0.   8. 128.]\n  [  8. 128.   2.]\n  [ 32.  50.   8.]]\n\n [[  2.  32. 128.]\n  [  0.   8. 128.]\n  [  8. 128.   2.]\n  [ 32.  50.   8.]]]\n\ndy/dx = \n [[ 4. 16. 32.]\n [ 0.  8. 32.]\n [ 8. 32.  4.]\n [16. 20.  8.]]\ndz/dx = \n [[ 8. 32. 64.]\n [ 0. 16. 64.]\n [16. 64.  8.]\n [32. 40. 16.]]\n</code></pre>\n\n<p>In particular, notice that the values of dz/dx are twice those of dy/dz since they are summed over the inputs to the stack.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9074}"
913,56802840,"{'items': [{'owner': {'reputation': 6958, 'user_id': 3994824}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1561708429, 'answer_id': 56802999, 'question_id': 56802840, 'body': '<p>tf.gather is a function to index an array. You gather the elements which you specify by the index argument. This is not natively posible for tensorflow tensors. </p>\n\n<p>tf.gather(y_pred, tf.range(0, batch_size, 3)) is equivalent in numpy to y_pred[0:batch_size:3], which means that you return every third element starting from the first one. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9070}"
914,74444314,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9070}"
915,46659101,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9070}"
916,40846881,"{'items': [{'owner': {'reputation': 65, 'user_id': 5624146}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1480347074, 'answer_id': 40847987, 'question_id': 40846881, 'body': '<p>You can find it and other related operations here:\n<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9070}"
917,47898147,"{'items': [{'owner': {'reputation': 3196, 'user_id': 2846062}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1513742095, 'answer_id': 47898560, 'question_id': 47898147, 'body': '<p>Replace <code>tf.nn.rnn_cell</code> with <code>tf.contrib.rnn</code></p>\n\n<p>Since version 1.0, <code>rnn</code> implemented as part of the contrib module.</p>\n\n<p>More information can be found here\n<a href=""https://www.tensorflow.org/api_guides/python/contrib.rnn"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_guides/python/contrib.rnn</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9066}"
918,44707368,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9066}"
919,41283115,"{'items': [{'owner': {'reputation': 4577, 'user_id': 1951176}, 'down_vote_count': 1, 'up_vote_count': 6, 'is_accepted': True, 'score': 5, 'creation_date': 1482415732, 'answer_id': 41285054, 'question_id': 41283115, 'body': ""<p>The difference is that <code>tf.nn.softmax_cross_entropy_with_logits</code> doesn't assume that the classes are mutually exclusive: </p>\n\n<blockquote>\n  <p>Measures the probability error in discrete classification tasks in\n  which each class is independent and not mutually exclusive. For\n  instance, one could perform multilabel classification where a picture\n  can contain both an elephant and a dog at the same time.</p>\n</blockquote>\n\n<p>Compare with <code>sparse_*</code>:</p>\n\n<blockquote>\n  <p>Measures the probability error in discrete classification tasks in\n  which the classes are mutually exclusive (each entry is in exactly one\n  class). For example, each CIFAR-10 image is labeled with one and only\n  one label: an image can be a dog or a truck, but not both.</p>\n</blockquote>\n\n<p>As such, with sparse functions, the dimensions of <code>logits</code> and <code>labels</code> are not the same: <code>labels</code> contain one number per example, whereas <code>logits</code> the number of classes per example, denoting probabilities.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9066}"
920,52254253,"{'items': [{'owner': {'reputation': 56, 'user_id': 7373907}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1564717599, 'answer_id': 57319659, 'question_id': 52254253, 'body': ""<p>You can verify your expectation by checking the shape of the dense kernel as follows.</p>\n\n<pre><code>&gt;&gt;&gt; inputx = tf.placeholder(float, shape=[2,3,4])\n&gt;&gt;&gt; dense_layer = tf.layers.dense(inputx, 128, tf.nn.relu)\n&gt;&gt;&gt; g=tf.get_default_graph()\n&gt;&gt;&gt; g.get_collection('variables')\n[&lt;tf.Variable 'dense/kernel:0' shape=(4, 128) dtype=float32_ref&gt;, &lt;tf.Variable 'dense/bias:0' shape=(128,) dtype=float32_ref&gt;]\n</code></pre>\n\n<p>The behavior of the dense layer is the same as a conv layer. </p>\n\n<p>You can consider inputx as an image which has width=2, height=3 and channel=4 and the dense layer as a conv layer which has 128 filters and filters size is 1*1.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9063}"
921,53247534,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9063}"
922,60143153,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9061}"
923,65754675,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9061}"
924,64093750,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9061}"
925,51625529,"{'items': [{'owner': {'reputation': 1630, 'user_id': 10025506}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1533127014, 'answer_id': 51633489, 'question_id': 51625529, 'body': '<p>To use either initializable or reinitializable iterators, you must create a class that inherits from tf.train.SessionRunHook. This class then have access to the session used by the tf.estimator functions. </p>\n\n<p>Here is quick example that you can adapt to your needs :</p>\n\n<pre><code>class IteratorInitializerHook(tf.train.SessionRunHook):\n    def __init__(self):\n        super(IteratorInitializerHook, self).__init__()\n        self.iterator_initializer_func = None # Will be set in the input_fn\n\n    def after_create_session(self, session, coord):\n        self.iterator_initializer_func(session) \n\n\ndef get_inputs(X, y):\n    iterator_initializer_hook = IteratorInitializerHook()\n\n    def input_fn():\n        X_pl = tf.placeholder(X.dtype, X.shape)\n        y_pl = tf.placeholder(y.dtype, y.shape)\n\n        dataset = tf.data.Dataset.from_tensor_slices((X_pl, y_pl))\n        dataset = ...\n        ...\n\n        iterator = dataset.make_initializable_iterator()\n        next_example, next_label = iterator.get_next()\n\n\n        iterator_initializer_hook.iterator_initializer_func = lambda sess: sess.run(iterator.initializer,\n                                                                                    feed_dict={X_pl: X, y_pl: y})\n\n        return next_example, next_label\n\n    return input_fn, iterator_initializer_hook\n\n...\n\ntrain_input_fn, train_iterator_initializer_hook = get_inputs(X_train, y_train)\ntest_input_fn, test_iterator_initializer_hook = get_inputs(X_test, y_test)\n\n...\n\nestimator.train(input_fn=train_input_fn,\n                hooks=[train_iterator_initializer_hook])\nestimator.evaluate(input_fn=test_input_fn,\n                   hooks=[test_iterator_initializer_hook])\n</code></pre>\n\n<p>This is a modified version from a code I found in a <a href=""https://k-d-w.org/blog/2017/12/denoising-autoencoder-as-tensorflow-estimator/"" rel=""nofollow noreferrer"">blogpost</a>  by <a href=""https://k-d-w.org/"" rel=""nofollow noreferrer"">Sebastian Plsterl</a>. Have a look under the ""Feeding data to an Estimator via the Dataset API"" section.</p>\n'}, {'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1549205240, 'answer_id': 54504022, 'question_id': 51625529, 'body': '<p>Or you can simply use <code>tf.estimator.train_and_evaluate</code>\n<a href=""https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate</a>\nIt allows you to use validation during training without needing to care about iterator at all.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9058}"
926,58963513,"{'items': [{'owner': {'reputation': 891, 'user_id': 8325802}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1597434217, 'answer_id': 63419162, 'question_id': 58963513, 'body': '<p>I had the same error with another Keras function. One of my parameters was a float by mistake.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9058}"
927,53919290,"{'items': [{'owner': {'reputation': 193, 'user_id': 10981818}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': False, 'score': 8, 'creation_date': 1550522534, 'answer_id': 54755059, 'question_id': 53919290, 'body': '<p>I had the same problem while working through the tutorial.  I changed the code from </p>\n\n<pre><code>def loss(labels, logits):\n    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n</code></pre>\n\n<p>to</p>\n\n<pre><code>def loss(labels, logits):\n    return tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n</code></pre>\n\n<p>and this resolved the issue without having to install tf-nightly.</p>\n'}, {'owner': {'reputation': 1355, 'user_id': 5053158}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1546010076, 'answer_id': 53960594, 'question_id': 53919290, 'body': '<p>The <code>from_logits</code> parameter is introduced in Tensorflow 1.13.</p>\n\n<p>You can compare 1.12 and 1.13 with these urls:</p>\n\n<pre><code>https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/python/keras/losses.py\nhttps://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/losses.py\n</code></pre>\n\n<p>1.13 is not released at the time of writing. This is why the tutorial starts with the line</p>\n\n<pre><code>!pip install -q tf-nightly\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9058}"
928,71947836,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1650530213, 'answer_id': 71951328, 'question_id': 71947836, 'body': '<p>Simplest way would be to use <code>tf.data.Dataset.zip</code>:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nX = np.arange(100)\nY = X*2\n\nsample_length = 20\ninput_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n  X, None, sequence_length=sample_length, sequence_stride=sample_length)\ntarget_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n  Y, None, sequence_length=sample_length, sequence_stride=sample_length)\n\ndataset = tf.data.Dataset.zip((input_dataset, target_dataset))\n\nfor x, y in dataset:\n  print(x.shape, y.shape)\n</code></pre>\n<pre><code>(5, 20) (5, 20)\n</code></pre>\n<p>You can then feed <code>dataset</code> directly to your model.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9058}"
929,45698621,"{'items': [{'owner': {'reputation': 13413, 'user_id': 3027854}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1502893106, 'answer_id': 45716063, 'question_id': 45698621, 'body': ""<p>The <code>label_idx</code> values is not a list hence you are facing this problem:</p>\n\n<p>Below example should clarify better:</p>\n\n<pre><code>label_idx = 1\n\nfeatures = dict(zip(['decoder_input'], [label_idx]))\n\nfeatures['decoder_input']\n\n# 1 output\n</code></pre>\n\n<p>where as if I change label_idx to a list:</p>\n\n<pre><code>label_idx = [1]\n\nfeatures = dict(zip(['decoder_input'], [label_idx]))\n\nfeatures['decoder_input']\n\n# [1] output\n</code></pre>\n\n<p>Also you can simplify how you create the dictionary:</p>\n\n<pre><code>features = {'decoder_input': [label_idx]} # if label_idx is a value\nfeatures = {'decoder_input': label_idx} # if label_idx is a list\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9058}"
930,55703097,"{'items': [{'owner': {'reputation': 2568, 'user_id': 7089239}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1555417389, 'answer_id': 55708080, 'question_id': 55703097, 'body': '<p>Turns out, all that was missing was the fact that one cannot assign to a variable inside a loop as <a href=""https://stackoverflow.com/a/55707514/7089239"">Vlad pointed out</a>. Instead, one can return the new value of a variable.</p>\n\n<pre><code>def make_update_op(w):\n    return w + 0.001\n\nnew_w = tf.while_loop(lambda _: True, make_update_op, (weights,), maximum_iterations=x.shape[0])\nupdate_op = weights.assign(new_w)\n</code></pre>\n\n<p>To use more variables one would need to return the same amount from the function and unpack them in Python, but the principle is the same.</p>\n\n<pre><code>def make_update_op(w, d):\n    return w + 0.001, d\n\nnew_w, _ = tf.while_loop(lambda *_: True, make_update_op, (weights, data), maximum_iterations=x.shape[0])\nupdate_op = weights.assign(new_w)\n</code></pre>\n'}, {'owner': {'reputation': 8315, 'user_id': 5154274}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1555415494, 'answer_id': 55707514, 'question_id': 55703097, 'body': '<p>The tensor that you\'re trying to assign a new value within a while loop is a result of a sequence of multiple operations-tensors (operation is node in the graph, while tensor is a directed edge). In particular, the while loop will produce:</p>\n\n<p><code>Variable/Read--&gt;while/Enter--&gt;while/Merge--&gt;while/Switch--&gt;while/Identity</code></p>\n\n<p>What you\'re trying to assign here is a tensor <code>while/Identity</code>.</p>\n\n<p><code>tf.while_loop</code> is usually used to iterate over the dimensions of a tensor (also over the  <code>None</code> - the unknown dimension). You\'re trying to iterate over the variables that are fully defined. You don\'t need to create a <code>tf.while_loop</code> for that. Just create operations that update each variable and group these operations together:</p>\n\n<pre class=""lang-py prettyprint-override""><code>update_ops = [w.assign(w + 0.001) for w in weights]\nupdate_op = tf.group(update_ops)\n</code></pre>\n\n<p>Now, when you execute the <code>update_op</code> with <code>tf.Session()</code> interface it will update all variables. </p>\n\n<p>Example:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\nv1 = tf.Variable(tf.ones((1, 2), dtype=tf.float32))\nv2 = tf.Variable(2*tf.ones((1, 3), dtype=tf.float32))\n\nupdate_ops = [w.assign(w + 0.001) for w in [v1, v2]]\nupdate_op = tf.group(update_ops)\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    print(\'before update:\')\n    print(v1.eval(), v2.eval())\n    print(\'after update:\')\n    sess.run(update_op) # &lt;-- update your variables\n    print(v1.eval(), v2.eval())\n\n    # before update:\n    # [[1. 1.]] [[2. 2. 2.]]\n    # after update:\n    # [[1.001 1.001]] [[2.001 2.001 2.001]]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9053}"
931,66874943,"{'items': [{'owner': {'reputation': 17612, 'user_id': 5666087}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1617122275, 'answer_id': 66874975, 'question_id': 66874943, 'body': '<p>This is because the data files are shuffled and the dataset is shuffled with <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset?hl=ru#shuffle"" rel=""nofollow noreferrer""><code>dataset.shuffle()</code></a>.</p>\n<p>With <code>dataset.shuffle()</code>, the data will be shuffled in a different way on each iteration by default.</p>\n<p>One can remove <code>shuffle_files=True</code> and set the argument <code>reshuffle_each_iteration=False</code> to prevent reshuffling on different iterations.</p>\n<p>The <code>.take()</code> function does not imply determinism. It will just take N items from the dataset in whichever order the dataset gives them.</p>\n<pre class=""lang-py prettyprint-override""><code># Construct a tf.data.Dataset\nds = tfds.load(\'mnist\', split=\'train\', shuffle_files=False)\n\n# Build your input pipeline\nds = ds.shuffle(1024, reshuffle_each_iteration=False).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n\nsingle_batch_dataset = ds.take(1)\n\nfor example in single_batch_dataset:\n    image, label = example[&quot;image&quot;], example[&quot;label&quot;]\n    print(label)\n    \nfor example in single_batch_dataset:\n    image, label = example[&quot;image&quot;], example[&quot;label&quot;]\n    print(label)\n</code></pre>\n<p>Output:</p>\n<pre class=""lang-py prettyprint-override""><code>tf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64)\ntf.Tensor([4 6 8 5 1 4 5 8 1 4 6 6 8 6 6 9 4 2 3 0 5 9 2 1 3 1 8 6 4 4 7 1], shape=(32,), dtype=int64)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9053}"
932,63379008,"{'items': [{'owner': {'reputation': 666, 'user_id': 14185819}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1599849950, 'answer_id': 63852660, 'question_id': 63379008, 'body': '<p>So this is a little tricky to think about but I\'ll try to explain the thinking.</p>\n<p>If you do <code>tf.linalg.tensor_diag([1,2,3,4])</code> this is intuitively gives a matrix with that diagonal:</p>\n<pre><code>[[1, 0, 0, 0],\n [0, 2, 0, 0],\n [0, 0, 3, 0],\n [0, 0, 0, 4]]\n</code></pre>\n<p>Notice you went from rank 1 to rank 2 doing this, the rank doubled. So to &quot;diagonalize&quot; it\'s going to end up doubling the rank.</p>\n<p>Now your question, <code>tf.linalg.tensor_diag([[1,2],[3,4]])</code> What you\'re passing in is a matrix so rank 2</p>\n<pre><code>[[1, 2],\n [3, 4]]\n</code></pre>\n<p>But now, how should this be diagonalized? So it\'s rank 2 and following the pattern means we\'ll end up with something of rank 4. In the previous example diagonalize sort of &quot;pulled up&quot; the vector into the higher rank. And each step of &quot;pulling up&quot; took a single value from the diagonal and put it there.</p>\n<p>So this matrix will also be &quot;pulled up&quot; and each step of the way leaving a value. So it\'s going to make 4 squares of <code>[[0,0],[0,0]]</code> and drop the value in each one. This would give us</p>\n<pre><code>[[1,0],\n [0,0]]\n[[0,2],\n [0,0]]\n[[0,0],\n [3,0]]\n[[0,0],\n [0,4]]\n</code></pre>\n<p>Lastly things will be &quot;grouped&quot; if they were originally (like <code>[1,2]</code> idk how better to say this) so that gives the final result of</p>\n<pre><code>[\n [\n  [[1,0],\n   [0,0]] ,\n  [[0,2],\n   [0,0]]\n ],\n [\n  [[0,0],\n   [3,0]] ,\n  [[0,0],\n   [0,4]]\n ]\n]\n</code></pre>\n<p>Which indeed gives us a rank 4 result </p>\n<p><strong>Note:</strong> You may want to look into the other <a href=""https://www.tensorflow.org/api_docs/python/tf/linalg/diag"" rel=""nofollow noreferrer"">diag function</a> for more of you\'re trying to do</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9053}"
933,65982015,"{'items': [{'owner': {'reputation': 18097, 'user_id': 5069957}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1612171012, 'answer_id': 65989991, 'question_id': 65982015, 'body': '<p>The <a href=""https://github.com/tensorflow/tfjs-models/tree/master/universal-sentence-encoder"" rel=""nofollow noreferrer"">universal sentence encoder</a> can be used to convert text into tensors</p>\n<pre><code>require(\'@tensorflow/tfjs\');\nconst use = require(\'@tensorflow-models/universal-sentence-encoder\');\n\nuse.load().then(model =&gt; {\n  // Embed an array of sentences.\n  const sentences = [\n    \'Hello.\',\n    \'How are you?\'\n  ];\n  model.embed(sentences).then(embeddings =&gt; {\n    // `embeddings` is a 2D tensor consisting of the 512-dimensional embeddings for each sentence.\n    // So in this example `embeddings` has the shape [2, 512].\n    embeddings.print(true /* verbose */);\n  });\n});\n</code></pre>\n<p><code>tf.pad</code> can later be used to padd the tensors</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9053}"
934,59268676,"{'items': [{'owner': {'reputation': 958, 'user_id': 12978602}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1587037154, 'answer_id': 61249331, 'question_id': 59268676, 'body': '<p>Please refer sample code to add tf.nn.conv1d_transpose inside a keras Sequential model</p>\n\n<pre><code>%tensorflow_version 1.x\n\n# Importing dependency\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, BatchNormalization, Lambda\n\n# Create a sequential model\nmodel = Sequential()\n\nx=input=[None,256,16]\n\ndef conv1d_transpose(x):\n    return tf.nn.conv1d_transpose(x, filters=[3.0,8.0,16.0], output_shape=[100, 1024, 8], strides=(4), padding=""SAME"")\n\nmodel.add(Conv1D(32,250,padding=\'same\',input_shape=(1500,9)))\nmodel.add(MaxPooling1D(2))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Lambda(conv1d_transpose, name=\'conv1d_transpose\'))\n\n# Display Model \nmodel.summary()\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>Model: ""sequential""\n    _________________________________________________________________\n    Layer (type)                 Output Shape              Param #   \n    =================================================================\n    conv1d (Conv1D)              (None, 1500, 32)          72032     \n    _________________________________________________________________\n    max_pooling1d (MaxPooling1D) (None, 750, 32)           0         \n    _________________________________________________________________\n    dropout (Dropout)            (None, 750, 32)           0         \n    _________________________________________________________________\n    batch_normalization (BatchNo (None, 750, 32)           128       \n    _________________________________________________________________\n    conv1d_transpose (Lambda)    (100, 1024, 8)            0         \n    =================================================================\n    Total params: 72,160\n    Trainable params: 72,096\n    Non-trainable params: 64\n    _________________________________________________________________\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9049}"
935,68354367,"{'items': [{'owner': {'reputation': 361, 'user_id': 6133787}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1626130100, 'answer_id': 68354601, 'question_id': 68354367, 'body': ""<p>I found a way to bypass the problem by avoiding usage of <code>model.add_metric</code> altogether, and passing a <code>Metric</code> object to the <code>compile()</code> method.<br>\nHowever, when passing an instance of <code>tf.keras.metrics.Mean</code> as follows:</p>\n<pre><code>model.compile(loss='mse', metrics=tf.keras.metrics.Mean())\n</code></pre>\n<p>I get the following error from the <code>compile()</code> method:</p>\n<pre><code>TypeError: update_state() got multiple values for argument 'sample_weight'\n</code></pre>\n<p>To solve this, I had to extend <code>tf.keras.metrics.Mean</code> and change the signature of <code>update_state</code> to match the expected signature.<br>\nHere is the final (working) code:</p>\n<pre><code>class FixedMean(tf.keras.metrics.Mean):\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        super().update_state(y_pred, sample_weight=sample_weight)\n\nx = [1, 2, 3, 4, 5, 6, 7, 8]\ny = [5 + i * 3 for i in x]\na = Input(shape=(1,))\noutput = Dense(1)(a)\nmodel = Model(inputs=a,outputs=output)\nmodel.compile(loss='mse', metrics=FixedMean())\nmodel.fit(x=x, y=y, epochs=100)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9049}"
936,38958662,"{'items': [{'owner': {'reputation': 12520, 'user_id': 2464597}, 'down_vote_count': 1, 'up_vote_count': 9, 'is_accepted': False, 'score': 8, 'creation_date': 1497978706, 'answer_id': 44659265, 'question_id': 38958662, 'body': '\n\n<p>You can get all of the node names in your model with something like:</p>\n\n<pre class=""lang-py prettyprint-override""><code>node_names = [node.name for node in tf.get_default_graph().as_graph_def().node]\n</code></pre>\n\n<p>Or with restoring the graph:</p>\n\n<pre class=""lang-py prettyprint-override""><code>saver = tf.train.import_meta_graph(/path/to/meta/graph)\nsess = tf.Session()\nsaver.restore(sess, /path/to/checkpoints)\ngraph = sess.graph\nprint([node.name for node in graph.as_graph_def().node])\n</code></pre>\n\n<p>You may need to filter these to get only your output nodes, or only the nodes that you want, but this can at least help you get the names for a graph that you have already trained and cannot afford to retrain with <code>name=\'some_name\'</code> defined for each node.</p>\n\n<p>Ideally, you want to define a <code>name</code> parameter for each operation or tensor that you are going to want to access later.</p>\n'}, {'owner': {'reputation': 3201, 'user_id': 6392807}, 'down_vote_count': 1, 'up_vote_count': 7, 'is_accepted': True, 'score': 6, 'creation_date': 1471278614, 'answer_id': 38959056, 'question_id': 38958662, 'body': '<p>You can choose names for the nodes in your model by passing the optional <code>name=""myname""</code> argument to pretty much any Tensorflow operator that builds a node. Tensorflow will pick names for graph nodes automatically if you don\'t specify them, but if you want to identify those nodes to a tool like freeze_graph.py, then it\'s best to choose the names yourself. Those names are what you pass to output_node_names.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9049}"
937,49688134,"{'items': [{'owner': {'reputation': 11854, 'user_id': 5140223}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1523032871, 'answer_id': 49697470, 'question_id': 49688134, 'body': '<p>I don\'t really understand why you want this loss function, but I will provide an answer anyway. Also, there is no need to evaluate the gradient within the function (in fact, you would be ""disconnecting"" the computational graph). The loss function could be implemented as follows:</p>\n\n<pre><code>from keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Dense, Input\n\ndef custom_loss(input_tensor, output_tensor):\n    def loss(y_true, y_pred):\n        gradients = K.gradients(output_tensor, input_tensor)\n        grad_pred = K.sum(gradients, axis=-1)\n        grad_true = K.sum(2*input_tensor, axis=-1)\n        return K.square(grad_pred - grad_true)\n    return loss\n\ninput_tensor = Input(shape=(2,))\nhidden = Dense(10, activation=\'relu\')(input_tensor)\noutput_tensor = Dense(1, activation=\'sigmoid\')(hidden)\nmodel = Model(input_tensor, output_tensor)\nmodel.compile(loss=custom_loss(input_tensor, output_tensor), optimizer=\'adam\')\n</code></pre>\n'}, {'owner': {'reputation': 2562, 'user_id': 7224320}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1523002963, 'answer_id': 49688441, 'question_id': 49688134, 'body': ""<p>A Keras loss must have <code>y_true</code> and <code>y_pred</code> as inputs. You can try adding your input object as both <code>x</code> and <code>y</code> during the fit:</p>\n\n<pre><code>def custom_loss(y_true,y_pred):\n    ...\n    return K.square(K.subtract(grad_true, grad_pred))\n\n...\nmodel.compile(loss=custom_loss, optimizer='adam')\n\nmodel.fit(X, X, ...)\n</code></pre>\n\n<p>This way, <code>y_true</code> will be the batch being processed at each iteration from the input <code>X</code>, while <code>y_pred</code> will be the output of the model for that particular batch.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9049}"
938,49555016,"{'items': [{'owner': {'reputation': 770, 'user_id': 2240521}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': True, 'score': 6, 'creation_date': 1523092491, 'answer_id': 49705763, 'question_id': 49555016, 'body': '<p>You can\'t ever call <code>tf.gradients</code> inside <code>tf.while_loop</code> in Tensorflow based on <a href=""https://github.com/tensorflow/tensorflow/issues/14101"" rel=""nofollow noreferrer"">this</a> and <a href=""https://github.com/tensorflow/tensorflow/issues/9450"" rel=""nofollow noreferrer"">this</a>, I found this out the hard way when I was trying to create conjugate gradient descent entirely into the <code>Tensorflow</code> graph.</p>\n\n<p>But if I understand your model correctly, you could make your own version of an <code>RNNCell</code> and wrap it in a <code>tf.dynamic_rnn</code>, but the actual cell \n implementation will be a little complex since you need to evaluate a condition dynamically at runtime.</p>\n\n<p>For starters, you can take a look at Tensorflow\'s <code>dynamic_rnn</code> code <a href=""https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/python/ops/rnn.py"" rel=""nofollow noreferrer"">here</a>.</p>\n\n<p>Alternatively, dynamic graphs have never been <code>Tensorflow</code>\'s strong suite, so consider using other frameworks like <code>PyTorch</code> or you can try out <code>eager_execution</code> and see if that helps.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9045}"
939,55422537,"{'items': [{'owner': {'reputation': 276, 'user_id': 5088987}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1554028032, 'answer_id': 55439968, 'question_id': 55422537, 'body': '<p>Ok, so eventually I found the answer, quoted in <a href=""https://stackoverflow.com/questions/51482730/tensorflow-how-to-export-estimator-using-tensorhub-module"">TensorFlow: how to export estimator using TensorHub module?</a> </p>\n\n<p>The problem was with serialization stuff I don\'t really understand. The solution allows to pass raw strings to <code>tf.estimator.export.build_raw_serving_input_receiver_fn</code> instead.</p>\n\n<p>My saving funciton now looks like this:</p>\n\n<pre class=""lang-py prettyprint-override""><code>  def save_serving_model(self,estimator):\n      feature_placeholder = {\'Headline\': tf.placeholder(\'string\', [1], name=\'headline_placeholder\'),\n      \'Description\': tf.placeholder(\'string\', [1], name=\'description_placeholder\')}\n      serving_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_placeholder)\n\n      estimator.export_savedmodel(""TEST_SERVING/"", serving_input_fn)\n</code></pre>\n\n<p>where using the <code>saved_model_cli</code> works. I.e.:</p>\n\n<pre class=""lang-sh prettyprint-override""><code>saved_model_cli run --dir /path/to/model/ --tag_set serve --signature_def predict --input_exprs=""Headline=[\'Finally, it works\'];Description=[\'Yay, it works\']"" \n\n</code></pre>\n\n<pre class=""lang-sh prettyprint-override""><code>Result for output key class_ids:\n[[2]]\nResult for output key classes:\n[[b\'2\']]\nResult for output key logits:\n[[-0.56755465  0.31625098  0.39260274]]\nResult for output key probabilities:\n[[0.16577701 0.40119565 0.4330274 ]]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9045}"
940,48299597,"{'items': [{'owner': {'reputation': 504, 'user_id': 2529808}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1520418672, 'answer_id': 49149664, 'question_id': 48299597, 'body': '<p>A random sharding of the dataset can be implemented with this Dataset transformation:</p>\n\n<pre class=""lang-py prettyprint-override""><code>def random_shard(shard_size, dataset_size):\n  num_shards = -(-dataset_size // shard_size)  # Ceil division.\n  offsets = np.linspace(\n      0, dataset_size, num=num_shards, endpoint=False, dtype=np.int64)\n\n  def _random_shard(dataset):\n    sharded_dataset = tf.data.Dataset.from_tensor_slices(offsets)\n    sharded_dataset = sharded_dataset.shuffle(num_shards)\n    sharded_dataset = sharded_dataset.flat_map(\n        lambda offset: dataset.skip(offset).take(shard_size))\n    return sharded_dataset\n\n  return _random_shard\n</code></pre>\n\n<p>This requires to know the total dataset size in advance. However, if you implement a file-based sharding approach, you also iterate on the full dataset once so that is not a major issue.</p>\n\n<p>Regarding efficiency, note that <code>skip(offset)</code> actually iterates on <code>offset</code> examples so a latency is to be expected if <code>offset</code> is large. Careful prefetching should help for this.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9043}"
941,50454095,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9043}"
942,44871248,"{'items': [{'owner': {'reputation': 5786, 'user_id': 5703903}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1499007928, 'answer_id': 44872215, 'question_id': 44871248, 'body': '<p>You definitely have to normalize your data for it to work and it does not necessarily have to be in the range [-1, 1]. </p>\n\n<p>Take a Computer Vision (CV) problem as an example. What some papers do is simply divide by <code>255.0</code>. Other papers, compute the <code>mean</code> and <code>standard_deviation</code> of each RGB channel from all the images. To normalize the images, we simply do <code>(x-mu)/sigma</code> over each channel.</p>\n\n<p>Since your data is unbounded like what you said, then we can\'t simply divide by a scalar. Perhaps the best approach is to normalize based on the data statistics. Specific to your case, you could perhaps find the <code>mean</code> and <code>standard_deviation</code> of each of your 30 dimensions.</p>\n\n<p>This <a href=""http://cs231n.github.io/neural-networks-2/"" rel=""nofollow noreferrer"">post</a> is more detailed and will potentially help you.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9043}"
943,70399567,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9043}"
944,58248787,"{'items': [{'owner': {'reputation': 401, 'user_id': 4909165}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1570669657, 'answer_id': 58314091, 'question_id': 58248787, 'body': '<p>Actually, this works for me</p>\n\n<pre><code>from tensorflow.core.util import event_pb2\n\nserialized_examples = tf.data.TFRecordDataset(path)\nfor serialized_example in serialized_examples:\n    event = event_pb2.Event.FromString(serialized_example.numpy())\n    for value in event.summary.value:\n        t = tf.make_ndarray(value.tensor)\n        print(value.tag, event.step, t, type(t))\n</code></pre>\n'}, {'owner': {'reputation': 2961, 'user_id': 4373898}, 'down_vote_count': 1, 'up_vote_count': 0, 'is_accepted': False, 'score': -1, 'creation_date': 1570607971, 'answer_id': 58299543, 'question_id': 58248787, 'body': '<p>I do not really know what you try to achieve, but if TFEvent files are regular TFRecord files you can use the new API this way.</p>\n\n<pre class=""lang-py prettyprint-override""><code>event_files = tf.data.Dataset.list_files(""./outputs/events.out.tfevents*"")\nserialized_examples = tf.data.TFRecordDataset(events_files)\nfor serialized_example in serialized_examples:\n  ...\n</code></pre>\n\n<p>Hope this can help.</p>\n\n<p>Kind.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9039}"
945,70932051,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9039}"
946,60067415,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9039}"
947,57296471,"{'items': [{'owner': {'reputation': 23856, 'user_id': 5627599}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1564596310, 'answer_id': 57296620, 'question_id': 57296471, 'body': '<p>You can pass an <code>async</code> function (or a function returning a Promise) to the generator. It is then okay to use <code>await</code> inside the function (even inside a loop) to handle any asynchronous tasks.</p>\n\n<p><strong>Code Sample</strong></p>\n\n<pre class=""lang-js prettyprint-override""><code>const dataset = tf.data.generator(async function* () {\n    const dataToDownload = await fetch(/* ... */);\n    while (/* ... */) {\n        const moreData = await fetch(/* ... */);\n        yield otherData;\n    }\n});\n</code></pre>\n\n<p>This example uses <a href=""https://github.com/bitinn/node-fetch"" rel=""nofollow noreferrer""><code>node-fetch</code></a>, of course any other method of downloading data also works fine.</p>\n\n<h3>Async Generators</h3>\n\n<p>Regarding the MDN documentation, generators can be defined as <code>async</code>, but this changes the way they work. Instead of returning the value right away, they will return a Promise that you have to await for. So, instead of calling <code>iterator.next()</code>, you have to call <code>await iterator.next()</code> to read the value.</p>\n\n<p><strong>Code Sample</strong></p>\n\n<pre class=""lang-js prettyprint-override""><code>async function* foo(index) {\n  while (true) {\n    yield index++;\n  }\n}\n\n(async () =&gt; {\n  const iterator = foo(0);\n  console.log((await iterator.next()).value); // 0\n  console.log((await iterator.next()).value); // 1\n})();\n</code></pre>\n\n<p>Luckily, Tensorflow.js is able to handle <code>async</code> functions/Promises in generators.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9039}"
948,69344858,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1639735620, 'answer_id': 70391467, 'question_id': 69344858, 'body': '<p>You can use <a href=""https://www.tensorflow.org/api_docs/python/tf/math/top_k"" rel=""nofollow noreferrer"">tf.math.top_k</a>:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\ny_pred = [[-18.6, 0.51, 2.94, -12.8]]\n\nmax_entries = 3\n\nvalues, indices = tf.math.top_k(y_pred, k=max_entries)\nprint(values)\nprint(indices)\n</code></pre>\n<pre><code>tf.Tensor([[  2.94   0.51 -12.8 ]], shape=(1, 3), dtype=float32)\ntf.Tensor([[2 1 3]], shape=(1, 3), dtype=int32)\n</code></pre>\n'}, {'owner': {'reputation': 309, 'user_id': 14366506}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1632750967, 'answer_id': 69347931, 'question_id': 69344858, 'body': ""<p>You can sort and take the first 3:</p>\n<pre><code>import tensorflow as tf\n\na = [1, 10, 26.9, 2.8, 166.32, 62.3]\nsorted_a = tf.sort(a,direction='DESCENDING')\nmax_3 = tf.gather(sorted_a, [0,1,2])\nprint(max_3)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9035}"
949,58986077,"{'items': [{'owner': {'reputation': 36, 'user_id': 12885088}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1581505305, 'answer_id': 60186849, 'question_id': 58986077, 'body': '<p>Have you tried changing it to <code>tf.nn.avg_pool</code>?\nIt seemed to work for me.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9035}"
950,70735454,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1642410237, 'answer_id': 70738806, 'question_id': 70735454, 'body': '<p>Maybe you could try directly iterating over your <code>list</code> of tensors instead of getting individual tensors by their index:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\ngrad = [tf.ones((2,10)), tf.ones((3,))]  # an example of what a gradient from tape.gradient can look like\n\n@tf.function\ndef flatten_grad1(grad):\n    temp = [None]*len(grad)\n    for i, g in enumerate(grad):\n        temp[i] = tf.reshape(g, (tf.math.reduce_prod(tf.shape(g)), ))\n    return tf.concat(temp, axis=0)\nprint(flatten_grad1(grad))\n</code></pre>\n<pre><code>tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(23,), dtype=float32)\n</code></pre>\n<p>With <code>tf.TensorArray</code>:</p>\n<pre class=""lang-py prettyprint-override""><code>@tf.function\ndef flatten_grad2(grad):\n    temp = tf.TensorArray(tf.float32, size=0, dynamic_size=True, infer_shape=False)\n    for g in grad:\n        temp = temp.write(temp.size(), tf.reshape(g, (tf.math.reduce_prod(tf.shape(g)), )))\n    return temp.concat()\n\nprint(flatten_grad2(grad))\n</code></pre>\n'}, {'owner': {'reputation': 919, 'user_id': 7617767}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1642385112, 'answer_id': 70735785, 'question_id': 70735454, 'body': '<p>Hi i think the biggest problem is the loops where in python computing loops are not encouraged.</p>\n<p>Here\'s an example of how to flatten using tf functions for your gradient variables looks kind of weird normally should be a consistent shape with a batch</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\nimport numpy as np\n\n@tf.function\ndef flatten(arr):\n     dim = tf.math.reduce_prod(tf.shape(arr)[1:])\n     return tf.reshape(arr, [-1, dim])\n\ngrad = tf.Variable(np.random.randn(100, 10, 10, 3))\n\nflatten_grad = flatten(grad)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9035}"
951,64552543,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9035}"
952,53583456,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1543791323, 'answer_id': 53585405, 'question_id': 53583456, 'body': ""<p>The original motivation for reinitializable iterators was as follows:</p>\n\n<ol>\n<li><p>The user's input data is in two or more <code>tf.data.Dataset</code> objects with the same structure but different pipeline definitions.</p>\n\n<p>For example, you might have a training data pipeline with augmentations in a <code>Dataset.map()</code>, and an evaluation data pipeline that produced raw examples, but they would both produce batches with the same structure (in terms of the number of tensors, their element types, shapes, etc.).</p></li>\n<li><p>The user would define a single training graph that took input from a <code>tf.data.Iterator</code>, created using <code>Iterator.from_structure()</code>.</p></li>\n<li><p>The user could then switch between the different input data sources by <strong>reinitializing</strong> the iterator from one of the datasets.</p></li>\n</ol>\n\n<p>In hindsight, reinitializable iterators have turned out to be quite hard to use for their intended purpose. In TensorFlow 2.0 (or 1.x with eager execution enabled), it is much easier to create iterators over different datasets using idiomatic Python <code>for</code> loops and high-level training APIs:</p>\n\n<pre><code>tf.enable_eager_execution()\n\nmodel = ...  # A `tf.keras.Model`, or some other class exposing `fit()` and `evaluate()` methods.\n\ntrain_data = ...  # A `tf.data.Dataset`.\neval_data = ...   # A `tf.data.Dataset`.\n\nfor i in range(NUM_EPOCHS):\n  model.fit(train_data, ...)\n\n  # Evaluate every 5 epochs.\n  if i % 5 == 0: \n    model.evaluate(eval_data, ...)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9031}"
953,68839011,"{'items': [{'owner': {'reputation': 520, 'user_id': 14420572}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1629320004, 'answer_id': 68839188, 'question_id': 68839011, 'body': '<p>First of all you can import <code>Sequential</code>, <code>Dense</code> and <code>Activation</code> directly by using <code>from tensorflow.keras.models import Sequential</code> and <code>from tensorflow.keras.layers import Dense, Activation</code></p>\n<p>You can implement <code>LeakyReLU</code> like this:</p>\n<pre><code>from tensorflow import keras\n\nmodel = keras.models.Sequential([\n    keras.layers.Dense(10),\n    keras.layers.LeakyReLU(alpha=0.05)\n])\n</code></pre>\n<p>You can specify the <code>LeakuReLU</code> activation function after you declare the layer as given in <a href=""https://keras.io/api/layers/activations/#about-advanced-activation-layers"" rel=""nofollow noreferrer"">keras documentation</a>.</p>\n'}, {'owner': {'reputation': 1462, 'user_id': 3791640}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1629319916, 'answer_id': 68839173, 'question_id': 68839011, 'body': '<p>To use LeakyReLU in a layer you can do this:</p>\n<pre class=""lang-py prettyprint-override""><code>ann.add(tf.keras.layers.Dense(\n  units=32, activation=tf.keras.layers.LeakyReLU(alpha=0.3)))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9031}"
954,57140835,"{'items': [{'owner': {'reputation': 3173, 'user_id': 2153636}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1621866420, 'answer_id': 67673805, 'question_id': 57140835, 'body': ""<p>You cannot because estimators can run arbitrary code in their <code>model_fn</code> functions and Keras models must be much more structured, whether sequential or functional they must consist of layers, basically.</p>\n<p>A Keras model is a very specific type of object that can therefore be easily wrapped and plugged into other abstractions.</p>\n<p>Estimators are based on arbitrary Python code with arbitrary control flow and so it's quite tricky to force any structure onto them.</p>\n<p>Estimators support 3 modes - train, eval and predict. Each of these could in theory have completely independent flows, with different weights, architectures etc. This is almost unthinkable in Keras and would essentially amount to 3 separate models.</p>\n<p>Keras, in contrast, supports 2 modes - train and test (which is necessary for things like Dropout and Regularisation).</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9031}"
955,48348775,"{'items': [{'owner': {'reputation': 1836, 'user_id': 1097517}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1561516759, 'answer_id': 56764433, 'question_id': 48348775, 'body': ""<p>Looks like <code>tf.data</code> profiling wasn't implemented. It seems to be added in version <code>1.14</code>. This snippet:</p>\n\n<pre><code>import tensorflow as tf\n\ndataset = tf.data.Dataset.range(100)\ndataset = dataset.shuffle(30)\ndataset = dataset.repeat()\n\niterator = dataset.make_one_shot_iterator()\nminibatch = iterator.get_next()\nrun_metadata = tf.RunMetadata()\noptions = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\nwith tf.Session() as session:\n    session.run(minibatch, options=options, run_metadata=run_metadata)\n\ntf.profiler.advise(tf.get_default_graph(), run_metadata)\n</code></pre>\n\n<p>Outputs:</p>\n\n<pre><code>Parsing Inputs...\n\nExpensiveOperationChecker:\ntop 1 operation type: OneShotIterator, cpu: 3.01ms, accelerator: 0us, total: 3.01ms (87.19%)\ntop 2 operation type: IteratorGetNext, cpu: 440us, accelerator: 0us, total: 440us (12.75%)\ntop 3 operation type: _retval_IteratorGetNext_0_0, cpu: 2us, accelerator: 0us, total: 2us (0.06%)\ntop 1 graph node: OneShotIterator, cpu: 3.01ms, accelerator: 0us, total: 3.01ms\ntop 2 graph node: IteratorGetNext, cpu: 440us, accelerator: 0us, total: 440us\ntest.py:7:&lt;module&gt;, cpu: 3.01ms, accelerator: 0us, total: 3.01ms\n\nOperationChecker:\n\nAcceleratorUtilizationChecker:\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9031}"
956,55420520,"{'items': [{'owner': {'reputation': 1569, 'user_id': 5752875}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': False, 'score': 6, 'creation_date': 1592968564, 'answer_id': 62547036, 'question_id': 55420520, 'body': '<p>In tensorflow addons, there\'s a pre-built <code>LayerNormLSTMCell</code> out of the box.</p>\n<p>See <a href=""https://www.tensorflow.org/addons/api_docs/python/tfa/rnn/LayerNormLSTMCell"" rel=""noreferrer"">this doc</a> for more details. You may have to install <code>tensorflow-addons</code> before you can import this cell.</p>\n<pre><code>pip install tensorflow-addons\n</code></pre>\n'}, {'owner': {'reputation': 47103, 'user_id': 38626}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': False, 'score': 6, 'creation_date': 1554782747, 'answer_id': 55584976, 'question_id': 55420520, 'body': '<p>You can create a custom cell by inheriting from the <code>SimpleRNNCell</code> class, like this:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.activations import get as get_activation\nfrom tensorflow.keras.layers import SimpleRNNCell, RNN, Layer\nfrom tensorflow.keras.layers.experimental import LayerNormalization\n\nclass SimpleRNNCellWithLayerNorm(SimpleRNNCell):\n    def __init__(self, units, **kwargs):\n        self.activation = get_activation(kwargs.get(""activation"", ""tanh""))\n        kwargs[""activation""] = None\n        super().__init__(units, **kwargs)\n        self.layer_norm = LayerNormalization()\n    def call(self, inputs, states):\n        outputs, new_states = super().call(inputs, states)\n        norm_out = self.activation(self.layer_norm(outputs))\n        return norm_out, [norm_out]\n</code></pre>\n\n<p>This implementation runs a regular <code>SimpleRNN</code> cell for one step without any <code>activation</code>, then it applies layer norm to the resulting output, then it applies the <code>activation</code>. Then you can use it like that:</p>\n\n<pre class=""lang-py prettyprint-override""><code>model = Sequential([\n    RNN(SimpleRNNCellWithLayerNorm(20), return_sequences=True,\n        input_shape=[None, 20]),\n    RNN(SimpleRNNCellWithLayerNorm(5)),\n])\n\nmodel.compile(loss=""mse"", optimizer=""sgd"")\nX_train = np.random.randn(100, 50, 20)\nY_train = np.random.randn(100, 5)\nhistory = model.fit(X_train, Y_train, epochs=2)\n</code></pre>\n\n<p>For GRU and LSTM cells, people generally apply layer norm on the gates (after the linear combination of the inputs and states, and before the sigmoid activation), so it\'s a bit trickier to implement. Alternatively, you can probably get good results by just applying layer norm before applying <code>activation</code> and <code>recurrent_activation</code>, which would be easier to implement.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9031}"
957,73752169,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9026}"
958,56452714,"{'items': [{'owner': {'reputation': 550, 'user_id': 12169382}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1649495648, 'answer_id': 71806700, 'question_id': 56452714, 'body': '<p>For other people who would like implement tf.gather_nd in pytorch, see <a href=""https://discuss.pytorch.org/t/how-to-do-the-tf-gather-nd-in-pytorch/6445/37"" rel=""nofollow noreferrer"">https://discuss.pytorch.org/t/how-to-do-the-tf-gather-nd-in-pytorch/6445/37</a> and his colab notebook.\nI adapt it a little bit to implement it by numpy:</p>\n<pre><code>def gather_nd(params, indices, batch_dims=0):\n    &quot;&quot;&quot; use numpy and tensorflow to implement tf.gather_nd\n    Adapt from : https://discuss.pytorch.org/t/how-to-do-the-tf-gather-nd-in-pytorch/6445/37\n    &quot;&quot;&quot;\n    # firstly, convert to numpy type, then use numpy to execute operations\n    if isinstance(params, tf.Tensor):\n      params = params.numpy()\n    else:\n      if not isinstance(indices, np.ndarray):\n        raise ValueError(f\'params must be `tf.Tensor` or `numpy.ndarray`. Got {type(params)}\')\n    if isinstance(indices, tf.Tensor):\n      indices = indices.numpy()\n    else:\n      if not isinstance(indices, np.ndarray):\n        raise ValueError(f\'indices must be `tf.Tensor` or `numpy.ndarray`. Got {type(indices)}\')\n\n    if batch_dims == 0:\n        orig_shape = list(indices.shape)\n        num_samples = int(np.prod(orig_shape[:-1]))\n        m = orig_shape[-1]\n        n = len(params.shape)\n\n        if m &lt;= n:\n            out_shape = orig_shape[:-1] + list(params.shape[m:])\n        else:\n            raise ValueError(\n                f\'the last dimension of indices must less or equal to the rank of params. Got indices:{indices.shape}, params:{params.shape}. {m} &gt; {n}\'\n            )\n        # indices_ = tf.transpose(tf.reshape(indices, [num_samples, m]), perm=[1, 0])\n        indices = indices.reshape((num_samples, m)).transpose().tolist()\n        output = params[indices]    # (num_samples, ...)\n\n        return tf.reshape(output,out_shape)  # or return numpy type: output.reshape(out_shape)\n    else:\n        batch_shape = params.shape[:batch_dims]\n        orig_indices_shape = list(indices.shape)\n        orig_params_shape = list(params.shape)\n        assert (\n            batch_shape == indices.shape[:batch_dims]\n        ), f\'if batch_dims is not 0, then both &quot;params&quot; and &quot;indices&quot; have batch_dims leading batch dimensions that exactly match.\'\n        mbs = np.prod(batch_shape)\n        if batch_dims != 1:\n            params = params.reshape(mbs, *(params.shape[batch_dims:]))\n            indices = indices.reshape(mbs, *(indices.shape[batch_dims:]))\n        output = []\n        for i in range(mbs):\n            output.append(gather_nd(params[i], indices[i], batch_dims=0))\n        output =np.stack(output, axis=0)\n        output_shape = orig_indices_shape[:-1] + list(orig_params_shape[orig_indices_shape[-1]+batch_dims:])\n        return tf.reshape(output,output_shape)  # or return numpy type: output.reshape(output_shape)\n</code></pre>\n'}, {'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1559725365, 'answer_id': 56457345, 'question_id': 56452714, 'body': '<p>This function should do an equivalent work:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ndef my_gather_nd(params, indices):\n    idx_shape = tf.shape(indices)\n    params_shape = tf.shape(params)\n    idx_dims = idx_shape[-1]\n    gather_shape = params_shape[idx_dims:]\n    params_flat = tf.reshape(params, tf.concat([[-1], gather_shape], axis=0))\n    axis_step = tf.cumprod(params_shape[:idx_dims], exclusive=True, reverse=True)\n    indices_flat = tf.reduce_sum(indices * axis_step, axis=-1)\n    result_flat = tf.gather(params_flat, indices_flat)\n    return tf.reshape(result_flat, tf.concat([idx_shape[:-1], gather_shape], axis=0))\n\n# Test\nnp.random.seed(0)\nwith tf.Graph().as_default(), tf.Session() as sess:\n    params = tf.constant(np.random.rand(10, 20, 30).astype(np.float32))\n    indices = tf.constant(np.stack([np.random.randint(10, size=(5, 8)),\n                                    np.random.randint(20, size=(5, 8))], axis=-1))\n    result1, result2 = sess.run((tf.gather_nd(params, indices),\n                                 my_gather_nd(params, indices)))\n    print(np.allclose(result1, result2))\n    # True\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9026}"
959,36570729,"{'items': [{'owner': {'reputation': 1, 'user_id': 11967763}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1646317182, 'answer_id': 71338691, 'question_id': 36570729, 'body': '<p>I had the same issue, apparently IndexedSlices objects are automatically created for some Embedding matrices when computing their gradients,</p>\n<p>If you want to access the gradients of the trainable variables of the Embedding, you need to convert the IndexedSlices to a tensor, by simply using:</p>\n<pre><code>tf.convert_to_tensor(gradients_of_the_embedding_layer)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9026}"
960,60444268,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9023}"
961,39493229,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': True, 'score': 7, 'creation_date': 1473870008, 'answer_id': 39495311, 'question_id': 39493229, 'body': '<p>From a look at <a href=""https://github.com/tensorflow/tensorflow/blob/bc64f05d4090262025a95438b42a54bfdc5bcc80/tensorflow/core/kernels/maxpooling_op.cc#L672"" rel=""noreferrer"">the implementation</a>, it appears that the <a href=""https://www.tensorflow.org/versions/r0.10/api_docs/python/nn.html#max_pool_with_argmax"" rel=""noreferrer""><code>tf.nn.max_pool_with_argmax()</code></a> is only implemented for GPU. If you are running the CPU-only build of TensorFlow, then you would get an error of the form <code>""No OpKernel was registered to support Op \'MaxPoolWithArgmax\' with these attrs ...""</code>.</p>\n\n<p>(This seems like a place where the documentation and the error message could be improved.)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9022}"
962,56491633,"{'items': [{'owner': {'reputation': 885, 'user_id': 2018567}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1588729973, 'answer_id': 61626018, 'question_id': 56491633, 'body': ""<p>@shaunshd , I finally fully understand the 3 tensors relationship in tf.scatter_nd_*() arguments, especially when the indices have multi-demensions. e.g:\nindices = tf.constant([[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3], [3,3,2]], dtype=tf.int32)</p>\n\n<p>Please don't expect tf.rank(indices)>2, tf.rank(indices)==2 is permanently true;</p>\n\n<p>The following is my test codes to show more complex test case than the examples provided in tensroflow's official website:</p>\n\n<pre><code>def testScatterNDUpdate(self):\n    ref = tf.Variable(np.zeros(shape=[4, 4, 4], dtype=np.float32))\n    indices = tf.constant([[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3], [3,3,2]], dtype=tf.int32)\n    updates = tf.constant([1,2,3,4,5], dtype=tf.float32)\n    #shape = (4,4,4)\n    print(tf.tensor_scatter_nd_update(ref, indices, updates))\n    print(ref.scatter_nd_update(indices, updates))\n    #print(updates.shape[-1]==shape[-1], updates.shape[0]&lt;=shape[0])\n    #conditions are:\n    #      updates.shape[0]==indices[0]\n    #      indices[1]&lt;=len(shape)\n    #      tf.rank(indices)==2\n</code></pre>\n\n<p>You also could understand the indices with the following psudo codes:</p>\n\n<pre><code>def scatter_nd_update(ref, indices, updates):\n    for i in range(tf.shape(indices)[0]):\n        ref[indices[i]]=updates[i]\n    return ref\n</code></pre>\n\n<p>Comapring with numpy's fancy indexing feature, tensorflow's indexing features are still very difficult to use and have different using style, not unified as same as numpy yet. Hope the situation could be better in tf3.x</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9022}"
963,55176818,"{'items': [{'owner': {'reputation': 11877, 'user_id': 5368083}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1552769746, 'answer_id': 55201406, 'question_id': 55176818, 'body': '<ol>\n<li><p>To support masking one should implement the <code>compute_mask</code> method inside the custom layer</p></li>\n<li><p>To access the mask, simply add as the second positional argument in the <code>call</code> method the argument <code>mask</code>, and it will be accessible (ex. <code>call(self, inputs, mask=None)</code>)</p></li>\n<li><p>This cannot be guessed, it is the layer\'s before responsible to calculate the mask </p></li>\n<li><p>Once you implemented the <code>compute_mask</code> passing the mask to the next layer happens automatically - excluding the case of model subclassing, which in this case it is up to you to calculate masks and pass them on.</p></li>\n</ol>\n\n<p>Example:</p>\n\n<pre class=""lang-py prettyprint-override""><code>class MyCustomKerasLayers(tf.keras.layers.Layer):\n    def __init__(self, .......):\n        ...\n\n    def compute_mask(self, inputs, mask=None):\n        # Just pass the received mask from previous layer, to the next layer or \n        # manipulate it if this layer changes the shape of the input\n        return mask\n\n    def call(self, input, mask=None):\n        # using \'mask\' you can access the mask passed from the previous layer\n</code></pre>\n\n<p>Notice that this example just passes on the mask, if the layer will output a shape different than the one received, you should change the mask accordingly in <code>compute_mask</code> to pass on the correct one</p>\n\n<h3>EDIT</h3>\n\n<p>Now explanation is also included in the <a href=""https://www.tensorflow.org/beta/guide/keras/masking_and_padding"" rel=""nofollow noreferrer""><code>tf.keras</code> masking and padding documentation</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9022}"
964,75474546,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9022}"
965,44936825,"{'items': [{'owner': {'reputation': 21, 'user_id': 8408117}, 'down_vote_count': 1, 'up_vote_count': 2, 'is_accepted': False, 'score': 1, 'creation_date': 1504020004, 'answer_id': 45942824, 'question_id': 44936825, 'body': '<p>Inpput_size for tf.TensorShape([200, None, 300]) is just 300</p>\n\n<p>Play with this example.</p>\n\n<pre><code>import os\nos.environ[""CUDA_DEVICE_ORDER""]=""PCI_BUS_ID""   # see TF issue #152\nos.environ[""CUDA_VISIBLE_DEVICES""]=""1""\nimport tensorflow as tf\nimport numpy as np\n\n\nn_steps = 2\nn_inputs = 3\nn_neurons = 5\nkeep_prob = 0.5\nlearning_rate = 0.001\n\n\nX = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\nX_seqs = tf.unstack(tf.transpose(X, perm=[1, 0, 2]))\n\nbasic_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\nbasic_cell_drop = tf.contrib.rnn.DropoutWrapper(\n    basic_cell,\n    input_keep_prob=keep_prob,\n    variational_recurrent=True,\n    dtype=tf.float32,\n    input_size=n_inputs)\n\noutput_seqs, states = tf.contrib.rnn.static_rnn(\n    basic_cell_drop,\n    X_seqs,\n    dtype=tf.float32)\noutputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])\n\ninit = tf.global_variables_initializer()\n\nX_batch = np.array([\n        # t = 0      t = 1 \n        [[0, 1, 2], [9, 8, 7]], # instance 1\n        [[3, 4, 5], [0, 0, 0]], # instance 2\n        [[6, 7, 8], [6, 5, 4]], # instance 3\n        [[9, 0, 1], [3, 2, 1]], # instance 4\n    ])\n\nwith tf.Session() as sess:\n    init.run()\n    outputs_val = outputs.eval(feed_dict={X: X_batch})\n\n\nprint(outputs_val)\n</code></pre>\n\n<p>See this for more details: <a href=""https://github.com/tensorflow/tensorflow/issues/7927"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/7927</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9018}"
966,55711355,"{'items': [{'owner': {'reputation': 533, 'user_id': 9217178}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1570784062, 'answer_id': 58337617, 'question_id': 55711355, 'body': '<p>As long as no answer, I will suggest mine, which contour the pb instead of solving it. Struggling for a long time, I finally neglected it by pruning it. Then graft the new input/ouput to it with a simpler way the placeholder. Moreover, this <strong>py_func is deprecated in TF2.0</strong>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9018}"
967,58412668,"{'items': [{'owner': {'reputation': 23, 'user_id': 15147418}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1615532956, 'answer_id': 66595678, 'question_id': 58412668, 'body': '<p>Since I have lost a couple of hours because of this. I would like to add to the good remark of Julian about defining the hparams config, that the tag of the metric you like to log with hparams and possibly its group in <code>hp.Metric(tag=\'epoch_accuracy\', group=\'validation\')</code> should match the one of a metric that you capture with Keras <code>model.fit(..., metrics=)</code>. See <a href=""https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/hparams/hparams_demo.py"" rel=""nofollow noreferrer"">hparams_demo</a> for a good example</p>\n'}, {'owner': {'reputation': 305, 'user_id': 10143615}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1587567930, 'answer_id': 61368410, 'question_id': 58412668, 'body': ""<p>The trick is to define the Hparams config with the path in which TensorBoard saves its validation logs.</p>\n<p>So, if your TensorBoard callback is set up as:</p>\n<pre><code>log_dir = 'path/to/training-logs'\ntensorboard_cb = TensorBoard(log_dir=log_dir)\n</code></pre>\n<p>Then you should set up Hparams like this:</p>\n<pre><code>hparams_dir = os.path.join(log_dir, 'validation')\n\nwith tf.summary.create_file_writer(hparams_dir).as_default():\n    hp.hparams_config(\n        hparams=HPARAMS,\n        metrics=[hp.Metric('epoch_accuracy')]  # metric saved by tensorboard_cb\n    )\n\nhparams_cb = hp.KerasCallback(\n    writer=hparams_dir,\n    hparams=HPARAMS\n)\n</code></pre>\n""}, {'owner': {'reputation': 682, 'user_id': 7818309}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1587627218, 'answer_id': 61381683, 'question_id': 58412668, 'body': '<p>I just want to add to the previous answers. If you are using TensorBoard in a notebook on Colab, the issue may not be due to your code, but due to how TensorBoard is run on Colab. And the solution is to kill the existing TensorBoard and launch it again. </p>\n\n<p>Please correct me if I am wrong. </p>\n\n<p>Sample code:</p>\n\n<pre class=""lang-py prettyprint-override""><code>from tensorboard.plugins.hparams import api as hp\n\nHP_LR = hp.HParam(\'learning_rate\', hp.Discrete([1e-4, 5e-4, 1e-3]))\nHPARAMS = [HP_LR]\n# this METRICS does not seem to have any effects in my example as \n# hp uses epoch_accuracy and epoch_loss for both training and validation anyway.\nMETRICS = [hp.Metric(\'epoch_accuracy\', group=""validation"", display_name=\'val_accuracy\')]\n# save the configuration\nlog_dir = \'/content/logs/hparam_tuning\'\nwith tf.summary.create_file_writer(log_dir).as_default():\n  hp.hparams_config(hparams=HPARAMS, metrics=METRICS)\n\n\ndef fitness_func(hparams, seed):\n  rng = random.Random(seed)\n\n  # here we build the model\n  model = tf.keras.Sequential(...)\n  model.compile(..., metrics=[\'accuracy\'])  # need to pass the metric of interest\n\n  # set up callbacks\n  _log_dir = os.path.join(log_dir, seed)\n  tb_callbacks = tf.keras.callbacks.TensorBoard(_log_dir)  # log metrics\n  hp_callbacks = hp.KerasCallback(_log_dir, hparams)  # log hparams\n\n  # fit the model\n  history = model.fit(\n    ..., validation_data=(x_te, y_te), callbacks=[tb_callbacks, hp_callbacks])\n\n\nrng = random.Random(0)\nsession_index = 0\n# random search\nnum_session_groups = 4\nsessions_per_group = 2\nfor group_index in range(num_session_groups):\n  hparams = {h: h.domain.sample_uniform(rng) for h in HPARAMS}\n  hparams_string = str(hparams)\n  for repeat_index in range(sessions_per_group):\n    session_id = str(session_index)\n    session_index += 1\n    fitness_func(hparams, session_id)\n</code></pre>\n\n<p>To check if there is any existing TensorBoard process, run the following in Colab:</p>\n\n<pre><code>!ps ax | grep tensorboard\n</code></pre>\n\n<p>Assume PID for the TensorBoard process is 5315. Then, </p>\n\n<pre><code>!kill 5315\n</code></pre>\n\n<p>and run</p>\n\n<pre><code># of course, replace the dir below with your log_dir\n%tensorboard --logdir=\'/content/logs/hparam_tuning\'\n</code></pre>\n\n<p>In my case, after I reset TensorBoard as above, it can properly log the metrics specified in <code>model.compile</code>, i.e., accuracies.</p>\n'}, {'owner': {'reputation': 4696, 'user_id': 7441757}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1575362607, 'answer_id': 59153124, 'question_id': 58412668, 'body': ""<p>I managed but not entirely sure what was the magic word. Here my flow in case it helps.</p>\n\n<pre><code>callbacks.append(hp.KerasCallback(log_dir, hparams))\n\nHP_NUM_LATENT = hp.HParam('num_latent_dim', hp.Discrete([2, 5, 100])) \nhparams = {\n   HP_NUM_LATENT: num_latent,\n}\n\nmodel = create_simple_model(latent_dim=hparams[HP_NUM_LATENT])  # returns compiled model\nmodel.fit(x, y, validation_data=validation_data, \n          epochs=4,\n          verbose=2,\n          callbacks=callbacks) \n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9018}"
968,58599039,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9018}"
969,45553280,"{'items': [{'owner': {'reputation': 58, 'user_id': 7421231}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1521021945, 'answer_id': 49274797, 'question_id': 45553280, 'body': '<p>In documentation for <a href=""https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/python/ops/rnn.py"" rel=""nofollow noreferrer"">raw_rnn</a>, they use</p>\n\n<pre><code>inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_time)\ninputs_ta = inputs_ta.unstack(inputs)\n</code></pre>\n\n<p><em>inputs</em> is a tensor with shape: (max_time,batch_size,num_hidden).\nHope this helps.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9018}"
970,54761088,"{'items': [{'owner': {'reputation': 4131, 'user_id': 13546426}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': False, 'score': 11, 'creation_date': 1550564753, 'answer_id': 54761708, 'question_id': 54761088, 'body': '<ul>\n<li><p><code>tf.nn.relu</code> : It comes from TensorFlow library. It is located in the <code>nn</code> module. Hence, it is used as an operation in neural networks. If <code>x</code> is a tensor then, </p>\n\n<pre><code>y = tf.nn.relu( x )\n</code></pre>\n\n<p>It is used in creating custom layers and NN. If you use it with Keras, you may face some problems while loading or saving the models or converting the model to TF Lite.</p></li>\n<li><p><code>tf.keras.activations.relu</code> : It comes from the Keras library included in TensorFlow. It is located in the <code>activations</code> module which also provides another activation functions. It is mostly used in Keras Layers ( <code>tf.keras.layers</code> ) for the <code>activation=</code> argument :</p>\n\n<pre><code>model.add( keras.layers.Dense( 25 , activation=tf.keras.activations.relu  ) )\n</code></pre>\n\n<p>But, it can also be used as the example in the above section. It is more specific to Keras ( <code>Sequential</code> or <code>Model</code> ) rather than raw TensorFlow computations.</p></li>\n</ul>\n\n<blockquote>\n  <p><code>tf.nn.relu</code> is a TensorFlow specific whereas <code>tf.keras.activations.relu</code> has more uses in Keras own library. If I create a NN with only TF,  I will most probably use <code>tf.nn.relu</code> and if I am creating a Keras Sequential model then I will use <code>tf.keras.activations.relu</code>.</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9013}"
971,62318212,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9013}"
972,51586693,"{'items': [{'owner': {'reputation': 385600, 'user_id': 4909087}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1532923379, 'answer_id': 51586823, 'question_id': 51586693, 'body': '<p>I think you should use <a href=""https://www.tensorflow.org/api_docs/python/tf/not_equal"" rel=""nofollow noreferrer""><code>tf.not_equal</code></a> to perform elementwise comparison on the tensor.</p>\n\n<pre><code>src = tf.constant([0, 1, 1, 0], dtype=tf.int8)\ntf.gather(src, tf.where(tf.not_equal(src, 0))).eval(session=tf.Session())\n\narray([[1],\n       [1]], dtype=int8)\n</code></pre>\n\n<p>You can also shorten this a bit and use <a href=""https://www.tensorflow.org/api_docs/python/tf/boolean_mask"" rel=""nofollow noreferrer""><code>tf.boolean_mask</code></a> instead of <code>tf.where</code> and <code>tf.gather</code>:</p>\n\n<pre><code>tf.boolean_mask(src, tf.not_equal(src, 0)).eval(session=tf.Session())\narray([1, 1], dtype=int8)\n</code></pre>\n\n<p>Note the difference in the shape of the outputs.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9013}"
973,60919434,"{'items': [{'owner': {'reputation': 187, 'user_id': 16681242}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1670865321, 'answer_id': 74774833, 'question_id': 60919434, 'body': ""<p>In this scenario, I would use <code>tensorflow_transform</code> in conjunction with <code>tensorflow_data_validation</code> to do the one hot encoding for a feature named <code>oh</code> in <code>some.csv</code>. The steps are as follows:</p>\n<ol>\n<li>Compute the statistics and infer the <code>SCHEMA</code> against your data.</li>\n<li>Set up a <code>preprocessing_fn</code> that you will run via tensorflow transform/apache beam</li>\n<li>Within <code>preprocessing_fn</code> figure out the depth of your one hot encoded feature (how many categories you're dealing with)</li>\n<li>Create a feature that represents an index that maps these categories to integers</li>\n<li>Pass this index feature to <code>tf.one_hot</code> and tell it what the depth is</li>\n<li>Clean up the intermediary feature and returned the transformed &quot;dictionary&quot;</li>\n</ol>\n<pre><code>import tensorflow_data_validation as tfdv\nimport tensorflow_transform as tfx\nTRAIN_FILE_PATH='./some.csv'\ntrain_stats = tfdv.generate_statistics_from_csv(data_location=TRAIN_FILE_PATH)\nSCHEMA = tfdv.infer_schema(statistics=train_stats)\n\ndef preprocessing_fn(inputs):\n    transformed = inputs.copy()\n    oh_domain = tfdv.get_domain(SCHEMA, 'oh')\n    oh_depth = len(oh_domain.value)\n    transformed['ohi'] = tft.compute_and_apply_vocabulary(transformed['oh'])\n    transformed['oh_oh'] = tf.one_hot(transformed['ohi'], depth = oh_depth)\n    del(transformed['ohi'])\n    return transformed\n\n</code></pre>\n<p>The above is a &quot;point&quot; solution in the sense it just addresses how to do this specific thing.  The periphery to be optimized is only having tensor operations within <code>preprocessing_fn</code> which you can do with some functional programming tricks, and some other things which might sacrifice readability for performance.</p>\n""}, {'owner': {'reputation': 4914, 'user_id': 4444546}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1585566278, 'answer_id': 60929195, 'question_id': 60919434, 'body': '<p>Ok I think I have found a proper answer:</p>\n\n<pre><code>def string_to_one_hot(labels):\n    colnames, codes = tf.unique(support_labels_name)\n    return colnames, tf.one_hot(codes, depth=tf.size(colnames))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9013}"
974,56321676,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9009}"
975,45237900,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9009}"
976,46904972,"{'items': [{'owner': {'reputation': 52739, 'user_id': 712995}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1508851026, 'answer_id': 46911617, 'question_id': 46904972, 'body': '<p>You can declare a custom numerical column and add it to the dataframe in your <a href=""https://www.tensorflow.org/get_started/input_fn"" rel=""nofollow noreferrer"">input function</a>:</p>\n\n<pre><code># Existing features\nage = tf.feature_column.numeric_column(""age"")\neducation_num = tf.feature_column.numeric_column(""education_num"")\n# Declare a custom column just like other columns\nmy_feature = tf.feature_column.numeric_column(""my_feature"")\n\n...\n# Add to the list of features\nfeature_columns = { ... age, education_num, my_feature, ... }\n\n...\ndef input_fn():\n  df_data = pd.read_csv(""input.csv"")\n  df_data = df_data.dropna(how=""any"", axis=0)\n  # Manually update the dataframe\n  df_data[""my_feature""] = df_data[""age""] * df_data[""education_num""]\n\n  return tf.estimator.inputs.pandas_input_fn(x=df_data,\n                                             y=labels,\n                                             batch_size=100,\n                                             num_epochs=10)\n\n...\nmodel.train(input_fn=input_fn())\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9009}"
977,50724495,"{'items': [{'owner': {'reputation': 671, 'user_id': 5703820}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1535899391, 'answer_id': 52138053, 'question_id': 50724495, 'body': '<p>You can simply run any architecture you want. And the validation and train data will be saved in your working folder and are viewable inside TensorBoard. There\'s filter to pick for all the models architecture that you\'ve ran.</p>\n\n<p><a href=""https://i.stack.imgur.com/sQK7b.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/sQK7b.png"" alt=""Filter""></a></p>\n'}, {'owner': {'reputation': 5186, 'user_id': 992489}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1528445724, 'answer_id': 50756280, 'question_id': 50724495, 'body': '<p>Save all models to a subdirectory of a parent directory and pass this parent directory as the logdir in tensorboard; this will put all curves in the same graph.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9009}"
978,60311184,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1582216301, 'answer_id': 60324574, 'question_id': 60311184, 'body': '<p>I think I get an idea of what you want, more or less, but I\'m not sure I see the need for the boolean array. If you want to do some iterative process where you compute or retrieve some values until they meet some condition, you can do that without additional arrays. See for example this loop to sample some random values until all of them meet a condition:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\n# Draw five random numbers until all are &gt; 0.5\nwith tf.Graph().as_default(), tf.Session() as sess:\n    tf.random.set_random_seed(0)\n    # Initial values, here simply initialized to zero\n    tensor1 = tf.zeros([5], dtype=tf.float32)\n    # Loop\n    tensor1 = tf.while_loop(\n        # Loop condition (negated goal condition)\n        lambda tensor1: ~tf.math.reduce_all(tensor1 &gt; 0.5),\n        # Loop body\n        lambda tensor1: tf.random.uniform(tf.shape(tensor1), dtype=tensor1.dtype),\n        # Loop variables\n        [tensor1])\n    # Returned loop value\n    print(tensor1.eval())\n    # [0.7778928  0.9396961  0.572209   0.6187117  0.89615726]\n</code></pre>\n\n<p>See if this helps and leave a comment if you are still not sure how to apply this to your particular case.</p>\n\n<hr>\n\n<p>EDIT: Seeing again your question, your <code>uniqueness</code> function computed both <code>tensor1</code> and the mask, so maybe a more similar analogous code would be this:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\ndef sample_numbers(shape, dtype):\n    tensor1 = tf.random.uniform(shape, dtype=dtype)\n    mask = tensor1 &gt; 0.5\n    return tensor1, mask\n\n# Draw five random numbers until all are &gt; 0.5\nwith tf.Graph().as_default(), tf.Session() as sess:\n    tf.random.set_random_seed(0)\n    # Initial values, here simply initialized to zero\n    tensor1 = tf.zeros([5], dtype=tf.float32)\n    mask = tf.zeros(tf.shape(tensor1), dtype=tf.bool)\n    # Loop\n    tensor1, _ = tf.while_loop(\n        # Loop condition (negated goal condition)\n        lambda tensor1, mask: ~tf.math.reduce_all(mask),\n        # Loop body\n        lambda tensor1, mask: sample_numbers(tf.shape(tensor1), tensor1.dtype),\n        # Loop variables\n        [tensor1, mask])\n    # Returned loop value\n    print(tensor1.eval())\n    # [0.95553064 0.5170193  0.69573617 0.9501506  0.99776053]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9005}"
979,67759756,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1623295541, 'answer_id': 67914261, 'question_id': 67759756, 'body': '<p>For a given directory structure</p>\n<pre><code>Classification/\n...Singer_A/\n......A_song_1.txt\n......A_song_2.txt\n...Singer_B/\n......B_song_1.txt\n......B_song_2.txt\n</code></pre>\n<p>Prepare dataset for binary classification <code>text_dataset_from_directory</code></p>\n<pre><code>import tensorflow as tf\nbatch_size = 32\nseed = 42\n#training dataset\nraw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    \'classificatio/\', \n    batch_size=batch_size, \n    validation_split=0.2, \n    subset=\'training\', \n    seed=seed)\n#validation dataset\nraw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    \'aclImdb/train\', \n    batch_size=batch_size, \n    validation_split=0.2, \n    subset=\'validation\', \n    seed=seed)\n</code></pre>\n<p>Once the train ad validation dataset is ready perform the data text preprocessing such as tokenization, make it lowercase, removing special character and vectorization. Using below sample code</p>\n<pre><code>def custom_standardization(input_data):\n  lowercase = tf.strings.lower(input_data)\n  stripped_html = tf.strings.regex_replace(lowercase, \'&lt;br /&gt;\', \' \')\n  return tf.strings.regex_replace(stripped_html,\n                                  \'[%s]\' % re.escape(string.punctuation),\n                                  \'\')\n</code></pre>\n<p>Refer the basic <a href=""https://www.tensorflow.org/tutorials/keras/text_classification"" rel=""nofollow noreferrer"">text binary classification</a> for more information.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9005}"
980,38356622,"{'items': [{'owner': {'reputation': 543, 'user_id': 6639245}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1469532695, 'answer_id': 38588739, 'question_id': 38356622, 'body': '<p>I\'m currently struggling with this myself. The following is mostly cribbed from <a href=""https://www.tensorflow.org/versions/master/how_tos/distributed/index.html"" rel=""nofollow"">the tensorflow distributed how-to guide</a>.</p>\n\n<p>You can pin ops to a job/task using <code>tf.device</code>:</p>\n\n<pre><code>clusterspec = \\\n    { ""worker"": \n        [ ""www.example0.com:2222""\n        , ""www.example1.com:2222""\n        , ""www.example2.com:2222""\n        ]\n    , ""master"":\n        [ ""localhost:2222"" ]\n    }\n\ncluster = tf.ClusterSpec(clusterspec)\n\na = tf.constant(3)\nb = tf.constant(2)\n\n# pin \'x\' to www.example0.com\nwith tf.device(""/job:worker/task:0""):\n    x = tf.mul(a, b)\n\n# pin \'y\' to www.example1.com\nwith tf.device(""/job:worker/task:1""):\n    y = tf.mul(a, b)\n\nserver = tf.train.Server(cluster, job_name=""master"", task_index=0)\nwith tf.Session(server.target) as sess:\n     # run the ops\n     print(sess.run([x, y]))\n</code></pre>\n\n<hr>\n\n<p><s>However, at least for me, this only works if all the worker processes are on the same machine as the master. Otherwise, it hangs at <code>sess.run</code>.</s> </p>\n\n<p>This turned out to be a problem with the use of <code>localhost</code> in the cluster specification. If you share the same cluster specification between servers, don\'t use <code>localhost</code>; instead, use the IP address or hostname of the computer that you think <code>localhost</code> refers to. In the case of the above example, suppose that you\'re running the master script on <code>www.master.com</code>. You have two options:</p>\n\n<h3>1. One clusterspec per server using localhost</h3>\n\n<p>On each server, <code>localhost</code> refers to the machine running the server.</p>\n\n<pre><code># on www.example0.com\nclusterspec = \\\n    { ""worker"":\n        [ ""localhost:2222""\n        , ""www.example1.com:2222""\n        , ""www.example2.com:2222""\n        ]\n    , ""master"":\n        [ ""www.master.com:2222"" ]\n    }\n\ncluster = tf.ClusterSpec(clusterspec)\nserver = tf.train.Server(cluster, job_name=""worker"", task_index=0)\nserver.join()\n\n# on www.example1.com\nclusterspec = \\\n    { ""worker"":\n        [ ""www.example0.com:2222""\n        , ""localhost:2222""\n        , ""www.example2.com:2222""\n        ]\n    , ""master"":\n        [ ""www.master.com:2222"" ]\n    }\n\ncluster = tf.ClusterSpec(clusterspec)\nserver = tf.train.Server(cluster, job_name=""worker"", task_index=1)\nserver.join()\n\n# on www.example2.com\nclusterspec = \\\n    { ""worker"":\n        [ ""www.example0.com:2222""\n        , ""www.example1.com:2222""\n        , ""localhost:2222""\n        ]\n    , ""master"":\n        [ ""www.master.com:2222"" ]\n    }\n\ncluster = tf.ClusterSpec(clusterspec)\nserver = tf.train.Server(cluster, job_name=""worker"", task_index=2)\nserver.join()\n\n# on www.master.com\nclusterspec = \\\n    { ""worker"":\n        [ ""www.example0.com:2222""\n        , ""www.example1.com:2222""\n        , ""www.example2.com:2222""\n        ]\n    , ""master"":\n        [ ""localhost:2222"" ]\n    }\n\ncluster = tf.ClusterSpec(clusterspec)\n\na = tf.constant(3)\nb = tf.constant(2)\n\nwith tf.device(""/job:worker/task:0""):\n    x = tf.mul(a, b)\n\nwith tf.device(""/job:worker/task:1""):\n    y = tf.mul(a, b)\n\nserver = tf.train.Server(cluster, job_name=""master"", task_index=0)\nwith tf.Session(server.target) as sess:\n     print(sess.run([x, y]))\n</code></pre>\n\n<h3>2. Shared clusterspec</h3>\n\n<p>One cluster specification, using IP addresses / domain names that can all be seen from every node.</p>\n\n<p>Saved in <code>clusterspec.json</code>:</p>\n\n<pre><code>{ ""worker"":\n  [ ""www.example0.com:2222""\n  , ""www.example1.com:2222""\n  , ""www.example2.com:2222""\n  ]\n, ""master"":\n  [ ""www.master.com:2222"" ]\n}\n</code></pre>\n\n<p>Then on each worker:</p>\n\n<pre><code>import json\n\nwith open(\'clusterspec.json\', \'r\') as f:\n    clusterspec = json.load(f)\n\ncluster = tf.ClusterSpec(clusterspec)\nserver = tf.train.Server(cluster, job_name=""worker"", task_index=&lt;INDEX OF TASK&gt;)\n</code></pre>\n\n<p>Then on the master:</p>\n\n<pre><code>import json\n\nwith open(\'clusterspec.json\', \'r\') as f:\n    clusterspec = json.load(f)\n\ncluster = tf.ClusterSpec(clusterspec)\n\na = tf.constant(3)\nb = tf.constant(2)\n\nwith tf.device(""/job:worker/task:0""):\n    x = tf.mul(a, b)\n\nwith tf.device(""/job:worker/task:1""):\n    y = tf.mul(a, b)\n\nserver = tf.train.Server(cluster, job_name=""master"", task_index=0)\nwith tf.Session(server.target) as sess:\n     print(sess.run([x, y]))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9003}"
981,56635027,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1560790888, 'answer_id': 56635868, 'question_id': 56635027, 'body': '<p>Use <a href=""https://www.tensorflow.org/api_docs/python/tf/where"" rel=""nofollow noreferrer""><code>tf.where</code></a> for that, for example like this (<a href=""https://github.com/tensorflow/tensorflow/issues/9284"" rel=""nofollow noreferrer"">broadcasting support for <code>tf.where</code> seems to be on its way</a>, but not there yet as far as I can tell, so you have to make sure all arguments have the same size with a vector of ones, or <a href=""https://www.tensorflow.org/api_docs/python/tf/fill"" rel=""nofollow noreferrer""><code>tf.fill</code></a>, <a href=""https://www.tensorflow.org/api_docs/python/tf/tile"" rel=""nofollow noreferrer""><code>tf.tile</code></a>...).</p>\n\n<pre><code>import tensorflow as tf\n\nwith tf.Graph().as_default(), tf.Session() as sess:\n    x = tf.placeholder(tf.float32, shape=[None])\n    y = tf.placeholder(tf.float32, shape=[None])\n    z = tf.placeholder(tf.float32, shape=[None])\n    ones = tf.ones_like(x)\n    r = tf.where(x &lt; y, 17 * ones, tf.where(x &gt; z, 23 * ones, -ones))\n    print(sess.run(r, feed_dict={x: [0, 1, 2, 3], y: [1, 1, 1, 1], z: [2, 2, 2, 2]}))\n    # [17. -1. -1. 23.]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9003}"
982,59260563,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1575958355, 'answer_id': 59261222, 'question_id': 59260563, 'body': '<p>I think you\'re not using the Model in the correct way. Try changing your code the following way.</p>\n\n<pre><code>from tensorflow.keras import layers, models\n\nipt = layers.Input(shape=[10, 5])\nconvs = []\nfsz = 8\nfs= [1, 2, 3]\nfor f in fs:\n    conv = layers.Conv1D(activation=\'tanh\', kernel_size=f, filters=200)(ipt)\n    pool = layers.MaxPooling1D(10 - fsz + 1, padding=""same"")(conv)\n    pool = layers.Flatten()(pool)\n    convs.append(pool)\nmerge = layers.Concatenate(axis=1)(convs)\n\nmodel = models.Model(inputs=ipt, outputs=merge)\nmodel.summary()\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9001}"
983,50083475,"{'items': [{'owner': {'reputation': 1046, 'user_id': 9376487}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1524983076, 'answer_id': 50083951, 'question_id': 50083475, 'body': ""<p>Generally speaking, I try the NumPy equivalents to the TensorFlow functions when I'm working things out.  Initially, the TensorFlow API had some quirky differences to the NumPy API, but enough users want the two packages to behave the same that TensorFlow is making changes.</p>\n\n<p>You say that the array <code>self.a</code> is guaranteed to be 1D.  All right then:</p>\n\n<pre><code>import numpy as np\narr = np.random.randint(-9,9,(10,))\nprint(arr)\nresult = np.stack([np.arange(np.shape(arr)[0], dtype=np.int32), arr], axis=1)\nprint(result)\n</code></pre>\n\n<p>Here's a sample output:</p>\n\n<pre><code>array([-5,  1,  0, -3, -9, -8,  3, -1,  0, -2])\n\narray([[ 0, -5],\n       [ 1,  1],\n       [ 2,  0],\n       [ 3, -3],\n       [ 4, -9],\n       [ 5, -8],\n       [ 6,  3],\n       [ 7, -1],\n       [ 8,  0],\n       [ 9, -2]])\n</code></pre>\n\n<p>So, it looks like the original 1D array is enlarged into a 2D array with a numerical index in the 0th column.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9001}"
984,74088086,"{'items': [{'owner': {'reputation': 892, 'user_id': 1331234}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1665958215, 'answer_id': 74091016, 'question_id': 74088086, 'body': '<p>If you go to the link you send you can read:</p>\n<p><code>Note that a seeded initializer will not produce the same random values across multiple calls, but multiple initializers will produce the same sequence when constructed with the same seed value.</code></p>\n<p>So yes is deterministic but not return the same value in a single build note that keras and tensorflow are keeping track of the calls you make if you want to do this in a single script you need to reset the backend for keras and is recommended use <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed"" rel=""nofollow noreferrer""><code>tf.keras.utils.set_random_seed</code></a> to set the seed, here an example how to do this</p>\n<pre><code>import tensorflow as tf\n\nseed = 123\n\ntf.keras.utils.set_random_seed(\n    seed\n)\ninitializer = tf.keras.initializers.GlorotNormal()\nvalues = initializer(shape=(2, 2))\nprint(values)\ntf.keras.backend.clear_session()\ntf.keras.utils.set_random_seed(\n    seed\n)\n\ninitializer1 = tf.keras.initializers.GlorotNormal()\nvalues1 = initializer1(shape=(2, 2))\nprint(values1)\n</code></pre>\n<p>This will print :</p>\n<pre><code>tf.Tensor(\n[[-0.7219447  -1.4678022 ]\n [-0.35725543 -1.1963991 ]], shape=(2, 2), dtype=float32)\ntf.Tensor(\n[[-0.7219447  -1.4678022 ]\n [-0.35725543 -1.1963991 ]], shape=(2, 2), dtype=float32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9001}"
985,58728086,"{'items': [{'owner': {'reputation': 8049, 'user_id': 232371}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': False, 'score': 6, 'creation_date': 1601494566, 'answer_id': 64144594, 'question_id': 58728086, 'body': '<p>As for the original broader question of whether you have to manually pass the <code>training</code> flag when using Keras Functional API, this example from the <a href=""https://keras.io/getting_started/intro_to_keras_for_researchers/#the-functional-api-for-modelbuilding"" rel=""noreferrer"">official docs</a> suggests that you <strong>should not</strong>:</p>\n<pre><code># ...\n\nx = Dropout(0.5)(x)\noutputs = Linear(10)(x)\nmodel = tf.keras.Model(inputs, outputs)\n\n# ...\n\n# You can pass a `training` argument in `__call__`\n# (it will get passed down to the Dropout layer).\ny = model(tf.ones((2, 16)), training=True)\n</code></pre>\n'}, {'owner': {'reputation': 364, 'user_id': 12250264}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': True, 'score': 7, 'creation_date': 1577682252, 'answer_id': 59525939, 'question_id': 58728086, 'body': '<p>I realized that there is a bug in the <code>BatchNormalization</code> documentation [1] where the <code>{{TRAINABLE_ATTRIBUTE_NOTE}}</code> isn\'t actually replaced with the intended note [2]:</p>\n\n<p><strong>About setting <code>layer.trainable = False</code> on a <code>BatchNormalization</code> layer:</strong>\n  The meaning of setting <code>layer.trainable = False</code> is to freeze the layer,\n  i.e. its internal state will not change during training:\n  its trainable weights will not be updated\n  during <code>fit()</code> or <code>train_on_batch()</code>, and its state updates will not be run.\n  Usually, this does not necessarily mean that the layer is run in inference\n  mode (which is normally controlled by the <code>training</code> argument that can\n  be passed when calling a layer). ""Frozen state"" and ""inference mode""\n  are two separate concepts.</p>\n\n<p>However, in the case of the <code>BatchNormalization</code> layer, <strong>setting\n  <code>trainable = False</code> on the layer means that the layer will be\n  subsequently run in inference mode</strong> (meaning that it will use\n  the moving mean and the moving variance to normalize the current batch,\n  rather than using the mean and variance of the current batch).\n  This behavior has been introduced in TensorFlow 2.0, in order\n  to enable <code>layer.trainable = False</code> to produce the most commonly\n  expected behavior in the convnet fine-tuning use case.\n  Note that:</p>\n\n<ul>\n<li>This behavior only occurs as of TensorFlow 2.0. In 1.*,\n  setting <code>layer.trainable = False</code> would freeze the layer but would\n  not switch it to inference mode.</li>\n<li>Setting <code>trainable</code> on an model containing other layers will\n  recursively set the <code>trainable</code> value of all inner layers.</li>\n<li>If the value of the <code>trainable</code>\n  attribute is changed after calling <code>compile()</code> on a model,\n  the new value doesn\'t take effect for this model\n  until <code>compile()</code> is called again.</li>\n</ul>\n\n<p>[1] <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization?version=stable"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization?version=stable</a></p>\n\n<p>[2] <a href=""https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/normalization_v2.py#L26-L65"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/normalization_v2.py#L26-L65</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9001}"
986,72627862,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 9001}"
987,54615708,"{'items': [{'owner': {'reputation': 7061, 'user_id': 5495381}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1549796446, 'answer_id': 54615713, 'question_id': 54615708, 'body': '<p>My workaround solution is as follows. Inspecting the <code>./tf</code> folder makes clear that the call to <code>model_to_estimator</code> stored the necessary files in a <code>keras</code> subfolder, while <code>export_model</code> expects those files to be in the <code>./tf</code> folder directly, as this is the path we specified for the <code>model_dir</code> argument:</p>\n\n<pre><code>$ tree ./tf\n./tf\n keras\n     checkpoint\n     keras_model.ckpt.data-00000-of-00001\n     keras_model.ckpt.index\n     keras_model.ckpt.meta\n\n1 directory, 4 files\n</code></pre>\n\n<p>The simple workaround is to move these files up one folder. This can be done with Python:</p>\n\n<pre><code>import os\nimport shutil\nfrom pathlib import Path\n\ndef up_one_dir(path):\n    """"""Move all files in path up one folder, and delete the empty folder\n    """"""\n    parent_dir = str(Path(path).parents[0])\n    for f in os.listdir(path):\n        shutil.move(os.path.join(path, f), parent_dir)\n    shutil.rmtree(path)\n\nup_one_dir(\'./tf/keras\')\n</code></pre>\n\n<p>Which will make the <code>model_dir</code> directory look like this:</p>\n\n<pre><code>$ tree ./tf\n./tf\n checkpoint\n keras_model.ckpt.data-00000-of-00001\n keras_model.ckpt.index\n keras_model.ckpt.meta\n\n0 directories, 4 files\n</code></pre>\n\n<p>Doing this manipulation in between the <code>model_to_estimator</code> and the <code>export_savedmodel</code> calls allows to export the model as desired:</p>\n\n<pre><code>export_path = \'./export\'\nestimator.export_savedmodel(\n    export_path,\n    serving_input_receiver_fn=serving_input_receiver_fn())\n</code></pre>\n\n<blockquote>\n  <p>INFO:tensorflow:SavedModel written to:\n  ./export/temp-b\'1549796240\'/saved_model.pb</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8996}"
988,44097181,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8996}"
989,50243230,"{'items': [{'owner': {'reputation': 52739, 'user_id': 712995}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1525879432, 'answer_id': 50256934, 'question_id': 50243230, 'body': '<p>Yep, the doc is rather confusing in this place. If you look at the internals of <code>tf.nn.raw_rnn</code>, the key term there is <strong>""in pseudo-code""</strong>, so the example in the doc isn\'t accurate.</p>\n\n<p>The exact source code looks like this (may differ depending on your tensorflow version):</p>\n\n\n\n<pre class=""lang-py prettyprint-override""><code>if emit_structure is not None:\n  flat_emit_structure = nest.flatten(emit_structure)\n  flat_emit_size = [emit.shape if emit.shape.is_fully_defined() else\n                    array_ops.shape(emit) for emit in flat_emit_structure]\n  flat_emit_dtypes = [emit.dtype for emit in flat_emit_structure]\nelse:\n  emit_structure = cell.output_size\n  flat_emit_size = nest.flatten(emit_structure)\n  flat_emit_dtypes = [flat_state[0].dtype] * len(flat_emit_size)\n</code></pre>\n\n<p>So it handles the case when <code>emit_structure is None</code> and simply takes the value <code>cell.output_size</code>. That\'s why nothing really breaks.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8996}"
990,52190877,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8996}"
991,66858658,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1617060232, 'answer_id': 66862900, 'question_id': 66858658, 'body': '<p>I find it easy to transpose the tensor so that the indexing dimension is the first dimension, gather the element and then put it back to the original shape.</p>\n<pre><code>output = tf.transpose(\n    tf.gather(\n        tf.transpose(input, [2,0,1]), \n        new_order\n    ), [1,2,0]\n)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8996}"
992,55094952,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 20, 'is_accepted': True, 'score': 20, 'creation_date': 1552300741, 'answer_id': 55099970, 'question_id': 55094952, 'body': '<p>In the snippet you have posted, <a href=""https://www.tensorflow.org/api_docs/python/tf/control_dependencies"" rel=""noreferrer""><code>tf.control_dependencies</code></a> is not having any effect. The function creates a context where <strong>new operations</strong> are created with a control dependency to the given operations, but in your code there are no new operations within the context, just evaluation of previously existing operations.</p>\n\n<p>In most cases, control flow in TensorFlow is ""obvious"", in the sense that there is only one way to make a computation correctly. However, when stateful objects (i.e. variables) are involved, there are situations that may be ambiguous. Consider the following example:</p>\n\n<pre><code>import tensorflow as tf\n\nv1 = tf.Variable(0)\nv2 = tf.Variable(0)\nupd1 = tf.assign(v1, v2 + 1)\nupd2 = tf.assign(v2, v1 + 1)\ninit = tf.global_variables_initializer()\n</code></pre>\n\n<p><code>v1</code> and <code>v2</code> are both variables initialized to <code>0</code> and then updated. However, each use the value of the other variable in the update. In a regular Python program things would run sequentially, so <code>upd1</code> would run first (so <code>v1</code> would be <code>1</code>) and <code>upd2</code> after (so <code>v2</code> would be <code>2</code>, because <code>v1</code> was <code>1</code>). But TensorFlow does not record the order in which operations are created, only their dependencies. So it may also happen that <code>upd2</code> runs before <code>upd1</code> (so <code>v1</code> would be <code>2</code> and <code>v2</code> would be <code>1</code>) or that both update values (<code>v2 + 1</code> and <code>v1 + 1</code>) are computed before the assignments (so both <code>v1</code> and <code>v2</code> would be <code>1</code> in the end). Indeed, if I run it several times:</p>\n\n<pre><code>for i in range(10):\n    with tf.Session() as sess:\n        sess.run(init)\n        sess.run([upd1, upd2])\n        print(*sess.run([v1, v2]))\n</code></pre>\n\n<p>I do not always get the same result (personally I get <code>1 1</code> and <code>2 1</code>, although technically <code>1 2</code> would also be possible). If for example you wanted to compute the new value for <code>v2</code> after <code>v1</code> has been updated, you could just do the following:</p>\n\n<pre><code>import tensorflow as tf\n\nv1 = tf.Variable(0)\nv2 = tf.Variable(0)\nupd1 = tf.assign(v1, v2 + 1)\nupd2 = tf.assign(v2, upd1 + 1)\ninit = tf.global_variables_initializer()\n</code></pre>\n\n<p>Here the new value <code>v2</code> is computed using <code>upd1</code>, which is guaranteed to be the value of the variable after the update. So here <code>upd2</code> would have an implicit dependency to the assignment, and so things would work as expected.</p>\n\n<p>But what if you wanted to always compute the new values for <code>v1</code> and <code>v2</code> using the non-updated variable values (that is, consistently end up with both <code>v1</code> and <code>v2</code> being <code>1</code>)? In that case you can use <a href=""https://www.tensorflow.org/api_docs/python/tf/control_dependencies"" rel=""noreferrer""><code>tf.control_dependencies</code></a>:</p>\n\n<pre><code>import tensorflow as tf\n\nv1 = tf.Variable(0)\nv2 = tf.Variable(0)\nnew_v1 = v2 + 1\nnew_v2 = v1 + 1\nwith tf.control_dependencies([new_v1, new_v2]):\n    upd1 = tf.assign(v1, new_v1)\n    upd2 = tf.assign(v2, new_v2)\ninit = tf.global_variables_initializer()\n</code></pre>\n\n<p>Here, the assignment operations cannot happen until the new values for <code>v1</code> and <code>v2</code> have been computed, so their final values will always be <code>1</code> in both cases.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8991}"
993,42399401,"{'items': [{'owner': {'reputation': 57117, 'user_id': 419116}, 'down_vote_count': 1, 'up_vote_count': 13, 'is_accepted': False, 'score': 12, 'creation_date': 1487790434, 'answer_id': 42400196, 'question_id': 42399401, 'body': '<p>Edit: better clarification of notation is <a href=""https://medium.com/@yaroslavvb/backprop-and-systolic-arrays-24e925d2050"" rel=""noreferrer"">here</a></p>\n\n<p><code>ys</code> are summed up to make a single scalar <code>y</code>, and then <code>tf.gradients</code> computes <code>dy/dx</code> where <code>x</code> represents variables from <code>xs</code></p>\n\n<p><code>grad_ys</code> represent the ""starting"" backprop value. They are 1 by default, but a different value can be when you want to chain several <code>tf.gradients</code> calls together -- you can pass in the output of previous <code>tf.gradients</code> call into <code>grad_ys</code> to continue the backprop flow.</p>\n\n<p>For formal definition, look at the chained expression in Reverse Accumulation here: <a href=""https://en.wikipedia.org/wiki/Automatic_differentiation#Reverse_accumulation"" rel=""noreferrer"">https://en.wikipedia.org/wiki/Automatic_differentiation#Reverse_accumulation</a></p>\n\n<p>The term corresponding to <code>dy/dw3 * dw3/dw2</code> in TensorFlow is a vector of 1\'s (think of it as if TensorFlow wraps cost with a dummy identity op). When you specify <code>grad_ys</code> this term is replaced with <code>grad_ys</code> instead of vector of <code>1</code>s</p>\n\n<p><a href=""https://i.stack.imgur.com/Ej7E4.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Ej7E4.png"" alt=""enter image description here""></a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8991}"
994,56047272,"{'items': [{'owner': {'reputation': 13934, 'user_id': 2455494}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1557401851, 'answer_id': 56058558, 'question_id': 56047272, 'body': ""<blockquote>\n  <p>But then it would be unnecessary to explicitly type the 3.0 constant\n  above.</p>\n</blockquote>\n\n<p>Absolutely correct. </p>\n\n<pre><code>a = tf.constant(3.0, dtype=tf.float32)\n</code></pre>\n\n<p>is equivalent to:</p>\n\n<pre><code>a = tf.constant(3.0)\n</code></pre>\n\n<p>The documentation is just demonstrating the different overloads. We might choose to explicitly provide the type if we want a different numerical precision (or even just to aid human readability) but if you want the default data type TF infers, then it's entirely unnecessary.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8991}"
995,41559723,"{'items': [{'owner': {'reputation': 3991, 'user_id': 5915270}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1535522072, 'answer_id': 52070350, 'question_id': 41559723, 'body': '<p>According to tensorflow documentation, you have to change the filter shape. Here I will put how this fact has described in latest TF documentation 1.9.</p>\n\n<p>For the tf.nn.conv_2d the filter variable should be -  A 4-D tensor of <strong>shape [filter_height, filter_width, <em>in_channels, out_channels</em>]</strong></p>\n\n<p>For the tf.nn.conv_2d_transpose the filter variable should be -  A 4-D tensor of <strong>shape [filter_height, filter_width, <em>out_channels,in_channels</em>]</strong></p>\n\n<ul>\n<li>Here clearly we can see we need to change the change the shape with respect to out_channels</li>\n</ul>\n'}, {'owner': {'reputation': 829, 'user_id': 7345996}, 'down_vote_count': 1, 'up_vote_count': 3, 'is_accepted': False, 'score': 2, 'creation_date': 1484049001, 'answer_id': 41568172, 'question_id': 41559723, 'body': ""<p>We needn't to transpose the filter manually.In general, wo organize our code in the following way.</p>\n\n<pre><code>stride = [1,1,1,1]\nconv1W = tf.Variable(tf.random.normal[4,4,3,20])\nconv1 = tf.nn.conv2d(input, conv1W, strides=stride, padding='SAME')\nconv1 = tf.nn.relu(conv1)\n</code></pre>\n\n<p>Then, do the deconv process</p>\n\n<pre><code>deconv1 = tf.nn.conv2d_transpose(conv1, conv1W, output_shape=[batch_size,output_height, output_width, output_channels],strides=stride)\nres = tf.nn.relu(deconv1)\n</code></pre>\n\n<p>The <code>res</code> is the result of deconv process.</p>\n\n<p>In a word, the <code>filter</code> and <code>stride</code> using in deconv process is the same as the <code>filter</code> and <code>stride</code> using in conv process.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8991}"
996,61925035,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8987}"
997,50820781,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': True, 'score': 11, 'creation_date': 1528819258, 'answer_id': 50821422, 'question_id': 50820781, 'body': '<p><code>tf.stack</code> always adds a new dimension, and always concatenates the given tensor along that new dimension. In your case, you have three tensors with shape <code>[2]</code>. Setting <code>axis=0</code> is the same as adding a new first dimension, so each tensor would now have shape <code>[1, 2]</code>, and concatenating across that dimension, so the final shape would be <code>[3, 2]</code>. That is, each tensor would be a ""row"" of the final tensor. With <code>axis=1</code> the shapes of each individual tensor would be extended to <code>[2, 1]</code>, and the result would have shape <code>[2, 3]</code>. So each given tensor would be a ""column"" of the resulting tensor.</p>\n\n<p>In other words, <code>tf.stack</code> is functionally equivalent to this:</p>\n\n<pre><code>def tf.stack(tensors, axis=0):\n    return tf.concatenate([tf.expand_dims(t, axis=axis) for t in tensors], axis=axis)\n</code></pre>\n\n<p>But the result that you expect would be obtained with something like this:</p>\n\n<pre><code>tf.concatenate([tf.expand_dims(t, axis=0) for t in tensors], axis=1)\n</code></pre>\n\n<p>Note that the added dimension and the concatenation dimension are different in this case.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8987}"
998,50998956,"{'items': [{'owner': {'reputation': 1086, 'user_id': 9535747}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1529746243, 'answer_id': 50999823, 'question_id': 50998956, 'body': '<p>While the documentation on <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool"" rel=""nofollow noreferrer"">tf.nn.avg_pool</a> doesn\'t explicitly state whether it supports pooling over batch or channel dimensions, the documentation on <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/pool"" rel=""nofollow noreferrer"">tf.nn.pool</a> (which internally calls <code>tf.nn.avg_pool</code> if <code>pooling_type</code> is set to <code>\'AVG\'</code>) explicitly states:</p>\n\n<blockquote>\n  <p><code>input</code>: Tensor of rank N+2, of shape <code>[batch_size] + input_spatial_shape + [num_channels]</code> if data_format does not start with ""NC"" (default), or <code>[batch_size, num_channels] + input_spatial_shape</code> if data_format starts with ""NC"". Pooling happens <strong>over the spatial dimensions only</strong>.</p>\n</blockquote>\n\n<p>However, you can transpose your tensor of shape <code>[batch_size, height, width, num_channels]</code> to, say, <code>[batch_size, height, num_channels, width]</code>, perform the average pooling and then transpose it back to original form, like in the following example:</p>\n\n<pre><code>input_data = tf.Variable(tf.random_normal([2,16,16,200], mean=10, stddev=10))\n\n# compute mean over channels dimension using tf.reduce_mean\nmean = tf.reduce_mean(input_data, reduction_indices=[3], keep_dims=True)\n\n# transpose to [batch_size, height, num_channels, width]\ninput_t = tf.transpose(input_data, [0,1,3,2])\n\n# get the value of num_channels\nnum_channels = input_t.get_shape().as_list()[2]\n\n# compute mean using tf.nn.avg_pool\navg = tf.nn.avg_pool(value=input_t,\n                      ksize=[1, 1, num_channels, 1],\n                      strides=[1, 1, num_channels, 1],\n                      padding=""SAME"")\n\n# transpose back to original form\ninput_tt = tf.transpose(avg, [0,1,3,2])\n\nsess = tf. InteractiveSession()\nsess.run(tf.initialize_all_variables())\n\navg_value = input_tt.eval()\nprint(""Shape after avg_pool method: %s"" % str(avg_value.shape))\n# &gt;&gt;&gt; (2, 16, 16, 1)\n\nmean_value = mean.eval()\nprint(""Shape after reduce_mean method: %s"" % str(mean_value.shape))\n# &gt;&gt;&gt; (2, 16, 16, 1)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8987}"
999,58822319,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8987}"
1000,42462895,"{'items': [{'owner': {'reputation': 2866, 'user_id': 5708323}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1488317070, 'answer_id': 42519002, 'question_id': 42462895, 'body': '<p>If you look at the Inference Library on Android, you\'ll see how you can load and run graphs:\n<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorFlowImageClassifier.java#L151"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorFlowImageClassifier.java#L151</a></p>\n\n<p>Here is the definition for that library:\n<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/android/java/org/tensorflow/contrib/android/TensorFlowInferenceInterface.java"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/android/java/org/tensorflow/contrib/android/TensorFlowInferenceInterface.java</a></p>\n\n<p>Does that help?</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8983}"
1001,53634736,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8982}"
1002,68095664,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8982}"
1003,51824310,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1534251223, 'answer_id': 51841961, 'question_id': 51824310, 'body': '<h2>What variational dropout does</h2>\n\n<p>As far as I know, the main novelty of variational dropout is using the same dropout mask for all unrolled steps (as you said).</p>\n\n<h2>Difference between <code>output_keep_prob</code> and the <code>state_keep_prob</code></h2>\n\n<p><code>output_keep_prob</code> is the dropout rate applied to the output (h) of the LSTM cell where <code>state_keep_prob</code> is the dropout rate applied to the cell (c) of the LSTM state.</p>\n\n<h2>Dropout choice in Keras</h2>\n\n<p>Looking at the <code>_generate_dropout_mask</code> method in the <a href=""https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L2220-L2232"" rel=""nofollow noreferrer"">LSTM source code</a> and <a href=""https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L1855-L1868"" rel=""nofollow noreferrer"">its use for the LSTMCell</a> of Keras, I think Keras LSTM uses variational recurrent dropout only for the recurrent connections (i.e. <code>self._recurrent_dropout_mask</code>) . But I\'m not 100% confident about this.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8982}"
1004,38033079,"{'items': [{'owner': {'reputation': 232, 'user_id': 5530615}, 'down_vote_count': 1, 'up_vote_count': 3, 'is_accepted': True, 'score': 2, 'creation_date': 1467126064, 'answer_id': 38079760, 'question_id': 38033079, 'body': '<p>There is a little bit about the number of threads to use at</p>\n\n<p><a href=""https://www.tensorflow.org/versions/r0.9/how_tos/reading_data/index.html#batching"" rel=""nofollow"">https://www.tensorflow.org/versions/r0.9/how_tos/reading_data/index.html#batching</a></p>\n\n<p>Unfortunately, I don\'t think there is a simple answer for batch sizes.\nThe efficient batch size for a network depends on a lot of details\nabout the network. In practice, if you care about optimal performance\nyou\'re going to need to do a bunch of trial and error (maybe starting\nfrom the values used by a similar network).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8982}"
1005,34801342,"{'items': [{'owner': {'reputation': 16941, 'user_id': 8143158}, 'down_vote_count': 0, 'up_vote_count': 9, 'is_accepted': False, 'score': 9, 'creation_date': 1565693413, 'answer_id': 57476195, 'question_id': 34801342, 'body': '<p>tfa has been deprecated, one can use preprocessing layer <code>[RandomRotation][1]</code>:</p>\n<p><code>tf.keras.layers.RandomRotation(factor)</code></p>\n<blockquote>\n<p>factor=(-0.2, 0.3) results in an output rotation by a random amount in\nthe range [-20% * 2pi, 30% * 2pi]. factor=0.2 results in an output\nrotating by a random amount in the range [-20% * 2pi, 20% * 2pi]</p>\n</blockquote>\n<p>[OLD] for tensorflow 2.0:</p>\n<pre><code>import tensorflow_addons as tfa\ntfa.image.transform_ops.rotate(image, radian)\n</code></pre>\n'}, {'owner': {'reputation': 389, 'user_id': 2797108}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1627516014, 'answer_id': 68568525, 'question_id': 34801342, 'body': '<p><em><strong>tf.contrib</strong></em> is <strong>not</strong> available in tensorflow <strong>2</strong>.</p>\n<p>For tensorflow &gt;= 2.* the following can be used:</p>\n<pre><code>tf.keras.preprocessing.image.random_rotation(x, rg, row_axis=1,col_axis=2, channel_axis=0,fill_mode=\'nearest\', cval=0., interpolation_order=1);\n</code></pre>\n<p>you can find the documantation here:\n<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_rotation"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_rotation</a></p>\n'}, {'owner': {'reputation': 3380, 'user_id': 3766568}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1542713417, 'answer_id': 53392066, 'question_id': 34801342, 'body': '<p>For rotating an image or a batch of images counter-clockwise by multiples of 90 degrees, you can use <code>tf.image.rot90(image,k=1,name=None)</code>.</p>\n\n<p><code>k</code> denotes the number of 90 degrees rotations you want to make.</p>\n\n<p>In case of a single image, <code>image</code> is a <code>3-D Tensor of shape [height, width, channels]</code> and in case of a batch of images, <code>image</code> is a <code>4-D Tensor of shape [batch, height, width, channels]</code></p>\n'}, {'owner': {'reputation': 513, 'user_id': 6772741}, 'down_vote_count': 0, 'up_vote_count': 9, 'is_accepted': False, 'score': 9, 'creation_date': 1529315067, 'answer_id': 50906665, 'question_id': 34801342, 'body': '<h2>Rotation and cropping in TensorFlow</h2>\n\n<p>I personally needed image rotation and cropping out black borders functions in TensorFlow as below.\n<a href=""https://i.stack.imgur.com/Guj8U.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Guj8U.jpg"" alt=""Example""></a>\nAnd I could implement this function as below.</p>\n\n<pre><code>def _rotate_and_crop(image, output_height, output_width, rotation_degree, do_crop):\n    """"""Rotate the given image with the given rotation degree and crop for the black edges if necessary\n    Args:\n        image: A `Tensor` representing an image of arbitrary size.\n        output_height: The height of the image after preprocessing.\n        output_width: The width of the image after preprocessing.\n        rotation_degree: The degree of rotation on the image.\n        do_crop: Do cropping if it is True.\n    Returns:\n        A rotated image.\n    """"""\n\n    # Rotate the given image with the given rotation degree\n    if rotation_degree != 0:\n        image = tf.contrib.image.rotate(image, math.radians(rotation_degree), interpolation=\'BILINEAR\')\n\n        # Center crop to ommit black noise on the edges\n        if do_crop == True:\n            lrr_width, lrr_height = _largest_rotated_rect(output_height, output_width, math.radians(rotation_degree))\n            resized_image = tf.image.central_crop(image, float(lrr_height)/output_height)    \n            image = tf.image.resize_images(resized_image, [output_height, output_width], method=tf.image.ResizeMethod.BILINEAR, align_corners=False)\n\n    return image\n\ndef _largest_rotated_rect(w, h, angle):\n    """"""\n    Given a rectangle of size wxh that has been rotated by \'angle\' (in\n    radians), computes the width and height of the largest possible\n    axis-aligned rectangle within the rotated rectangle.\n    Original JS code by \'Andri\' and Magnus Hoff from Stack Overflow\n    Converted to Python by Aaron Snoswell\n    Source: http://stackoverflow.com/questions/16702966/rotate-image-and-crop-out-black-borders\n    """"""\n\n    quadrant = int(math.floor(angle / (math.pi / 2))) &amp; 3\n    sign_alpha = angle if ((quadrant &amp; 1) == 0) else math.pi - angle\n    alpha = (sign_alpha % math.pi + math.pi) % math.pi\n\n    bb_w = w * math.cos(alpha) + h * math.sin(alpha)\n    bb_h = w * math.sin(alpha) + h * math.cos(alpha)\n\n    gamma = math.atan2(bb_w, bb_w) if (w &lt; h) else math.atan2(bb_w, bb_w)\n\n    delta = math.pi - alpha - gamma\n\n    length = h if (w &lt; h) else w\n\n    d = length * math.cos(alpha)\n    a = d * math.sin(alpha) / math.sin(delta)\n\n    y = a * math.cos(gamma)\n    x = y * math.tan(gamma)\n\n    return (\n        bb_w - 2 * x,\n        bb_h - 2 * y\n    )\n</code></pre>\n\n<p>If you need further implementation of example and visualization in TensorFlow, you can use <a href=""https://github.com/kobiso/Image-Rotation-and-Cropping-tensorflow"" rel=""noreferrer"">this repository</a>.\nI hope this could be helpful to other people.</p>\n'}, {'owner': {'reputation': 11827, 'user_id': 1978504}, 'down_vote_count': 2, 'up_vote_count': 6, 'is_accepted': True, 'score': 4, 'creation_date': 1452869705, 'answer_id': 34813809, 'question_id': 34801342, 'body': ""<p><strong>Update</strong>: see @astromme's answer below. Tensorflow now supports rotating images natively.</p>\n\n<p>What you can do while there is no native method in tensorflow is something like this:</p>\n\n<pre><code>from PIL import Image\nsess = tf.InteractiveSession()\n\n# Pass image tensor object to a PIL image\nimage = Image.fromarray(image.eval())\n\n# Use PIL or other library of the sort to rotate\nrotated = Image.Image.rotate(image, degrees)\n\n# Convert rotated image back to tensor\nrotated_tensor = tf.convert_to_tensor(np.array(rotated))\n</code></pre>\n""}, {'owner': {'reputation': 2120, 'user_id': 1004331}, 'down_vote_count': 0, 'up_vote_count': 34, 'is_accepted': False, 'score': 34, 'creation_date': 1502646761, 'answer_id': 45663250, 'question_id': 34801342, 'body': '<p>This can be done in <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/image/rotate"" rel=""noreferrer"">tensorflow now</a>:</p>\n\n<pre><code>tf.contrib.image.rotate(images, degrees * math.pi / 180, interpolation=\'BILINEAR\')\n</code></pre>\n'}, {'owner': {'reputation': 27506, 'user_id': 407650}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1493937773, 'answer_id': 43793868, 'question_id': 34801342, 'body': '<p>Here\'s the <a href=""https://stackoverflow.com/a/40483687/407650"">@zimmermc</a> answer updated to Tensorflow v0.12</p>\n\n<p>Changes:</p>\n\n<ul>\n<li><code>pack()</code> is now <code>stack()</code></li>\n<li><p>order of <code>split</code> parameters reversed</p>\n\n<pre><code>def rotate_image_tensor(image, angle, mode=\'white\'):\n    """"""\n    Rotates a 3D tensor (HWD), which represents an image by given radian angle.\n\n    New image has the same size as the input image.\n\n    mode controls what happens to border pixels.\n    mode = \'black\' results in black bars (value 0 in unknown areas)\n    mode = \'white\' results in value 255 in unknown areas\n    mode = \'ones\' results in value 1 in unknown areas\n    mode = \'repeat\' keeps repeating the closest pixel known\n    """"""\n    s = image.get_shape().as_list()\n    assert len(s) == 3, ""Input needs to be 3D.""\n    assert (mode == \'repeat\') or (mode == \'black\') or (mode == \'white\') or (mode == \'ones\'), ""Unknown boundary mode.""\n    image_center = [np.floor(x/2) for x in s]\n\n    # Coordinates of new image\n    coord1 = tf.range(s[0])\n    coord2 = tf.range(s[1])\n\n    # Create vectors of those coordinates in order to vectorize the image\n    coord1_vec = tf.tile(coord1, [s[1]])\n\n    coord2_vec_unordered = tf.tile(coord2, [s[0]])\n    coord2_vec_unordered = tf.reshape(coord2_vec_unordered, [s[0], s[1]])\n    coord2_vec = tf.reshape(tf.transpose(coord2_vec_unordered, [1, 0]), [-1])\n\n    # center coordinates since rotation center is supposed to be in the image center\n    coord1_vec_centered = coord1_vec - image_center[0]\n    coord2_vec_centered = coord2_vec - image_center[1]\n\n    coord_new_centered = tf.cast(tf.stack([coord1_vec_centered, coord2_vec_centered]), tf.float32)\n\n    # Perform backward transformation of the image coordinates\n    rot_mat_inv = tf.dynamic_stitch([[0], [1], [2], [3]], [tf.cos(angle), tf.sin(angle), -tf.sin(angle), tf.cos(angle)])\n    rot_mat_inv = tf.reshape(rot_mat_inv, shape=[2, 2])\n    coord_old_centered = tf.matmul(rot_mat_inv, coord_new_centered)\n\n    # Find nearest neighbor in old image\n    coord1_old_nn = tf.cast(tf.round(coord_old_centered[0, :] + image_center[0]), tf.int32)\n    coord2_old_nn = tf.cast(tf.round(coord_old_centered[1, :] + image_center[1]), tf.int32)\n\n    # Clip values to stay inside image coordinates\n    if mode == \'repeat\':\n        coord_old1_clipped = tf.minimum(tf.maximum(coord1_old_nn, 0), s[0]-1)\n        coord_old2_clipped = tf.minimum(tf.maximum(coord2_old_nn, 0), s[1]-1)\n    else:\n        outside_ind1 = tf.logical_or(tf.greater(coord1_old_nn, s[0]-1), tf.less(coord1_old_nn, 0))\n        outside_ind2 = tf.logical_or(tf.greater(coord2_old_nn, s[1]-1), tf.less(coord2_old_nn, 0))\n        outside_ind = tf.logical_or(outside_ind1, outside_ind2)\n\n        coord_old1_clipped = tf.boolean_mask(coord1_old_nn, tf.logical_not(outside_ind))\n        coord_old2_clipped = tf.boolean_mask(coord2_old_nn, tf.logical_not(outside_ind))\n\n        coord1_vec = tf.boolean_mask(coord1_vec, tf.logical_not(outside_ind))\n        coord2_vec = tf.boolean_mask(coord2_vec, tf.logical_not(outside_ind))\n\n    coord_old_clipped = tf.cast(tf.transpose(tf.stack([coord_old1_clipped, coord_old2_clipped]), [1, 0]), tf.int32)\n\n    # Coordinates of the new image\n    coord_new = tf.transpose(tf.cast(tf.stack([coord1_vec, coord2_vec]), tf.int32), [1, 0])\n\n    image_channel_list = tf.split(image, s[2], 2)\n\n    image_rotated_channel_list = list()\n    for image_channel in image_channel_list:\n        image_chan_new_values = tf.gather_nd(tf.squeeze(image_channel), coord_old_clipped)\n\n        if (mode == \'black\') or (mode == \'repeat\'):\n            background_color = 0\n        elif mode == \'ones\':\n            background_color = 1\n        elif mode == \'white\':\n            background_color = 255\n\n        image_rotated_channel_list.append(tf.sparse_to_dense(coord_new, [s[0], s[1]], image_chan_new_values,\n                                                             background_color, validate_indices=False))\n\n    image_rotated = tf.transpose(tf.stack(image_rotated_channel_list), [1, 2, 0])\n\n    return image_rotated\n</code></pre></li>\n</ul>\n'}, {'owner': {'reputation': 623, 'user_id': 6375313}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': False, 'score': 11, 'creation_date': 1478598538, 'answer_id': 40483687, 'question_id': 34801342, 'body': '<p>Because I wanted to be able to rotate tensors I came up with the following piece of code, which rotates a [height, width, depth] tensor by a given angle:</p>\n\n<pre><code>def rotate_image_tensor(image, angle, mode=\'black\'):\n    """"""\n    Rotates a 3D tensor (HWD), which represents an image by given radian angle.\n\n    New image has the same size as the input image.\n\n    mode controls what happens to border pixels.\n    mode = \'black\' results in black bars (value 0 in unknown areas)\n    mode = \'white\' results in value 255 in unknown areas\n    mode = \'ones\' results in value 1 in unknown areas\n    mode = \'repeat\' keeps repeating the closest pixel known\n    """"""\n    s = image.get_shape().as_list()\n    assert len(s) == 3, ""Input needs to be 3D.""\n    assert (mode == \'repeat\') or (mode == \'black\') or (mode == \'white\') or (mode == \'ones\'), ""Unknown boundary mode.""\n    image_center = [np.floor(x/2) for x in s]\n\n    # Coordinates of new image\n    coord1 = tf.range(s[0])\n    coord2 = tf.range(s[1])\n\n    # Create vectors of those coordinates in order to vectorize the image\n    coord1_vec = tf.tile(coord1, [s[1]])\n\n    coord2_vec_unordered = tf.tile(coord2, [s[0]])\n    coord2_vec_unordered = tf.reshape(coord2_vec_unordered, [s[0], s[1]])\n    coord2_vec = tf.reshape(tf.transpose(coord2_vec_unordered, [1, 0]), [-1])\n\n    # center coordinates since rotation center is supposed to be in the image center\n    coord1_vec_centered = coord1_vec - image_center[0]\n    coord2_vec_centered = coord2_vec - image_center[1]\n\n    coord_new_centered = tf.cast(tf.pack([coord1_vec_centered, coord2_vec_centered]), tf.float32)\n\n    # Perform backward transformation of the image coordinates\n    rot_mat_inv = tf.dynamic_stitch([[0], [1], [2], [3]], [tf.cos(angle), tf.sin(angle), -tf.sin(angle), tf.cos(angle)])\n    rot_mat_inv = tf.reshape(rot_mat_inv, shape=[2, 2])\n    coord_old_centered = tf.matmul(rot_mat_inv, coord_new_centered)\n\n    # Find nearest neighbor in old image\n    coord1_old_nn = tf.cast(tf.round(coord_old_centered[0, :] + image_center[0]), tf.int32)\n    coord2_old_nn = tf.cast(tf.round(coord_old_centered[1, :] + image_center[1]), tf.int32)\n\n    # Clip values to stay inside image coordinates\n    if mode == \'repeat\':\n        coord_old1_clipped = tf.minimum(tf.maximum(coord1_old_nn, 0), s[0]-1)\n        coord_old2_clipped = tf.minimum(tf.maximum(coord2_old_nn, 0), s[1]-1)\n    else:\n        outside_ind1 = tf.logical_or(tf.greater(coord1_old_nn, s[0]-1), tf.less(coord1_old_nn, 0))\n        outside_ind2 = tf.logical_or(tf.greater(coord2_old_nn, s[1]-1), tf.less(coord2_old_nn, 0))\n        outside_ind = tf.logical_or(outside_ind1, outside_ind2)\n\n        coord_old1_clipped = tf.boolean_mask(coord1_old_nn, tf.logical_not(outside_ind))\n        coord_old2_clipped = tf.boolean_mask(coord2_old_nn, tf.logical_not(outside_ind))\n\n        coord1_vec = tf.boolean_mask(coord1_vec, tf.logical_not(outside_ind))\n        coord2_vec = tf.boolean_mask(coord2_vec, tf.logical_not(outside_ind))\n\n    coord_old_clipped = tf.cast(tf.transpose(tf.pack([coord_old1_clipped, coord_old2_clipped]), [1, 0]), tf.int32)\n\n    # Coordinates of the new image\n    coord_new = tf.transpose(tf.cast(tf.pack([coord1_vec, coord2_vec]), tf.int32), [1, 0])\n\n    image_channel_list = tf.split(2, s[2], image)\n\n    image_rotated_channel_list = list()\n    for image_channel in image_channel_list:\n        image_chan_new_values = tf.gather_nd(tf.squeeze(image_channel), coord_old_clipped)\n\n        if (mode == \'black\') or (mode == \'repeat\'):\n            background_color = 0\n        elif mode == \'ones\':\n            background_color = 1\n        elif mode == \'white\':\n            background_color = 255\n\n        image_rotated_channel_list.append(tf.sparse_to_dense(coord_new, [s[0], s[1]], image_chan_new_values,\n                                                             background_color, validate_indices=False))\n\n    image_rotated = tf.transpose(tf.pack(image_rotated_channel_list), [1, 2, 0])\n\n    return image_rotated\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8982}"
1006,74702527,"{'items': [{'owner': {'reputation': 16941, 'user_id': 8143158}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1670348349, 'answer_id': 74706883, 'question_id': 74702527, 'body': '<p>For the first step, you can reduce the loop into matrix operation by finding the closest match using <code>broadcasting</code>.</p>\n<pre><code>indices = tf.reduce_sum(tf.math.abs(D[:,None] - a), 2)     \n#numpy is_close\n\ntf.gather(D,tf.where(indices &lt; 1e-6)[:,0])\n</code></pre>\n<p>Example:</p>\n<pre><code>D = tf.random.normal(shape=(5,3))\na = tf.concat([tf.random.normal(shape=(2,3)), D[:2],], axis=0)\n\n#Here a last 2 rows of `a` are made same as first two rows of D.\n#D is array([[ 0.6221494 ,  0.39071774,  0.5728211 ],\n   [ 0.926828  ,  0.8460992 ,  0.08634651],\n   [-0.39511812, -0.02012417,  1.0490925 ],\n   [-0.31207308,  0.41652176,  0.85152763],\n   [-1.27271   , -0.09542792, -0.16090107]]\n#a is array([[ 0.9826471 ,  0.25055575, -0.4920534 ],\n   [-0.3222343 ,  0.91883016,  1.2904693 ],\n   [ 0.6221494 ,  0.39071774,  0.5728211 ],\n   [ 0.926828  ,  0.8460992 ,  0.08634651]]\n</code></pre>\n<p>numpy.is_close() operation</p>\n<pre><code>indices = tf.reduce_sum(tf.math.abs(D[:,None] - a), 2)  \n#this compares each row of D with each row of a. So we get a (5,4) matrix for the above example.\n</code></pre>\n<p>Gather D close to a:</p>\n<pre><code>tf.gather(D,tf.where(indices &lt; 1e-6)[:,0])\n#output\narray([[0.6221494 , 0.39071774, 0.5728211 ],\n       [0.926828  , 0.8460992 , 0.08634651]],\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8977}"
1007,57349824,"{'items': [{'owner': {'reputation': 425, 'user_id': 2710943}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1565021259, 'answer_id': 57362313, 'question_id': 57349824, 'body': '<p>So the answer is:</p>\n\n<pre><code>rnn_outputs, rnn_states  = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"", return_state=True, return_sequences=True)(X)\n</code></pre>\n\n<p>instead of </p>\n\n<pre><code>rnn_outputs = tf.keras.layers.RNN(cell,dtype=tf.float32, name=""hidden1"")(X)\n</code></pre>\n\n<p>so the parameter <code>return_sequences=True</code> make the RNN return the time series as well, and well, this is the point.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8977}"
1008,59408065,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1576755174, 'answer_id': 59408929, 'question_id': 59408065, 'body': ""<p>You're not assigning the dataset returned by <code>map</code> to anything. Simply do,</p>\n\n<pre><code>dataset = tf.data.Dataset.from_tensor_slices(myData)\ndataset = dataset.map(myFunc)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8977}"
1009,51691199,"{'items': [{'owner': {'reputation': 385600, 'user_id': 4909087}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1533441189, 'answer_id': 51691247, 'question_id': 51691199, 'body': '<p>The first 3 arguments are required. The first is the shape of the input tensor. The second is the split specification. The API currently supports splits along one dimension only. The split specification has the same number of dimensions as the shape, with one split being >= 1 and the others being 1. The last argument is the tensor itself, or a callable that returns it.</p>\n\n<p>First example:</p>\n\n<pre><code>tf.create_partitioned_variables(v.shape, [2, 1], v)\n</code></pre>\n\n<p>Second example:</p>\n\n<pre><code>[tf.squeeze(v) \n    for v in tf.create_partitioned_variables(\n        v.shape, [2, 1, 1], v)]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8977}"
1010,47658691,"{'items': [{'owner': {'reputation': 2281, 'user_id': 2047442}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1596704851, 'answer_id': 63280309, 'question_id': 47658691, 'body': '<p>In <code>tf 2.0</code> you can easily check that these ops are the same. The only difference that you may remove all axis with <code>dim == 1</code> without specifying them. So in the last line you may use <code>tf.squeeze(x_resh)</code> instead of <code>tf.squeeze(x_resh, [1, 2])</code>.</p>\n<pre><code>size = [2, 3]\ntf.random.set_seed(42)\nx = tf.random.normal(size)\nx\n&lt;tf.Tensor: shape=(2, 3), dtype=float32, numpy=\narray([[ 0.3274685, -0.8426258,  0.3194337],\n       [-1.4075519, -2.3880599, -1.0392479]], dtype=float32)&gt;\n\nx_resh = tf.reshape(x, [2, 1, 1, 3])\nx_resh\n&lt;tf.Tensor: shape=(2, 1, 1, 3), dtype=float32, numpy=\narray([[[[ 0.3274685, -0.8426258,  0.3194337]]],\n       [[[-1.4075519, -2.3880599, -1.0392479]]]], dtype=float32)&gt;\n\ntf.reshape(x_resh, [2, 3])\n&lt;tf.Tensor: shape=(2, 3), dtype=float32, numpy=\narray([[ 0.3274685, -0.8426258,  0.3194337],\n       [-1.4075519, -2.3880599, -1.0392479]], dtype=float32)&gt;\n\ntf.squeeze(x_resh, [1, 2])\n&lt;tf.Tensor: shape=(2, 3), dtype=float32, numpy=\narray([[ 0.3274685, -0.8426258,  0.3194337],\n       [-1.4075519, -2.3880599, -1.0392479]], dtype=float32)&gt;\n</code></pre>\n'}, {'owner': {'reputation': 5966, 'user_id': 1190882}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1512493436, 'answer_id': 47658937, 'question_id': 47658691, 'body': '<p>Why do you say <a href=""https://www.tensorflow.org/api_docs/python/tf/squeeze"" rel=""nofollow noreferrer"">tf.squeeze</a> is not supported? In order to remove 1 dimensional axis from tensor, <code>tf.squeeze</code> is the correct operation. But you can achieve your desired work with <code>tf.reshape</code> as well though I will suggest you to make use of <code>tf.squeeze</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8977}"
1011,45549251,"{'items': [{'owner': {'reputation': 766, 'user_id': 919431}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1502181517, 'answer_id': 45563400, 'question_id': 45549251, 'body': '<p>I found a solution to my problem using <a href=""https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook"" rel=""nofollow noreferrer""><code>tf.train.SessionRunHook</code></a>. I create a <code>SessionRunHook</code> object that initialises the iterator after the session is created:</p>\n\n<pre><code>class IteratorInitializerHook(tf.train.SessionRunHook):\n    def __init__(self):\n        super(IteratorInitializerHook, self).__init__()\n        self.iterator_initiliser_func = None\n\n    def after_create_session(self, session, coord):\n        self.iterator_initiliser_func(session)\n</code></pre>\n\n<p>The initializer function is set when creating the Dataset Iterator:</p>\n\n<pre><code>iterator_initiliser_hook.iterator_initiliser_func = \\\n    lambda sess: sess.run(\n        iterator.initializer,\n        feed_dict={images_placeholder: images,\n                   labels_placeholder: labels})\n</code></pre>\n\n<p>And I pass in the hook objects to <code>train_monitors</code> and <code>eval_hooks</code> parameters of <code>tf.contrib.learn.Experiment</code>.</p>\n\n<p>The resulting <code>graph.pbtxt</code> file is now only 500K while the <code>.meta</code> files are only 244K.</p>\n\n<p><a href=""https://gist.github.com/peterroelants/6a7b3cc802f7f855744e3a74a1fab354#file-mnist_new_dataset_hook-py"" rel=""nofollow noreferrer""><strong>Full example here.</strong></a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8972}"
1012,50945733,"{'items': [{'owner': {'reputation': 14819, 'user_id': 624547}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1529498507, 'answer_id': 50948546, 'question_id': 50945733, 'body': '<p>From <a href=""https://www.tensorflow.org/api_docs/python/tf/errors/OutOfRangeError"" rel=""nofollow noreferrer"">tf.errors.OutofRangeError</a> doc:</p>\n\n<blockquote>\n  <p>Raised when an operation iterates past the valid input range.</p>\n  \n  <p>This exception is raised in ""end-of-file"" conditions, such as when a\n  <code>tf.QueueBase.dequeue</code> operation is blocked on an empty queue, and a\n  <code>tf.QueueBase.close</code> operation executes.</p>\n</blockquote>\n\n<p>I.e. it is a normal, python-esque behavior. You are iterating over your queue until it\'s empty; and you know it is when the <code>OutofRangeError</code> is thrown.</p>\n\n<p>This also matches the behavior of normal python <code>Queue</code>:</p>\n\n<pre class=""lang-python prettyprint-override""><code>import Queue\n\nq = Queue.Queue()\ntry:\n    task=q.get(False)\n    # ...\nexcept Queue.Empty:\n    # Handle empty queue here\n    pass\n</code></pre>\n\n<p>You can find a small discussion here on the advantages of this try-catch concept: <a href=""https://stackoverflow.com/questions/11247439/python-queue-empty-exception-handling"">Python: Queue.Empty Exception Handling</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8972}"
1013,67344068,"{'items': [{'owner': {'reputation': 41, 'user_id': 16441304}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1626195583, 'answer_id': 68366591, 'question_id': 67344068, 'body': '<p>I dont think changing the values inside numpy arrays will generate a new graph. Consider the following minimal code exampls:</p>\n<pre><code>@tf.function \ndef test(input): \n  print(&quot;Tracing with input= &quot;, input)\n  tf.print(&quot;Executing with input = &quot;, input)\n</code></pre>\n<p>The first print is only executed during tracing, the second for every call. Calling it with a list leads to:</p>\n<pre><code>test([1,2])\ntest([3,4])\n&gt;&gt;&gt; Tracing with input =  [1, 2]\n&gt;&gt;&gt; Executing with input [1, 2]\n&gt;&gt;&gt; Tracing with input =  [3, 4]\n&gt;&gt;&gt; Executing with input [3, 4]\n</code></pre>\n<p>whereas calling it with numpy-arrays leads to:</p>\n<pre><code>test(np.array([1,2]))\ntest(np.array([3,4]))\n&gt;&gt;&gt; Tracing with input =  Tensor(&quot;input:0&quot;, shape=(2,), dtype=int32)\n&gt;&gt;&gt; Executing with input [1 2]\n&gt;&gt;&gt; Executing with input [3, 4]\n</code></pre>\n<p>Here no tracing is done for the second call. This suggests at least that numpy-arrays are handled the same way as tensorflow tensors.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8972}"
1014,46372554,"{'items': [{'owner': {'reputation': 1492, 'user_id': 8179854}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1506113005, 'answer_id': 46372916, 'question_id': 46372554, 'body': '<p>The <code>labels</code> and <code>C</code> were constants during the graph definition. Therefore, you don\'t need to feed them again when calling <code>sess.run()</code>. I just slightly changed the line to <code>one_hot = sess.run(one_hot_matrix1)</code> and it should work now.</p>\n\n<pre><code>def one_hot_matrix(labels, C):\n    """"""\n    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n                     will be 1. \n\n    Arguments:\n    labels -- vector containing the labels \n    C -- number of classes, the depth of the one hot dimension\n\n    Returns: \n    one_hot -- one hot matrix\n    """"""\n\n    ### START CODE HERE ###\n\n    # Create a tf.constant equal to C (depth), name it \'C\'. (approx. 1 line)\n    C = tf.constant(C, name=""C"")\n    #labels =tf.placeholder(labels, name=""labels"")\n\n    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n    one_hot_matrix1 = tf.one_hot(indices=labels, depth=C, axis=0)\n\n    # Create the session (approx. 1 line)\n    sess = tf.Session()\n\n    # Run the session (approx. 1 line)\n    one_hot = sess.run(one_hot_matrix1) #, feed_dict={labels:labels, C:C}\n\n    # Close the session (approx. 1 line). See method 1 above.\n    sess.close()\n\n    ### END CODE HERE ###\n\n    return one_hot\n</code></pre>\n\n<p>Run:</p>\n\n<pre><code>labels = np.array([1,2,3,0,2,1])\none_hot = one_hot_matrix(labels, C = 4)\nprint (""one_hot = "" + str(one_hot))\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>one_hot = [[ 0.  0.  0.  1.  0.  0.]\n [ 1.  0.  0.  0.  0.  1.]\n [ 0.  1.  0.  0.  1.  0.]\n [ 0.  0.  1.  0.  0.  0.]]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8972}"
1015,75482826,"{'items': [{'owner': {'reputation': 604, 'user_id': 17658327}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1676634303, 'answer_id': 75483884, 'question_id': 75482826, 'body': '<p><strong>Short answer:</strong></p>\n<blockquote>\n<p>Is this to make it as Leaky ReLU?</p>\n</blockquote>\n<p>Yes, the <code>negative_slope</code> parameter of <code>tf.keras.layers.ReLU</code> plays the same role as <code>alpha</code> does in <code>tf.keras.layers.LeakyReLU</code>. For example, <code>tf.keras.layers.ReLU(negative_slope=0.5)</code> and <code>tf.keras.layers.LeakyReLU(alpha=0.5)</code> have the same behavior.</p>\n<hr />\n<p>Here is a visualization of their behavior:</p>\n<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\nrelu=tf.keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\nrelu_neg_half=tf.keras.layers.ReLU(max_value=None, negative_slope=0.5, threshold=0.0)\nrelu_neg_1tenth=tf.keras.layers.ReLU(max_value=None, negative_slope=0.1, threshold=0.0)\nrelu_neg_1tenth_thresh_1=tf.keras.layers.ReLU(max_value=None, negative_slope=0.1, threshold=1.)\nrelu_neg_1tenth_thresh_2=tf.keras.layers.ReLU(max_value=None, negative_slope=0.1, threshold=2.)\n\nlrelu_alph_half=tf.keras.layers.LeakyReLU(alpha=0.5)\nlrelu_alph_1tenth=tf.keras.layers.LeakyReLU(alpha=0.1)\n\nx=np.linspace(-5,5,101)\n\nfig = plt.figure(figsize=(6,6), dpi=150)\nmarkevery=0.05\nplt.plot(x, relu(x), \'-o\', markevery=markevery, label=&quot;ReLU | negative_slope=0.0&quot;)\nplt.plot(x, relu_neg_half(x), \'--s\', markevery=markevery, label=&quot;ReLU | negative_slope=0.5&quot;)\nplt.plot(x, relu_neg_1tenth(x), \'--p\', markevery=markevery, label=&quot;ReLU | negative_slope=0.1&quot;)\nplt.plot(x, relu_neg_1tenth_thresh_2(x), \'--d\', markevery=markevery, label=&quot;ReLU | negative_slope=0.1 | threshold=2.0&quot;)\n\nplt.plot(x, lrelu_alph_half(x), \'--v\', markevery=markevery*1.2, label=&quot;LeakyReLU | alpha=0.5&quot;)\nplt.plot(x, lrelu_alph_1tenth(x), \'--^\', markevery=markevery*1.2, label=&quot;LeakyReLU | alpha=0.5&quot;)\n\nplt.legend(frameon=False)\nplt.savefig(\'relu.png\', bbox_inches=\'tight\')\n</code></pre>\n<p>Output:\n<a href=""https://i.stack.imgur.com/MpmVB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MpmVB.png"" alt=""enter image description here"" /></a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8968}"
1016,41789133,"{'items': [{'owner': {'reputation': 1, 'user_id': 8343303}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1500627220, 'answer_id': 45233303, 'question_id': 41789133, 'body': '<p><a href=""https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/rnn_cell_impl.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/ops/rnn_cell_impl.py</a></p>\n\n<p>Line #308 - 314</p>\n\n<p>class LSTMStateTuple(_LSTMStateTuple):\n  """"""Tuple used by LSTM Cells for <code>state_size</code>, <code>zero_state</code>, and output state.\n  Stores two elements: <code>(c, h)</code>, in that order.\n  Only used when <code>state_is_tuple=True</code>.\n  """"""</p>\n'}, {'owner': {'reputation': 78826, 'user_id': 395857}, 'down_vote_count': 0, 'up_vote_count': 21, 'is_accepted': False, 'score': 21, 'creation_date': 1487658766, 'answer_id': 42360236, 'question_id': 41789133, 'body': '<p>I agree that the documentation is unclear. Looking at <a href=""https://github.com/tensorflow/tensorflow/blob/66d5d1fa0c192ca4c9b75cde216866805eb160f2/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L291-L382"" rel=""noreferrer""><code>tf.nn.rnn_cell.LSTMCell.__call__</code></a> clarifies (I took the code from TensorFlow 1.0.0):</p>\n\n<pre><code>def __call__(self, inputs, state, scope=None):\n    """"""Run one step of LSTM.\n\n    Args:\n      inputs: input Tensor, 2D, batch x num_units.\n      state: if `state_is_tuple` is False, this must be a state Tensor,\n        `2-D, batch x state_size`.  If `state_is_tuple` is True, this must be a\n        tuple of state Tensors, both `2-D`, with column sizes `c_state` and\n        `m_state`.\n      scope: VariableScope for the created subgraph; defaults to ""lstm_cell"".\n\n    Returns:\n      A tuple containing:\n\n      - A `2-D, [batch x output_dim]`, Tensor representing the output of the\n        LSTM after reading `inputs` when previous state was `state`.\n        Here output_dim is:\n           num_proj if num_proj was set,\n           num_units otherwise.\n      - Tensor(s) representing the new state of LSTM after reading `inputs` when\n        the previous state was `state`.  Same type and shape(s) as `state`.\n\n    Raises:\n      ValueError: If input size cannot be inferred from inputs via\n        static shape inference.\n    """"""\n    num_proj = self._num_units if self._num_proj is None else self._num_proj\n\n    if self._state_is_tuple:\n      (c_prev, m_prev) = state\n    else:\n      c_prev = array_ops.slice(state, [0, 0], [-1, self._num_units])\n      m_prev = array_ops.slice(state, [0, self._num_units], [-1, num_proj])\n\n    dtype = inputs.dtype\n    input_size = inputs.get_shape().with_rank(2)[1]\n    if input_size.value is None:\n      raise ValueError(""Could not infer input size from inputs.get_shape()[-1]"")\n    with vs.variable_scope(scope or ""lstm_cell"",\n                           initializer=self._initializer) as unit_scope:\n      if self._num_unit_shards is not None:\n        unit_scope.set_partitioner(\n            partitioned_variables.fixed_size_partitioner(\n                self._num_unit_shards))\n      # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n      lstm_matrix = _linear([inputs, m_prev], 4 * self._num_units, bias=True,\n                            scope=scope)\n      i, j, f, o = array_ops.split(\n          value=lstm_matrix, num_or_size_splits=4, axis=1)\n\n      # Diagonal connections\n      if self._use_peepholes:\n        with vs.variable_scope(unit_scope) as projection_scope:\n          if self._num_unit_shards is not None:\n            projection_scope.set_partitioner(None)\n          w_f_diag = vs.get_variable(\n              ""w_f_diag"", shape=[self._num_units], dtype=dtype)\n          w_i_diag = vs.get_variable(\n              ""w_i_diag"", shape=[self._num_units], dtype=dtype)\n          w_o_diag = vs.get_variable(\n              ""w_o_diag"", shape=[self._num_units], dtype=dtype)\n\n      if self._use_peepholes:\n        c = (sigmoid(f + self._forget_bias + w_f_diag * c_prev) * c_prev +\n             sigmoid(i + w_i_diag * c_prev) * self._activation(j))\n      else:\n        c = (sigmoid(f + self._forget_bias) * c_prev + sigmoid(i) *\n             self._activation(j))\n\n      if self._cell_clip is not None:\n        # pylint: disable=invalid-unary-operand-type\n        c = clip_ops.clip_by_value(c, -self._cell_clip, self._cell_clip)\n        # pylint: enable=invalid-unary-operand-type\n\n      if self._use_peepholes:\n        m = sigmoid(o + w_o_diag * c) * self._activation(c)\n      else:\n        m = sigmoid(o) * self._activation(c)\n\n      if self._num_proj is not None:\n        with vs.variable_scope(""projection"") as proj_scope:\n          if self._num_proj_shards is not None:\n            proj_scope.set_partitioner(\n                partitioned_variables.fixed_size_partitioner(\n                    self._num_proj_shards))\n          m = _linear(m, self._num_proj, bias=False, scope=scope)\n\n        if self._proj_clip is not None:\n          # pylint: disable=invalid-unary-operand-type\n          m = clip_ops.clip_by_value(m, -self._proj_clip, self._proj_clip)\n          # pylint: enable=invalid-unary-operand-type\n\n    new_state = (LSTMStateTuple(c, m) if self._state_is_tuple else\n                 array_ops.concat([c, m], 1))\n    return m, new_state\n</code></pre>\n\n<p>The key lines are:</p>\n\n<pre><code>c = (sigmoid(f + self._forget_bias) * c_prev + sigmoid(i) *\n         self._activation(j))\n</code></pre>\n\n<p>and </p>\n\n<pre><code>m = sigmoid(o) * self._activation(c)\n</code></pre>\n\n<p>and </p>\n\n<pre><code>new_state = (LSTMStateTuple(c, m) \n</code></pre>\n\n<p>If you compare the  code to compute <code>c</code> and <code>m</code> with the LSTM equations (see below), you can see it corresponds to the cell state (typically denoted with <code>c</code>) and hidden state (typically denoted with <code>h</code>), respectively:</p>\n\n<p><a href=""https://i.stack.imgur.com/fFh9H.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/fFh9H.png"" alt=""enter image description here""></a></p>\n\n<p><code>new_state = (LSTMStateTuple(c, m)</code> indicates that the first element of the returned state tuple is <code>c</code> (cell state a.k.a. <code>c_state</code>), and the second element of the returned state tuple is <code>m</code> (hidden state a.k.a. <code>m_state</code>).</p>\n'}, {'owner': {'reputation': 2429, 'user_id': 2283175}, 'down_vote_count': 0, 'up_vote_count': 14, 'is_accepted': True, 'score': 14, 'creation_date': 1485744772, 'answer_id': 41928428, 'question_id': 41789133, 'body': '<p>I\'ve stumbled upon same question, here\'s how I understand it! Minimalistic LSTM example:</p>\n\n<pre><code>import tensorflow as tf\n\nsample_input = tf.constant([[1,2,3]],dtype=tf.float32)\n\nLSTM_CELL_SIZE = 2\n\nlstm_cell = tf.nn.rnn_cell.BasicLSTMCell(LSTM_CELL_SIZE, state_is_tuple=True)\nstate = (tf.zeros([1,LSTM_CELL_SIZE]),)*2\n\noutput, state_new = lstm_cell(sample_input, state)\n\ninit_op = tf.global_variables_initializer()\n\nsess = tf.Session()\nsess.run(init_op)\nprint sess.run(output)\n</code></pre>\n\n<p>Notice that <code>state_is_tuple=True</code> so when passing <code>state</code> to this <code>cell</code>, it needs to be in the <code>tuple</code> form. <code>c_state</code> and <code>m_state</code> are probably ""Memory State"" and ""Cell State"", though I honestly am NOT sure, as these terms are only mentioned in the docs. In the code and papers about <code>LSTM</code> - letters <code>h</code> and <code>c</code> are commonly used to denote ""output value"" and ""cell state"".\n<a href=""http://colah.github.io/posts/2015-08-Understanding-LSTMs/"" rel=""noreferrer"">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a>\nThose tensors represent combined internal state of the cell, and should be passed together. Old way to do it was to simply concatenate them, and new way is to use tuples.</p>\n\n<p>OLD WAY:</p>\n\n<pre><code>lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(LSTM_CELL_SIZE, state_is_tuple=False)\nstate = tf.zeros([1,LSTM_CELL_SIZE*2])\n\noutput, state_new = lstm_cell(sample_input, state)\n</code></pre>\n\n<p>NEW WAY:</p>\n\n<pre><code>lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(LSTM_CELL_SIZE, state_is_tuple=True)\nstate = (tf.zeros([1,LSTM_CELL_SIZE]),)*2\n\noutput, state_new = lstm_cell(sample_input, state)\n</code></pre>\n\n<p>So, basically all we did, is changed <code>state</code> from being 1 tensor of length <code>4</code> into two tensors of length <code>2</code>. The content remained the same. <code>[0,0,0,0]</code> becomes <code>([0,0],[0,0])</code>. (This is supposed to make it faster)</p>\n'}, {'owner': {'reputation': 21, 'user_id': 2904506}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1485123128, 'answer_id': 41796717, 'question_id': 41789133, 'body': '<p>Maybe this excerpt from the code will help</p>\n\n<pre><code>def __call__(self, inputs, state, scope=None):\n  """"""Long short-term memory cell (LSTM).""""""\n  with vs.variable_scope(scope or type(self).__name__):  # ""BasicLSTMCell""\n    # Parameters of gates are concatenated into one multiply for efficiency.\n    if self._state_is_tuple:\n      c, h = state\n    else:\n      c, h = array_ops.split(1, 2, state)\n    concat = _linear([inputs, h], 4 * self._num_units, True)\n\n    # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n    i, j, f, o = array_ops.split(1, 4, concat)\n\n    new_c = (c * sigmoid(f + self._forget_bias) + sigmoid(i) *\n             self._activation(j))\n    new_h = self._activation(new_c) * sigmoid(o)\n\n    if self._state_is_tuple:\n      new_state = LSTMStateTuple(new_c, new_h)\n    else:\n      new_state = array_ops.concat(1, [new_c, new_h])\n    return new_h, new_state\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8968}"
1017,73328337,"{'items': [{'owner': {'reputation': 77, 'user_id': 6620870}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1660328757, 'answer_id': 73338373, 'question_id': 73328337, 'body': '<p>Im have a very similar problem with Post Training Quantization and asked about it on <a href=""https://github.com/tensorflow/model-optimization/issues/1002"" rel=""nofollow noreferrer"">GitHub</a></p>\n<p>I could manage to get results from the TFLite model but they were not good enough. <a href=""https://colab.research.google.com/drive/1XuWniYM6q_0Uffp6SqSC5GUoS4Bd78RM?usp=sharing"" rel=""nofollow noreferrer"">Here</a> is the notebook how I did it. Maybe it helps you to get a step forward.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8968}"
1018,67847893,"{'items': [{'owner': {'reputation': 4843, 'user_id': 13726668}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1622890189, 'answer_id': 67848775, 'question_id': 67847893, 'body': '<p>The line in the tutorial:</p>\n<blockquote>\n<p>You can call the function on one skip-grams\'s target word and pass the\ncontext word as a true class to exclude it from being sampled</p>\n</blockquote>\n<p>That\'s misleading.</p>\n<blockquote>\n<p>What does true_classes mean in this function?</p>\n</blockquote>\n<p>Function returns <code>true_expected_count</code> which is defined in this <a href=""https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/ops/candidate_sampling_ops.py#L180"" rel=""nofollow noreferrer"">line of the source code.</a>.</p>\n<p><code>true_classes</code> seems only used to calculate <code>true_expected_count</code>. So this function <strong>does not exclude</strong> negative classes. Every label has a probability to get sampled.</p>\n<p>I copy an example code that can be experimented on (in case something happens to the link), <a href=""https://github.com/tensorflow/tensorflow/issues/44758#issuecomment-828114423"" rel=""nofollow noreferrer"">taken from this GitHub issue</a>:</p>\n<pre><code># Do sampling 1000 times using true_classes [0, 8]\nsample_func = lambda ii: tf.random.log_uniform_candidate_sampler(true_classes=[[ii]], num_true=1, num_sampled=4, unique=True, range_max=8, seed=42)\ndd = {ii : np.stack([sample_func(ii)[0].numpy() for jj in range(1000)]) for ii in range(8)}\n# Calculate the distribution in each true_class\nfor ii in dd:\n    print(&quot;true_class:&quot;, ii, &quot;, negative value_counts:&quot;, pd.value_counts(dd[ii].flatten()).to_dict())\n# true_class: 0 , negative value_counts: {0: 871, 1: 722, 2: 584, 3: 466, 4: 402, 5: 329, 7: 319, 6: 307}\n# true_class: 1 , negative value_counts: {0: 867, 1: 695, 2: 571, 3: 485, 4: 411, 5: 380, 6: 316, 7: 275}\n# true_class: 2 , negative value_counts: {0: 869, 1: 716, 2: 541, 3: 488, 4: 389, 5: 357, 6: 321, 7: 319}\n# true_class: 3 , negative value_counts: {0: 877, 1: 715, 2: 582, 3: 482, 4: 394, 5: 355, 6: 318, 7: 277}\n# true_class: 4 , negative value_counts: {0: 883, 1: 716, 2: 566, 3: 489, 4: 394, 5: 367, 6: 316, 7: 269}\n# true_class: 5 , negative value_counts: {0: 862, 1: 717, 2: 583, 3: 496, 4: 376, 5: 357, 6: 315, 7: 294}\n# true_class: 6 , negative value_counts: {0: 859, 1: 725, 2: 575, 3: 482, 4: 413, 5: 356, 6: 302, 7: 288}\n# true_class: 7 , negative value_counts: {0: 880, 1: 724, 2: 555, 3: 488, 4: 425, 5: 324, 7: 302, 6: 302}\n\n# Result of `true_expected_count`\nprint({ii : np.mean([sample_func(ii)[1].numpy() for jj in range(1000)]) for ii in range(8)})\n# {0: 0.99967235, 1: 0.7245632, 2: 0.5737029, 3: 0.47004792, 4: 0.3987442, 5: 0.34728608, 6: 0.3084587, 7: 0.27554017}\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8968}"
1019,55764694,"{'items': [{'owner': {'reputation': 480, 'user_id': 11524628}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1596105600, 'answer_id': 63171424, 'question_id': 55764694, 'body': '<p>In addition to <a href=""https://stackoverflow.com/users/3574081/mrry"">mrry</a>\'s answer, there are two points I would like to add:</p>\n<h3>(1) In TF 2, we can use tf.GradientTape without building a graph, like this:</h3>\n<pre><code>@tf.custom_gradient\ndef custom_square(x):\n  def grad(dy):\n    return tf.constant(0.0)\n  return tf.square(x), grad\n\nwith tf.GradientTape() as tape:\n  x = tf.Variable(5.0)\n  s_2 = custom_square(x)\n\nprint(tape.gradient(s_2,x).numpy())\n</code></pre>\n<h3>(2) Multiply your <code>custom grad</code> with the previous grad</h3>\n<p>Be careful, gradient calculation is a chained computation, we should multiply our custom grad by <code>dy</code> (the previously computed gradient).\nWithout doing this, our customized function will be broken in a chain calculation. This is an example:</p>\n<pre><code>@tf.custom_gradient\ndef custom_square(x):\n  def grad(dy):\n    return tf.constant(4.0)\n  return tf.square(x), grad\n\nwith tf.GradientTape(persistent=True) as tape:\n  x = tf.Variable(5.0)\n  s_2 = custom_square(x)\n  s_4 = custom_square(s_2)\n\nprint(&quot;Grad from s_4 to x: &quot;,tape.gradient(s_4,x).numpy())\nprint(&quot;Grad from s_4 to s_2: &quot;,tape.gradient(s_4,s_2).numpy())\nprint(&quot;Grad from s_2 to x: &quot;,tape.gradient(s_2,x).numpy())\n</code></pre>\n<p>The result:</p>\n<pre><code>Grad from s_4 to x:  4.0\nGrad from s_4 to s_2:  4.0\nGrad from s_2 to x:  4.0\n</code></pre>\n<p>Grad from <code>s_4</code> to <code>x</code> should be 16 (accumulated grad from <code>s_4</code> to <code>s_2</code> and grad frm <code>s_2</code> to <code>x</code>).</p>\n<p><img src=""https://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cdelta&space;s4%7D%7B%5Cdelta&space;x%7D=%5Cfrac%7B%5Cdelta&space;s4%7D%7B%5Cdelta&space;s2%7D*%5Cfrac%7B%5Cdelta&space;s2%7D%7B%5Cdelta&space;x%7D=4*4=16"" title=""\\frac{\\delta s4}{\\delta x}=\\frac{\\delta s4}{\\delta s2}*\\frac{\\delta s2}{\\delta x}=4*4=16"" /></p>\n<p>but the result was 4. That mean it didn\'t accumulate gradient from previous step.</p>\n<p>Multiply the custom grad with <code>dy</code>will solve the problem:</p>\n<pre><code>@tf.custom_gradient\ndef custom_square(x):\n  def grad(dy):\n    return tf.constant(4.0)*dy\n  return tf.square(x), grad\n\nwith tf.GradientTape(persistent=True) as tape:\n  x = tf.Variable(5.0)\n  s_2 = custom_square(x)\n  s_4 = custom_square(s_2)\n\nprint(&quot;Grad from s_4 to x: &quot;,tape.gradient(s_4,x).numpy())\nprint(&quot;Grad from s_4 to s_2: &quot;,tape.gradient(s_4,s_2).numpy())\nprint(&quot;Grad from s_2 to x: &quot;,tape.gradient(s_2,x).numpy())\n</code></pre>\n<p>Here is the result:</p>\n<pre><code>Grad from s_4 to x:  16.0\nGrad from s_4 to s_2:  4.0\nGrad from s_2 to x:  4.0\n</code></pre>\n<p>You can try the implementation through Colab here: <a href=""https://colab.research.google.com/drive/1gbLopOLJiyznDA-Cr473bZEeWkWh_KGG?usp=sharing"" rel=""nofollow noreferrer"">https://colab.research.google.com/drive/1gbLopOLJiyznDA-Cr473bZEeWkWh_KGG?usp=sharing</a></p>\n'}, {'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': True, 'score': 8, 'creation_date': 1555958373, 'answer_id': 55799378, 'question_id': 55764694, 'body': '<p>There is no built-in mechanism in TensorFlow 2.0 to override all gradients for a built-in operator within a scope. However, if you are able to modify the call-site for each call to the built-in operator, you can use the <code>tf.custom_gradient</code> decorator as follows:</p>\n\n<pre><code>@tf.custom_gradient\ndef custom_square(x):\n  def grad(dy):\n    return tf.constant(0.0)\n  return tf.square(x), grad\n\nwith tf.Graph().as_default() as g:\n  x = tf.Variable(5.0)\n  with tf.GradientTape() as tape:\n    s_2 = custom_square(x)\n\n  with tf.compat.v1.Session() as sess:\n    sess.run(tf.compat.v1.global_variables_initializer())            \n    print(sess.run(tape.gradient(s_2, x)))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8968}"
1020,71149271,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1645088114, 'answer_id': 71154993, 'question_id': 71149271, 'body': ""<p>You can remove features by only filtering the features that you want. This how you can modify only one feature:</p>\n<pre><code>import tensorflow as tf\nimport pandas as pd\n\ndf = pd.DataFrame(data={'color': ['red', 'blue','green'], 'price': [120, 80, 90], 'weight': [3.2, 4.0, 5]})\ndf.to_csv('data.csv', index=False)\n\ndataset = tf.data.experimental.make_csv_dataset('/content/data.csv', batch_size=1, num_epochs = 1, shuffle=False)\ndataset = dataset.map(lambda x: (x['color'], x['price'], x['weight']+2))\n\nfor x in dataset:\n  print(x[0], x[1], x[2])\n</code></pre>\n<pre><code>tf.Tensor([b'red'], shape=(1,), dtype=string) tf.Tensor([120], shape=(1,), dtype=int32) tf.Tensor([5.2], shape=(1,), dtype=float32)\ntf.Tensor([b'blue'], shape=(1,), dtype=string) tf.Tensor([80], shape=(1,), dtype=int32) tf.Tensor([6.], shape=(1,), dtype=float32)\ntf.Tensor([b'green'], shape=(1,), dtype=string) tf.Tensor([90], shape=(1,), dtype=int32) tf.Tensor([7.], shape=(1,), dtype=float32)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8963}"
1021,66287320,"{'items': [{'owner': {'reputation': 43, 'user_id': 12038028}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1625642171, 'answer_id': 68281606, 'question_id': 66287320, 'body': '<p>I was wondering about this as well. Turns out that -2 is <code>tf.data.UNKNOWN_CARDINALITY</code> (<a href=""https://www.tensorflow.org/api_docs/python/tf/data#UNKNOWN_CARDINALITY"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/data#UNKNOWN_CARDINALITY</a>), which represents that TF doesn\'t know how many elements the <code>flat_map</code> returns per item.</p>\n<p>I just asked <a href=""https://stackoverflow.com/questions/68281714/windowing-a-tensorflow-dataset-without-losing-cardinality-information"">Windowing a TensorFlow dataset without losing cardinality information?</a> to see if anyone knows a way to window datasets without losing cardinality.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8963}"
1022,52938457,"{'items': [{'owner': {'reputation': 1853, 'user_id': 3532564}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1540261685, 'answer_id': 52940303, 'question_id': 52938457, 'body': ""<p>When doing </p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ntf.reset_default_graph()\nwith tf.Session() as sess:\n    y1 = tf.stack([55, 0, 55])\n    y2 = tf.stack([11, 22, 44])\n    y3 = tf.constant([0, 0, 1])\n\n    x_tmp = tf.stack([y1, y2, y3])\n    x1 = tf.reshape(x, [3, 3])\n\n    x_res, x1_res = sess.run([x, x1])\n\n\n    print(x_res)\n    print(x1_res)\n</code></pre>\n\n<p>It seems to print out </p>\n\n<pre><code>[[55  0 55]\n [11 22 44]\n [ 0  0  1]]\n[[55  0 55]\n [11 22 44]\n [ 0  0  1]]\n</code></pre>\n\n<p>just fine? Perhaps I'm misunderstanding the question</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8963}"
1023,66385626,"{'items': [{'owner': {'reputation': 362, 'user_id': 11744909}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1614345023, 'answer_id': 66386415, 'question_id': 66385626, 'body': '<p>Actually, you are not using NLTK libraries during inferencing from the saved model.</p>\n<p>Your model only needs text as vectors to work, that are handled by the <em>vectorize_layer</em> in your code. if you want to preprocess your text before inferencing you should import libraries and preprocess it.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8960}"
1024,57134808,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8960}"
1025,61136605,"{'items': [{'owner': {'reputation': 43, 'user_id': 10796214}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1591862267, 'answer_id': 62319650, 'question_id': 61136605, 'body': ""<p>I figure it because i didn't save the transformer model in the pb file</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8960}"
1026,59432671,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8960}"
1027,59729634,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1589985980, 'answer_id': 61916049, 'question_id': 59729634, 'body': ""<p>Since you have already mentioned the answer, providing the explanation and code details below for the community.  </p>\n\n<p>For TensorFlow 2 you need to use GradientTape to compute gradients of loss for input.  </p>\n\n<p>Here is the explanation of how GradientTape works.  </p>\n\n<p>Let's create some sample toy function.  </p>\n\n<pre><code>def f(w1, w2):\n    return 3 * w1 ** 2 + 2 * w1 * w2  \n</code></pre>\n\n<p>Define w1, w2, and compute gradients. </p>\n\n<pre><code>w1, w2 = tf.Variable(5.), tf.Variable(3.)\nwith tf.GradientTape() as tape:\n    z = f(w1, w2)\n\ngradients = tape.gradient(z, [w1, w2])  \n</code></pre>\n\n<p><strong>Output gradients:</strong> </p>\n\n<pre><code>[&lt;tf.Tensor: shape=(), dtype=float32, numpy=36.0&gt;,\n &lt;tf.Tensor: shape=(), dtype=float32, numpy=10.0&gt;] \n</code></pre>\n\n<p>Now, let's see how the GradientTape works with <code>tf.constant</code> as Input instead of <code>tf.Variable</code>.  </p>\n\n<pre><code>c1, c2 = tf.constant(5.), tf.constant(3.)\nwith tf.GradientTape() as tape:\n    z = f(c1, c2)\n\ngradients = tape.gradient(z, [c1, c2])  \n</code></pre>\n\n<p><strong>Output for gradients will be.</strong>  </p>\n\n<pre><code>[None, None]  \n</code></pre>\n\n<p>By default, the tape will only track operations involving variables, so if\nyou try to compute the gradient of z with regard to anything other than a\nvariable, the result will be None.  </p>\n\n<p>This will be the same case with inputs also Since the inputs are not variables, you would need to tell the tape to <strong>watch</strong> them.  </p>\n\n<p>You can force the tape to watch any tensors you like, to record\nevery operation that involves them. You can then compute gradients with\nregard to these tensors as if they were variables.  </p>\n\n<p><strong>GradientTape with watch:</strong>  </p>\n\n<pre><code>with tf.GradientTape() as tape:\n    tape.watch(c1)\n    tape.watch(c2)\n    z = f(c1, c2)\n\ngradients = tape.gradient(z, [c1, c2])  \n</code></pre>\n\n<p>You can see the output gradients now:  </p>\n\n<pre><code>[&lt;tf.Tensor: shape=(), dtype=float32, numpy=36.0&gt;,\n &lt;tf.Tensor: shape=(), dtype=float32, numpy=10.0&gt;]\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8960}"
1028,70424291,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1640015809, 'answer_id': 70424516, 'question_id': 70424291, 'body': '<p>Try <code>tf.stack</code> with <code>tf.gather_nd</code>:</p>\n<pre class=""lang-py prettyprint-override""><code>z = tf.gather_nd(t_arr, tf.stack([t_r, t_c], axis=1))\n</code></pre>\n<pre><code>tf.Tensor([ 517  517 1876 1876 2138 2138 3103 3103 3482 3482 1802 1802], shape=(12,), dtype=int32)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8955}"
1029,61245158,"{'items': [{'owner': {'reputation': 1166, 'user_id': 3595278}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1587024882, 'answer_id': 61245606, 'question_id': 61245158, 'body': ""<p>You should parse the example first, and batch second:</p>\n\n<pre><code>data = data.map(parse_example).batch(1)\n</code></pre>\n\n<p>Otherwise the dimensions don't match for your parser.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8955}"
1030,66514664,"{'items': [{'owner': {'reputation': 23445, 'user_id': 1735003}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1615496300, 'answer_id': 66590458, 'question_id': 66514664, 'body': '<p>Is this the old fashioned way that you are looking after?</p>\n<pre><code>with tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    sess.run(sr)\n</code></pre>\n'}, {'owner': {'reputation': 9205, 'user_id': 5230735}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1615299134, 'answer_id': 66548520, 'question_id': 66514664, 'body': '<p>To create an numpy array from a tensorflow tensor  you can use `make_ndarray\' : <a href=""https://www.tensorflow.org/api_docs/python/tf/make_ndarray"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/make_ndarray</a></p>\n<p><code>make_ndarray</code> takes proto tensor as argument so you have to convert the tensor into a proto tensor first</p>\n<p><code>proto_tensor = tf.make_tensor_proto(a)  # convert tensor a to a proto tensor</code></p>\n<p>( <a href=""https://www.geeksforgeeks.org/tensorflow-how-to-create-a-tensorproto/"" rel=""nofollow noreferrer"">https://www.geeksforgeeks.org/tensorflow-how-to-create-a-tensorproto/</a> )</p>\n<p><a href=""https://stackoverflow.com/questions/34097281/convert-a-tensor-to-numpy-array-in-tensorflow"">Convert a tensor to numpy array in Tensorflow?</a></p>\n<p>the tensor has to be if shape <code>(img_height, img_width, 3)</code>, the <code>3</code> if you want to generate an RGB image (3 channels), see the following code to convert an numpy aaray to an image using <code>PIL</code></p>\n<p>To generate an image from the numpy array then you can use <code>PIL</code> (Python Imaging Library) : <a href=""https://stackoverflow.com/questions/2659312/how-do-i-convert-a-numpy-array-to-and-display-an-image"">How do I convert a numpy array to (and display) an image?</a></p>\n<pre><code>from PIL import Image\nimport numpy as np\nimg_w, img_h = 200, 200\ndata = np.zeros((img_h, img_w, 3), dtype=np.uint8)  &lt;- zero np_array depth 3 for RGB\ndata[100, 100] = [255, 0, 0]    &lt;- fille array with 255,0,0 in RGB\nimg = Image.fromarray(data, \'RGB\')    &lt;- array to image (all black then)\nimg.save(\'test.png\')\nimg.show()\n</code></pre>\n<p>source : <a href=""https://www.w3resource.com/python-exercises/numpy/python-numpy-exercise-109.php"" rel=""nofollow noreferrer"">https://www.w3resource.com/python-exercises/numpy/python-numpy-exercise-109.php</a></p>\n'}, {'owner': {'reputation': 34678, 'user_id': 10908375}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1615299565, 'answer_id': 66548666, 'question_id': 66514664, 'body': '<p>If you execute eagerly it works:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport tensorflow_hub as hub\n\nmodel = hub.load(&quot;https://tfhub.dev/captain-pool/esrgan-tf2/1&quot;)\n\nx = np.random.rand(1, 224, 224, 3).astype(np.float32)\n\nimage = model(x)\n</code></pre>\n<p>Then you can use <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/save_img"" rel=""nofollow noreferrer""><code>tf.keras.preprocessing.image.save_img</code></a> to save the resulting image. You may have to multiply the result by <code>255</code> and convert to <code>np.uint8</code> for that function to work, I\'m not sure.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8955}"
1031,42049256,"{'items': [{'owner': {'reputation': 5778, 'user_id': 6824418}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1486407186, 'answer_id': 42075126, 'question_id': 42049256, 'body': '<p>As far as your first paragraph goes: the answer is that each step in your input pipeline should have enough bandwidth to feed the model (and probably not too much more). You can easily run into bottlenecks if e.g. moving from one queue to another is fast but not enough data is being fed to the first queue (because of I/O issues, for example). You could also imagine having huge numbers of parallel readers and plenty of I/O bandwidth but only a single thread responsible for collecting all of those examples being the bottleneck. Some back-of-the-envelope computation may help, but ultimately you should be <a href=""https://stackoverflow.com/questions/40191367/tensorflow-get-amount-of-samples-in-queue"">monitoring the number of examples in each queue</a>.</p>\n\n<p>As for the second question, <a href=""https://www.tensorflow.org/api_docs/python/io_ops/input_pipeline#batch"" rel=""nofollow noreferrer"">tf.train.batch does start its own queue runner</a>. The actual enqueuing/dequeuing happens asynchronously, which is why it\'s important to monitor queue sizes to make sure that training isn\'t consuming data faster than the input pipeline is producing it.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8955}"
1032,63882987,"{'items': [{'owner': {'reputation': 3908, 'user_id': 2967377}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1662659767, 'answer_id': 73653285, 'question_id': 63882987, 'body': '<blockquote>\n<p>Does anybody have a Tensorflow 2 tf.keras subclass for the L-BFGS algorithm?</p>\n</blockquote>\n<p>Yes, here\'s (yet another) implementation L-BFGS (and <em>any</em> other <code>scipy.optimize.minimize</code> solver) for your consideration in case it fits your use case:</p>\n<ul>\n<li><a href=""https://pypi.org/project/kormos/"" rel=""nofollow noreferrer"">https://pypi.org/project/kormos/</a></li>\n<li><a href=""https://github.com/mbhynes/kormos"" rel=""nofollow noreferrer"">https://github.com/mbhynes/kormos</a></li>\n</ul>\n<p>This package has a similar goal to Pedro\'s answer above, but I would recommend it over the <code>keras-opt</code> package if you run into issues with memory consumption during training. I implemented <code>kormos</code> when trying to build a Rendle-type factorization machine and kept OOMing with other full-batch solver implementations.</p>\n<blockquote>\n<p>These two options are quite cumbersome to use, especially when using custom models. So I am planning to implement a custom subclass of tf.keras.optimizers to use L-BFGS. But before I start, I was curious, whether somebody already tackled this task?</p>\n</blockquote>\n<p>Agreed, it\'s a little cumbersome to fit the signatures of <code>tfp</code> and <code>scipy</code> into the parameter fitting procedure in <code>keras</code>, because of the way that <code>keras</code> steps in and out of an optimizer that has persistent state between calls, which is not how most [old school?] optimization libraries work.</p>\n<p>This is addressed specifically in the <code>kormos</code> package since IMO during prototyping it\'s a pretty common workflow to alternate between <em>either</em> a stochastic optimizer and a full-batch deterministic optimizer, and this should be simple enough to do ad hoc in the python interpreter.</p>\n<p>The package has models that extend <code>keras.Model</code> and <code>keras.Sequential</code>:</p>\n<ul>\n<li><a href=""https://kormos.readthedocs.io/en/latest/#kormos.models.BatchOptimizedModel"" rel=""nofollow noreferrer""><code>kormos.models.BatchOptimizedModel</code></a></li>\n<li><a href=""https://kormos.readthedocs.io/en/latest/#kormos.models.BatchOptimizedSequentialModel"" rel=""nofollow noreferrer""><code>kormos.models.BatchOptimizedSequentialModel</code></a></li>\n</ul>\n<p>These can be compiled to be fit with <em>either</em> the standard or the <code>scipy</code> solvers; it would look something like this:</p>\n<pre><code>from tensorflow import keras\nfrom kormos.models import BatchOptimizedSequentialModel\n\n# Create an Ordinary Least Squares regressor\nmodel = BatchOptimizedSequentialModel()\nmodel.add(keras.layers.Dense(\n  units=1,\n  input_shape=(5,),\n))\n\n# compile the model for stochastic optimization\nmodel.compile(loss=keras.losses.MeanSquaredError(), optimizer=&quot;sgd&quot;)\nmodel.fit(...)\n\n# compile the model for deterministic optimization using scipy.optimize.minimize\nmodel.compile(loss=keras.losses.MeanSquaredError(), optimizer=&quot;L-BFGS-B&quot;)\nmodel.fit(...)\n</code></pre>\n'}, {'owner': {'reputation': 2652, 'user_id': 5298937}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1608160358, 'answer_id': 65332478, 'question_id': 63882987, 'body': '<p>I\'ve implemented an interface between keras and SciPy optimize.\n<a href=""https://github.com/pedro-r-marques/keras-opt"" rel=""nofollow noreferrer"">https://github.com/pedro-r-marques/keras-opt</a></p>\n<p>I\'m using \'cg\' by default but you should also be able to use \'l-bfgs\'. Take a look at the unit tests for example usage. I will add documentation as soon as possible.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8951}"
1033,36693740,"{'items': [{'owner': {'reputation': 2246, 'user_id': 1427200}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1657993996, 'answer_id': 73006494, 'question_id': 36693740, 'body': '<p>In TensorFlow, a variable is just another tensor (like tf.constant or tf.placeholder). It just so happens that variables can be modified by the computation. tf.placeholder is used for inputs that will be provided externally to the computation at run-time (e.g. training data). tf.Variable is used for inputs that are part of the computation and are going to be modified by the computation (e.g. weights of a neural network).</p>\n'}, {'owner': {'reputation': 3738, 'user_id': 6302803}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1604325182, 'answer_id': 64646873, 'question_id': 36693740, 'body': ""<p>For TF V1:</p>\n<ol>\n<li><p>Constant is with initial value and it won't change in the computation;</p>\n</li>\n<li><p>Variable is with initial value and it can change in the computation; (so good for parameters)</p>\n</li>\n<li><p>Placeholder is without initial value and it won't change in the computation. (so good for inputs like prediction instances)</p>\n</li>\n</ol>\n<p>For TF V2, same but they try to hide Placeholder (graph mode is not preferred).</p>\n""}, {'owner': {}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1582188877, 'answer_id': 60316058, 'question_id': 36693740, 'body': '<p><strong>Tensorflow 2.0 Compatible Answer</strong>: The concept of Placeholders, <strong><code>tf.placeholder</code></strong> will not be available in <strong><code>Tensorflow 2.x (&gt;= 2.0)</code></strong> by default, as the Default Execution Mode is Eager Execution.</p>\n\n<p>However, we can use them if used in <strong><code>Graph Mode</code></strong> (<code>Disable Eager Execution</code>).</p>\n\n<p>Equivalent command for TF Placeholder in version 2.x is <strong><code>tf.compat.v1.placeholder</code></strong>.</p>\n\n<p>Equivalent Command for TF Variable in version 2.x is <strong><code>tf.Variable</code></strong> and if you want to migrate the code from 1.x to 2.x, the equivalent command is </p>\n\n<p><strong><code>tf.compat.v2.Variable</code></strong>.</p>\n\n<p>Please refer this <a href=""https://www.tensorflow.org/guide"" rel=""nofollow noreferrer"">Tensorflow Page</a> for more information about Tensorflow Version 2.0.</p>\n\n<p>Please refer the <a href=""https://www.tensorflow.org/guide/migrate"" rel=""nofollow noreferrer"">Migration Guide</a> for more information about migration from versions 1.x to 2.x.</p>\n'}, {'owner': {'reputation': 6384, 'user_id': 3552975}, 'down_vote_count': 0, 'up_vote_count': 66, 'is_accepted': False, 'score': 66, 'creation_date': 1472269226, 'answer_id': 39177244, 'question_id': 36693740, 'body': '<p>Since Tensor computations compose of <a href=""https://www.tensorflow.org/api_docs/python/tf/Graph"" rel=""noreferrer"">graphs</a> then it\'s better to interpret the two in terms of graphs. </p>\n\n<p>Take for example the simple linear regression </p>\n\n<pre><code>WX+B=Y\n</code></pre>\n\n<p>where <code>W</code> and <code>B</code> stand for the weights and bias and <code>X</code> for the observations\' inputs and <code>Y</code> for the observations\' outputs.</p>\n\n<p>Obviously <code>X</code> and <code>Y</code> are of the same nature (manifest variables) which differ from that of <code>W</code> and <code>B</code> (latent variables). <code>X</code> and <code>Y</code> are values of the samples (observations) and hence need a <strong>place to be filled</strong>, while <code>W</code> and <code>B</code> are the weights and bias, <em>Variables</em> (the previous values affect the latter) in the graph which should be trained using different <code>X</code> and <code>Y</code> pairs. We place different samples to the <em>Placeholders</em> to train the <em>Variables</em>.  </p>\n\n<p>We only need to <strong>save or restore</strong> the <em>Variables</em> (at checkpoints) to save or rebuild the graph with the code. </p>\n\n<p><em>Placeholders</em> are mostly holders for the different datasets (for example training data or test data). However, <em>Variables</em> are trained in the training process for the specific tasks, i.e., to predict the outcome of the input or map the inputs to the desired labels. They remain the same until you retrain or fine-tune the model using different or the same samples to fill into the <em>Placeholders</em> often through the dict. For instance:</p>\n\n<pre><code> session.run(a_graph, dict = {a_placeholder_name : sample_values}) \n</code></pre>\n\n<p><em>Placeholders</em> are also passed as parameters to set models. </p>\n\n<p>If you change placeholders (add, delete, change the shape etc) of a model in the middle of training, you can still reload the checkpoint without any other modifications. But if the variables of a saved model are changed, you should adjust the checkpoint accordingly to reload it and continue the training (all variables defined in the graph should be available in the checkpoint).   </p>\n\n<p>To sum up, if the values are from the samples (observations you already have) you safely make a placeholder to hold them, while if you need a parameter to be trained harness a <em>Variable</em> (simply put, set the <em>Variables</em> for the values you want to get using TF automatically). </p>\n\n<p>In some interesting models, like <a href=""https://github.com/anishathalye/neural-style/blob/master/stylize.py#L104"" rel=""noreferrer"">a style transfer model</a>, the input pixes are going to be optimized and the normally-called model variables are fixed, then we should make the input (usually initialized randomly) as a variable as implemented in that link. </p>\n\n<p>For more information please infer to this <a href=""https://www.tensorflow.org/get_started/get_started"" rel=""noreferrer"">simple and illustrating doc</a>.</p>\n'}, {'owner': {'reputation': 140, 'user_id': 5057404}, 'down_vote_count': 0, 'up_vote_count': 14, 'is_accepted': False, 'score': 14, 'creation_date': 1532779275, 'answer_id': 51571189, 'question_id': 36693740, 'body': '<p>Tensorflow uses three types of containers to store/execute the process</p>\n\n<ol>\n<li><p>Constants :Constants holds the typical data.</p></li>\n<li><p>variables: Data values will be changed, with respective the functions such as cost_function..</p></li>\n<li><p>placeholders: Training/Testing data will be passed in to the graph.</p></li>\n</ol>\n'}, {'owner': {'reputation': 81, 'user_id': 8462755}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': False, 'score': 8, 'creation_date': 1532460628, 'answer_id': 51506244, 'question_id': 36693740, 'body': '<p><strong>Variables</strong> </p>\n\n<p>A TensorFlow variable is the best way to represent shared, persistent state manipulated by your program. Variables are manipulated via the tf.Variable class. Internally, a tf.Variable stores a persistent tensor. Specific operations allow you to read and modify the values of this tensor. These modifications are visible across multiple tf.Sessions, so multiple workers can see the same values for a tf.Variable. Variables must be initialized before using. </p>\n\n<p>Example:</p>\n\n<pre><code>x = tf.Variable(3, name=""x"")\ny = tf.Variable(4, name=""y"")\nf = x*x*y + y + 2\n</code></pre>\n\n<p>This creates a computation graph. The variables (x and y) can be initialized and the function (f) evaluated in a tensorflow session as follows:</p>\n\n<pre><code>with tf.Session() as sess:\n     x.initializer.run()\n     y.initializer.run()\n     result = f.eval()\nprint(result)\n42\n</code></pre>\n\n<p><strong>Placeholders</strong> </p>\n\n<p>A placeholder is a node (same as a variable) whose value can be initialized in the future. These nodes basically output the value assigned to them during runtime. A placeholder node can be assigned using the tf.placeholder() class to which you can provide arguments such as type of the variable and/or its shape. Placeholders are extensively used for representing the training dataset in a machine learning model as the training dataset keeps changing. </p>\n\n<p>Example:</p>\n\n<pre><code>A = tf.placeholder(tf.float32, shape=(None, 3))\nB = A + 5\n</code></pre>\n\n<p>Note: \'None\' for a dimension means \'any size\'.</p>\n\n<pre><code>with tf.Session as sess:\n    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n\nprint(B_val_1)\n[[6. 7. 8.]]\nprint(B_val_2)\n[[9. 10. 11.]\n [12. 13. 14.]]\n</code></pre>\n\n<p>References:</p>\n\n<ol>\n<li><a href=""https://www.tensorflow.org/guide/variables"" rel=""noreferrer"">https://www.tensorflow.org/guide/variables</a></li>\n<li><a href=""https://www.tensorflow.org/api_docs/python/tf/placeholder"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/placeholder</a></li>\n<li>O\'Reilly: Hands-On Machine Learning with Scikit-Learn &amp; Tensorflow</li>\n</ol>\n'}, {'owner': {'reputation': 1033, 'user_id': 4315914}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1529886567, 'answer_id': 51015000, 'question_id': 36693740, 'body': '<p>Think of a <strong>computation graph</strong>. In such graph, we need an input node to pass our data to the graph, those nodes should be defined as Placeholder in <strong>tensorflow</strong>.</p>\n\n<p>Do not think as a general program in Python. You can write a Python program and do all those stuff that guys explained in other answers just by Variables, but for computation graphs in tensorflow, to feed your data to the graph, you need to define those nods as Placeholders.</p>\n'}, {'owner': {'reputation': 1230, 'user_id': 7769653}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': False, 'score': 6, 'creation_date': 1527945749, 'answer_id': 50657356, 'question_id': 36693740, 'body': '<p>Think of <code>Variable</code> in tensorflow as a normal variables which we use in programming languages. We initialize variables, we can modify it later as well. Whereas <code>placeholder</code> doesnt require initial value. Placeholder simply allocates block of memory for future use. Later, we can use <code>feed_dict</code> to feed the data into <code>placeholder</code>. By default, <code>placeholder</code> has an unconstrained shape, which allows you to feed tensors of different shapes in a session. You can make constrained shape by passing optional argument -shape, as I have done below.</p>\n\n<pre><code>x = tf.placeholder(tf.float32,(3,4))\ny =  x + 2\n\nsess = tf.Session()\nprint(sess.run(y)) # will cause an error\n\ns = np.random.rand(3,4)\nprint(sess.run(y, feed_dict={x:s}))\n</code></pre>\n\n<p>While doing Machine Learning task, most of the time we are unaware of number of rows but (lets assume) we do know the number of features or columns. In that case, we can use None.</p>\n\n<pre><code>x = tf.placeholder(tf.float32, shape=(None,4))\n</code></pre>\n\n<p>Now, at run time we can feed any matrix with 4 columns and any number of rows.</p>\n\n<p>Also, Placeholders are used for input data ( they are kind of variables which we use to feed our model), where as Variables are parameters such as weights that we train over time.</p>\n'}, {'owner': {'reputation': 3934, 'user_id': 1115377}, 'down_vote_count': 0, 'up_vote_count': 14, 'is_accepted': False, 'score': 14, 'creation_date': 1487496889, 'answer_id': 42325639, 'question_id': 36693740, 'body': '<p>Adding to other\'s answers, they also explain it very well in this <a href=""https://www.tensorflow.org/versions/r0.11/tutorials/mnist/beginners/"" rel=""noreferrer"">MNIST tutorial</a> on Tensoflow website:</p>\n\n<blockquote>\n  <p>We describe these interacting operations by manipulating symbolic\n  variables. Let\'s create one:</p>\n  \n  <p><code>x = tf.placeholder(tf.float32, [None, 784])</code>, </p>\n  \n  <p><code>x</code> isn\'t a specific value. It\'s a placeholder, a value that we\'ll input when we ask TensorFlow to\n  run a computation. We want to be able to input any number of MNIST\n  images, each flattened into a 784-dimensional vector. We represent\n  this as a 2-D tensor of floating-point numbers, with a shape [None,\n  784]. (Here None means that a dimension can be of any length.)</p>\n  \n  <p>We also need the weights and biases for our model. We could imagine\n  treating these like additional inputs, but TensorFlow has an even\n  better way to handle it: <code>Variable</code>. A <code>Variable</code> is a modifiable tensor\n  that lives in TensorFlow\'s graph of interacting operations. It can be\n  used and even modified by the computation. For machine learning\n  applications, one generally has the model parameters be <code>Variable</code>s.</p>\n  \n  <p><code>W = tf.Variable(tf.zeros([784, 10]))</code></p>\n  \n  <p><code>b = tf.Variable(tf.zeros([10]))</code></p>\n  \n  <p>We create these <code>Variable</code>s by giving <code>tf.Variable</code> the initial value of\n  the <code>Variable</code>: in this case, we initialize both <code>W</code> and <code>b</code> as tensors full\n  of zeros. Since we are going to learn <code>W</code> and <code>b</code>, it doesn\'t matter very\n  much what they initially are.</p>\n</blockquote>\n'}, {'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 35, 'is_accepted': False, 'score': 35, 'creation_date': 1493456313, 'answer_id': 43693704, 'question_id': 36693740, 'body': '<p>The most obvious difference between the <a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""noreferrer"">tf.Variable</a> and the <a href=""https://www.tensorflow.org/api_docs/python/tf/placeholder"" rel=""noreferrer"">tf.placeholder</a> is that</p>\n\n<hr>\n\n<blockquote>\n  <p>you use variables to hold and update parameters. Variables are\n  in-memory buffers containing tensors. They must be explicitly\n  initialized and can be saved to disk during and after training. You\n  can later restore saved values to exercise or analyze the model.</p>\n</blockquote>\n\n<p>Initialization of the variables is done with <code>sess.run(tf.global_variables_initializer())</code>. Also while creating a variable, you need to pass a Tensor as its initial value to the <code>Variable()</code> constructor and when you create a variable you always know its shape.</p>\n\n<hr>\n\n<p>On the other hand, you can\'t update the placeholder. They also should not be initialized, but because they are a promise to have a tensor, you need to feed the value into them <code>sess.run(&lt;op&gt;, {a: &lt;some_val&gt;})</code>. And at last, in comparison to a variable, placeholder might not know the shape. You can either provide parts of the dimensions or provide nothing at all.</p>\n\n<hr>\n\n<p><strong>There other differences:</strong></p>\n\n<ul>\n<li>the values inside the variable can be updated during optimizations</li>\n<li>variables can be <a href=""https://www.tensorflow.org/programmers_guide/variable_scope"" rel=""noreferrer"">shared</a>, and can be <a href=""https://stackoverflow.com/q/40736859/1090562"">non-trainable</a></li>\n<li>the values inside the variable can be stored after training</li>\n<li>when the variable is created, <a href=""https://www.tensorflow.org/programmers_guide/variables#creation"" rel=""noreferrer"">3 ops are added to a graph</a> (variable op, initializer op, ops for the initial value)</li>\n<li><a href=""https://stackoverflow.com/a/43536220/1090562"">placeholder is a function, Variable is a class</a> (hence an uppercase)</li>\n<li>when you use TF in a distributed environment, variables are stored in a special place (<a href=""https://www.tensorflow.org/deploy/distributed"" rel=""noreferrer"">parameter server</a>) and are shared between the workers.</li>\n</ul>\n\n<p>Interesting part is that not only placeholders can be fed. You can feed the value to a Variable and even to a constant.</p>\n'}, {'owner': {'reputation': 31993, 'user_id': 5106574}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1506148214, 'answer_id': 46376767, 'question_id': 36693740, 'body': '<p><strong>Placeholder :</strong></p>\n\n<ol>\n<li><p>A placeholder is simply a variable that we will assign data to at a later date. It allows us to create our operations and build our computation graph, without needing the data. In TensorFlow terminology, we then feed data into the graph through these placeholders.</p></li>\n<li><p>Initial values are not required but can have default values with <code>tf.placeholder_with_default)</code></p></li>\n<li><p>We have to provide value at runtime like :</p>\n\n<pre><code>a = tf.placeholder(tf.int16) // initialize placeholder value\nb = tf.placeholder(tf.int16) // initialize placeholder value\n\nuse it using session like :\n\nsess.run(add, feed_dict={a: 2, b: 3}) // this value we have to assign at runtime\n</code></pre></li>\n</ol>\n\n<p><strong>Variable :</strong></p>\n\n<ol>\n<li>A TensorFlow variable is the best way to represent shared,\npersistent state manipulated by your program. </li>\n<li>Variables are manipulated via the tf.Variable class. A tf.Variable \nrepresents a tensor whose value can be changed by running ops on it.</li>\n</ol>\n\n<p>Example : <code>tf.Variable(""Welcome to tensorflow!!!"")</code></p>\n'}, {'owner': {'reputation': 30816, 'user_id': 410072}, 'down_vote_count': 0, 'up_vote_count': 42, 'is_accepted': False, 'score': 42, 'creation_date': 1493206355, 'answer_id': 43633003, 'question_id': 36693740, 'body': '<p><strong>TL;DR</strong></p>\n\n<p><strong>Variables</strong></p>\n\n<ul>\n<li>For parameters to learn</li>\n<li>Values can be derived from training</li>\n<li>Initial values are required (often random)</li>\n</ul>\n\n<p><strong>Placeholders</strong></p>\n\n<ul>\n<li>Allocated storage for data (such as for image pixel data during a feed)</li>\n<li>Initial values are not required (but can be set, see <code>tf.placeholder_with_default</code>)</li>\n</ul>\n'}, {'owner': {'reputation': 18516, 'user_id': 1384641}, 'down_vote_count': 0, 'up_vote_count': 10, 'is_accepted': False, 'score': 10, 'creation_date': 1489149364, 'answer_id': 42718577, 'question_id': 36693740, 'body': '<p>Example snippet:</p>\n\n<pre><code>import numpy as np\nimport tensorflow as tf\n\n### Model parameters ###\nW = tf.Variable([.3], tf.float32)\nb = tf.Variable([-.3], tf.float32)\n\n### Model input and output ###\nx = tf.placeholder(tf.float32)\nlinear_model = W * x + b\ny = tf.placeholder(tf.float32)\n\n### loss ###\nloss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n\n### optimizer ###\noptimizer = tf.train.GradientDescentOptimizer(0.01)\ntrain = optimizer.minimize(loss)\n\n### training data ###\nx_train = [1,2,3,4]\ny_train = [0,-1,-2,-3]\n\n### training loop ###\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init) # reset values to wrong\nfor i in range(1000):\n  sess.run(train, {x:x_train, y:y_train})\n</code></pre>\n\n<p>As the name say placeholder is a promise to provide a value later i.e.</p>\n\n<p><strong>Variable</strong> are simply the training parameters (<code>W</code>(matrix), <code>b</code>(bias) same as the normal variables you use in your day to day programming, which the trainer updates/modify on each run/step.</p>\n\n<p>While <strong>placeholder</strong> doesn\'t require any initial value, that when you created <code>x</code> and <code>y</code> TF doesn\'t allocated any memory, instead later when you feed the placeholders in the <code>sess.run()</code> using <code>feed_dict</code>, TensorFlow will allocate the appropriately sized memory for them (<code>x</code> and <code>y</code>) - this unconstrained-ness allows us to feed any size and shape of data.</p>\n\n<hr>\n\n<p><strong>In nutshell</strong>:</p>\n\n<p><strong>Variable</strong> - is a parameter you want trainer (i.e. GradientDescentOptimizer) to update after each step.</p>\n\n<p><strong>Placeholder</strong> demo - </p>\n\n<pre><code>a = tf.placeholder(tf.float32)\nb = tf.placeholder(tf.float32)\nadder_node = a + b  # + provides a shortcut for tf.add(a, b)\n</code></pre>\n\n<p>Execution:</p>\n\n<pre><code>print(sess.run(adder_node, {a: 3, b:4.5}))\nprint(sess.run(adder_node, {a: [1,3], b: [2, 4]}))\n</code></pre>\n\n<p>resulting in the output</p>\n\n<pre><code>7.5\n[ 3.  7.]\n</code></pre>\n\n<p>In the first case 3 and 4.5 will be passed to <code>a</code> and <code>b</code> respectively, and then to adder_node ouputting 7. In second case there\'s a feed list, first step 1 and 2 will be added, next 3 and 4 (<code>a</code> and <code>b</code>).</p>\n\n<hr>\n\n<p>Relevant reads:</p>\n\n<ul>\n<li><a href=""https://www.tensorflow.org/api_docs/python/tf/placeholder"" rel=""noreferrer""><strong>tf.placeholder</strong></a> doc. </li>\n<li><a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""noreferrer""><strong>tf.Variable</strong></a> doc. </li>\n<li><a href=""https://www.quora.com/What-is-the-difference-between-Variables-and-Placeholders-in-tensor-flow"" rel=""noreferrer"">Variable VS placeholder</a>.</li>\n</ul>\n'}, {'owner': {'reputation': 8427, 'user_id': 364772}, 'down_vote_count': 2, 'up_vote_count': 193, 'is_accepted': False, 'score': 191, 'creation_date': 1460984580, 'answer_id': 36694819, 'question_id': 36693740, 'body': '<p>In short, you use <code>tf.Variable</code> for trainable variables such as weights (W) and biases (B) for your model.</p>\n\n<pre><code>weights = tf.Variable(\n    tf.truncated_normal([IMAGE_PIXELS, hidden1_units],\n                    stddev=1.0 / math.sqrt(float(IMAGE_PIXELS))), name=\'weights\')\n\nbiases = tf.Variable(tf.zeros([hidden1_units]), name=\'biases\')\n</code></pre>\n\n<p><code>tf.placeholder</code> is used to feed actual training examples.</p>\n\n<pre><code>images_placeholder = tf.placeholder(tf.float32, shape=(batch_size, IMAGE_PIXELS))\nlabels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))\n</code></pre>\n\n<p>This is how you feed the training examples during the training:</p>\n\n<pre><code>for step in xrange(FLAGS.max_steps):\n    feed_dict = {\n       images_placeholder: images_feed,\n       labels_placeholder: labels_feed,\n     }\n    _, loss_value = sess.run([train_op, loss], feed_dict=feed_dict)\n</code></pre>\n\n<p>Your <code>tf.variables</code> will be trained (modified) as the result of this training.</p>\n\n<p>See more at <a href=""https://www.tensorflow.org/versions/r0.7/tutorials/mnist/tf/index.html"">https://www.tensorflow.org/versions/r0.7/tutorials/mnist/tf/index.html</a>. (Examples are taken from the web page.)</p>\n'}, {'owner': {'reputation': 47089, 'user_id': 121687}, 'down_vote_count': 8, 'up_vote_count': 89, 'is_accepted': False, 'score': 81, 'creation_date': 1461010757, 'answer_id': 36703529, 'question_id': 36693740, 'body': ""<p>The difference is that with <code>tf.Variable</code> you have to provide an initial value when you declare it. With <code>tf.placeholder</code> you don't have to provide an initial value and you can specify it at run time with the <code>feed_dict</code> argument inside <code>Session.run</code></p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8951}"
1034,62211822,"{'items': [{'owner': {'reputation': 81, 'user_id': 9334184}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1591385973, 'answer_id': 62223005, 'question_id': 62211822, 'body': '<p>So the right way to do this is here, Feature engineering and Pre-processing can be done in the <code>serving_default</code> method through below option. I tested it further via Tensorflow serving.</p>\n\n<pre><code>@tf.function\ndef serving(WERKS, DIFGRIRD, SCENARIO, TOTIRQTY, VSTATU, EKGRP, TOTGRQTY, VPATD, EKORG, NODLGR, DIFGRIRV, NODLIR, KTOKK):\n    ##Feature engineering\n    nodlgrbyvpatd = tf.cast(NODLGR / VPATD, tf.float32)\n\n    payload = {\n        \'WERKS\': WERKS,\n        \'DIFGRIRD\': DIFGRIRD,\n        \'SCENARIO\': SCENARIO,\n        \'TOTIRQTY\': TOTIRQTY,\n        \'VSTATU\': VSTATU,\n        \'EKGRP\': EKGRP,\n        \'TOTGRQTY\': TOTGRQTY,\n        \'VPATD\': VPATD,\n        \'EKORG\': EKORG,\n        \'NODLGR\': NODLGR,\n        \'DIFGRIRV\': DIFGRIRV,\n        \'NODLIR\': NODLIR,\n        \'KTOKK\': KTOKK,\n        \'nodlgrbyvpatd\': nodlgrbyvpatd,        \n    }\n\n    ## Predict\n    ##IF THERE IS AN ERROR IN NUMBER OF PARAMS PASSED HERE OR DATA TYPE THEN IT GIVES ERROR, ""COULDN\'T COMPUTE OUTPUT TENSOR""\n    predictions = m_(payload)\n    return predictions\n\nserving = serving.get_concrete_function(WERKS=tf.TensorSpec([None,], dtype= tf.string, name=\'WERKS\'), \n                                        DIFGRIRD=tf.TensorSpec([None,], name=\'DIFGRIRD\'),\n                                        SCENARIO=tf.TensorSpec([None,], dtype= tf.string, name=\'SCENARIO\'), \n                                        TOTIRQTY=tf.TensorSpec([None,], name=\'TOTIRQTY\'),\n                                        VSTATU=tf.TensorSpec([None,], dtype= tf.string, name=\'VSTATU\'), \n                                        EKGRP=tf.TensorSpec([None,], dtype= tf.string, name=\'EKGRP\'),\n                                        TOTGRQTY=tf.TensorSpec([None,], name=\'TOTGRQTY\'), \n                                        VPATD=tf.TensorSpec([None,], name=\'VPATD\'),\n                                        EKORG=tf.TensorSpec([None,], dtype= tf.string, name=\'EKORG\'), \n                                        NODLGR=tf.TensorSpec([None,], name=\'NODLGR\'),\n                                        DIFGRIRV=tf.TensorSpec([None,], name=\'DIFGRIRV\'),\n                                        NODLIR=tf.TensorSpec([None,], name=\'NODLIR\'),\n                                        KTOKK=tf.TensorSpec([None,], dtype= tf.string, name=\'KTOKK\')\n                                        )\n\nversion = ""1""\ntf.saved_model.save(\n    m_,\n    ""./exported_model/"" + version,\n    signatures=serving\n)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8951}"
1035,62476015,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8951}"
1036,45784815,"{'items': [{'owner': {'reputation': 2354, 'user_id': 2878004}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1503250375, 'answer_id': 45784993, 'question_id': 45784815, 'body': '<p>I think these three lines might do what you want. First, you make a mask. Then, you create the random data. Finally, fill in the masked values with the random data.</p>\n\n<pre><code>mask = tf.equal(a, 0.0)\nr = tf.random_uniform(tf.shape(a), minval = 0.0,maxval=1.0,dtype=tf.float32)\ntargets = tf.where(mask, r, a)\n</code></pre>\n'}, {'owner': {'reputation': 16941, 'user_id': 8143158}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1503251362, 'answer_id': 45785156, 'question_id': 45784815, 'body': '<p>You can use <code>tf.where</code> to achieve the same:</p>\n\n<pre><code>A = tf.Variable(a)\nB = tf.where(A==0., tf.random_normal(A.get_shape()), tf.cast(A, tf.float32))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8951}"
1037,73414383,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8946}"
1038,47644412,"{'items': [{'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1512436238, 'answer_id': 47644525, 'question_id': 47644412, 'body': '<p>The error is raised because the <code>tf.feature_column</code> methods expect the input to be batched, and \nI think the cause is a simple typo, which is dropping out the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch"" rel=""noreferrer""><code>Dataset.batch()</code></a> transformation. Replace the <code>dataset.batch(batch_size)</code> with the following line:</p>\n\n<pre><code>dataset = dataset.batch(batch_size)\n</code></pre>\n\n<p>Calling any of the <code>tf.data.Dataset</code> transformations methods (e.g. <code>Dataset.map()</code>, <code>Dataset.repeat()</code>, <code>Dataset.batch()</code>) does not modify the object on which you called those methods. Instead, these methods return a <em>new</em> <code>Dataset</code> object that you can either use for further transformations, or to make an <code>Iterator</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8946}"
1039,44871420,"{'items': [{'owner': {'reputation': 2353, 'user_id': 7241513}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1499032864, 'answer_id': 44875593, 'question_id': 44871420, 'body': ""<p>If you are trying to do continuous why can't you just reshape your input placeholders to be of shape <code>[BATCH, TIME_STEPS, 1]</code> and add that one extra dimension into your input via <code>tf.expand_dims(input, 2)</code>. This way, your input would match the dimensions that <code>dynamic_rnn</code> expects (actually in your case, since you are doing <code>time_major=True</code> your input should be of shape <code>[TIME_STEPS, BATCH, 1])</code></p>\n\n<p>I'd be curious to know how you'd then handle the switch of the output dimension from your cell size to 1. Right now you have this line:</p>\n\n<pre><code>decoder_logits = tf.contrib.layers.linear(decoder_outputs, VOCAB_SIZE)\n</code></pre>\n\n<p>But since you are no longer doing a classification, then <code>VOCAB_SIZE</code> is just 1? I asked a similar question here a few days ago, but didn't get any responses. I'm doing it this way (using 1), but not sure whether it's appropriate (seems to sort-of work in practice, but not perfectly).</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8946}"
1040,43114238,"{'items': [{'owner': {'reputation': 960, 'user_id': 7604321}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1490869754, 'answer_id': 43115193, 'question_id': 43114238, 'body': '<p>Doing it with <code>tf.Summaries</code> is probably a good idea. You could then visualize it all in Tesnorboard, much like with some of the tutorials and the inception retraining code.\nAlternatively you could perform fetches within your <code>sess.run()</code> call to grab whatever tensors you like at every step (i.e. every run call).</p>\n\n<p>I have pasted a response to a similar question regarding extracting the cross entropy from another question below:\nWhen you do your session run call (e.g. <code>res = sess.run(...)</code> ) then you can put in a fetch for your cross entropy variable.</p>\n\n<p>For example, let\'s say you have a complicated <code>sess.run()</code> call that gets some predictions but you also want to your cross entropy then you may have code that looks like this:</p>\n\n<pre><code>feeds={x_data:x,y_data:y}\nfetches=[y_result,cross_entropy]\nres=sess.run(fetches=fetches, feed_dict=feeds) predictions=res[0]\n#your first fetch parameter xent=res[1] #Your second fetch parameter.\n</code></pre>\n\n<p>Fetches within the run call allows you to ""fetch"" tensors from your graph.</p>\n\n<p>You should be able to do the above but instead of cross entropy, just a list of whatever you want. I use it to fetch both my summaries and also intermediate accuracy values.</p>\n'}, {'owner': {'reputation': 1318, 'user_id': 6778091}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1490869863, 'answer_id': 43115241, 'question_id': 43114238, 'body': '<pre><code>for step in range(num_train_steps):\n    _, weight_values, bias_values = sess.run([your_train_op, weight, bias])\n    # save weight_values and bias_values\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8943}"
1041,56284927,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8943}"
1042,35565312,"{'items': [{'owner': {'reputation': 648, 'user_id': 292896}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1526775500, 'answer_id': 50430612, 'question_id': 35565312, 'body': '<p>Tensorflow 1.8 has added tf.image.sobel_edges() so that is the easiest and probably most robust way todo this now.</p>\n'}, {'owner': {'reputation': 125638, 'user_id': 3574081}, 'down_vote_count': 0, 'up_vote_count': 14, 'is_accepted': True, 'score': 14, 'creation_date': 1456207240, 'answer_id': 35569977, 'question_id': 35565312, 'body': '<p>Perhaps I\'m missing a subtlety here, but it appears that you could apply a Sobel filter to an image using <a href=""https://www.tensorflow.org/versions/master/api_docs/python/array_ops.html#expand_dims"" rel=""noreferrer""><code>tf.expand_dims()</code></a> and <a href=""https://www.tensorflow.org/versions/r0.7/api_docs/python/nn.html#conv2d"" rel=""noreferrer""><code>tf.nn.conv2d()</code></a>, as follows:</p>\n\n<pre><code>sobel_x = tf.constant([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], tf.float32)\nsobel_x_filter = tf.reshape(sobel_x, [3, 3, 1, 1])\nsobel_y_filter = tf.transpose(sobel_x_filter, [1, 0, 2, 3])\n\n# Shape = height x width.\nimage = tf.placeholder(tf.float32, shape=[None, None])\n\n# Shape = 1 x height x width x 1.\nimage_resized = tf.expand_dims(tf.expand_dims(image, 0), 3)\n\nfiltered_x = tf.nn.conv2d(image_resized, sobel_x_filter,\n                          strides=[1, 1, 1, 1], padding=\'SAME\')\nfiltered_y = tf.nn.conv2d(image_resized, sobel_y_filter,\n                          strides=[1, 1, 1, 1], padding=\'SAME\')\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8941}"
1043,47814401,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8941}"
1044,63020800,"{'items': [{'owner': {'reputation': 53, 'user_id': 8410038}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1595757031, 'answer_id': 63098555, 'question_id': 63020800, 'body': '<p>I found pretty useful information about <code>Checkpoint</code> class. It does not come from the documentation but from the tutorial, <a href=""https://www.tensorflow.org/guide/checkpoint#loading_mechanics"" rel=""nofollow noreferrer"">Training Checkpoints &gt; Loading Mechanism</a>.</p>\n<p>This is what I understand so far:</p>\n<ol>\n<li>The keyword arguments are basically the name of the attributes that are saved in our checkpoint file.</li>\n<li>The variable that is passed to that particular keyword argument is the variable whose value we want to replace with checkpoint values, in other words, our model attributes.</li>\n<li>The checkpoint architecture must match our model architecture in order to make this variable restoration works.</li>\n</ol>\n<p>If we want to know what are the attributes that are saved in our checkpoint file, we can run this command</p>\n<pre><code>tf.train.list_variables(tf.train.latest_checkpoint(\'path_to_checkpoint\'))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8941}"
1045,72720129,"{'items': [{'owner': {'reputation': 21, 'user_id': 19431212}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1656661063, 'answer_id': 72825886, 'question_id': 72720129, 'body': '<p><strong>3. can I use the argument top_k with the value top_k=2 would be helpful here or it is not suitable for my classification of 4 classes only?</strong></p>\n<p>According to the description, it will only calculate top_k(with the function of _filter_top_k) predictions, and turn other predictions to <code>False</code> if you use this argument</p>\n<p>The example from official document link:<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision</a></p>\n<p>You may also want to read the original code:\n<a href=""https://github.com/keras-team/keras/blob/07e13740fd181fc3ddec7d9a594d8a08666645f6/keras/utils/metrics_utils.py#L487"" rel=""nofollow noreferrer"">https://github.com/keras-team/keras/blob/07e13740fd181fc3ddec7d9a594d8a08666645f6/keras/utils/metrics_utils.py#L487</a>\n<em><strong>With top_k=2, it will calculate precision over y_true[:2] and y_pred[:2]</strong></em></p>\n<pre><code>m = tf.keras.metrics.Precision(top_k=2)\nm.update_state([0, 0, 1, 1], [1, 1, 1, 1])\nm.result().numpy()\n0.0\n</code></pre>\n<p>As we can see the note posted in the example here, it will only calculate y_true[:2] and y_pred[:2], which means the precision will calculate only top 2 predictions (also turn the rest of y_pred to 0).</p>\n<p>If you want to use 4 classes classification, the argument of <code>class_id</code> maybe enough.</p>\n<p><strong>4.While I am measuring the performance of each class, What could be the difference when I set the top_k=1 and not setting top_koverall?</strong>\nThe function will calculate the precision across all the predictions your model make if you don\'t set <code>top_k</code> value. If you want to measure the perfromance.</p>\n<p>Top k may works for other model, not for classification model</p>\n'}, {'owner': {'reputation': 483, 'user_id': 16744902}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1656364680, 'answer_id': 72778398, 'question_id': 72720129, 'body': '<p><strong>1. Is it macro or micro ?</strong></p>\n<p>To be precise, all the metrics are reset at the beginning of every epoch and at the beginning of every validation if there is. So I guess, we can call it macro.</p>\n<p><strong>2. Class specific precision and recall ?</strong></p>\n<p>You can take a look at <code>tf.compat.v1.metrics.precision_at_k</code>  and <code>tf.compat.v1.metrics.recall_at_k</code>. It seems that it computes the respectivly the precision at the recall for a specific <strong>class k</strong>.</p>\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/compat/v1/metrics/precision_at_k"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/compat/v1/metrics/precision_at_k</a></p>\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/compat/v1/metrics/recall_at_k"" rel=""nofollow noreferrer"">https://www.tensorflow.org/api_docs/python/tf/compat/v1/metrics/recall_at_k</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8941}"
1046,74434308,"{'items': [{'owner': {'reputation': 16941, 'user_id': 8143158}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1668453398, 'answer_id': 74436752, 'question_id': 74434308, 'body': ""<p>Two different <code>operation seed</code> can generate the same sequence. I don't think there is any guarantee that no two consecutive tensors are repeated. For example,</p>\n<pre><code>tf.random.set_seed(1234)\nprint(tf.random.shuffle(constant_tensor, seed=6))\nprint(tf.random.shuffle(constant_tensor, seed=7))\n\n#ouputs are same even though the `operation seed` is different.\ntf.Tensor([1 3 2], shape=(3,), dtype=int32)\ntf.Tensor([1 3 2], shape=(3,), dtype=int32)\n</code></pre>\n<p>In your second example if you reduce the <code>maxval</code>, you should observe the repetition happening as well.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8941}"
1047,65277703,"{'items': [{'owner': {'reputation': 291, 'user_id': 14043558}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1608588177, 'answer_id': 65400540, 'question_id': 65277703, 'body': '<p>From the TensorFlow Model Garden reference for ResNet, the mean and standard deviation of a dataset is often calculated beforehand and each batch is standardized via mean subtract and dividing by the standard deviation. See <a href=""https://github.com/tensorflow/models/blob/master/official/vision/image_classification/preprocessing.py#L384-L387"" rel=""nofollow noreferrer"">here</a> for a reference (this uses ImageNet statistics).</p>\n<p>I would suggest creating a separate script that calculates the mean and standardization and doing the same. Could you also point to the documentation where <code>tf.image.per_image_standardization</code> is not supported? I don\'t see why this wouldn\'t work, but you shouldn\'t apply it as a layer like in the provided code snippet. It should be in the data preprocessing pipeline like in the above reference.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8936}"
1048,55451403,"{'items': [{'owner': {'reputation': 2502, 'user_id': 5922329}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1559653286, 'answer_id': 56444474, 'question_id': 55451403, 'body': '<p>First create a tf.data.options instance. Then set the properties as you wish. For example:</p>\n\n<pre><code>dataset = tf.data.Dataset.range(10000)\n\noptions = tf.data.Options()\noptions.experimental_optimization.apply_default_optimizations = True\noptions.experimental_threading.private_threadpool_size = 10\n\ndataset = dataset.with_options(options)\n</code></pre>\n\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/data/Options"" rel=""nofollow noreferrer"">For all options available to you</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8936}"
1049,66623244,"{'items': [{'owner': {'reputation': 6543, 'user_id': 13337635}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1615749809, 'answer_id': 66628652, 'question_id': 66623244, 'body': '<p>In order to extract the probabilities from the logits of the model using a softmax function you can do the following:</p>\n<p>This is the array of logits that are also the <code>predictions</code> you get from the model</p>\n<pre><code>const logits = [-2.5525975227355957, 7.398464679718018, -3.252196788787842, 4.710395812988281, -4.636396408081055]\n</code></pre>\n<p>You can call <code>tf.softmax()</code> on the array of values</p>\n<pre><code>const probabilities = tf.softmax(logits)\n</code></pre>\n<p>Result:</p>\n<pre><code>[0.0000446, 0.9362511, 0.0000222, 0.0636765, 0.0000056]\n</code></pre>\n<p>Then if you wanted to get the index with the highest probability you can make use of <code>tf.argMax()</code>:</p>\n<pre><code>const results = tf.argMax(probabilities).dataSync()[0]\n</code></pre>\n<p>Result:</p>\n<pre><code>1\n</code></pre>\n<h3>Edit</h3>\n<p>I am not too familiar with jQuery so this might not be correct. But here is how I would get the probabilities of the outputs in descending order:</p>\n<pre><code>let probabilities = tf.softmax(predictions).dataSync();\n$(&quot;#prediction-list&quot;).empty();\nprobabilities.forEach(function(p, i) {\n  $(&quot;#prediction-list&quot;).append(\n    `&lt;li&gt;${TARGET_CLASSES[i]}: ${p.toFixed(6)}&lt;/li&gt;`\n  );\n});\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8936}"
1050,51396366,"{'items': [{'owner': {'reputation': 1229, 'user_id': 6280540}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1531901434, 'answer_id': 51396802, 'question_id': 51396366, 'body': '<p>For simple activation layers you can just use the Activation layer.</p>\n\n<pre><code>Activation(\'relu\')\n</code></pre>\n\n<p><a href=""https://keras.io/activations/"" rel=""nofollow noreferrer"">Available activations can be found here</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8936}"
1051,56231695,"{'items': [{'owner': {'reputation': 9218, 'user_id': 867889}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1558418350, 'answer_id': 56231916, 'question_id': 56231695, 'body': '<p>One would use this method to register the loss defined by user.</p>\n\n<p>Namely, if you have created a tensor that defines your loss, for example as <code>my_loss = tf.mean(output)</code> you can use this method to add it to loss collection. You might want to do that if you are not tracking all your losses manually. For example if you are using a method like <code>tf.losses.get_total_loss()</code>.</p>\n\n<p>Inside <code>tf.losses.add_loss</code> is very much straightforward:</p>\n\n<pre><code>def add_loss(loss, loss_collection=ops.GraphKeys.LOSSES):\n  if loss_collection and not context.executing_eagerly():\n    ops.add_to_collection(loss_collection, loss)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8932}"
1052,59528975,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8932}"
1053,61884176,"{'items': [{'owner': {'reputation': 43, 'user_id': 13544655}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1589872530, 'answer_id': 61885247, 'question_id': 61884176, 'body': ""<p>Name scopes are entirely for naming convenience. It has nothing to do with python scope. Whenever you perform an operation in tensorflow it will get a name according to some state maintained by tensorflow, but if you want those operations to be named clearly for your use case then name scope is used. Any operation within the name scope will have the provided value appended in it's name, there is no use more than that. Regarding the implementation, I highly doubt that those scope implementations will be exposed in python. All tensor creation operations are executed by C++ backend of tensorflow, so scopes should be mostly handled by them</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8932}"
1054,68431633,"{'items': [{'owner': {'reputation': 1637, 'user_id': 5523920}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1626890413, 'answer_id': 68474421, 'question_id': 68431633, 'body': '<p><code>random_crop</code> always return the same sequence of crops only when <strong>both</strong> global seed <strong>and</strong> operation seed are set.</p>\n<ol>\n<li>global seed is set using <code>tf.random.set_seed(global_seed)</code></li>\n<li>operation seed is set by passing the seed argument into the operation, i.e., <code>tf.image.random_crop(value, size, seed=ops_seed)</code></li>\n</ol>\n<p>whereas what <code>stateless_random_crop</code> returns is totally determined by the seed you pass into it when the device and tensorflow version are unchanged.</p>\n<p>And you are correct that the functions look redundant and duplicate but actually <code>tf.image.random_crop</code> is from the old RNGs API and it may be buggy in graph mode. The new RNGs API is <code>tf.random.Generator</code> and the stateless RNGs. For more information, see <a href=""https://www.tensorflow.org/guide/random_numbers"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/random_numbers</a></p>\n<p>Using <code>tf.random.Generator</code> in combination with <code>stateless_random_crop</code>:</p>\n<pre><code>class new_RNGs_random_crop:\n  def __init__(self,seed,size):\n    self.rand_generator=tf.random.Generator.from_seed(seed)\n    self.size=size\n  def random_crop(self,x):\n    return tf.image.stateless_random_crop(x,self.size,\n           seed=self.rand_generator.uniform_full_int([2],dtype=tf.int32))\n\ndummy_dataset=tf.data.Dataset.from_tensor_slices(np.arange(2*3*3).reshape((2,3,3))).batch(1)\ncropper=new_RNGs_random_crop(88883,(1,2,2))\ndummy_dataset=dummy_dataset.map(cropper.random_crop)\n\nfor image in dummy_dataset:\n  print(image)\n</code></pre>\n<p>Example outputs:</p>\n<pre><code>tf.Tensor(\n[[[3 4]\n  [6 7]]], shape=(1, 2, 2), dtype=int64)\ntf.Tensor(\n[[[ 9 10]\n  [12 13]]], shape=(1, 2, 2), dtype=int64)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8932}"
1055,50263822,"{'items': [{'owner': {'reputation': 5186, 'user_id': 992489}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1526062999, 'answer_id': 50298156, 'question_id': 50263822, 'body': ""<p>They are essentially the same, and it doesn't matter which one you use. The <code>tf.keras.layers</code> layers have guaranteed compatibility with the keras API, but that's the only difference.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8928}"
1056,76447508,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8928}"
1057,48224021,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8928}"
1058,66049816,"{'items': [{'owner': {'reputation': 805, 'user_id': 9875707}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1613072107, 'answer_id': 66161614, 'question_id': 66049816, 'body': '<p>As they were saying in the comments, do no introduce the input when defining the model. That is:</p>\n<pre><code>def build_model():\n    model = keras.Sequential([\n        MyDenseLayer(10),\n        keras.layers.Activation(tf.nn.relu),\n        keras.layers.Dense(1, activation=tf.nn.relu)\n        ])\n    return model\n</code></pre>\n<p>And then you can try:</p>\n<pre><code>model = build_model()\nmodel(tf.random.uniform((100, 100)))\n</code></pre>\n<p>P.S: question has been laying around for days, but this was solved by @Marco Cerliani (I can delete it in any case)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8928}"
1059,51330841,"{'items': [{'owner': {'reputation': 140, 'user_id': 1446639}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1536863799, 'answer_id': 52319880, 'question_id': 51330841, 'body': ""<p>As you figured out, estimator automatically saves an restores the model for you during the training. export_savemodel might be useful if you want to deploy you model to the field (for example providing the best model for Tensorflow Serving). </p>\n\n<p>Here is a simple example:</p>\n\n<pre><code>est.export_savedmodel(export_dir_base=FLAGS.export_dir, serving_input_receiver_fn=serving_input_fn)\n</code></pre>\n\n<p><code>def serving_input_fn():\n    inputs = {'features': tf.placeholder(tf.float32, [None, 128, 128, 3])}\n    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n</code></p>\n\n<p>Basically serving_input_fn is responsible for replacing dataset pipelines with a placeholder. In the deployment you can feed data to this placeholder as the input to your model for inference or prediction.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8928}"
1060,44244763,"{'items': [{'owner': {'reputation': 36, 'user_id': 5353723}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1496074477, 'answer_id': 44246730, 'question_id': 44244763, 'body': ""<p>I think the problem is that the initial code creates dependencies between dummy identity ops implicitly created by <code>control_flow_ops.with_dependencies</code> and not the actual <code>tf.Print</code> ops. Tensorflow seems to only ensure that the ops in the dependency list have been already executed but the order of other preceding ops is not fixed. In the above example, the dependencies are created on the dummy identity ops created by <code>control_flow_ops.with_dependencies</code>:</p>\n\n<pre><code>    dependency = control_flow_ops.with_dependencies([dependency], x)\n</code></pre>\n\n<p>which should be equivalent to:</p>\n\n<pre><code>        with tf.control_dependencies([dependency]):\n            dependency = tf.identity(x)\n</code></pre>\n\n<p>Thus, the dependencies here are created between the <code>tf.identity</code> ops and not the <code>tf.Print</code> ops. The <code>tf.Print</code> ops can be run in any order, the strict ordering is only on the <code>tf.identity</code> ops. I don't think it is possible to achieve the desired behavior with <code>control_flow_ops.with_dependencies</code>. Instead one has to use <code>with tf.control_dependencies</code> instead (as already suggested by the op):</p>\n\n<pre><code>xs = [tf.constant(x) for x in range(10)]\ndependency = None\ndxs = []\n\nfor x in xs:\n    if dependency is None:\n        dependency = tf.Print(x, [x])\n    else:\n        with tf.control_dependencies([dependency]):\n            dependency = tf.Print(x, [x])\n\n    dxs.append(dependency)\n</code></pre>\n""}, {'owner': {'reputation': 33799, 'user_id': 127480}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1496068149, 'answer_id': 44244929, 'question_id': 44244763, 'body': '<p>Using <code>tf.control_dependencies</code> correctly does solve this problem:</p>\n\n<pre><code>import tensorflow as tf\n\nxs = [tf.constant(x) for x in range(10)]\ndependency = None\ndxs = []\n\nfor x in xs:\n    if dependency is None:\n        dependency = tf.Print(x, [x])\n    else:\n        with tf.control_dependencies([dependency]):\n            dependency = tf.Print(x, [x])\n\n    dxs.append(dependency)\n\nprint_all_op = tf.group(*dxs)\n\nwith tf.Session() as session:\n    session.run(print_all_op)\n</code></pre>\n\n<p>Note that the <code>Print</code> operation needs to be created within the <code>tf.control_dependencies</code> context manager.</p>\n\n<p>I am still unclear why the <code>control_flow_ops.with_dependencies</code> version fails.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8923}"
1061,60761888,"{'items': [{'owner': {'reputation': 85288, 'user_id': 2097240}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1584639046, 'answer_id': 60762283, 'question_id': 60761888, 'body': '<p>No custom layer has ""input"" layers. That doesn\'t make much sense. The input is what you pass to the layer when you call it. </p>\n\n<p>So:</p>\n\n<pre><code>import tensorflow as tf\n\nclass ConvBN(tf.keras.layers.Layer):\n    def __init__(self, activation, name):\n        super().__init__()\n\n        #here you just ""store"" the layers, you don\'t use them\n        #you also store any other property you find necessary for the call\n        self.conv = tf.keras.layers.Conv2D(\n            filters=16,\n            kernel_size=3,\n            strides=(1, 1),\n            padding=""same"",\n            name = name+\'_conv\'\n        )\n       self.bn = tf.keras.layers.BatchNormalization(name = name + ""_bn"")\n       self.activation = tf.keras.layers.Activation(activation, name = name + ""_act"")\n\n    def call(self, inputs):\n        #here you ""use"" the layers with the given input to produce an output\n        out = self.conv(inputs)\n        out = self.bn(out)\n        out = self.activation(out)\n\n        return out\n</code></pre>\n\n<p>You could also, if you\'re not going to use ""the same layer"" more than once, create simpler bloks:</p>\n\n<pre><code>def convGroup(input_tensor, activation, name):\n    out = tf.keras.layers.Conv2D(\n            filters=16,\n            kernel_size=3,\n            strides=(1, 1),\n            padding=""same"",\n            name = name+\'_conv\'\n        )(input_tensor)\n    out = tf.keras.layers.BatchNormalization(name = name + ""_bn"")(out)\n    out = tf.keras.layers.Activation(activation, name = name + ""_act"")(out)\n\n    return out\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8923}"
1062,44103457,"{'items': [{'owner': {'reputation': 543, 'user_id': 6433136}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1495543350, 'answer_id': 44135179, 'question_id': 44103457, 'body': '<p>The tf.Variable() Op is using the ""initial"" variable as its initial value.  If you look at the help for <a href=""https://www.tensorflow.org/api_docs/python/tf/Variable"" rel=""nofollow noreferrer"">Variable</a>, you will see the first parameter in the _ <em>init</em> _ method is ""initial_value"".</p>\n\n<p>Your code calls ""tf.initialize_all_variables()"" only once which calls the initilaize op the ""tf.truncated_normal"" which creates the [2,3] matrix to initialize output to the same value.  Your code then prints 2 copies of that variable.  If you would like to re-init the variable, you need to explicitly state that like this:</p>\n\n<pre><code>initial = tf.truncated_normal([2,3], mean=100.0, stddev = 10.0)\noutput = tf.Variable(initial)\nsess = tf.InteractiveSession()\nsess.run(tf.initialize_all_variables())\nprint output.eval()\nsess.run(tf.initialize_all_variables())\nprint output.eval()\n</code></pre>\n\n<p>This might not be the functionality you are looking for as this has the side effect or re-initializing all variables (trainging weights, etc).</p>\n\n<p>If you are looking to get just the random data set, call the initial op directly.  Also note, since you don\'t have any variables or other Ops that require initialization you don\'t need that Op to execute to prepare the graph.</p>\n\n<pre><code>initial = tf.truncated_normal([2,3], mean=100.0, stddev = 10.0)\nsess = tf.InteractiveSession()\nprint initial.eval() \nprint initial.eval()\n</code></pre>\n\n<p>You can directly mix the ""initial"" op with math operators as well.  So if you are looking for random variable at each sess.run() don\'t use a variable but use the initial Op directly.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8923}"
1063,50210594,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8923}"
1064,48815906,"{'items': [{'owner': {'reputation': 2146, 'user_id': 3086290}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': True, 'score': 11, 'creation_date': 1521210684, 'answer_id': 49323191, 'question_id': 48815906, 'body': '<p>Here is a <code>EarlyStoppingHook</code> sample implementation:</p>\n\n<pre class=""lang-py prettyprint-override""><code>import numpy as np\nimport tensorflow as tf\nimport logging\nfrom tensorflow.python.training import session_run_hook\n\n\nclass EarlyStoppingHook(session_run_hook.SessionRunHook):\n    """"""Hook that requests stop at a specified step.""""""\n\n    def __init__(self, monitor=\'val_loss\', min_delta=0, patience=0,\n                 mode=\'auto\'):\n        """"""\n        """"""\n        self.monitor = monitor\n        self.patience = patience\n        self.min_delta = min_delta\n        self.wait = 0\n        if mode not in [\'auto\', \'min\', \'max\']:\n            logging.warning(\'EarlyStopping mode %s is unknown, \'\n                            \'fallback to auto mode.\', mode, RuntimeWarning)\n            mode = \'auto\'\n\n        if mode == \'min\':\n            self.monitor_op = np.less\n        elif mode == \'max\':\n            self.monitor_op = np.greater\n        else:\n            if \'acc\' in self.monitor:\n                self.monitor_op = np.greater\n            else:\n                self.monitor_op = np.less\n\n        if self.monitor_op == np.greater:\n            self.min_delta *= 1\n        else:\n            self.min_delta *= -1\n\n        self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n\n    def begin(self):\n        # Convert names to tensors if given\n        graph = tf.get_default_graph()\n        self.monitor = graph.as_graph_element(self.monitor)\n        if isinstance(self.monitor, tf.Operation):\n            self.monitor = self.monitor.outputs[0]\n\n    def before_run(self, run_context):  # pylint: disable=unused-argument\n        return session_run_hook.SessionRunArgs(self.monitor)\n\n    def after_run(self, run_context, run_values):\n        current = run_values.results\n\n        if self.monitor_op(current - self.min_delta, self.best):\n            self.best = current\n            self.wait = 0\n        else:\n            self.wait += 1\n            if self.wait &gt;= self.patience:\n                run_context.request_stop()\n</code></pre>\n\n<p>This implementation is based on <a href=""https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/python/keras/_impl/keras/callbacks.py"" rel=""noreferrer"">Keras implementation</a>.</p>\n\n<p>To use it with CNN MNIST <a href=""https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/examples/tutorials/layers/cnn_mnist.py"" rel=""noreferrer"">example</a> create hook and pass it to <code>train</code>.</p>\n\n<pre class=""lang-py prettyprint-override""><code>early_stopping_hook = EarlyStoppingHook(monitor=\'sparse_softmax_cross_entropy_loss/value\', patience=10)\n\nmnist_classifier.train(\n  input_fn=train_input_fn,\n  steps=20000,\n  hooks=[logging_hook, early_stopping_hook])\n</code></pre>\n\n<p>Here <code>sparse_softmax_cross_entropy_loss/value</code> is the name of the loss op in that example.</p>\n\n<p><strong>EDIT 1:</strong></p>\n\n<p>It looks like there is no ""official"" way of finding loss node when using estimators (or I can\'t find it). </p>\n\n<p>For the <code>DNNRegressor</code> this node has name <code>dnn/head/weighted_loss/Sum</code>.</p>\n\n<p>Here is how to find it in the graph:</p>\n\n<ol>\n<li><p>Start tensorboard in model directory. In my case I didn\'t set any directory so estimator used temporary directory and printed this line:<br>\n<code>WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpInj8SC</code><br>\nStart tensorboard:</p>\n\n<pre><code>tensorboard --logdir /tmp/tmpInj8SC\n</code></pre></li>\n<li><p>Open it in browser and navigate to GRAPHS tab.\n<a href=""https://i.stack.imgur.com/yCyL2.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/yCyL2.png"" alt=""enter image description here""></a></p></li>\n<li><p>Find loss in the graph. Expand blocks in the sequence: <code>dnn</code>  <code>head</code>  <code>weighted_loss</code> and click on the <code>Sum</code> node (note that there is summary node named <code>loss</code> connected to it).\n<a href=""https://i.stack.imgur.com/TP0zO.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/TP0zO.png"" alt=""enter image description here""></a></p></li>\n<li><p>Name shown in the info ""window"" to the right is the name of the selected node, that need to be passed to <code>monitor</code> argument pf <code>EarlyStoppingHook</code>.</p></li>\n</ol>\n\n<p>Loss node of the <code>DNNClassifier</code> has the same name by default. Both <code>DNNClassifier</code> and <code>DNNRegressor</code> have optional argument <code>loss_reduction</code> that influences loss node name and behavior (defaults to <code>losses.Reduction.SUM</code>).</p>\n\n<p><strong>EDIT 2:</strong></p>\n\n<p>There is a way of finding loss without looking at the graph.<br>\nYou can use <code>GraphKeys.LOSSES</code> collection to get the loss. But this way will work only after training started. So you can use it only in a hook. </p>\n\n<p>For example you can remove <code>monitor</code> argument from the <code>EarlyStoppingHook</code> class and change its <code>begin</code> function to always use the first loss in the collection: </p>\n\n<pre class=""lang-py prettyprint-override""><code>self.monitor = tf.get_default_graph().get_collection(tf.GraphKeys.LOSSES)[0]\n</code></pre>\n\n<p>You also probably need to check that there is a loss in the collection.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8923}"
1065,58867494,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1591541409, 'answer_id': 62247080, 'question_id': 58867494, 'body': ""<p>This might be a bug in <code>Tensorflow Version 2.0</code> but it is fixed in <code>Tensorflow Version 2.1</code>.</p>\n\n<p>So, please upgrade your Tensorflow Version to either <code>2.1</code> or <code>2.2</code> and the issue will be resolved.</p>\n\n<p>Working code is mentioned below:</p>\n\n<pre><code>!pip install tensorflow==2.2\n\nimport tensorflow as tf\nprint(tf.__version__)\n\nimg_arr = tf.keras.Input(shape = (100,100,3))\ntf.image.resize(img_arr, [224, 224]) # works\ntf.image.resize_with_pad(img_arr, 224, 224) # # works now in TF &gt;= 2.1\n</code></pre>\n\n<p>Output:</p>\n\n<pre><code>2.2.0\n\n&lt;tf.Tensor 'Pad_1:0' shape=(None, 224, 224, 3) dtype=float32&gt;\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8918}"
1066,37044006,"{'items': [{'owner': {'reputation': 8427, 'user_id': 691733}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': True, 'score': 7, 'creation_date': 1462460343, 'answer_id': 37053896, 'question_id': 37044006, 'body': '<p>The problem is in the first argument to <code>tf.cond</code>. From the documentation <a href=""https://www.tensorflow.org/versions/r0.8/api_docs/python/control_flow_ops.html#cond"">here</a>, about the type of the first argument to <code>tf.cond</code> :</p>\n\n<pre><code>pred: A scalar determining whether to return the result of fn1 or fn2.\n</code></pre>\n\n<p>Note that it has to be a <strong>scalar</strong>. You are using the result of comparing a tensor and a tensor, which gives you a <code>(1,)</code> <strong>tensor</strong>, <em>NOT</em> a scalar. You can convert it to a scalar using the <a href=""https://www.tensorflow.org/versions/r0.8/api_docs/python/array_ops.html#reshape""><code>tf.reshape</code></a> operator as follows :</p>\n\n<pre><code>t = tf.equal(x_stretch, WORKING, name=""is_stretch_x"")\nx_list_stretched = tf.cond(tf.reshape(t, []),\n                           create_mult_func(tf, amount, x_list), create_no_op_func(x_list))\n</code></pre>\n\n<p>Complete working program :</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nX = tf.constant([1, 0])\nY = tf.constant([0, 1])\nBOTH = tf.constant([1, 1])\nWORKING = tf.constant(1)\n\ndef create_mult_func(tf, amount, list):\n    def f1():\n        return tf.scalar_mul(amount, list)\n    return f1\n\ndef create_no_op_func(tensor):\n    def f1():\n        return tensor\n    return f1\n\ndef stretch(tf, points, dim, amount):\n    """"""points is a 2 by ??? tensor, dim is a 1 by 2 tensor, amount is tensor scalor""""""\n    x_list, y_list = tf.split(0, 2, points)\n    x_stretch, y_stretch = tf.split(0, 2, dim)\n    is_stretch_X = tf.equal(x_stretch, WORKING, name=""is_stretch_x"")\n    is_stretch_Y = tf.equal(y_stretch, WORKING, name=""is_stretch_Y"")\n    x_list_stretched = tf.cond(tf.reshape(is_stretch_X, []),\n                               create_mult_func(tf, amount, x_list), create_no_op_func(x_list))\n    y_list_stretched = tf.cond(tf.reshape(is_stretch_Y, []),\n                               create_mult_func(tf, amount, y_list), create_no_op_func(y_list))\n    return tf.pack([x_list_stretched, y_list_stretched])\n\nexample_points = np.array([[1, 1], [2, 2]], dtype=np.float32)\nexample_point_list = tf.placeholder(tf.float32)\n\nresult = stretch(tf, example_point_list, X, 1)\nsess = tf.Session()\n\nwith tf.Session() as sess:\n    result = sess.run(result, feed_dict={example_point_list: example_points})\n    print(result)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8918}"
1067,34619177,"{'items': [{'owner': {'reputation': 1, 'user_id': 9916645}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1619948930, 'answer_id': 67354959, 'question_id': 34619177, 'body': '<p>this explanation complements:</p>\n<p><a href=""https://stackoverflow.com/questions/44410135/keras-conv2d-own-filters/45865398#45865398"">Keras Conv2d own filters</a></p>\n<p>I had some doubts about the <em>filter</em> parameters in keras.conv2d because when I learned I was supposed to set my own filter design. But this parameters tells how many filters to test and keras itself will try to find the best filters weights.</p>\n'}, {'owner': {'reputation': 83, 'user_id': 5847573}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1604310020, 'answer_id': 64643042, 'question_id': 34619177, 'body': ""<p>It's performing convulition throught the picture when you are trying for example image classifation thuis function has all the parameters need to do that.</p>\n<p>When you are basically can chose the filter dimension. Strides. Padding. Before to used its need to undestant the concepts of convolution</p>\n""}, {'owner': {'reputation': 216387, 'user_id': 1090562}, 'down_vote_count': 0, 'up_vote_count': 73, 'is_accepted': True, 'score': 73, 'creation_date': 1495414764, 'answer_id': 44103248, 'question_id': 34619177, 'body': '<p>2D convolution is computed in a similar way one would calculate <a href=""http://www.riptutorial.com/tensorflow/example/30750/math-behind-1d-convolution-with-advanced-examples-in-tf"" rel=""noreferrer"">1D convolution</a>: you slide your kernel over the input, calculate the element-wise multiplications and sum them up. But instead of your kernel/input being an array, here they are matrices.</p>\n\n<hr>\n\n<p>In the most basic example there is no padding and stride=1. Let\'s assume your <code>input</code> and <code>kernel</code> are:\n<a href=""https://i.stack.imgur.com/yTCl8.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/yTCl8.png"" alt=""enter image description here""></a></p>\n\n<p>When you use your kernel you will receive the following output: <a href=""https://i.stack.imgur.com/TPhBi.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/TPhBi.png"" alt=""enter image description here""></a>, which is calculated in the following way:</p>\n\n<ul>\n<li>14 = 4 * 1 + 3 * 0 + 1 * 1 + 2 * 2 + 1 * 1 + 0 * 0 + 1 * 0 + 2 * 0 + 4 * 1</li>\n<li>6  = 3 * 1 + 1 * 0 + 0 * 1 + 1 * 2 + 0 * 1 + 1 * 0 + 2 * 0 + 4 * 0 + 1 * 1</li>\n<li>6  = 2 * 1 + 1 * 0 + 0 * 1 + 1 * 2 + 2 * 1 + 4 * 0 + 3 * 0 + 1 * 0 + 0 * 1</li>\n<li>12 = 1 * 1 + 0 * 0 + 1 * 1 + 2 * 2 + 4 * 1 + 1 * 0 + 1 * 0 + 0 * 0 + 2 * 1</li>\n</ul>\n\n<p>TF\'s <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv2d"" rel=""noreferrer"">conv2d</a> function calculates convolutions in batches and uses a slightly different format. For an input it is <code>[batch, in_height, in_width, in_channels]</code> for the kernel it is <code>[filter_height, filter_width, in_channels, out_channels]</code>. So we need to provide the data in the correct format:</p>\n\n<pre><code>import tensorflow as tf\nk = tf.constant([\n    [1, 0, 1],\n    [2, 1, 0],\n    [0, 0, 1]\n], dtype=tf.float32, name=\'k\')\ni = tf.constant([\n    [4, 3, 1, 0],\n    [2, 1, 0, 1],\n    [1, 2, 4, 1],\n    [3, 1, 0, 2]\n], dtype=tf.float32, name=\'i\')\nkernel = tf.reshape(k, [3, 3, 1, 1], name=\'kernel\')\nimage  = tf.reshape(i, [1, 4, 4, 1], name=\'image\')\n</code></pre>\n\n<p>Afterwards the convolution is computed with:</p>\n\n<pre><code>res = tf.squeeze(tf.nn.conv2d(image, kernel, [1, 1, 1, 1], ""VALID""))\n# VALID means no padding\nwith tf.Session() as sess:\n   print sess.run(res)\n</code></pre>\n\n<p>And will be equivalent to the one we calculated by hand. </p>\n\n<hr>\n\n<p>For <a href=""http://www.riptutorial.com/tensorflow/example/30755/some-padding--strides-1"" rel=""noreferrer"">examples with padding/strides, take a look here</a>.</p>\n'}, {'owner': {'reputation': 477, 'user_id': 8190089}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1528236179, 'answer_id': 50709573, 'question_id': 34619177, 'body': '<p>In addition to other answers, conv2d operation is operating in c++ (cpu) or cuda for gpu machines that requires to flatten and reshape data in certain way and use gemmBLAS or cuBLAS(cuda) matrix multiplication.</p>\n'}, {'owner': {'reputation': 81, 'user_id': 8685078}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': False, 'score': 8, 'creation_date': 1506537128, 'answer_id': 46454888, 'question_id': 34619177, 'body': ""<p>I tried to implement conv2d (for my studying). Well, I wrote that:</p>\n\n<pre><code>def conv(ix, w):\n   # filter shape: [filter_height, filter_width, in_channels, out_channels]\n   # flatten filters\n   filter_height = int(w.shape[0])\n   filter_width = int(w.shape[1])\n   in_channels = int(w.shape[2])\n   out_channels = int(w.shape[3])\n   ix_height = int(ix.shape[1])\n   ix_width = int(ix.shape[2])\n   ix_channels = int(ix.shape[3])\n   filter_shape = [filter_height, filter_width, in_channels, out_channels]\n   flat_w = tf.reshape(w, [filter_height * filter_width * in_channels, out_channels])\n   patches = tf.extract_image_patches(\n       ix,\n       ksizes=[1, filter_height, filter_width, 1],\n       strides=[1, 1, 1, 1],\n       rates=[1, 1, 1, 1],\n       padding='SAME'\n   )\n   patches_reshaped = tf.reshape(patches, [-1, ix_height, ix_width, filter_height * filter_width * ix_channels])\n   feature_maps = []\n   for i in range(out_channels):\n       feature_map = tf.reduce_sum(tf.multiply(flat_w[:, i], patches_reshaped), axis=3, keep_dims=True)\n       feature_maps.append(feature_map)\n   features = tf.concat(feature_maps, axis=3)\n   return features\n</code></pre>\n\n<p>Hope I did it properly. Checked on MNIST, had very close results (but this implementation is slower). I hope this helps you.</p>\n""}, {'owner': {'reputation': 143, 'user_id': 7378751}, 'down_vote_count': 0, 'up_vote_count': 12, 'is_accepted': False, 'score': 12, 'creation_date': 1499945731, 'answer_id': 45079451, 'question_id': 34619177, 'body': ""<p>Just to add to the other answers, you should think of the parameters in </p>\n\n<pre><code>filter = tf.Variable(tf.random_normal([3,3,5,7]))\n</code></pre>\n\n<p>as '5' corresponding to the number of channels in each filter. Each filter is a 3d cube, with a depth of 5. Your filter depth must correspond to your input image's depth. The last parameter, 7, should be thought of as the number of filters in the batch. Just forget about this being 4D, and instead imagine that you have a set or a batch of 7 filters. What you do is create 7 filter cubes with dimensions (3,3,5).</p>\n\n<p>It is a lot easier to visualize in the Fourier domain since convolution becomes point-wise multiplication. For an input image of dimensions (100,100,3) you can rewrite the filter dimensions as</p>\n\n<pre><code>filter = tf.Variable(tf.random_normal([100,100,3,7]))\n</code></pre>\n\n<p>In order to obtain one of the 7 output feature maps, we simply perform the point-wise multiplication of the filter cube with the image cube, then we sum the results across the channels/depth dimension (here it's 3), collapsing to a 2d (100,100) feature map. Do this with each filter cube, and you get 7 2D feature maps.</p>\n""}, {'owner': {'reputation': 6287, 'user_id': 997378}, 'down_vote_count': 2, 'up_vote_count': 167, 'is_accepted': False, 'score': 165, 'creation_date': 1452368715, 'answer_id': 34698115, 'question_id': 34619177, 'body': '<p>Ok I think this is about the simplest way to explain it all.</p>\n\n<hr>\n\n<p>Your example is 1 image, size 2x2, with 1 channel. You have 1 filter, with size 1x1, and 1 channel (size is height x width x channels x number of filters). </p>\n\n<p>For this simple case the resulting 2x2, 1 channel image (size 1x2x2x1, number of images x height x width x x channels) is the result of multiplying the filter value by each pixel of the image.</p>\n\n<hr>\n\n<p>Now let\'s try more channels:</p>\n\n<pre class=""lang-py prettyprint-override""><code>input = tf.Variable(tf.random_normal([1,3,3,5]))\nfilter = tf.Variable(tf.random_normal([1,1,5,1]))\n\nop = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'VALID\')\n</code></pre>\n\n<p>Here the 3x3 image and the 1x1 filter each have 5 channels. The resulting image will be 3x3 with 1 channel (size 1x3x3x1), where the value of each pixel is the dot product across channels of the filter with the corresponding pixel in the input image.</p>\n\n<hr>\n\n<p>Now with a 3x3 filter</p>\n\n<pre class=""lang-py prettyprint-override""><code>input = tf.Variable(tf.random_normal([1,3,3,5]))\nfilter = tf.Variable(tf.random_normal([3,3,5,1]))\n\nop = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'VALID\')\n</code></pre>\n\n<p>Here we get a 1x1 image, with 1 channel (size 1x1x1x1). The value is the sum of the 9, 5-element dot products. But you could just call this a 45-element dot product.</p>\n\n<hr>\n\n<p>Now with a bigger image</p>\n\n<pre class=""lang-py prettyprint-override""><code>input = tf.Variable(tf.random_normal([1,5,5,5]))\nfilter = tf.Variable(tf.random_normal([3,3,5,1]))\n\nop = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'VALID\')\n</code></pre>\n\n<p>The output is a 3x3 1-channel image (size 1x3x3x1). \nEach of these values is a sum of 9, 5-element dot products. </p>\n\n<p>Each output is made by centering the filter on one of the 9 center pixels of the input image, so that none of the filter sticks out. The <code>x</code>s below represent the filter centers for each output pixel.</p>\n\n<pre><code>.....\n.xxx.\n.xxx.\n.xxx.\n.....\n</code></pre>\n\n<hr>\n\n<p>Now with ""SAME"" padding:</p>\n\n<pre class=""lang-py prettyprint-override""><code>input = tf.Variable(tf.random_normal([1,5,5,5]))\nfilter = tf.Variable(tf.random_normal([3,3,5,1]))\n\nop = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'SAME\')\n</code></pre>\n\n<p>This gives a 5x5 output image (size 1x5x5x1). This is done by centering the filter at each position on the image. </p>\n\n<p>Any of the 5-element dot products where the filter sticks out past the edge of the image get a value of zero. </p>\n\n<p>So the corners are only sums of 4, 5-element dot products.</p>\n\n<hr>\n\n<p>Now with multiple filters.</p>\n\n<pre class=""lang-py prettyprint-override""><code>input = tf.Variable(tf.random_normal([1,5,5,5]))\nfilter = tf.Variable(tf.random_normal([3,3,5,7]))\n\nop = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding=\'SAME\')\n</code></pre>\n\n<p>This still gives a 5x5 output image, but with 7 channels (size 1x5x5x7). Where each channel is produced by one of the filters in the set.</p>\n\n<hr>\n\n<p>Now with strides 2,2:</p>\n\n<pre class=""lang-py prettyprint-override""><code>input = tf.Variable(tf.random_normal([1,5,5,5]))\nfilter = tf.Variable(tf.random_normal([3,3,5,7]))\n\nop = tf.nn.conv2d(input, filter, strides=[1, 2, 2, 1], padding=\'SAME\')\n</code></pre>\n\n<p>Now the result still has 7 channels, but is only 3x3 (size 1x3x3x7).</p>\n\n<p>This is because instead of centering the filters at every point on the image, the filters are centered at every other point on the image, taking steps (strides) of width 2. The <code>x</code>\'s below represent the filter center for each output pixel, on the input image.</p>\n\n<pre><code>x.x.x\n.....\nx.x.x\n.....\nx.x.x\n</code></pre>\n\n<hr>\n\n<p>And of course the first dimension of the input is the number of images so you can apply it over a batch of 10 images, for example:</p>\n\n<pre class=""lang-py prettyprint-override""><code>input = tf.Variable(tf.random_normal([10,5,5,5]))\nfilter = tf.Variable(tf.random_normal([3,3,5,7]))\n\nop = tf.nn.conv2d(input, filter, strides=[1, 2, 2, 1], padding=\'SAME\')\n</code></pre>\n\n<p>This performs the same operation, for each image independently, giving a stack of 10 images as the result (size 10x3x3x7)  </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8918}"
1068,49542954,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8918}"
1069,56002345,"{'items': [{'owner': {'reputation': 1889, 'user_id': 4317543}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1557141187, 'answer_id': 56004047, 'question_id': 56002345, 'body': ""<p>You can use <code>get_weights()</code> on layers to get the weight values of particular layers. Here is an example code for your case:</p>\n\n<pre><code>import tensorflow as tf\n\ninput_x = tf.placeholder(tf.float32, [None, 3], name='x')    \ndense1 = tf.keras.Dense(3, activation='relu')\nl1 = dense1(input_x)\ndense2 = tf.keras.Dense(1)\ny = dense2(l1)\n\nweights = dense1.get_weights()\n</code></pre>\n\n<p>It can be done in a even simpler way with Keras API as follows:</p>\n\n<pre><code>def mymodel():\n    i = Input(shape=(3, ))\n    x = Dense(3, activation='relu')(i)\n    o = Dense(1)(x)\n\n    model = Model(input=i, output=o)\n    return model\n\n\nmodel = mymodel()\n\nnames = [weight.name for layer in model.layers for weight in layer.weights]\nweights = model.get_weights()\n\nfor name, weight in zip(names, weights):\n    print(name, weight.shape)\n</code></pre>\n\n<p>This example gets weight matrices for each layer of your model.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8914}"
1070,62236460,"{'items': [{'owner': {'reputation': 66044, 'user_id': 133374}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1647872113, 'answer_id': 71559081, 'question_id': 62236460, 'body': '<p>In addition to the answer by Slowpoke, reparameterization is another option. E.g. let\'s say you have a param <code>p</code> which should be bounded in [lower_bound,upper_bound], you could write:</p>\n<pre class=""lang-py prettyprint-override""><code>p_inner = tf.Variable(...)  # unbounded\np = tf.sigmoid(p_inner) * (upper_bound - lower_bound) + lower_bound\n</code></pre>\n<p>However, this will change the behavior of gradient descent.</p>\n'}, {'owner': {'reputation': 1069, 'user_id': 1692060}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1591536719, 'answer_id': 62246104, 'question_id': 62236460, 'body': '<p>It seems to me (I can be mistaken) that <strong>constrained optimization</strong> (you can google for it in tensorflow) is not exactly the case for which tensroflow was designed. You may want to take a look at <a href=""https://github.com/google-research/tensorflow_constrained_optimization"" rel=""noreferrer"">this repo</a>, it may satisfy your needs, but as far as I understand, it\'s still not solving arbitrary constrained optimization, just some classification problems with labels and features, compatible with precision/recall scores. </p>\n\n<p>If you want to use constraints on the tensorflow variable (i.e. some function applied after gradient step - which you can do manually also - by taking variable values, doing manipulations, and reassigning then), it means that you will be cutting variables after each step done using gradient in <em>general space</em>. It\'s a question whether you will successfully reach the right optimization goal this way, or your variables will stuck at boundaries, because <code>general</code> gradient will point somewhere outside.</p>\n\n<p><strong>My approach 1</strong></p>\n\n<p>If your problem is simple enough. you can try to parametrize your <code>x2</code> and <code>x3</code> as <code>x2 = x3 + t</code>, and then try to do cutting in the graph:</p>\n\n<pre><code>x3 = tf.get_variable(\'x3\',\n                   dtype=tf.float32,\n                   shape=(1,),\n                   initializer=tf.random_uniform_initializer(minval=1., maxval=10.),\n                   constraint=lambda z: tf.clip_by_value(z, 1, 10))\nt = tf.get_variable(\'t\',\n                   dtype=tf.float32,\n                   shape=(1,),\n                   initializer=tf.random_uniform_initializer(minval=1., maxval=10.),\n                   constraint=lambda z: tf.clip_by_value(z, 1, 10))\nx2 = x3 + t\n</code></pre>\n\n<p>Then, on a separate call additionally do</p>\n\n<p><code>sess.run(tf.assign(x2, tf.clip_by_value(x2, 1.0, 10.0)))</code></p>\n\n<p>But my opinion is that it won\'t work well. </p>\n\n<p><strong>My approach 2</strong></p>\n\n<p>I would also try to invent some loss terms to keep variables within constraints, which is more likely to work. For example, constraint for x2 to be in the interval <code>[1,10]</code> will be:</p>\n\n<p><code>loss += alpha*tf.abs(tf.math.tan(((x-5.5)/4.5)*pi/2))</code></p>\n\n<p>Here the expression under <code>tan</code> is brought to <code>-pi/2,pi/2</code> and then <code>tan</code> function is used to make it grow very rapidly when it reaches boundaries. In this case I think you\'re more likely to find your optimum, but again the loss weight <code>alpha</code> might be too big and training will stuck somewhere nearby, if required value of <code>x2</code> lies near the boundary. In this case you can try to use smaller <code>alpha</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8914}"
1071,52582188,"{'items': [{'owner': {'reputation': 11, 'user_id': 10410925}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1538347851, 'answer_id': 52582799, 'question_id': 52582188, 'body': '<p>I solve it by tf.case</p>\n\n<pre><code>pipeline = tf.case({tf.greater(global_step, tf.constant(5000,tf.int64)):images-pipe_3, tf.less(global_step, tf.constant(2000,tf.int64):images_pipe_1)}, default=images_pipe_2, exclusive=True)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8914}"
1072,44949292,"{'items': [{'owner': {'reputation': 18809, 'user_id': 1361822}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': False, 'score': 5, 'creation_date': 1499351629, 'answer_id': 44951916, 'question_id': 44949292, 'body': ""<p>Easy enough to confirm they are the same:</p>\n\n<pre><code>In [1]: import tensorflow as tf\n\nIn [2]: tf.nn.tanh\nOut[2]: &lt;function tensorflow.python.ops.math_ops.tanh&gt;\n\nIn [3]: tf.tanh\nOut[3]: &lt;function tensorflow.python.ops.math_ops.tanh&gt;\n\nIn [4]: tf.nn.tanh == tf.tanh\nOut[4]: True\n\nIn [5]: tf.__version__\nOut[5]: '0.11.0rc1'\n</code></pre>\n""}, {'owner': {'reputation': 81, 'user_id': 5587601}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1499347340, 'answer_id': 44950205, 'question_id': 44949292, 'body': ""<p>No there isn't any difference.</p>\n\n<p>The availability of both is probably due to the library evolving and still changing its API, being still in an initial state of maturing.\nWe could expect the library to avoid those fundamental duplications in the future when the main API is finally set (I'd expect so towards 2.0).</p>\n""}, {'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1499346030, 'answer_id': 44949661, 'question_id': 44949292, 'body': '<p>No, there\'s no difference.</p>\n\n<p>In the <code>tensorflow/tensorflow/python/ops/nn.py</code> file (that\'s where <code>tf.nn</code> is defined) we can find the definition of <code>tanh</code>:</p>\n\n<pre><code>from tensorflow.python.ops.math_ops import tanh\n</code></pre>\n\n<p>also, there\'s this <code>TODO</code> <a href=""https://github.com/tensorflow/tensorflow/blob/0b723590631432584d0761c03285eabb55116c6d/tensorflow/python/ops/nn.py"" rel=""nofollow noreferrer"">here</a></p>\n\n<pre><code># TODO(cwhipkey): sigmoid and tanh should not be exposed from tf.nn.\n</code></pre>\n\n<p>Thus, probably tanh will be removed from the <code>tf.nn</code> package.</p>\n\n<p>Hence <code>tf.tanh</code> (that\'s defined <a href=""https://github.com/tensorflow/tensorflow/blob/cf18c6d384a96a53b448bd51a90c117af0ed7c96/tensorflow/python/ops/math_ops.py"" rel=""nofollow noreferrer"">here</a>) is the one to use.</p>\n'}, {'owner': {'reputation': 23445, 'user_id': 1735003}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1499345994, 'answer_id': 44949647, 'question_id': 44949292, 'body': '<p>They are the exact same alias to <code>tensorflow.python.ops.math_ops.tanh</code>.</p>\n\n<p>Same thing goes for <code>tf.sigmoid</code> and <code>tf.nn.sigmoid</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8914}"
1073,61988657,"{'items': [{'owner': {'reputation': 153, 'user_id': 8142734}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1590337254, 'answer_id': 61988850, 'question_id': 61988657, 'body': '<p>The returned value represents the number of required indices to uniquely address each element (in your case 2). And 2 is a 0-dim tensor which explains why shape is null. Refer to the documentation for more infos.</p>\n'}, {'owner': {'reputation': 3807, 'user_id': 11070463}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1590336877, 'answer_id': 61988767, 'question_id': 61988657, 'body': ""<p>It's because the output of <code>tf.rank()</code> is a tensor itself. Instead of returning the rank as an integer, the output is a tensor with a single int32 value that represents the rank of the given input tensor. The shape <code>()</code> is the shape of the output value, not the input tensor (single value tensors have shape <code>()</code>).</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8914}"
1074,65437493,"{'items': [{'owner': {'reputation': 4213, 'user_id': 13509540}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1608952151, 'answer_id': 65453360, 'question_id': 65437493, 'body': ""<p>I believe this is what you want:</p>\n<pre><code>import pandas as pd\nimport tensorflow as tf\n\nd = {&quot;kw_text&quot;: [['amazon', 'google'], ['google', 'facebook', 'microsoft']], \n     &quot;kw_text_weight&quot;: [['0.5', '0.5'], ['0.5', '0.3', '0.2']]}\n\ndf = pd.DataFrame(d)\n\n# Convert string to float\nfor i in range(len(df.index)):\n    df['kw_text_weight'][i] = [float(s) for s in df['kw_text_weight'][i]]\n\n# Build dataset\nrt=tf.ragged.constant(df['kw_text_weight'].tolist())\nkw_text_weight_data = tf.data.Dataset.from_tensor_slices(rt)\n\nfor feature_batch in kw_text_weight_data:\n    print(feature_batch)\n</code></pre>\n<p>Outputs:</p>\n<pre><code>tf.Tensor([0.5 0.5], shape=(2,), dtype=float32)\ntf.Tensor([0.5 0.3 0.2], shape=(3,), dtype=float32)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8909}"
1075,59174710,"{'items': [{'owner': {'reputation': 2424, 'user_id': 2131957}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1575460626, 'answer_id': 59175498, 'question_id': 59174710, 'body': '<p>According to the function documentation </p>\n\n<blockquote>\n  <p>... It returns a list of Tensor of length len(xs) where each tensor is the sum(dy/dx) for y in ys.</p>\n</blockquote>\n\n<p>So this is exactly what you stated in the first part - each output tensor is a sum of ys <em>total</em> derivatives w.r.t. the corresponding x. </p>\n\n<p>The documentation suggests use of <code>stop_gradients</code> parameter to calculate partial derivatives instead, i.e. tensors provided for this parameter are considered constant in the differentiation. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8909}"
1076,65953591,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8909}"
1077,67872566,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8909}"
1078,70686521,"{'items': [{'owner': {'reputation': 13995, 'user_id': 12750353}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1642018985, 'answer_id': 70687917, 'question_id': 70686521, 'body': '<p>When you slice data like in <code>Data[:20]</code> it will produce a sequence with length <code>min(20, len(Data))</code>. So I guess your data has length less than 20.</p>\n<p>Other message says it has rank 2, so I guess it has one of the following shapes</p>\n<pre class=""lang-txt prettyprint-override""><code>       1   10272\n       2    5136\n       3    3424\n       4    2568\n       6    1712\n       8    1284\n      12     856\n      16     642\n</code></pre>\n<p>Any of those result in a tensor with <code>10272</code> elements as your first message shows, and that\'s not a multiple of 20.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8909}"
1079,60616507,"{'items': [{'owner': {'reputation': 2669, 'user_id': 262432}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1583842402, 'answer_id': 60617419, 'question_id': 60616507, 'body': '<p>There is no difference, it is <a href=""https://github.com/tensorflow/tensorflow/blob/f99cd711a9629fbdd801aaed2a5cae54c0daa870/tensorflow/python/eager/backprop.py#L720"" rel=""nofollow noreferrer"">the same class</a>:</p>\n\n<pre><code>@tf_export(""GradientTape"", ""autodiff.GradientTape"", v1=[""GradientTape""])\nclass GradientTape(object):\n  ...\n</code></pre>\n\n<p>TensorFlow internals generally do not use the public API and import other internal modules directly.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8904}"
1080,49370940,"{'items': [{'owner': {'reputation': 607, 'user_id': 3921232}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1521619217, 'answer_id': 49400941, 'question_id': 49370940, 'body': '<p>I found a nice answer based on pure python, unfortunately I do not find the source anymore. It first converts every char to an int, and then replaces the int with an one-hot array. It has unicity over the whole program, even over all programms if the alphabet is the same length and the same order.</p>\n\n<pre><code>    # Is the alphabet of all possible chars you want to convert\n    alphabet = ""abcdefghijklmnopqrstuvwxyz0123456789""\n\n    def convert_to_onehot(data):\n        #Creates a dict, that maps to every char of alphabet an unique int based on position\n        char_to_int = dict((c,i) for i,c in enumerate(alphabet))\n        encoded_data = []\n        #Replaces every char in data with the mapped int\n        encoded_data.append([char_to_int[char] for char in data])\n        print(encoded_data) # Prints the int encoded array\n\n        #This part now replaces the int by an one-hot array with size alphabet\n        one_hot = []\n        for value in encoded_data:\n            #At first, the whole array is initialized with 0\n            letter = [0 for _ in range(len(alphabet))]\n            #Only at the number of the int, 1 is written\n            letter[value] = 1\n            one_hot.append(letter)\n        return one_hot\n\n   print(convert_to_onehot(""hello world""))\n</code></pre>\n'}, {'owner': {'reputation': 525, 'user_id': 1508542}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1521492737, 'answer_id': 49372190, 'question_id': 49370940, 'body': '<p>You can use keras <code>to_categorical</code></p>\n\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n# define the document\ntext = \'The quick brown fox jumped over the lazy dog.\'\n# estimate the size of the vocabulary\nwords = set(tf.keras.preprocessing.text.text_to_word_sequence(text))\nvocab_size = len(words)\nprint(vocab_size)\n# integer encode the document\nresult = tf.keras.utils.to_categorical(tf.keras.preprocessing\n                                         .text.one_hot(text, round(vocab_size*1.3)))\nprint(result)\n</code></pre>\n\n<p>Result</p>\n\n<pre><code>[[1, 2, 3, 4, 5, 6, 1, 7, 8]]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8903}"
1081,73074491,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8903}"
1082,52959039,"{'items': [{'owner': {'reputation': 3596, 'user_id': 6780025}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1541643859, 'answer_id': 53200675, 'question_id': 52959039, 'body': '<p>The argument to <code>activation</code> should be a function that takes a tensor and returns a tensor. <code>tf.nn.leaky_relu</code> is such a function.</p>\n\n<p><code>tf.nn.leaky_relu(alpha = 0.001)</code> is not valid Python. You are not specifying the only required argument <code>features</code>. Python does not know how to run a function without a required argument. What you want is something like this:</p>\n\n<pre><code>def my_relu(features):\n    return tf.nn.leaky_relu(features, alpha=0.001)\n\ntf.layers.conv1d(..., activation=my_relu, ...)\n</code></pre>\n\n<p>The argument to <code>activity_regularizer</code> is a function taking your layer\'s activity (i.e. output) and computing a penalty for it. Usually you give high penalty for large activations. This function should output a scalar. I don\'t know why <code>activity_regularizer = tf.layers.batch_normalization</code> does not complain but it is probably doing not what you expect. Typical regularizers are <code>l1</code> and <code>l2</code> norms (see <a href=""https://keras.io/regularizers/"" rel=""nofollow noreferrer"">https://keras.io/regularizers/</a>). Batch normalization is a layer, not a regularizer.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8903}"
1083,38213440,"{'items': [{'owner': {'reputation': 5790, 'user_id': 1460422}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1658857722, 'answer_id': 73127716, 'question_id': 38213440, 'body': '<p>I\'m not sure what version of Tensorflow it was added in, but in Tensorflow 2.4 and above at least there is now a new function to get the length of a string: <code>tf.strings.length(string_tensor)</code>. Here\'s an example of it at work:</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\nstr_1 = tf.constant(&quot;yaaaaay&quot;)\nstr_2 = tf.constant(&quot;&quot;)\n\nprint(str_1)\nprint(str_2)\n\nprint(tf.strings.length(str_1))\nprint(tf.strings.length(str_2))\n</code></pre>\n<p>Example output:</p>\n<pre><code>tf.Tensor(b\'yaaaaay\', shape=(), dtype=string)\ntf.Tensor(b\'\', shape=(), dtype=string)\ntf.Tensor(7, shape=(), dtype=int32)\ntf.Tensor(0, shape=(), dtype=int32)\n</code></pre>\n'}, {'owner': {'reputation': 94, 'user_id': 6918405}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1504001293, 'answer_id': 45936319, 'question_id': 38213440, 'body': '<p>This works for me:</p>\n\n<pre><code>x = tf.constant(""Hello everyone"")\n\n# Launch the default graph.\nwith tf.Session() as sess:\n    print(tf.size(tf.string_split([x],"""")).eval())\n</code></pre>\n'}, {'owner': {'reputation': 6287, 'user_id': 997378}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1497879404, 'answer_id': 44632126, 'question_id': 38213440, 'body': '<p>Another sub-optimal option is to convert your strings to sparse:</p>\n\n<pre><code>strings = [\'Why hello\',\'world\',\'!\']\nchars = tf.string_split(strings,"""")\n</code></pre>\n\n<p>Then calculate the max index on each line +1</p>\n\n<pre><code>line_number = chars.indices[:,0]\nline_position = chars.indices[:,1]\nlengths = tf.segment_max(data = line_position, \n                         segment_ids = line_number) + 1\n\nwith tf.Session() as sess:\n    print(lengths.eval())\n\n[9 5 1]\n</code></pre>\n'}, {'owner': {'reputation': 8427, 'user_id': 691733}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1467762294, 'answer_id': 38214514, 'question_id': 38213440, 'body': '<p>No such function exists as of TensorFlow version 0.9. However, you can use <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/script_ops.html#py_func"" rel=""nofollow""><code>tf.py_func</code></a> to run arbitrary Python functions over TensorFlow tensors. Here is one way to get length of a TensorFlow string :</p>\n\n<pre><code>def string_length(t):\n  return tf.py_func(lambda p: [len(x) for x in p], [t], [tf.int64])[0]\n\na = tf.constant([""Hello everyone""], tf.string)\nsess = tf.InteractiveSession()\nsess.run(string_length(a))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8900}"
1084,46139202,"{'items': [{'owner': {'reputation': 3, 'user_id': 5423940}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1505041432, 'answer_id': 46140009, 'question_id': 46139202, 'body': ""<p>Nevermind, for those having the same problem I fixed it. In my model function i had:</p>\n\n<pre><code>input_layer = tf.reshape(features, [-1, 256, 256, 1])\n</code></pre>\n\n<p>Which raised the type error. To fix it you have to access the 'x' key in the features dictionary:</p>\n\n<pre><code>input_layer = tf.reshape(features['x'], [-1, 256, 256, 1]) \n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8900}"
1085,69672777,"{'items': [{'owner': {'reputation': 1418, 'user_id': 4292033}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1636040112, 'answer_id': 69841818, 'question_id': 69672777, 'body': ""<p>Maybe you could use a loop on the trainable variables? I know it's a basic idea.</p>\n<pre><code>with tf.GradientTape(persistent=True) as tape:\n    loss = tf.reduce_mean(model(x,training=True)**2)\n    g_list, h_list = [], []\n    for train_var in model.trainable_variables:\n      g = tape.gradient(loss, train_var)\n      g_list.append(g)\n      h_list.append(tape.jacobian(g, train_var))\n</code></pre>\n<p>You could also use a second loop before computing the Jacobian and try to concatenate the output lists.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8900}"
1086,55590729,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8900}"
1087,50153291,"{'items': [{'owner': {'reputation': 4810, 'user_id': 4320693}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': True, 'score': 8, 'creation_date': 1525346209, 'answer_id': 50153746, 'question_id': 50153291, 'body': '<p>All <a href=""https://www.tensorflow.org/api_docs/python/tf/DType#max"" rel=""noreferrer"">TensorFlow datatypes have the min and max properties</a>, that return the maximum and minimum values the type can hold. E.g.,</p>\n\n<pre><code>import tensorflow as tf\n\nprint( tf.float32.max )\n</code></pre>\n\n<p>Outputs:</p>\n\n<blockquote>\n  <p>3.4028235e+38</p>\n</blockquote>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8900}"
1088,61564748,"{'items': [{'owner': {'reputation': 233, 'user_id': 13323402}, 'down_vote_count': 0, 'up_vote_count': 19, 'is_accepted': False, 'score': 19, 'creation_date': 1595441390, 'answer_id': 63040620, 'question_id': 61564748, 'body': ""<p>They do indeed start to resemble each other as they are improved, so it is useful to see where they come from. Initially, the difference was that:</p>\n<ul>\n<li><code>@tf.function</code> turns python code into a series of TensorFlow graph nodes.</li>\n<li><code>tf.py_function</code> wraps an existing python function into a single graph node.</li>\n</ul>\n<p>This means that <code>tf.function</code> requires your code to be relatively simple while <code>tf.py_function</code> can handle any python code, no matter how complex.</p>\n<p>While this line is indeed blurring, with <code>tf.py_function</code> doing more interpretation and <code>tf.function</code> accepting lot's of complex python commands, the general rule stays the same:</p>\n<ul>\n<li>If you have relatively simple logic in your python code, use <code>tf.function</code>.</li>\n<li>When you use complex code, like large external libraries (e.g. connecting to a database, or loading a large external NLP package) use <code>tf.py_function</code>.</li>\n</ul>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8895}"
1089,45428557,"{'items': [{'owner': {'reputation': 3532, 'user_id': 7590993}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1501560255, 'answer_id': 45428789, 'question_id': 45428557, 'body': '<p>use set to find the unique ..diff the len and append trailing 0</p>\n\n<pre><code>x = [1, 1, 2, 4, 4, 4, 7, 8, 8]\nlength = len(x)\n\nprint(length)\ny = list(set(x))\n\nprint(y)\npad = length - len(list(set(x)))\n\nfor index in range(0,pad):\n    y.append(0)\n\n\nprint(y)\n</code></pre>\n\n<p>Output</p>\n\n<pre><code>9\n[1, 2, 4, 7, 8]\n[1, 2, 4, 7, 8, 0, 0, 0, 0]\n</code></pre>\n'}, {'owner': {'reputation': 16941, 'user_id': 8143158}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1501560135, 'answer_id': 45428768, 'question_id': 45428557, 'body': '<p>You can use <code>tf.pad</code> to pad the zeros after calling <code>tf.unique</code>.</p>\n\n<pre><code>x = tf.placeholder(tf.int32, shape=(None))\ny, idx = tf.unique(x)\ny = tf.pad(y,[[0,(tf.shape(x) - tf.shape(y))[0]]])\n\nsess = tf.InteractiveSession()\nprint(sess.run(y, {x:np.random.randint(0,10, (10), dtype=np.int32)}))\n</code></pre>\n'}, {'owner': {'reputation': 1374, 'user_id': 6227912}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1501559609, 'answer_id': 45428687, 'question_id': 45428557, 'body': '<p>Your need separate treatment the problem.</p>\n\n<pre><code>y = [1, 2, 4, 7, 8]\nidx = [0, 0, 1, 2, 2, 2, 3, 4, 4]\n\nfor ii in range(0, len(idx) - len(y)):\n    y.append(0)\n\nprint(y)\n</code></pre>\n\n<p>The output is</p>\n\n<pre><code>[1, 2, 4, 7, 8, 0, 0, 0, 0]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8895}"
1090,66367312,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8895}"
1091,58963793,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1591253052, 'answer_id': 62188422, 'question_id': 58963793, 'body': ""<p>As it clearly says in the error, it is expecting shape [2,2] for <code>assign_add</code> on v which is having the shape [2,2]. \nIf you try to give any shape other than the initial shape of the Tensor which you are trying to do <code>assign_add</code> the error will be given.  </p>\n\n<p>Below is the modified code with the expected shape for the operation.  </p>\n\n<pre><code>import tensorflow as tf\n\n# Create a variable.\nw = tf.constant([1, 2, 3, 4], tf.float32, shape=[2, 2])\n\n# Use the variable in the graph like any Tensor.\ny = tf.matmul(w,tf.constant([7, 8, 9, 10], tf.float32, shape=[2, 2]))\nv= tf.Variable(w)\n# The overloaded operators are available too.\nz = tf.sigmoid(w + y)\ntf.shape(z)\n# Assign a new value to the variable with `assign()` or a related method.\nv.assign(w + 1)\nprint(v)\nv.assign_add(tf.constant([1, 2, 3, 4], tf.float32, shape=[2, 2]))  \n</code></pre>\n\n<p>Output for v:  </p>\n\n<pre><code>&lt;tf.Variable 'UnreadVariable' shape=(2, 2) dtype=float32, numpy=\narray([[3., 5.],\n       [7., 9.]], dtype=float32)&gt; \n</code></pre>\n\n<p>Now the following Tensor comparison is returning <code>True</code>.  </p>\n\n<pre><code>tf.shape(v) == tf.shape(tf.constant([1.0, 21],tf.float32)) \n</code></pre>\n\n<blockquote>\n  <p><code>&lt;tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])&gt;</code> </p>\n</blockquote>\n\n<p>Coming to your <code>tf.Session()</code> question, in TensorFlow 2.0 eager execution is enabled by default, still, if you need to disable eager execution and can use <code>tf.Session</code> like below.</p>\n\n<pre><code>import tensorflow as tf\n\ntf.compat.v1.disable_eager_execution()\n\nhello = tf.constant('Hello, TensorFlow!')\n\nsess = tf.compat.v1.Session()\n\nprint(sess.run(hello)) \n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8895}"
1092,60708695,"{'items': [{'owner': {'reputation': 20653, 'user_id': 1346276}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1584373831, 'answer_id': 60709116, 'question_id': 60708695, 'body': '<p><code>if</code> statements are converted to <code>cond</code>, but that only takes scalar arguments for the predicate (and does no broadcasting).  Try <a href=""https://www.tensorflow.org/api_docs/python/tf/where"" rel=""nofollow noreferrer""><code>where</code></a> instead: </p>\n\n<pre><code>return tf.where(x &gt;= 0, (r**2 * x + 1)**(1/r) - 1/r, K.exp(r*x) - 1/r))\n</code></pre>\n\n<p>(Can\'t test this currently with TensorFlow, but that\'s at least how Numpy behaves...)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8895}"
1093,50036568,"{'items': [{'owner': {'reputation': 634, 'user_id': 9675667}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1524726899, 'answer_id': 50036981, 'question_id': 50036568, 'body': '<p>You do not actually want to calculate a gradient, you want to calculate the Jacobian. A gradient is the application of the nabla operator to a scalar function with respect to a vector while the Jacobian is simply a matrix where every element J_ij is the derivative of y_i with respect to x_j, which is what you want.</p>\n\n<p>This is still not implemented in Tensorflow, but has been discussed in detail <a href=""https://github.com/tensorflow/tensorflow/issues/675"" rel=""nofollow noreferrer"">here</a>. You\'ll probably find a working way for you there.</p>\n\n<p>The basic Idea is to call the <a href=""https://www.tensorflow.org/api_docs/python/tf/gradients"" rel=""nofollow noreferrer""><code>tf.gradients</code></a> with respect to only one variable at a time and then constructing the Jacobian from there manually.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8890}"
1094,61998940,"{'items': [{'owner': {'reputation': 6758, 'user_id': 5986907}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1590402794, 'answer_id': 62000599, 'question_id': 61998940, 'body': '<p>You\'re right, and that\'s by design. A constrained variable in GPflow is represented by a <code>Parameter</code>. The <code>Parameter</code> wraps the <code>unconstrained_variable</code>. When you access <code>.trainable_variables</code> on your model, this will include the <code>unconstrained_variable</code> of the <code>Parameter</code>, and so when you pass these variables to the optimizer, the optimizer will train those rather than the <code>Parameter</code> itself.</p>\n\n<p>But your model doesn\'t see the <code>unconstrained_value</code>, it sees the <code>Parameter</code> interface which is a <code>tf.Tensor</code>-like interface related to the wrapped <code>unconstrained_variable</code> via an optional transformation. This transformation maps the unconstrained value to a constrained value. As such, your model will only see the constrained value. It\'s not a problem that your constrained value must be positive, the transform will map negative values of the unconstrained values to positive values for the constrained value.</p>\n\n<p>You can see the unconstrained and constrained values of the first <code>Parameter</code> for your kernel, as well as the transform that relates them, with</p>\n\n<pre class=""lang-py prettyprint-override""><code>param = model.kernel.parameters[0]\nparam.value()  # this is what your model will see\nparam.unconstrained_variable  # this is what the optimizer will see\nparam.transform  # the above two are related via this\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8890}"
1095,62752605,"{'items': [{'owner': {'reputation': 6847, 'user_id': 9670056}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1594031447, 'answer_id': 62754154, 'question_id': 62752605, 'body': '<p>Based on <a href=""https://stackoverflow.com/questions/35241251/in-tensorflow-what-is-the-difference-between-sampled-softmax-loss-and-softmax-c"">this other question</a>, it looks like it is cross entropy.</p>\n<p>Besides, the main difference between <code>sampled_softmax_loss</code> and <code>softmax_cross_entropy_with_logits</code> (the standard cross_entropy loss in TF) is that the first only takes into account a subset V of your vocabulary to calculate your loss, while the second takes into account your entire vocabulary.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8890}"
1096,75403101,"{'items': [{'owner': {'reputation': 89, 'user_id': 1998707}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1676061502, 'answer_id': 75415909, 'question_id': 75403101, 'body': '<p>Here\'s how I got it working with <code>tf.data.Dataset.from_tensor_slices()</code> and <code>tf.distribute.MirroredStrategy.experimental_distribute_dataset()</code>:</p>\n<pre class=""lang-py prettyprint-override""><code>#Data exists in the form of dictionaries of large numpy arrays\nx_train, y_train, x_validation, y_validation = {},{},{},{}\n\n#Create tensorflow datasets using CPU / system memory\nwith tf.device(&quot;CPU&quot;):\n    train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n    valid = tf.data.Dataset.from_tensor_slices((x_validation, y_validation))\n\nbatch_size = 1024\nepochs = 30\n\ndistributed_strategy = tf.distribute.MirroredStrategy()\nnum_gpu = distributed_strategy.num_replicas_in_sync\n\n#Create a distributed dataset from the tensorflow datasets.\n#The data gets streamed to the GPUs, so shuffling, repetition / epoch, and batch\n#size need to be manually specified\ntrain = train.shuffle(100*batch_size).repeat(epochs).batch(num_gpu * batch_size, drop_remainder=True)\ntrain_dist = distributed_strategy.experimental_distribute_dataset(train)\n\nvalid = valid.repeat(epochs).batch(num_gpu * batch_size, drop_remainder=True)\n\n#Build and compile the model\nwith distributed_strategy.scope():\n    train_model = build_model(**model_params)\n    train_model.compile(\n        optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n        loss = losses,\n        loss_weights = weights    )\n\n#Train the model. steps_per_epoch and validation_steps need to be specified.\ntrain_model.fit(\n    train_dist,\n    validation_data = valid,\n    epochs = epochs,\n    steps_per_epoch = int(len(train)//epochs),\n    validation_steps = int(len(valid)//epochs),\n    use_multiprocessing = True,\n    verbose = 1,\n)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8890}"
1097,76040030,"{'items': [{'owner': {'reputation': 55, 'user_id': 11586050}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1684981366, 'answer_id': 76328494, 'question_id': 76040030, 'body': '<p>You need to convert the dataset to a format the model can read. One option would be to have a TensorFlow dataset where each example is a tuple <code>(image, label)</code>.</p>\n<p>You can convert the Hugging Face dataset to a TensorFlow dataset with the method <code>to_tf_dataset()</code> such as this:</p>\n<p><code>ds_train = ds[&quot;train&quot;].to_tf_dataset(batch_size=BATCH_SIZE)</code></p>\n<p>This will return a dictionary per example <code>{&quot;image&quot;: tf.Tensor(image), &quot;label&quot;: tf.Tensor(label)}</code>. You can apply an additional function to map the dataset:</p>\n<pre class=""lang-py prettyprint-override""><code>def format_dataset(example):\n    image = example[&quot;image&quot;]\n    label = example[&quot;label&quot;]\n    return (image, label)\n\nds_train = ds_train.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n</code></pre>\n<p>This way you will have a tuple <code>(image, label)</code> per example, where both image and label are <code>tf.Tensor()</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8886}"
1098,41125728,"{'items': [{'owner': {'reputation': 257, 'user_id': 6785153}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1481666065, 'answer_id': 41131225, 'question_id': 41125728, 'body': '<p>The problem is that the order in which moving_mean is updated, could cause the gradients to use the updated version of moving_mean, instead of the original moving_mean used as shift. So to make sure the same value is used in the forward pass and in the backward pass we make an explicit copy.</p>\n'}, {'owner': {'reputation': 4577, 'user_id': 1951176}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1481653432, 'answer_id': 41128028, 'question_id': 41125728, 'body': '<p>There is not much information about it around, but it may be used to convert a tensor reference to a regular tensor. Their behavior differ when you push them to the queue (if the tensor reference changes the value of the tensor). You can read more about it in this <a href=""https://stackoverflow.com/questions/40668712/enqueue-and-increment-variable-in-tensor-flow"">question</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8886}"
1099,56229730,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8886}"
1100,49405794,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8883}"
1101,54945641,"{'items': [{'owner': {'reputation': 55360, 'user_id': 349130}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1551449284, 'answer_id': 54946310, 'question_id': 54945641, 'body': '<p>The input shape should be in the first layer of your model, but you are putting it in the second. So Keras is assuming a shape from your training data.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8882}"
1102,47947629,"{'items': [{'owner': {'reputation': 546, 'user_id': 8096451}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1513978330, 'answer_id': 47947630, 'question_id': 47947629, 'body': '<p>So here is the deal. You must make sure that your custom Input Function returns a dictionary of {inputs} and a dictionary of {outputs}.\nThe dictionary keys must match your Keras input/output layers name.</p>\n\n<p>From TF docs:</p>\n\n<p><em>First, recover the input name(s) of Keras model, so we can use them as the\nfeature column name(s) of the Estimator input function</em></p>\n\n<p>This is correct. \nHere is how I did this:</p>\n\n<pre><code># Get inputs and outout Keras model name to fuse them into the infrastructure.\nkeras_input_names_list = keras_model.input_names\nkeras_target_names_list = keras_model.output_names\n</code></pre>\n\n<p>Now, that you have the names, you need to go to your own input function and change it so it will deliver two dictionaries with the corresponding input and output names. </p>\n\n<p>In my example, before the change, the input function returned [image_batch],[label_batch]. This is basically a bug because it is stated that the inputfn returns a dictionary and not a list. </p>\n\n<p>To solve this, we need to wrap it up into a dict:</p>\n\n<pre><code>image_batch_dict = dict(zip(keras_input_names_list , [image_batch]))\nlabel_batch_dict = dict(zip(keras_target_names_list , [label_batch]))\n</code></pre>\n\n<p>Only now, TF will be able to connect the input function to the Keras input layers. </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8882}"
1103,45705070,"{'items': [{'owner': {'reputation': 121, 'user_id': 12920441}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1589820865, 'answer_id': 61874845, 'question_id': 45705070, 'body': '<p>A code snippet that worked for me to load a pb file and inference on a single image. </p>\n\n<p>The code follows the following steps: load the pb file into a GraphDef (a serialized version of a graph     (used to read pb files), load GraphDef into a Graph, get input and output tensors by their names, inference on a single image.</p>\n\n<pre><code>import tensorflow as tf \nimport numpy as np\nimport cv2\n\nINPUT_TENSOR_NAME = \'input_tensor_name:0\'\nOUTPUT_TENSOR_NAME = \'output_tensor_name:0\'\n\n# Read image, get shape\n# Add dimension to fit batch shape\nimg = cv2.imread(IMAGE_PATH)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimage = img.astype(float)\nheight, width, channels = image.shape\nimage = np.expand_dims(image, 0)  # Add dimension (to fit batch shape)\n\n\n# Read pb file into the graph as GraphDef - Serialized version of a graph     (used to read pb files)\nwith tf.gfile.FastGFile(PB_PATH, \'rb\') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n\n# Load GraphDef into Graph\nwith tf.Graph().as_default() as graph:\n    tf.import_graph_def(graph_def, name="""")\n\n# Get tensors (input and output) by name\ninput_tensor = graph.get_tensor_by_name(INPUT_TENSOR_NAME)\noutput_tensor = graph.get_tensor_by_name(OUTPUT_TENSOR_NAME)\n\n# Inference on single image\nwith tf.Session(graph=graph) as sess:\n    output_vals = sess.run(output_tensor, feed_dict={input_tensor: image})  #\n</code></pre>\n'}, {'owner': {'reputation': 61, 'user_id': 10446396}, 'down_vote_count': 0, 'up_vote_count': 6, 'is_accepted': False, 'score': 6, 'creation_date': 1538488520, 'answer_id': 52609865, 'question_id': 45705070, 'body': '<p>Here\'s the code snippet to load and restore/predict models using the simple_save</p>\n\n<pre><code>#Save the model:\ntf.saved_model.simple_save(sess, export_dir=saveModelPath,\n                                   inputs={""inputImageBatch"": X_train, ""inputClassBatch"": Y_train,\n                                           ""isTrainingBool"": isTraining},\n                                   outputs={""predictedClassBatch"": predClass})\n</code></pre>\n\n<p>Note that using simple_save sets certain default values (this can be seen at: <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/simple_save.py"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/simple_save.py</a>)</p>\n\n<p>Now, to restore and use the inputs/outputs dict:</p>\n\n<pre><code>from tensorflow.python.saved_model import tag_constants\nfrom tensorflow.python.saved_model import signature_constants\n\nwith tf.Session() as sess:\n  model = tf.saved_model.loader.load(export_dir=saveModelPath, sess=sess, tags=[tag_constants.SERVING]) #Note the SERVINGS tag is put as default.\n\n  inputImage_name = model.signature_def[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY].inputs[\'inputImageBatch\'].name\n  inputImage = tf.get_default_graph().get_tensor_by_name(inputImage_name)\n\n  inputLabel_name = model.signature_def[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY].inputs[\'inputClassBatch\'].name\n  inputLabel = tf.get_default_graph().get_tensor_by_name(inputLabel_name)\n\n  isTraining_name = model.signature_def[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY].inputs[\'isTrainingBool\'].name\n  isTraining = tf.get_default_graph().get_tensor_by_name(isTraining_name)\n\n  outputPrediction_name = model.signature_def[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY].outputs[\'predictedClassBatch\'].name\n  outputPrediction = tf.get_default_graph().get_tensor_by_name(outputPrediction_name)\n\n  outPred = sess.run(outputPrediction, feed_dict={inputImage:sampleImages, isTraining:False})\n\n  print(""predicted classes:"", outPred)\n</code></pre>\n\n<p>Note: the default signature_def was needed to make use of the tensor names specified in the input &amp; output dicts.</p>\n'}, {'owner': {'reputation': 8480, 'user_id': 2210667}, 'down_vote_count': 0, 'up_vote_count': 25, 'is_accepted': True, 'score': 25, 'creation_date': 1502932963, 'answer_id': 45725245, 'question_id': 45705070, 'body': '<p>What was missing was the <code>signature</code></p>\n\n<pre><code># Saving\nbuilder = tf.saved_model.builder.SavedModelBuilder(export_dir)\nbuilder.add_meta_graph_and_variables(sess, [""tag""], signature_def_map= {\n        ""model"": tf.saved_model.signature_def_utils.predict_signature_def(\n            inputs= {""x"": x},\n            outputs= {""finalnode"": model})\n        })\nbuilder.save()\n\n# loading\nwith tf.Session(graph=tf.Graph()) as sess:\n    tf.saved_model.loader.load(sess, [""tag""], export_dir)\n    graph = tf.get_default_graph()\n    x = graph.get_tensor_by_name(""x:0"")\n    model = graph.get_tensor_by_name(""finalnode:0"")\n    print(sess.run(model, {x: [5, 6, 7, 8]}))\n</code></pre>\n'}, {'owner': {'reputation': 3633, 'user_id': 5330223}, 'down_vote_count': 2, 'up_vote_count': 4, 'is_accepted': False, 'score': 2, 'creation_date': 1502862745, 'answer_id': 45705969, 'question_id': 45705070, 'body': '<p><code>Tensorflow</code>\'s preferred way of building and using a model in different languages is <code>tensorflow serving</code></p>\n\n<p>Now in your case, you are using <code>saver.save</code> to save the model. This way it saves a <code>meta</code> file, <code>ckpt</code> file and some other files to save the weights and network information, steps trained etc. This is the preferred way of saving while you are training.</p>\n\n<p>If you are done with training now you should freeze the graph using <code>SavedModelBuilder</code> from the files you save by <code>saver.save</code>. This frozen graph contains a <code>pb</code> file and contains all the network and weights.</p>\n\n<p>This frozen model should be used to serve by <code>tensorflow serving</code> and then other languages can use the model using <code>gRPC</code> protocol.</p>\n\n<p>The whole procedure is described in <a href=""https://medium.com/towards-data-science/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198"" rel=""nofollow noreferrer"">this</a> excellent tutorial.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8882}"
1104,67362672,"{'items': [{'owner': {'reputation': 16444, 'user_id': 9215780}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1621777371, 'answer_id': 67660424, 'question_id': 67362672, 'body': '<p>About the <a href=""https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_update"" rel=""nofollow noreferrer""><code>tf.tensor_scatter_nd_update</code></a>, you\'re right that it returns a new <a href=""https://www.tensorflow.org/guide/tensor"" rel=""nofollow noreferrer""><strong>tf.tensor</strong></a> (and not <a href=""https://www.tensorflow.org/guide/variable"" rel=""nofollow noreferrer""><strong>tf.Variable</strong></a>). But about the <a href=""https://www.tensorflow.org/api_docs/python/tf/Variable#assign"" rel=""nofollow noreferrer""><code>assign</code></a> which is an attribute of <a href=""https://www.tensorflow.org/guide/variable"" rel=""nofollow noreferrer""><strong>tf.Variable</strong></a>, I think you somewhat misread the document; the <code>value</code> is just the new item that you want to assign in particular indices of your old variable.</p>\n<p>AFAIK, in <a href=""/questions/tagged/tensorflow"" class=""post-tag"" title=""show questions tagged &#39;tensorflow&#39;"" rel=""tag"">tensorflow</a> all tensors are immutable like <a href=""/questions/tagged/python"" class=""post-tag"" title=""show questions tagged &#39;python&#39;"" rel=""tag"">python</a> numbers and strings; you can never update the contents of a tensor, only create a new one, <a href=""https://www.tensorflow.org/guide/tensor"" rel=""nofollow noreferrer"">source</a>. And directly updating or manipulating of <code>tf.tensor</code> or <code>tf.Variable</code> such as <a href=""/questions/tagged/numpy"" class=""post-tag"" title=""show questions tagged &#39;numpy&#39;"" rel=""tag"">numpy</a> like item assignment is still not supported. Check the following Github issues to follow up the discussions: <a href=""https://github.com/tensorflow/tensorflow/issues/33131"" rel=""nofollow noreferrer"">#33131</a>, <a href=""https://github.com/tensorflow/tensorflow/issues/14132"" rel=""nofollow noreferrer"">#14132</a>.</p>\n<hr />\n<p>In <a href=""/questions/tagged/numpy"" class=""post-tag"" title=""show questions tagged &#39;numpy&#39;"" rel=""tag"">numpy</a>, we can do an in-place item assignment that you showed in the comment box.</p>\n<pre><code>import numpy as np\n\na = np.array([1,2,3])  \nprint(a) # [1 2 3]\na[1] = 0\nprint(a) # [1 0 3] \n</code></pre>\n<p>A similar result can be achieved in <strong>tf.Variable</strong> with <code>assign</code> attribute.</p>\n<pre><code>import tensorflow as tf \n\nb = tf.Variable([1,2,3])\nb.numpy() # array([1, 2, 3], dtype=int32)\n\nb[1].assign(0)\nb.numpy() # array([1, 0, 3], dtype=int32)\n</code></pre>\n<p>Later, we can convert it to <strong>tf. tensor</strong> as follows.</p>\n<pre><code>b_ten = tf.convert_to_tensor(b)\nb_ten.numpy() # array([1, 0, 3], dtype=int32)\n</code></pre>\n<p>We can do such item assignment in <strong>tf.tensor</strong> too but we need to convert it to <strong>tf.Variable</strong> first, (I know, not very intuitive).</p>\n<pre><code>tensor = [[1, 1], [1, 1], [1, 1]]    # tf.rank(tensor) == 2\nindices = [[0, 1], [2, 0]]           # num_updates == 2, index_depth == 2\nupdates = [5, 10]                    # num_updates == 2\nx = tf.tensor_scatter_nd_update(tensor, indices, updates)\nx\n&lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy=\narray([[ 1,  5],\n       [ 1,  1],\n       [10,  1]], dtype=int32)&gt;\n</code></pre>\n<pre><code>x = tf.Variable(x)\nx\n&lt;tf.Variable \'Variable:0\' shape=(3, 2) dtype=int32, numpy=\narray([[ 1,  5],\n       [ 1,  1],\n       [10,  1]], dtype=int32)&gt;\n\nx[0].assign([5,1])\nx\n&lt;tf.Variable \'Variable:0\' shape=(3, 2) dtype=int32, numpy=\narray([[ 5,  1],\n       [ 1,  1],\n       [10,  1]], dtype=int32)&gt;\n</code></pre>\n<pre><code>x = tf.convert_to_tensor(x)\nx\n&lt;tf.Tensor: shape=(3, 2), dtype=int32, numpy=\narray([[ 5,  1],\n       [ 1,  1],\n       [10,  1]], dtype=int32)&gt;\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8882}"
1105,62994289,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8878}"
1106,64356209,"{'items': [{'owner': {'reputation': 10889, 'user_id': 7370153}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1602689677, 'answer_id': 64356791, 'question_id': 64356209, 'body': '<p>The <code>shuffle</code> parameter has no effect on the <code>fit</code> function when using the <code>tf.data.Dataset</code> API.</p>\n<p>If we read the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">documentation</a> (emphasis is mine) :</p>\n<blockquote>\n<p>shuffle: Boolean (whether to shuffle the training data before each epoch) or str (for \'batch\'). <strong>This argument is ignored when x is a generator.</strong> \'batch\' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when steps_per_epoch is not None.</p>\n</blockquote>\n<p>It\'s not super clear, but we can have a hint that the shuffle argument will be ignored when using a <code>tf.data.Dataset</code>, as it behave like a generator.</p>\n<p>To be certain, lets dive in the code. If we look at the code of the <a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/engine/training.py#L824-L1146"" rel=""nofollow noreferrer""><code>fit</code></a> method, you will see that the data is handled by a special class, <code>DataHandler</code>. Looking at the code of this class, we see that this is an Adapter class to handle different kind of data. We are interrested in the class that handle tf.data.Dataset, <a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/engine/data_adapter.py#L678-L752"" rel=""nofollow noreferrer""><code>DatasetAdapter</code></a>, and we can see that this class does not take into account the <code>shuffle</code> parameter :</p>\n<pre class=""lang-py prettyprint-override""><code>  def __init__(self,\n               x,\n               y=None,\n               sample_weights=None,\n               steps=None,\n               **kwargs):\n    super(DatasetAdapter, self).__init__(x, y, **kwargs)\n    # Note that the dataset instance is immutable, its fine to reuse the user\n    # provided dataset.\n    self._dataset = x\n\n    # The user-provided steps.\n    self._user_steps = steps\n\n    self._validate_args(y, sample_weights, steps)\n</code></pre>\n<hr />\n<p>If you want to shuffle your dataset, use the <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle"" rel=""nofollow noreferrer"">shuffle</a> function from the <code>tf.data.Dataset</code> API.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8878}"
1107,43108211,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8878}"
1108,53206900,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1541678439, 'answer_id': 53207330, 'question_id': 53206900, 'body': ""<p>EDIT: Actually, seeing again how <code>K.get_session()</code> works, it should return the current default session, so I'm not sure <code>set_session</code> is doing anything meaningful there. I'll leave the answer just in case you want to try but probably this won't help.</p>\n\n<hr>\n\n<p>Maybe you can get it to work with something like this:</p>\n\n<pre><code>from contextlib import contextmanager\n\nclass NN:\n    def __init__(self):\n        self.graph = tf.Graph()\n        self.session = tf.Session(graph=self.graph)\n\n    def predict(self, x):\n        with self._context():\n            return self.model.predict(x)\n\n    @contextmanager\n    def _context(self):\n        prev_sess = K.get_session()\n        K.set_session(self.session)\n        with self.graph.as_default(), self.session.as_default():\n            yield\n        K.set_session(prev_sess)\n</code></pre>\n\n<p>Note that the Keras session object is a global variable, so I suppose this should work as long as you don't try to use these contexts from multiple threads.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8878}"
1109,65464181,"{'items': [{'owner': {'reputation': 871, 'user_id': 10199571}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1614007459, 'answer_id': 66318522, 'question_id': 65464181, 'body': ""<p>Let me clarify some confusion here. TPUs are only offered on Google Cloud and the <code>TPUClusterResolver</code> implementation queries GCP APIs to get the cluster config for the TPU node. Thus, no you can't use <code>TPUClusterResolver</code> with AWS sagemaker, but you should try it out with TPUs on GCP instead or try find some other documentation on Sagemaker's end on how they enable cluster resolving on their end (if they do).</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8878}"
1110,44232566,"{'items': [{'owner': {'reputation': 21, 'user_id': 7984184}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1540042591, 'answer_id': 52906254, 'question_id': 44232566, 'body': '<p>In eager execution, there are two ways.</p>\n\n<ol>\n<li>Calculate by hand with <code>tf.add_n([tf.square(i) for i in layer.variables]) * l2_coef</code>\n.</li>\n<li>Using <code>layer.losses</code> when the layer is created with <code>kernel_regularizer</code>.</li>\n</ol>\n\n<p>As shown in the official examples: <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/densenet/densenet_test.py"" rel=""nofollow noreferrer"">densenet_test.py</a></p>\n\n<pre><code>rand_input = tf.random_uniform((10, 3, 32, 32))\nweight_decay = 1e-4\n\nconv = tf.keras.layers.Conv2D(\n    3, (3, 3),\n    padding=\'same\',\n    use_bias=False,\n    kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n\noptimizer = tf.train.GradientDescentOptimizer(0.1)\nconv(rand_input)  # Initialize the variables in the layer\n\ndef compute_true_l2(vs, wd):\n  return tf.reduce_sum(tf.square(vs)) * wd\n\ntrue_l2 = compute_true_l2(conv.variables, weight_decay)\nkeras_l2 = tf.add_n(conv.losses)\nself.assertAllClose(true_l2, keras_l2)\n\nwith tf.GradientTape() as tape_true, tf.GradientTape() as tape_keras:\n  loss = tf.reduce_sum(conv(rand_input))\n  loss_with_true_l2 = loss + compute_true_l2(conv.variables, weight_decay)\n  loss_with_keras_l2 = loss + tf.add_n(conv.losses)\n\ntrue_grads = tape_true.gradient(loss_with_true_l2, conv.variables)\nkeras_grads = tape_keras.gradient(loss_with_keras_l2, conv.variables)\nself.assertAllClose(true_grads, keras_grads)\n</code></pre>\n'}, {'owner': {'reputation': 507, 'user_id': 4833773}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': False, 'score': 4, 'creation_date': 1537450061, 'answer_id': 52426262, 'question_id': 44232566, 'body': ""<p>I see two incomplete answers, so here is the complete one:</p>\n\n<pre><code>regularizer = tf.contrib.layers.l2_regularizer(scale=0.1)\n    layer2 = tf.layers.conv2d(\n        inputs,\n        filters,\n        kernel_size,\n        kernel_regularizer=regularizer)\n</code></pre>\n\n<p>alternatively:</p>\n\n<pre><code>layer2 = tf.layers.conv2d(inputs, \n     filters, \n     kernel_size,                        \n     kernel_regularizer= tf.contrib.layers.l2_regularizer(scale=0.1))\n</code></pre>\n\n<p>don't forget to add it to the final loss:</p>\n\n<pre><code>l2_loss = tf.losses.get_regularization_loss()\n....\nloss += l2_loss\n</code></pre>\n\n<p>Basically, add regularization when defining a layer and then make sure you add regularization loss to your loss.</p>\n""}, {'owner': {'reputation': 4206, 'user_id': 6933420}, 'down_vote_count': 1, 'up_vote_count': 39, 'is_accepted': True, 'score': 38, 'creation_date': 1496048089, 'answer_id': 44238354, 'question_id': 44232566, 'body': '<p>You can pass them into <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/conv2d"" rel=""noreferrer""><code>tf.layers.conv2d</code> as arguments:</a></p>\n\n<pre><code>regularizer = tf.contrib.layers.l2_regularizer(scale=0.1)\nlayer2 = tf.layers.conv2d(\n    inputs,\n    filters,\n    kernel_size,\n    kernel_regularizer=regularizer)\n</code></pre>\n\n<p>Then you should add the regularization loss to your loss like this:</p>\n\n<pre><code>l2_loss = tf.losses.get_regularization_loss()\nloss += l2_loss\n</code></pre>\n\n<p><em>Edit: Thanks Zeke Arneodo, Tom and srcolinas I added, the last bit on your feedback so that the accepted answer provides the complete solution.</em></p>\n'}, {'owner': {'reputation': 664, 'user_id': 6323080}, 'down_vote_count': 0, 'up_vote_count': 16, 'is_accepted': False, 'score': 16, 'creation_date': 1513026956, 'answer_id': 47761542, 'question_id': 44232566, 'body': '<p>Isn\'t the answer in your question? You can also use tf.losses.get_regularization_loss (<a href=""https://www.tensorflow.org/api_docs/python/tf/losses/get_regularization_loss"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/losses/get_regularization_loss</a>), which will collect all the REGULARIZATION_LOSSES.</p>\n\n<pre><code>...\nlayer2 = tf.layers.conv2d(input, \n     filters, \n     kernel_size,                        \n     kernel_regularizer= tf.contrib.layers.l2_regularizer(scale=0.1))\n...\nl2_loss = tf.losses.get_regularization_loss()\nloss += l2_loss\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8873}"
1111,41353079,"{'items': [{'owner': {'reputation': 5631, 'user_id': 6490351}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1482971839, 'answer_id': 41371684, 'question_id': 41353079, 'body': '<p>As @Wes Doyle pointed out, it returns 50% of each dimension, which is consistent with the illustration in the comments, the original size is 4x8 (4 ""|"" signs and 8 ""-"" signs), and the cropped size is 2x4 (2 ""X"" vertically, 4 ""X"" horizontally).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8873}"
1112,48471926,"{'items': [{'owner': {'reputation': 2170, 'user_id': 3353601}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1574284980, 'answer_id': 58963587, 'question_id': 48471926, 'body': ""<p>Just wanted to add that this can be done for datasets where each element is a dictionary as well. For example, if one element of the input dataset looks like</p>\n\n<pre><code>{ 'feat1': [2,4], 'feat2': [3]}\n</code></pre>\n\n<p>And for each element you want to split into to elements based on the elements in feat1, you could write:</p>\n\n<pre><code>def split(element):\n    dict_of_new_elements = {\n        'feat1': [\n            element['feat1'][:, 0],\n            element['feat1'][:, 1]]\n        'feat2': [\n            element['feat2'],\n            element['feat2']]\n    }\n    return tf.data.Dataset.from_tensor_slices(dict_of_new_elements)\ndataset.flat_map(split)\n</code></pre>\n\n<p>Which would yield</p>\n\n<pre><code>[\n    {'feat1': 2, 'feat2': 3},\n    {'feat1': 4, 'feat2': 3},\n]\n</code></pre>\n""}, {'owner': {'reputation': 30867, 'user_id': 4790871}, 'down_vote_count': 0, 'up_vote_count': 11, 'is_accepted': True, 'score': 11, 'creation_date': 1517189843, 'answer_id': 48493272, 'question_id': 48471926, 'body': ""<p>Two more steps were required to achieve this. First, the map function needs to return a numpy array, not a list.</p>\n\n<p>Then you can use <code>flat_map</code> combined with <code>Dataset().from_tensor_slices()</code> to flatten them. The code below now produces the desired result:</p>\n\n<p>Tested in Tensorflow 1.5 (copy/paste runnable example)</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ninput = [10, 20, 30]\n\ndef my_map_func(i):\n  return np.array([i, i + 1, i + 2])\n\nds = tf.data.Dataset.from_tensor_slices(input)\nds = ds.map(map_func=lambda input: tf.py_func(\n  func=my_map_func, inp=[input], Tout=[tf.int64]\n))\nds = ds.flat_map(lambda x: tf.data.Dataset().from_tensor_slices(x))\n\nelement = ds.make_one_shot_iterator().get_next()\n\nwith tf.Session() as sess:\n  for _ in range(9):\n    print(sess.run(element))\n</code></pre>\n\n<hr>\n\n<p>Here is a method of doing this if you have multiple variables to return, in this example I input a string (such as a filename) and output multiples of both strings and integers. In this case I repeat the string for each of the integers of [10, 20, 30]. </p>\n\n<p>Copy/paste runnable example:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ninput = [b'testA', b'testB', b'testC']\n\ndef my_map_func(input):\n  return np.array([input, input, input]), np.array([10, 20, 30])\n\nds = tf.data.Dataset.from_tensor_slices(input)\nds = ds.map(map_func=lambda input: tf.py_func(\n    func=my_map_func, inp=[input], Tout=[tf.string, tf.int64]))\nds = ds.flat_map(lambda mystr, myint: tf.data.Dataset().zip((\n  tf.data.Dataset().from_tensor_slices(mystr),\n  tf.data.Dataset().from_tensor_slices(myint))\n))\n\nelement = ds.make_one_shot_iterator().get_next()\n\nwith tf.Session() as sess:\n  for _ in range(9):\n    print(sess.run(element))\n</code></pre>\n""}, {'owner': {'reputation': 1470, 'user_id': 8037585}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': False, 'score': 3, 'creation_date': 1537069125, 'answer_id': 52350741, 'question_id': 48471926, 'body': '<p>one clean solution using <code>flat_map</code> and <code>from_tensor_slices</code></p>\n\n<pre><code>import tensorflow as tf\n\ninput = [10, 20, 30]\n\nds = tf.data.Dataset.from_tensor_slices(input)\nds = ds.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nelement = ds.make_one_shot_iterator().get_next()\n\nwith tf.Session() as sess:\n    for _ in range(9):\n        print(sess.run(element))\n\n# 10\n# 11\n# 12\n# 20\n# 21\n# 22\n# 30\n# 31\n# 32\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8873}"
1113,55379830,"{'items': [{'owner': {'reputation': 4493, 'user_id': 5786339}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1553708653, 'answer_id': 55383531, 'question_id': 55379830, 'body': '<p>Not sure what exactly are you looking for, but maybe this will help\nUsed <code>tf.random.uniform</code> to avoid tensor/float operation</p>\n\n<pre><code>def speed_tune(x, lower_bound=1, upper_bound=2):\n    speed_rate = tf.random.uniform([1,], lower_bound, upper_bound, dtype=tf.int32)\n    newshape = tf.shape(x)[1:] # get the tensor shape except for rank 0(None)\n    newshape = newshape * speed_rate # randomly stretch or compress the signal\n    return tf.reshape(x, newshape)\n</code></pre>\n\n<p>Used <code>tf.reshape</code>, not sure what you meant by <code>tf.resize</code> </p>\n\n<pre><code>x = tf.placeholder(tf.int32, (None, 1000)) # x is a 1D audio signal\ny = speed_tune(x)\ndata = np.random.rand(1, 1000)\n\nwith tf.Session() as sess:\n    sess.run(y, feed_dict={x:data})\n</code></pre>\n\n<p>Another way is to use <code>tf.pad</code>:\nFor example:</p>\n\n<pre><code>n = 10\ntensor = tf.constant(np.random.rand(1, 10))\npaddings = tf.constant([[0,1], [0,0]])\n</code></pre>\n\n<p>this exact pad setup means that you add n zeros in the end of tensor. In order to get initial dimension you reshape it</p>\n\n<pre><code>padded = tf.pad(tensor, paddings)\noutput  = tf.reshape(padded, [1,n*2])\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8873}"
1114,41449338,"{'items': [{'owner': {'reputation': 11, 'user_id': 1882931}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1483490988, 'answer_id': 41454591, 'question_id': 41449338, 'body': '<p>Thanks Yaroslav! I provide the code and results from my run, just in case somebody else is interested. If you try the code please be patient for a few minutes.</p>\n\n<p>Code:</p>\n\n<pre><code>import sys\nimport numpy as np\nimport tensorflow as tf\nfrom datetime import datetime\n\n\ndevice_names = [""/cpu:0"", ""/gpu:0"", ""/gpu:1""]\nshapes = [(3000, 3000), (6000, 6000), (9000, 9000), (12000, 12000)]\nmessages = [""RESULTS\\n""]\n\ndef timing_run(matrix_type, config_name, warmup):\n    configs = {""simple"": tf.ConfigProto(log_device_placement=False),\n               ""optim"": tf.ConfigProto(graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)))}\n\n    messages.append(""matrix={}+config={}+warmup={}"".format(matrix_type, config_name, warmup))\n    tf.set_random_seed(1234)\n    for device_name in device_names:\n        for shape in shapes:\n            with tf.device(device_name):\n                if matrix_type == ""random_uniform"":\n                    random_matrix = tf.random_uniform(shape=shape,\n                                                      minval=0,\n                                                      maxval=1,\n                                                      seed=1234)\n                else:\n                    random_matrix = tf.zeros(shape)\n                result_op = tf.reduce_sum(tf.matmul(random_matrix,tf.transpose(random_matrix)))\n\n            session = tf.Session(config=configs[config_name])\n            result1, result2 = -1.0, -1.0\n            # warm up\n            start_time1 = datetime.now()\n            result1 = session.run(result_op)\n            time_diff1 = datetime.now() - start_time1\n            messages.append((device_name,\n                             ""shape = {}"".format(shape),\n                             ""times = {} seconds"".format(time_diff1.total_seconds()),\n                             ""result = {}"".format(result1)))\n            if warmup:\n                # warmed up - runs if warmup=True.\n                start_time2 = datetime.now()\n                result2 = session.run(result_op)\n                time_diff2 = datetime.now() - start_time2\n                messages.append((device_name,\n                                 ""shape = {}"".format(shape),\n                                 ""times = {} seconds"".format(time_diff2.total_seconds()),\n                                 ""result = {}"".format(result1),\n                                 ""*****WARMED UP*****""))\n            session.close()\n        messages.append(""++++++++++++++++++++++++++++++++++++++++++++++++++++"")\n    messages.append(""\\n\\n"")\n\n\n\nif __name__ == ""__main__"":\n    timing_run(matrix_type=""random_uniform"", config_name=""simple"", warmup=False)\n    timing_run(matrix_type=""random_uniform"", config_name=""simple"", warmup=True)\n    timing_run(matrix_type=""random_uniform"", config_name=""optim"", warmup=False)\n    timing_run(matrix_type=""zeros"", config_name=""simple"", warmup=False)\n    timing_run(matrix_type=""zeros"", config_name=""simple"", warmup=True)\n    timing_run(matrix_type=""zeros"", config_name=""optim"", warmup=False)\n\n    # print timings\n    for e in messages:\n        print(e)\n</code></pre>\n\n<p>Summary:</p>\n\n<pre><code>matrix=random_uniform+config=simple+warmup=False\n(\'/cpu:0\', \'shape = (3000, 3000)\', \'times = 0.428429 seconds\', \'result = 6754431488.0\')\n(\'/cpu:0\', \'shape = (6000, 6000)\', \'times = 2.806464 seconds\', \'result = 54023852032.0\')\n(\'/cpu:0\', \'shape = (9000, 9000)\', \'times = 9.36232 seconds\', \'result = 184425938944.0\')\n(\'/cpu:0\', \'shape = (12000, 12000)\', \'times = 22.376751 seconds\', \'result = 439655661568.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:0\', \'shape = (3000, 3000)\', \'times = 0.392957 seconds\', \'result = 6754390016.0\')\n(\'/gpu:0\', \'shape = (6000, 6000)\', \'times = 0.082889 seconds\', \'result = 54006833152.0\')\n(\'/gpu:0\', \'shape = (9000, 9000)\', \'times = 0.221844 seconds\', \'result = 182251814912.0\')\n(\'/gpu:0\', \'shape = (12000, 12000)\', \'times = 0.438476 seconds\', \'result = 431995879424.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:1\', \'shape = (3000, 3000)\', \'times = 0.483864 seconds\', \'result = 6754393088.0\')\n(\'/gpu:1\', \'shape = (6000, 6000)\', \'times = 0.097571 seconds\', \'result = 54006833152.0\')\n(\'/gpu:1\', \'shape = (9000, 9000)\', \'times = 0.250176 seconds\', \'result = 182252044288.0\')\n(\'/gpu:1\', \'shape = (12000, 12000)\', \'times = 0.473314 seconds\', \'result = 431996567552.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n\n\nmatrix=random_uniform+config=simple+warmup=True\n(\'/cpu:0\', \'shape = (3000, 3000)\', \'times = 0.475717 seconds\', \'result = 6754431488.0\')\n(\'/cpu:0\', \'shape = (3000, 3000)\', \'times = 0.379542 seconds\', \'result = 6754431488.0\', \'*****WARMED UP*****\')\n(\'/cpu:0\', \'shape = (6000, 6000)\', \'times = 2.856803 seconds\', \'result = 54023852032.0\')\n(\'/cpu:0\', \'shape = (6000, 6000)\', \'times = 2.798967 seconds\', \'result = 54023852032.0\', \'*****WARMED UP*****\')\n(\'/cpu:0\', \'shape = (9000, 9000)\', \'times = 9.447787 seconds\', \'result = 184425938944.0\')\n(\'/cpu:0\', \'shape = (9000, 9000)\', \'times = 9.385646 seconds\', \'result = 184425938944.0\', \'*****WARMED UP*****\')\n(\'/cpu:0\', \'shape = (12000, 12000)\', \'times = 21.752967 seconds\', \'result = 439655661568.0\')\n(\'/cpu:0\', \'shape = (12000, 12000)\', \'times = 21.832136 seconds\', \'result = 439655661568.0\', \'*****WARMED UP*****\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:0\', \'shape = (3000, 3000)\', \'times = 0.067066 seconds\', \'result = 6754394624.0\')\n(\'/gpu:0\', \'shape = (3000, 3000)\', \'times = 0.008072 seconds\', \'result = 6754394624.0\', \'*****WARMED UP*****\')\n(\'/gpu:0\', \'shape = (6000, 6000)\', \'times = 0.123611 seconds\', \'result = 54006833152.0\')\n(\'/gpu:0\', \'shape = (6000, 6000)\', \'times = 0.057391 seconds\', \'result = 54006833152.0\', \'*****WARMED UP*****\')\n(\'/gpu:0\', \'shape = (9000, 9000)\', \'times = 0.248432 seconds\', \'result = 182251913216.0\')\n(\'/gpu:0\', \'shape = (9000, 9000)\', \'times = 0.18535 seconds\', \'result = 182251913216.0\', \'*****WARMED UP*****\')\n(\'/gpu:0\', \'shape = (12000, 12000)\', \'times = 0.48081 seconds\', \'result = 431996043264.0\')\n(\'/gpu:0\', \'shape = (12000, 12000)\', \'times = 0.412447 seconds\', \'result = 431996043264.0\', \'*****WARMED UP*****\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:1\', \'shape = (3000, 3000)\', \'times = 0.105071 seconds\', \'result = 6754395648.0\')\n(\'/gpu:1\', \'shape = (3000, 3000)\', \'times = 0.008107 seconds\', \'result = 6754395648.0\', \'*****WARMED UP*****\')\n(\'/gpu:1\', \'shape = (6000, 6000)\', \'times = 0.137264 seconds\', \'result = 54006849536.0\')\n(\'/gpu:1\', \'shape = (6000, 6000)\', \'times = 0.064462 seconds\', \'result = 54006849536.0\', \'*****WARMED UP*****\')\n(\'/gpu:1\', \'shape = (9000, 9000)\', \'times = 0.280302 seconds\', \'result = 182251831296.0\')\n(\'/gpu:1\', \'shape = (9000, 9000)\', \'times = 0.191399 seconds\', \'result = 182251831296.0\', \'*****WARMED UP*****\')\n(\'/gpu:1\', \'shape = (12000, 12000)\', \'times = 0.509208 seconds\', \'result = 431996534784.0\')\n(\'/gpu:1\', \'shape = (12000, 12000)\', \'times = 0.4263 seconds\', \'result = 431996534784.0\', \'*****WARMED UP*****\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n\n\nmatrix=random_uniform+config=optim+warmup=False\n(\'/cpu:0\', \'shape = (3000, 3000)\', \'times = 0.552631 seconds\', \'result = 6754431488.0\')\n(\'/cpu:0\', \'shape = (6000, 6000)\', \'times = 2.894024 seconds\', \'result = 54023852032.0\')\n(\'/cpu:0\', \'shape = (9000, 9000)\', \'times = 9.394226 seconds\', \'result = 184425938944.0\')\n(\'/cpu:0\', \'shape = (12000, 12000)\', \'times = 21.870817 seconds\', \'result = 439655661568.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:0\', \'shape = (3000, 3000)\', \'times = 0.107416 seconds\', \'result = 6754392576.0\')\n(\'/gpu:0\', \'shape = (6000, 6000)\', \'times = 0.163633 seconds\', \'result = 54006804480.0\')\n(\'/gpu:0\', \'shape = (9000, 9000)\', \'times = 0.304741 seconds\', \'result = 182251667456.0\')\n(\'/gpu:0\', \'shape = (12000, 12000)\', \'times = 0.526494 seconds\', \'result = 431995944960.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:1\', \'shape = (3000, 3000)\', \'times = 0.119625 seconds\', \'result = 6754394624.0\')\n(\'/gpu:1\', \'shape = (6000, 6000)\', \'times = 0.203158 seconds\', \'result = 54006800384.0\')\n(\'/gpu:1\', \'shape = (9000, 9000)\', \'times = 0.317646 seconds\', \'result = 182251978752.0\')\n(\'/gpu:1\', \'shape = (12000, 12000)\', \'times = 0.544184 seconds\', \'result = 431996076032.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n\n\nmatrix=zeros+config=simple+warmup=False\n(\'/cpu:0\', \'shape = (3000, 3000)\', \'times = 0.632157 seconds\', \'result = 0.0\')\n(\'/cpu:0\', \'shape = (6000, 6000)\', \'times = 2.901679 seconds\', \'result = 0.0\')\n(\'/cpu:0\', \'shape = (9000, 9000)\', \'times = 9.345713 seconds\', \'result = 0.0\')\n(\'/cpu:0\', \'shape = (12000, 12000)\', \'times = 21.707619 seconds\', \'result = 0.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:0\', \'shape = (3000, 3000)\', \'times = 0.498451 seconds\', \'result = 0.0\')\n(\'/gpu:0\', \'shape = (6000, 6000)\', \'times = 2.900121 seconds\', \'result = 0.0\')\n(\'/gpu:0\', \'shape = (9000, 9000)\', \'times = 9.4296 seconds\', \'result = 0.0\')\n(\'/gpu:0\', \'shape = (12000, 12000)\', \'times = 21.750406 seconds\', \'result = 0.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:1\', \'shape = (3000, 3000)\', \'times = 0.523286 seconds\', \'result = 0.0\')\n(\'/gpu:1\', \'shape = (6000, 6000)\', \'times = 2.887522 seconds\', \'result = 0.0\')\n(\'/gpu:1\', \'shape = (9000, 9000)\', \'times = 9.377383 seconds\', \'result = 0.0\')\n(\'/gpu:1\', \'shape = (12000, 12000)\', \'times = 21.639043 seconds\', \'result = 0.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n\n\nmatrix=zeros+config=simple+warmup=True\n(\'/cpu:0\', \'shape = (3000, 3000)\', \'times = 0.520212 seconds\', \'result = 0.0\')\n(\'/cpu:0\', \'shape = (3000, 3000)\', \'times = 0.000172 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n(\'/cpu:0\', \'shape = (6000, 6000)\', \'times = 2.914485 seconds\', \'result = 0.0\')\n(\'/cpu:0\', \'shape = (6000, 6000)\', \'times = 0.000166 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n(\'/cpu:0\', \'shape = (9000, 9000)\', \'times = 9.346122 seconds\', \'result = 0.0\')\n(\'/cpu:0\', \'shape = (9000, 9000)\', \'times = 0.000207 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n(\'/cpu:0\', \'shape = (12000, 12000)\', \'times = 21.715376 seconds\', \'result = 0.0\')\n(\'/cpu:0\', \'shape = (12000, 12000)\', \'times = 0.0002 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:0\', \'shape = (3000, 3000)\', \'times = 0.556841 seconds\', \'result = 0.0\')\n(\'/gpu:0\', \'shape = (3000, 3000)\', \'times = 0.000234 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n(\'/gpu:0\', \'shape = (6000, 6000)\', \'times = 2.936608 seconds\', \'result = 0.0\')\n(\'/gpu:0\', \'shape = (6000, 6000)\', \'times = 0.000244 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n(\'/gpu:0\', \'shape = (9000, 9000)\', \'times = 9.34956 seconds\', \'result = 0.0\')\n(\'/gpu:0\', \'shape = (9000, 9000)\', \'times = 0.000246 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n(\'/gpu:0\', \'shape = (12000, 12000)\', \'times = 21.634354 seconds\', \'result = 0.0\')\n(\'/gpu:0\', \'shape = (12000, 12000)\', \'times = 0.000221 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:1\', \'shape = (3000, 3000)\', \'times = 0.562244 seconds\', \'result = 0.0\')\n(\'/gpu:1\', \'shape = (3000, 3000)\', \'times = 0.000255 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n(\'/gpu:1\', \'shape = (6000, 6000)\', \'times = 2.961658 seconds\', \'result = 0.0\')\n(\'/gpu:1\', \'shape = (6000, 6000)\', \'times = 0.000237 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n(\'/gpu:1\', \'shape = (9000, 9000)\', \'times = 9.308582 seconds\', \'result = 0.0\')\n(\'/gpu:1\', \'shape = (9000, 9000)\', \'times = 0.000239 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n(\'/gpu:1\', \'shape = (12000, 12000)\', \'times = 21.707127 seconds\', \'result = 0.0\')\n(\'/gpu:1\', \'shape = (12000, 12000)\', \'times = 0.000261 seconds\', \'result = 0.0\', \'*****WARMED UP*****\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n\n\n\nmatrix=zeros+config=optim+warmup=False\n(\'/cpu:0\', \'shape = (3000, 3000)\', \'times = 0.560451 seconds\', \'result = 0.0\')\n(\'/cpu:0\', \'shape = (6000, 6000)\', \'times = 2.978946 seconds\', \'result = 0.0\')\n(\'/cpu:0\', \'shape = (9000, 9000)\', \'times = 9.3279 seconds\', \'result = 0.0\')\n(\'/cpu:0\', \'shape = (12000, 12000)\', \'times = 21.694664 seconds\', \'result = 0.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:0\', \'shape = (3000, 3000)\', \'times = 0.249778 seconds\', \'result = 0.0\')\n(\'/gpu:0\', \'shape = (6000, 6000)\', \'times = 0.365332 seconds\', \'result = 0.0\')\n(\'/gpu:0\', \'shape = (9000, 9000)\', \'times = 0.663667 seconds\', \'result = 0.0\')\n(\'/gpu:0\', \'shape = (12000, 12000)\', \'times = 1.032716 seconds\', \'result = 0.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n(\'/gpu:1\', \'shape = (3000, 3000)\', \'times = 0.299856 seconds\', \'result = 0.0\')\n(\'/gpu:1\', \'shape = (6000, 6000)\', \'times = 0.294592 seconds\', \'result = 0.0\')\n(\'/gpu:1\', \'shape = (9000, 9000)\', \'times = 0.55067 seconds\', \'result = 0.0\')\n(\'/gpu:1\', \'shape = (12000, 12000)\', \'times = 0.806868 seconds\', \'result = 0.0\')\n++++++++++++++++++++++++++++++++++++++++++++++++++++\n</code></pre>\n'}, {'owner': {'reputation': 57117, 'user_id': 419116}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1483467868, 'answer_id': 41449981, 'question_id': 41449338, 'body': '<p>I suspect this this related to GPU kernel optimization. If you ""pre-warm"" your GPU by running the same computation shape, the next execution is much faster. There\'s PTX compilation that <a href=""https://stackoverflow.com/questions/40410210/tensorflow-2-gpu-slower-then-single-gpu/40430717#40430717"">adds a couple of seconds</a> to the first usage of kernel on a GPU in a process, but it\'s peculiar that your runtime increases with size of the matrix, perhaps there\'s some profiling going on as well.</p>\n\n<p>Note that without <code>tf.OptimizerOptions.L0</code> it becomes implausibly fast, so there\'s some caching happening as well.</p>\n\n<pre><code>shape = (6000, 6000)\nwith tf.device(""/gpu:0""):\n    random_matrix_gpu = tf.zeros(shape)\n    result_op_gpu = tf.reduce_sum(tf.matmul(random_matrix_gpu,tf.transpose(random_matrix_gpu)))\nwith tf.device(""/cpu:0""):\n    random_matrix_cpu = tf.zeros(shape)\n    result_op_cpu = \n\ntf.reduce_sum(tf.matmul(random_matrix_cpu,tf.transpose(random_matrix_cpu)))\nconfig = tf.ConfigProto(graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)))\nsess = tf.Session(config=config)\n\ndef profile(op, msg):\n    start_time = time.time()\n    sess.run(op)\n    print(msg, time.time()-start_time)\n\nprofile(result_op_cpu, ""cpu1"")\nprofile(result_op_cpu, ""cpu2"")\nprofile(result_op_gpu, ""gpu1"")\nprofile(result_op_gpu, ""gpu2"")\n</code></pre>\n\n<p>I see this:</p>\n\n<pre><code>cpu1 1.716048240661621\ncpu2 1.509080171585083\ngpu1 4.192790746688843\ngpu2 0.13361549377441406\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8873}"
1115,52471675,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1537796300, 'answer_id': 52480679, 'question_id': 52471675, 'body': '<p>You can check it with <code>op.type</code>:</p>\n\n<pre><code>assert tf.placeholder(""float"", []).op.type == \'Placeholder\'\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8868}"
1116,45107068,"{'items': [{'owner': {'reputation': 3805, 'user_id': 2156909}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1500382875, 'answer_id': 45167585, 'question_id': 45107068, 'body': '<p>The answer is to use a saver to restore the parameters and to wrap the <code>saver.restore</code> function so it can be used as a <code>init_fn</code> of the <code>Scaffold</code>. This wrapper has to take two arguments: <code>scaffold</code> and <code>sess</code>, of which <code>sess</code> is used to restore the parameters and the <code>scaffold</code> is thrown away.</p>\n\n<p>Complete code:</p>\n\n<pre><code>import sys\nimport tensorflow as tf\nslim = tf.contrib.slim\nimport argparse\nimport model as M\nimport decoder as D\n\n\nFLAGS = None\n\n\ndef train(_):\n    vgg_19_ckpt_path=\'/media/data/projects/project_daphnis/pretrained_models/vgg_19.ckpt\'\n    train_log_dir = ""/media/data/projects/project_daphnis/train_log_dir""\n\n    ps_hosts = FLAGS.ps_hosts.split("","")\n    worker_hosts = FLAGS.worker_hosts.split("","")\n\n    # Create a cluster from the parameter server and worker hosts.\n    cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})\n\n    # Create and start a server for the local task.\n    server = tf.train.Server(cluster,\n                             job_name=FLAGS.job_name,\n                             task_index=FLAGS.task_index)\n\n    if FLAGS.job_name == ""ps"":\n        server.join()\n    elif FLAGS.job_name == ""worker"":\n        if not tf.gfile.Exists(train_log_dir):\n            tf.gfile.MakeDirs(train_log_dir)\n\n        # Assigns ops to the local worker by default.\n        with tf.device(tf.train.replica_device_setter(\n                worker_device=""/job:worker/task:%d"" % FLAGS.task_index,\n                cluster=cluster)):\n\n            # Set up the data loading:\n            image, c, p, s = \\\n                D.get_training_dataset_data_provider()\n\n            image, c, p, s = \\\n                tf.train.batch([image, c, p, s],\n                               batch_size=16)\n\n            # Define the model:\n            predictions, loss, end_points = M.model_as_in_paper(\n                image, c, p, s\n            )\n\n            values_to_restore = slim.get_variables_to_restore(\n                include=[""vgg_19""],\n                exclude=[\n                    \'vgg_19/conv4_3_X\',\n                    \'vgg_19/conv4_4_X\']\n        )\n\n\n            # Specify the optimization scheme:\n            optimizer = tf.train.AdamOptimizer(learning_rate=.00001)\n\n            # create_train_op that ensures that when we evaluate it to get the loss,\n            # the update_ops are done and the gradient updates are computed.\n            train_op = slim.learning.create_train_op(loss, optimizer)\n        tf.summary.scalar(""losses/total_loss"", loss)\n\n        # The StopAtStepHook handles stopping after running given steps.\n        hooks = [tf.train.StopAtStepHook(last_step=1000000)]\n\n        pre_train_saver = tf.train.Saver(values_to_restore)\n\n        def load_pretrain(scaffold, sess):\n            pre_train_saver.restore(sess,\n                                    vgg_19_ckpt_path)\n\n        # The MonitoredTrainingSession takes care of session initialization,\n        # restoring from a checkpoint, saving to a checkpoint, and closing when done\n        # or an error occurs.\n        with tf.train.MonitoredTrainingSession(\n                master=server.target,\n                is_chief=(FLAGS.task_index == 0),\n                checkpoint_dir=train_log_dir,\n                hooks=hooks,\n                scaffold=tf.train.Scaffold(\n                    init_fn=load_pretrain,\n                    summary_op=tf.summary.merge_all())) as mon_sess:\n\n            while not mon_sess.should_stop():\n                # Run a training step asynchronously.\n                # See `tf.train.SyncReplicasOptimizer` for additional details on how to\n                # perform *synchronous* training.\n                # mon_sess.run handles AbortedError in case of preempted PS.\n                mon_sess.run(train_op)\n\nif __name__ == ""__main__"":\n    if __name__ == ""__main__"":\n        parser = argparse.ArgumentParser()\n        parser.register(""type"", ""bool"", lambda v: v.lower() == ""true"")\n        # Flags for defining the tf.train.ClusterSpec\n        parser.add_argument(\n            ""--ps_hosts"",\n            type=str,\n            default="""",\n            help=""Comma-separated list of hostname:port pairs""\n        )\n        parser.add_argument(\n            ""--worker_hosts"",\n            type=str,\n            default="""",\n            help=""Comma-separated list of hostname:port pairs""\n        )\n        parser.add_argument(\n            ""--job_name"",\n            type=str,\n            default="""",\n            help=""One of \'ps\', \'worker\'""\n        )\n        # Flags for defining the tf.train.Server\n        parser.add_argument(\n            ""--task_index"",\n            type=int,\n            default=0,\n            help=""Index of task within the job""\n        )\n        FLAGS, unparsed = parser.parse_known_args()\n        tf.app.run(main=train, argv=[sys.argv[0]] + unparsed)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8868}"
1117,65634172,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1622185281, 'answer_id': 67734241, 'question_id': 65634172, 'body': '<p>Functionality of tf.keras.metrics.Mean and tf.math.reduce_mean are slightly different.\nLook at the example</p>\n<p>#tf.keras.metrics.Mean: CASE1</p>\n<pre><code>import tensorflow as tf\nx = tf.constant([[1, 3, 5, 7],[1, 1, 0, 0]])\nm = tf.keras.metrics.Mean()\nm.update_state(x)\nm.result().numpy()\n</code></pre>\n<p>Output:</p>\n<pre><code>1.886\n</code></pre>\n<p>#tf.keras.metrics.Mean: CASE2</p>\n<pre><code>m.reset_state()\nm.update_state([1, 3, 5, 7], sample_weight=[1, 1, 0, 0])\nm.result().numpy()\n</code></pre>\n<p>Output:</p>\n<pre><code>2.0\n</code></pre>\n<p>#tf.math.reduce_mean</p>\n<p>#CASE1</p>\n<pre><code>y = tf.reduce_mean(x)\n</code></pre>\n<p>Output:</p>\n<pre><code>tf.Tensor(2, shape=(), dtype=int32)\n</code></pre>\n<p>#CASE2</p>\n<pre><code>y = tf.reduce_mean(x1,1)\n</code></pre>\n<p>Output:</p>\n<pre><code>tf.Tensor([4 0], shape=(2,), dtype=int32)\n</code></pre>\n<p>#CASE3</p>\n<pre><code>y = tf.reduce_mean(x1,0)\n</code></pre>\n<p>Output:</p>\n<pre><code>tf.Tensor([1 2 2 3], shape=(4,), dtype=int32)\n</code></pre>\n<p>In case of <code>tf.math.reduce_mean</code>, you see that when axis(numpy) is 1, it computes mean across (1, 3, 5, 7) and (1,1,0,0), so 1 defines across which axis the mean is computed. When it is 0, the mean is computed across(1,1),(3,1),(5,0) and (7,0), and so on.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8868}"
1118,42430331,"{'items': [{'owner': {'reputation': 165, 'user_id': 5721911}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1488826502, 'answer_id': 42633390, 'question_id': 42430331, 'body': '<p>The solution in <a href=""https://stackoverflow.com/questions/37697747/typeerror-tensor-object-does-not-support-item-assignment-in-tensorflow"">TypeError: &#39;Tensor&#39; object does not support item assignment in TensorFlow</a> pretty much solves the problem as Atirag pointed out, but \'tf.pack()\' seems to have been deprecated. Just for completeness, here is an up-to-date solution to the posted problem:</p>\n\n<pre><code>x0 = tf.Variable(tf.ones(1, dtype=tf.float32))\ndef f(x):\n    return tf.sin(x)\nx = [x0]\nfor i in range(1, 100):\n    x.append(f(x[i - 1]))\n\ntf.stack(x)\n</code></pre>\n'}, {'owner': {'reputation': 1670, 'user_id': 1269703}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1487908003, 'answer_id': 42430404, 'question_id': 42430331, 'body': ""<pre><code>def f(x):\n    return tf.sin(x)\nx = []\nx.append(tf.constant(1.0))\nfor i in range(1,100):\n    x.append(f(i))\n</code></pre>\n\n<p>Is this what you want?\nThis is not recursive by the way. It's iterative.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8868}"
1119,63004540,"{'items': [{'owner': {'reputation': 1159, 'user_id': 5235528}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1595287702, 'answer_id': 63005207, 'question_id': 63004540, 'body': '<p>You have to specify the padding at the beginning and the padding at the end of your vector by matrix of shape (1,2) :</p>\n<pre><code>tf.pad(tf.constant([1, 2, 3, 45]), [[ 0 , 20]], constant_values=10)\n</code></pre>\n<p>if you have three-dimensional tensor (rank = 3 e.g : (225,225,3) ) the padding matrix has to be of shape (3, 2 ) where &quot;3&quot; is the rank, and &quot;2&quot; to specify the padding at the beginning and end of each dimension.</p>\n<p>For example, a padding matrix  = [ [0,2], [5,5], [2,0] ], means that we want to pad the first dimension by 0 at the beginning (=no padding) and 2 at the end .padding the second dimension by 5 at beginning and 5 at the end.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8868}"
1120,64642944,"{'items': [{'owner': {'reputation': 31, 'user_id': 14562728}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1604369458, 'answer_id': 64655865, 'question_id': 64642944, 'body': '<p>I found this issue has been reported on Github repository of Tensorflow: <a href=""https://github.com/tensorflow/tensorflow/issues/43568"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/43568</a></p>\n<p>This is caused by using <strong>tf.summary</strong> in model while <strong>tf.keras.callbacks.TensorBoard</strong> callback is also enabled, and the step will always be zero. The issue reporter gives a temporary solution.</p>\n<p>To fix it, inherit the <strong>tf.keras.callbacks.TensorBoard</strong> class and overwrite the <strong>on_train_begin</strong> method and <strong>on_test_begin</strong> method like this:</p>\n<pre><code>class TensorBoardFix(tf.keras.callbacks.TensorBoard):\n&quot;&quot;&quot;\nThis fixes incorrect step values when using the TensorBoard callback with custom summary ops\n&quot;&quot;&quot;\n\ndef on_train_begin(self, *args, **kwargs):\n    super(TensorBoardFix, self).on_train_begin(*args, **kwargs)\n    tf.summary.experimental.set_step(self._train_step)\n\n\ndef on_test_begin(self, *args, **kwargs):\n    super(TensorBoardFix, self).on_test_begin(*args, **kwargs)\n    tf.summary.experimental.set_step(self._val_step)\n</code></pre>\n<p>And use this fixed callback class in <strong>model.fit()</strong>:</p>\n<pre><code>tensorboard_callback = TensorBoardFix(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq=1)\nmodel.fit(dataset, epochs=200, callbacks=[tensorboard_callback])\n</code></pre>\n<p>This solve my problem and now I can get proper step inside my model by calling <strong>tf.summary.experimental.get_step()</strong>.</p>\n<p>(This issue may be fixed in later version of TensorFlow)</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8863}"
1121,58550146,"{'items': [{'owner': {'reputation': 78, 'user_id': 1480784}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1689358405, 'answer_id': 76690233, 'question_id': 58550146, 'body': '<p>As batch normalization behaves differently during training and inference, the <code>training</code> variable you pass into <code>call()</code> needs to be fed into the <code>BatchNormalization</code> layer.</p>\n<pre><code>import tensorflow as tf\n\ndef call(self, inputs, training=False):\n    x = tf.keras.layers.BatchNormalization()(inputs, training=training)\n    return x\n</code></pre>\n'}, {'owner': {'reputation': 437, 'user_id': 817824}, 'down_vote_count': 1, 'up_vote_count': 1, 'is_accepted': True, 'score': 0, 'creation_date': 1582434975, 'answer_id': 60359400, 'question_id': 58550146, 'body': '<p>I started using pyTorch. It solved the problem.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8862}"
1122,40451974,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1483652846, 'answer_id': 41495299, 'question_id': 40451974, 'body': '<p>I\'m using tensorflow 0.12 and <code>clear_devices=True</code> and <code>tf.device(\'/cpu:0\')</code> was not working with me (saver.restore was still trying to assign variables to /gpu:0). </p>\n\n<p>I really needed to force everything to /cpu:0 since I was loading several models which wouldn\'t fit in GPU memory anyways. Here are two alternatives to force everything to /cpu:0</p>\n\n<ol>\n<li>Set <code>os.environ[\'CUDA_VISIBLE_DEVICES\']=\'\'</code> </li>\n<li>Use the device_count of ConfigProto like <code>tf.Session(config=tf.ConfigProto(device_count={""GPU"": 0, ""CPU"": 1}))</code></li>\n</ol>\n'}, {'owner': {'reputation': 57117, 'user_id': 419116}, 'down_vote_count': 0, 'up_vote_count': 8, 'is_accepted': False, 'score': 8, 'creation_date': 1478460511, 'answer_id': 40453582, 'question_id': 40451974, 'body': '<p>Use <code>clear_devices</code> flag, ie </p>\n\n<pre><code>saver = tf.train.import_meta_graph(""/tmp/graph.meta"", clear_devices=True)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8862}"
1123,59359113,"{'items': [{'owner': {'reputation': 10975, 'user_id': 1699075}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1576526431, 'answer_id': 59363499, 'question_id': 59359113, 'body': '<p>It is difficult to say either is better at this point. Because keras backend offers unique feature(s) (still).</p>\n\n<p>For example, <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/backend/rnn"" rel=""nofollow noreferrer""><code>K.rnn</code></a> is a very valuable function provided by Keras backend. This can be used to iterate the temporal output of a sequential model (LSTM/GRU) on the temporal dimension. This is pretty useful when you have to do a <code>map()</code> like function on each temporal output of a sequential model (e.g. computing attention vector for each LSTM output of the encoder). This is a very convenient functions to achieve the above because, (as far as I know) doing this with <code>tf.*</code> involves <code>tf.gather</code> and can become ugly (especially in TF 1.x). I am not really sure about other functions that might offer a unique advantage over <code>tf.*</code>. But probably there are a few (e.g. <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/backend/foldl?version=stable"" rel=""nofollow noreferrer""><code>K.foldl</code></a>). </p>\n\n<p>On the other hand, <code>tf.*</code> does offer many more functions than what the Keras backend offers. </p>\n\n<p>In conclusion, I think it\'s too early to completely avoid Keras backend. But I do feel like the keras backend will get merged to <code>tf.*</code> at some point in order to offer a more consistent API.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8862}"
1124,55168906,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1552585730, 'answer_id': 55169030, 'question_id': 55168906, 'body': '<p>With non-sparse cross-entropy functions, you need to one-hot encode your labels so they have the same shape as your logits:</p>\n\n<pre><code>loss = tf.nn.weighted_cross_entropy_with_logits(tf.one_hot(labels, 2), logits, pos_weight)\n</code></pre>\n\n<p>Note <a href=""https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy"" rel=""nofollow noreferrer""><code>tf.losses.sparse_softmax_cross_entropy</code></a> also admits a <code>weights</code> parameter, although it has a slightly different meaning (it is just a sample-wise weight). The equivalent formulation should be:</p>\n\n<pre><code>loss = tf.losses.sparse_softmax_cross_entropy(labels, logits,\n                                              weights=pos_weight * labels + (1 - labels))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8862}"
1125,67211152,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1632491074, 'answer_id': 69316071, 'question_id': 67211152, 'body': '<p>According to latest document on <a href=""https://www.tensorflow.org/api_docs/python/tf/where"" rel=""nofollow noreferrer"">tf.where</a></p>\n<blockquote>\n<p>If x and y are provided (both have non-None values):</p>\n<p>tf.where will choose an output shape from the shapes of condition, x,\nand y that all three shapes are broadcastable to.</p>\n<p>The condition tensor acts as a mask that chooses whether the\ncorresponding element / row in the output should be taken from x (if\nthe element in condition is True) or y (if it is false).</p>\n</blockquote>\n<p>For Example:</p>\n<pre><code>tf.where([True, False, False, True], [1,2,3,4], [100,200,300,400])\n</code></pre>\n<p>#It is taking true  index values from [1,2,3,4] that is  [1,4] and false index values from [100,200,300,400] that is [200,300]</p>\n<p>Output:</p>\n<blockquote>\n<p>&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([  1, 200, 300,   4],\ndtype=int32)&gt;</p>\n</blockquote>\n<p>As you can see output tensor shape  as input numpy arrays.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8858}"
1126,72329108,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8858}"
1127,57526164,"{'items': [{'owner': {'reputation': 11, 'user_id': 13753239}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1598870712, 'answer_id': 63669319, 'question_id': 57526164, 'body': '<p>@nessuno \'s answer is excellent and it helps me a lot. While, actually the doc <a href=""https://www.tensorflow.org/api_docs/python/tf/autograph/to_graph"" rel=""nofollow noreferrer"">tf.autograph.to_graph</a> explains the relation ship between autograpsh and tf.funciton directly:</p>\n<blockquote>\n<p>Unlike tf.function, to_graph is a low-level transpiler that converts Python code to TensorFlow graph code. It does not implement any caching, variable management or create any actual ops, and is best used where greater control over the generated TensorFlow graph is desired. Another difference from tf.function is that to_graph will not wrap the graph into a TensorFlow function or a Python callable. Internally, tf.function uses to_graph.</p>\n</blockquote>\n'}, {'owner': {'reputation': 26626, 'user_id': 2891324}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1565972680, 'answer_id': 57528083, 'question_id': 57526164, 'body': '<p>I covered and answered all your questions in a three-part article: ""Analyzing tf.function to discover AutoGraph strengths and subtleties"": <a href=""https://pgaleone.eu/tensorflow/tf.function/2019/03/21/dissecting-tf-function-part-1/"" rel=""noreferrer"">part 1</a>, <a href=""https://pgaleone.eu/tensorflow/tf.function/2019/04/03/dissecting-tf-function-part-2/"" rel=""noreferrer"">part 2</a>, <a href=""https://pgaleone.eu/tensorflow/tf.function/2019/05/10/dissecting-tf-function-part-3/"" rel=""noreferrer"">part 3</a>.</p>\n\n<p>To summarize and answer your 3 questions:</p>\n\n<ul>\n<li>What is the relationship between <code>tf.function</code> and <code>autograph.to_graph</code>?</li>\n</ul>\n\n<p><code>tf.function</code> uses AutoGraph by default. What happens when you <strong>invoke</strong> the first time a tf.function-decorated function is that:</p>\n\n<ol>\n<li>The function body is executed (in TensorFlow 1.x like, thus without eager mode) and its execution is traced (now tf.function knows which nodes are present, which branch of the <code>if</code> to keep and so on)</li>\n<li>At the same time, AutoGraph starts and tries to convert to <code>tf.*</code> calls, the Python statements it knows (<code>while</code> -> <code>tf.while</code>, <code>if</code> -> <code>tf.cond</code>, ...)-.</li>\n</ol>\n\n<p>Merging the information from points 1 and 2 a new graph is built, and based on the function name and the type of the parameters it is cached in a map (see the articles for a better understanding).</p>\n\n<ul>\n<li>Is the autograph.to_graph snippet still supported in TF2.0?</li>\n</ul>\n\n<p>Yes, <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/autograph/to_graph"" rel=""noreferrer""><code>tf.autograph.to_graph</code></a> is still present and it creates a session internally for you (in TF2 you don\'t have to worry about them).</p>\n\n<p>At any rate, I suggest you read the three articles linked since they cover in detail this and other peculiarities of <code>tf.function</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8858}"
1128,62668694,"{'items': [{'owner': {'reputation': 1205, 'user_id': 5714255}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1594424631, 'answer_id': 62843705, 'question_id': 62668694, 'body': '<p>Those operations are for an internal purpose, they are implemented in c++ so you\'ll need to download the source code, code (in c++) your own tests, compile and run them, since most of those operations do not have a Python wrapper.</p>\n<p>Here you can find the <a href=""https://www.tensorflow.org/api_docs/cc"" rel=""nofollow noreferrer"">c++ api</a>.</p>\n<p>This <a href=""https://www.tensorflow.org/guide/create_op"" rel=""nofollow noreferrer"">tutorial</a> may help you if you are starting with tf operation. It does not do what you want, as it works with custom public operations.</p>\n<p>You may have a look to the tests already implemented in tf code, fore example <a href=""https://github.com/tensorflow/tensorflow/blob/abbeddb86f458c79910e1546fbb76694140c9362/tensorflow/core/common_runtime/function_test.cc"" rel=""nofollow noreferrer"">this</a> test file.</p>\n<p>However, I will strongly recommend that you reconsider if you really need to test those functions. Testing every single function from TensorFlow, even the internal ones, is going to be a hard job.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8858}"
1129,68878231,"{'items': [{'owner': {}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1643964818, 'answer_id': 70983654, 'question_id': 68878231, 'body': '<p><strong>TF.gradients</strong></p>\n<p><code>tf.gradients</code> is only valid in a graph context. In particular, it is valid in the context of a <code>tf.function</code> wrapper, where code is executing as a graph.</p>\n<pre><code>@tf.function\ndef example():\n  a = tf.constant(0.)\n  b = 2 * a\n  return tf.gradients(a + b, [a, b], stop_gradients=[a, b])\nexample()\n</code></pre>\n<p><strong>tf.GradientTape</strong></p>\n<p>TensorFlow provides the <code>tf.GradientTape</code> API for automatic differentiation. TensorFlow <code>&quot;records&quot;</code> relevant operations executed inside the context of a <code>tf.GradientTape</code> onto a <code>&quot;tape&quot;</code>. TensorFlow then uses that tape to compute the gradients of a &quot;recorded&quot; computation using <strong>reverse mode differentiation</strong>. <code>tf.GradientTape</code> not really required <code>tf.function</code> wrapper. It automatically runs in Graph mode.</p>\n<pre><code>x = tf.constant(3.0)\nwith tf.GradientTape() as g:\n  g.watch(x)\n  y = x * x\ndy_dx = g.gradient(y, x)\nprint(dy_dx)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8858}"
1130,67561368,"{'items': [{'owner': {'reputation': 1428, 'user_id': 10617503}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1621249387, 'answer_id': 67568419, 'question_id': 67561368, 'body': '<p>If you go <a href=""https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/backend.py#L4718"" rel=""nofollow noreferrer"">deep enough</a>, you might find that <code>tf.keras.layers.LeakyReLU</code> is actually calling <code>tf.nn.leaky_relu</code> under the hood.</p>\n<p>Therefore, I don\'t think there should be any difference in using the latter or former.</p>\n<p>Although, from my experience I would suggest to stick with Keras Layers as much as possible, if you are using Keras API, to avoid any serialization issues later on.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8853}"
1131,59422616,"{'items': [{'owner': {'reputation': 2961, 'user_id': 4373898}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1576833670, 'answer_id': 59422682, 'question_id': 59422616, 'body': '<p>What is the shape of <code>self.max_outputs_num</code>?</p>\n\n<p>From <a href=""https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression?version=stable"" rel=""nofollow noreferrer"">the documentation</a>:</p>\n\n<blockquote>\n  <p><strong><code>max_output_size</code></strong>: A scalar integer Tensor representing the maximum number of boxes to be selected by non max suppression.</p>\n</blockquote>\n\n<p>Here, it seems to be an 1-D array, as the error message report it between brackets.\nMoreover, it would match the error message, as a scalar has a rank 0 and a 1-D array as a rank 1.</p>\n\n<p>Thus, you should probably convert your <code>self.max_outputs_num</code> from an array to a scalar.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8853}"
1132,48033687,"{'items': [{'owner': {'reputation': 1, 'user_id': 9705944}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1524762659, 'answer_id': 50048576, 'question_id': 48033687, 'body': '<p>I encountered the same problem when using <em>tf.train.shuffle_batch</em>. The solution is to add the parameter <strong>enqueue_many = True</strong>.  The default is the parameter enqueue_many is <strong>False</strong>.</p>\n\n<p>As explained in the documentation in <a href=""https://www.tensorflow.org/api_docs/python/tf/train/shuffle_batch"" rel=""nofollow noreferrer"">tf.train.shuffle_batch</a> \n""If enqueue_many is True, tensors is assumed to represent a batch of examples, where the first dimension is indexed by example, and all members of tensors should have the same size in the first dimension. If an input tensor has shape [*, x, y, z], the output will have shape [batch_size, x, y, z].""</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8853}"
1133,60977051,"{'items': [{'owner': {'reputation': 47, 'user_id': 6334302}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1585767844, 'answer_id': 60978459, 'question_id': 60977051, 'body': '<p>How did you create this dataset?</p>\n\n<p>If each element in the dataset is in the format <code>(input_data, target_data)</code> then you can do </p>\n\n<pre><code>input_dataset = dataset.map(lambda x,y: x)\ntarget_dataset = dataset.map(lambda x,y: y)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8853}"
1134,67542939,"{'items': [{'owner': {'reputation': 133, 'user_id': 4284407}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1621196177, 'answer_id': 67561207, 'question_id': 67542939, 'body': '<p>It is happening because of <code>autograph</code>. In the case of the <code>_return</code> function, because the <code>r</code> value is returned, it is generating the complete graph (with <code>r</code> as the leaf node). But, in the case of <code>_no_return</code> function, there is no return value, and the autograph does not set <code>r</code> as the leaf node, and because there is no leaf node the overall graph has nothing in it.</p>\n<p>Thus, you observe this speed-up because the function is not computing anything.</p>\n<p>Add any leaf nodes (as shown in the demo below)</p>\n<pre><code>def _no_return(batch):\n    # your old code\n    tf.print(r) # this will create another leaf node, \n    # or you can try\n    tf.summary.scalar(r)\n</code></pre>\n<p>you will observe a similar performance between <code>_return</code> and <code>_no_return</code>. Also, if you remove <code>@tf.function</code> decorator, then also you will see the same performance.</p>\n<p>lemme know if you have any more doubts.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8849}"
1135,71335830,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1646304853, 'answer_id': 71335932, 'question_id': 71335830, 'body': ""<p>I think the confusion comes from using a <code>tf.keras.Sequential</code> model, which does not need an explicit <code>Input</code> layer. Consider the following two models, which are equivalent:</p>\n<pre><code>import tensorflow as tf\n\nmodel1 = tf.keras.Sequential([\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(5, activation='relu'),\n    ])\n\nmodel1.build((1, 28, 28, 1))\n</code></pre>\n<pre><code>model2 = tf.keras.Sequential([\n      tf.keras.layers.Input((28, 28, 1)),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(5, activation='relu'),\n    ])\n</code></pre>\n<p>The difference is that I explicitly set the input shape of <code>model2</code> using an <code>Input</code> layer. In <code>model1</code>, the input shape will be inferred when you pass real data to it or call <code>model.build</code>.</p>\n<p>Now regarding the <code>Flatten</code> layer, this layer simply converts a n-dimensional tensor (for example <code>(28, 28, 1)</code>) into a 1D tensor <code>(28 x 28 x 1)</code>. The <code>Flatten</code> layer and <code>Input</code> layer can coexist in a <code>Sequential</code> model but do not depend on each other.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8849}"
1136,74545053,"{'items': [{'owner': {'reputation': 31, 'user_id': 19101082}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1670582210, 'answer_id': 74741915, 'question_id': 74545053, 'body': '<p>The C functions that the python function <code>tf.gradients</code> calls on can be found in the following header file:</p>\n<pre><code>#include &quot;tensorflow/core/gradients/grad_ops.h&quot;\n</code></pre>\n<p>You can use <code>tensorflow::GradientTape</code> to initialize a tape which the can call on the <code>gradient</code> function to compute the gradient of a tensor <code>y</code> in respect to <code>x</code>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8849}"
1137,74906407,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8849}"
1138,59727776,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8849}"
1139,71059361,"{'items': [{'owner': {'reputation': 26189, 'user_id': 9657861}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1644494651, 'answer_id': 71064797, 'question_id': 71059361, 'body': '<p>You need to assign the batched dataset to a variable and you should also use a loss function in <code>model.compile</code> because the default value is <code>None</code> and you can\'t learn anything with it. Here is a working example:</p>\n<pre class=""lang-py prettyprint-override""><code>import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\n\nprint(\'numpy version: {}\'.format(np.__version__))\nprint(\'keras version: {}\'.format(keras.__version__))\nprint(\'tensorflow version: {}\'.format(tf.__version__))\nX = np.random.uniform(size=(1000,75))\nY = np.random.uniform(size=(1000))\n\ndata = tf.data.Dataset.from_tensor_slices((X, Y))\nprint(data.cardinality().numpy())\ndata = data.batch(batch_size=100, drop_remainder=True)\n\ndef API_Model(input_shape, name=&quot;test_model&quot;):\n\n    inputs = layers.Input(shape=input_shape)\n    x = layers.Dense(1)(inputs)\n    outputs = layers.Activation(\'relu\')(x)\n\n    return keras.Model(inputs=inputs, outputs=outputs, name=name)\n\napi_model = API_Model(input_shape=(X.shape[1],))\napi_model.compile(loss=\'mse\')\napi_model.summary()\napi_model.fit(data, epochs=10)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8844}"
1140,66467746,"{'items': [{'owner': {'reputation': 358, 'user_id': 5310949}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1614827066, 'answer_id': 66467976, 'question_id': 66467746, 'body': '<pre><code>def map_decorator(func):\n    def wrapper(inp):\n        # Use a tf.py_function to prevent auto-graph from compiling the method\n        return tf.py_function(\n            func,\n            inp=[inp],\n            Tout=(inp.dtype)\n        )\n    return wrapper\n\ntf.concat(list(ds.map(map_decorator(qt.transform)).as_numpy_iterator()), axis=0)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8843}"
1141,57995171,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8843}"
1142,52533156,"{'items': [{'owner': {'reputation': 86, 'user_id': 6911920}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1551757893, 'answer_id': 54995142, 'question_id': 52533156, 'body': ""<p>Custom estimators require you to define your graph from scratch, you can pass  initializer for every layer/ operation(if its constructor takes initializer argument), it's done usually inside model_fn, or inside the function that defines the graph </p>\n""}, {'owner': {'reputation': 2146, 'user_id': 3086290}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1538046648, 'answer_id': 52535618, 'question_id': 52533156, 'body': '<p><code>DNNRegressor</code> uses <a href=""https://www.tensorflow.org/api_docs/python/tf/glorot_uniform_initializer"" rel=""nofollow noreferrer"">glorot_uniform_initializer</a> (aka Xavier uniform), it is hardcoded in the <a href=""https://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/python/estimator/canned/dnn.py#L102"" rel=""nofollow noreferrer"">implementation</a>.</p>\n\n<p>To use a different initializer with estimators API you have to use <a href=""https://www.tensorflow.org/guide/custom_estimators"" rel=""nofollow noreferrer"">custom estimator</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8843}"
1143,59709349,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8843}"
1144,48543654,"{'items': [{'owner': {'reputation': 52739, 'user_id': 712995}, 'down_vote_count': 0, 'up_vote_count': 5, 'is_accepted': True, 'score': 5, 'creation_date': 1517413828, 'answer_id': 48546187, 'question_id': 48543654, 'body': '<p><a href=""https://www.tensorflow.org/api_docs/python/tf/train/Server"" rel=""nofollow noreferrer""><code>tf.train.Server</code></a> is designed for distributed computation within a <em>cluster</em>, when there is a need to <em>communicate</em> between different nodes. This is especially useful when training is distributed across multiple machines or in some cases across multiple GPUs on a single machine. From the documentation:</p>\n<blockquote>\n<p>An in-process TensorFlow server, for use in distributed training.</p>\n<p>A <code>tf.train.Server</code> instance encapsulates a set of devices and a <code>tf.Session</code> target that can participate in distributed training. A server belongs to a cluster (specified by a <code>tf.train.ClusterSpec</code>), and corresponds to a particular task in a named job. <strong>The server can communicate with any other server in the same cluster</strong>.</p>\n</blockquote>\n<p>Spawning multiple processes with <code>multiprocessing.Process</code> isn\'t a cluster in Tensorflow sense, because the child processes aren\'t interacting with each other. This method is easier to setup, but it\'s <strong>limited to a single machine</strong>. Since you say you have just one machine, this might not be a strong argument, but if you ever plan to scale to a cluster of machines, you\'ll have to redesign the whole approach.</p>\n<p><code>tf.train.Server</code> is thus a more universal and scalable solution. Besides, it allows to organize complex training with some non-trivial communications, e.g., async gradient updates. Whether it is faster to train or not greatly depends on a task, I don\'t think there will be a significant difference on one shared GPU.</p>\n<p>Just for the reference, here\'s how the code looks like with the server (between graph replication example):</p>\n\n<pre class=""lang-py prettyprint-override""><code># specify the cluster\'s architecture\ncluster = tf.train.ClusterSpec({\n  \'ps\': [\'192.168.1.1:1111\'],\n  \'worker\': [\'192.168.1.2:1111\',\n             \'192.168.1.3:1111\']\n})\n\n# parse command-line to specify machine\njob_type = sys.argv[1]  # job type: &quot;worker&quot; or &quot;ps&quot;\ntask_idx = sys.argv[2]  # index job in the worker or ps list as defined in the ClusterSpec\n\n# create TensorFlow Server. This is how the machines communicate.\nserver = tf.train.Server(cluster, job_name=job_type, task_index=task_idx)\n\n# parameter server is updated by remote clients.\n# will not proceed beyond this if statement.\nif job_type == \'ps\':\n  server.join()\nelse:\n  # workers only\n  with tf.device(tf.train.replica_device_setter(worker_device=\'/job:worker/task:\' + task_idx,\n                                                cluster=cluster)):\n    # build your model here as if you only were using a single machine\n    pass\n\n  with tf.Session(server.target):\n    # train your model here\n    pass\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8839}"
1145,47935393,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8839}"
1146,62418856,"{'items': [{'owner': {'reputation': 6086, 'user_id': 990421}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1596106165, 'answer_id': 63171558, 'question_id': 62418856, 'body': '<h2><code>tf.map_fn(func, elems)</code>:</h2>\n<p>Maps over axis 0. For example:</p>\n<pre class=""lang-py prettyprint-override""><code>tf.map_fn(lambda x: x*2, tf.constant([1, 2, 3])) # =&gt; [2, 4, 6]\ntf.map_fn(lambda x: x[0]*x[1], tf.constant([[1, 0], [2, 4], [3, 5]])) # =&gt; [0, 8, 15]\n</code></pre>\n<h2><code>tf.nest.map_structure(func, *structure)</code></h2>\n<h3>When <code>len(structure)==1</code></h3>\n<p>Conceptually:</p>\n<pre class=""lang-py prettyprint-override""><code>tf.map_fn(func, flatten(structure[0]))\n# then reapplies the structure[0] to the return value\n</code></pre>\n<p>For example:</p>\n<pre class=""lang-py prettyprint-override""><code>tf.nest.map_structure(lambda x: x*2, tf.constant((1, 2, 3))) # =&gt; (2, 4, 6)\ntf.nest.map_structure(lambda x: x*2, (1, (2, 3))) # =&gt; (2, (4, 6))\n</code></pre>\n<h3>When <code>len(structure) &gt; 1</code>, <code>func</code> is applied over the zip of all structure\'s elements</h3>\n<p>Conceptually:</p>\n<pre class=""lang-py prettyprint-override""><code>tf.map_fn(func, zip(*[flatten(_) _ in structure]))\n# then reapplies the structure[0] to the return value \n# (all elements in structure must have the same structure,\n#  i.e., structure[0] structureEqualsTo structure[1], etc.,)\n</code></pre>\n<p>For example:</p>\n<pre class=""lang-py prettyprint-override""><code>tf.nest.map_structure(lambda *x: sum(x), [1, [0]], [2, [4]], [3, [5]]) \n# =&gt; [sum([1,2,3]),[sum([0,4,5])]] == [6, [9]]\n</code></pre>\n'}, {'owner': {'reputation': 1, 'user_id': 10272762}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1594180205, 'answer_id': 62787244, 'question_id': 62418856, 'body': ""<p>I was confused by these two functions as well and wish there are better documentations. But one difference I do notice is that <code>tf.nest.structure(func, *structure)</code> applies <code>func</code> on each structure of <code>structure</code>, while <code>tf.map_fn(func, elems)</code> first unpack <code>elems</code> on dimension <code>0</code> and then applies <code>func</code> on the resulted sequence.</p>\n<p>Consider the following example:</p>\n<pre><code>example = [np.array([1, 2, 3]), np.array([-1, 1, -1])]\n\n\nresult_1 = tf.map_fn(lambda x: x[0] * x[1], example, dtype=tf.int64)\nprint(f&quot;{result_1=}&quot;)\n\nresult_2 = tf.nest.map_structure(lambda x: x[0] * x[1], example)\nprint(f&quot;{result_2=}&quot;)\n</code></pre>\n<p>Output:</p>\n<pre><code>result_1=&lt;tf.Tensor: shape=(3,), dtype=int64, numpy=array([-1,  2, -3])&gt;\nresult_2=[2, -1]\n</code></pre>\n<p>Back to your original question, I couldn't answer 1 and 2 either. As for 3, the two cases I can think of are:</p>\n<ol>\n<li>If your input is a <code>tf.Tensor</code> whose first dimension is batch size then use  <code>map_fn</code></li>\n<li>If your input is a list whose length is batch size then use <code>map_structure</code>.</li>\n</ol>\n<p>Again it'd be great if someone could clarify my understanding.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8839}"
1147,57120680,"{'items': [{'owner': {'reputation': 79, 'user_id': 7880796}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1631474440, 'answer_id': 69154537, 'question_id': 57120680, 'body': '<p>I think that maybe copy.deepcopy() could work...\nfor example:</p>\n<pre><code>import copy \ntensor_2 = copy.deepcopy(tensor_1)\n</code></pre>\n<p>Python doc about deepcopy:\n<a href=""https://docs.python.org/3/library/copy.html"" rel=""nofollow noreferrer"">https://docs.python.org/3/library/copy.html</a></p>\n'}, {'owner': {'reputation': 34635, 'user_id': 3767239}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1563585151, 'answer_id': 57121052, 'question_id': 57120680, 'body': '<p>You can use a named <a href=""https://www.tensorflow.org/api_docs/python/tf/assign"" rel=""nofollow noreferrer""><code>tf.assign</code></a> operation and then run only that operation via <a href=""https://www.tensorflow.org/api_docs/python/tf/Graph#get_operation_by_name"" rel=""nofollow noreferrer""><code>Graph.get_operation_by_name</code></a>. This won\'t fetch the tensor\'s value but just run the assign operation on the graph. Consider the following example:</p>\n\n<pre><code>import tensorflow as tf\n\na = tf.placeholder(tf.int32, shape=(2,))\nw = tf.Variable([1, 2])  # Updated in the training loop.\nb = tf.Variable([0, 0])  # Backup; stores intermediate result.\nt = tf.assign(w, tf.math.multiply(a, w))  # Update during training.\ntf.assign(b, w, name=\'backup\')\n\ninit_op = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init_op)\n    x = [2, 2]\n    # Emulate training loop:\n    for i in range(3):\n        print(\'w = \', sess.run(t, feed_dict={a: x}))\n    # Backup without retrieving the value (returns None).\n    print(\'Backup now: \', end=\'\')\n    print(sess.run(tf.get_default_graph().get_operation_by_name(\'backup\')))\n    # Train a bit more:\n    for i in range(3):\n        print(\'w = \', sess.run(t, feed_dict={a: x}))\n    # Check the backed-up value:\n    print(\'Backup: \', sess.run(b))  # Is [8, 16].\n</code></pre>\n\n<p>So for your example you could do:</p>\n\n<pre><code>t3 = tf.Variable([], validate_shape=False)\ntf.assign(t3, t2, validate_shape=False, name=\'backup\')\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8839}"
1148,50442156,"{'items': [{'owner': {'reputation': 3596, 'user_id': 6780025}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1526940518, 'answer_id': 50457193, 'question_id': 50442156, 'body': '<p>There is no support for this use case in TensorFlow at the moment. Unfortunately, ""replicating the inference function"" based only on the SavedModel (which is basically the computation graph with some metadata), is a fairly complex (and brittle, if implemented) graph transformation problem.</p>\n\n<p>If you don\'t have access to the source code that produced this model, your best bet is to load the SavedModel 4 times into 4 separate graphs, rewriting the target device to the corresponding GPU each time. Then, run each graph/session separately.</p>\n\n<p>Note that you can invoke <code>sess.run()</code> multiple times concurrently since <code>sess.run()</code> releases the GIL for the time of actual computation. All you need is several Python threads.  </p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8839}"
1149,75939760,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8834}"
1150,47167409,"{'items': [{'owner': {'reputation': 3059, 'user_id': 3991470}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1510106974, 'answer_id': 47170433, 'question_id': 47167409, 'body': '<p>The operation underneath is the same (see <a href=""https://stackoverflow.com/questions/42785026/tf-nn-conv2d-vs-tf-layers-conv2d"">here</a>).</p>\n\n<p>As for the kernel and its initialization, I took a glimpse in the code and it <em>looked</em> the same... the <code>layers.conv2d</code> call a <code>tf.get_variable</code> at the end of the day.</p>\n\n<p>But I wanted to see it empirically, so here is a test code that declares a conv2d using each method (<code>tf.layers.conv2d</code> and <code>tf.nn.conv2d</code>), evaluates the initialized kernels and compares them.</p>\n\n<p>I\'ve arbitrarily set the things that shouldn\'t interfere in the comparison, such as an input tensor and the strides.</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\n\n# the way you described in your question\ndef _nn(input_tensor, initializer, filters, size):\n    kernel = tf.get_variable(\n        initializer=initializer, \n        shape=[size, size, 32, filters],\n        name=\'kernel\')\n\n    conv = tf.nn.conv2d(\n        input=input_tensor,\n        filter=kernel,\n        strides=[1, 1, 1, 1],\n        padding=\'SAME\')\n\n    return kernel\n\n# the other way\ndef _layer(input_tensor, initializer, filters, size):\n    tf.layers.conv2d(\n        inputs=input_tensor,\n        filters=filters,\n        kernel_size=size,\n        kernel_initializer=initializer)\n\n    # \'conv2d/kernel:0\' is the name of the generated kernel\n    return tf.get_default_graph().get_tensor_by_name(\'conv2d/kernel:0\')\n\ndef _get_kernel(method):\n    # an isolated context for each conv2d\n    graph = tf.Graph()\n    sess = tf.Session(graph=graph)\n\n    with graph.as_default(), sess.as_default():\n        # important so that same randomness doesnt play a role\n        tf.set_random_seed(42)\n\n        # arbitrary input tensor with compatible shape\n        input_tensor = tf.constant(1.0, shape=[1, 64, 64, 32])\n\n        initializer = tf.contrib.layers.xavier_initializer()\n\n        kernel = method(\n            input_tensor=input_tensor,\n            initializer=initializer,\n            filters=32,\n            size=3)\n\n        sess.run(tf.global_variables_initializer())\n        return sess.run(kernel)\n\nif __name__ == \'__main__\':\n    kernel_nn = _get_kernel(_nn)\n    kernel_layer = _get_kernel(_layer)\n\n    print(\'kernels are \', end=\'\')\n    # compares shape and values\n    if np.array_equal(kernel_layer, kernel_nn):\n        print(\'exactly the same\')\n    else:\n        print(\'not the same!\')\n</code></pre>\n\n<p>And the output is... <strong>kernels are exactly the same</strong>.</p>\n\n<p>The docs, btw: <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv2d"" rel=""nofollow noreferrer"">tf.nn.conv2d</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/layers/conv2d"" rel=""nofollow noreferrer"">tf.layers.conv2d</a>.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8834}"
1151,58867635,"{'items': [{'owner': {'reputation': 18465, 'user_id': 2934579}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1574121407, 'answer_id': 58924670, 'question_id': 58867635, 'body': '<p>Checkout <a href=""https://github.com/svenboesiger/tfmongodb"" rel=""nofollow noreferrer"">TFMongoDB</a>, a C++ implemented dataset op for Tensorflow that allows you to connect to your MongoDB. </p>\n\n<pre><code>dataset = MongoDBDataset(""dbname"", ""collname"")\ndataset = dataset.map(_parse_line)\nrepeat_dataset2 = dataset.repeat()\nbatch_dataset = repeat_dataset2.batch(20)\n\niterator = iterator_ops.Iterator.from_structure(batch_dataset.output_types)\n#init_op = iterator.make_initializer(dataset)\ninit_batch_op = iterator.make_initializer(batch_dataset)\nget_next = iterator.get_next()\n\nwith tf.Session() as sess:\n    sess.run(init_batch_op, feed_dict={})\n\n    for i in range(5):\n        print(sess.run(get_next))\n</code></pre>\n'}, {'owner': {'reputation': 3255, 'user_id': 31045}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1573774205, 'answer_id': 58868125, 'question_id': 58867635, 'body': '<p>Retrieve the data from the database and store it as a numpy array. If the array is too big for memory, try a memmap array.</p>\n\n<p>Then create a generator, here is an example for images and their onehot encodings from my own code:</p>\n\n<pre><code>def tf_augmented_image_generator(images,\n                                 onehots,\n                                 batch_size,\n                                 map_fn,\n                                 shuffle_size=1000,\n                                 num_parallel_calls=tf.data.experimental.AUTOTUNE):\n    """"""\n    Create a generator suing a tf.data.Dataframe with augmentation via a map function.\n    The generator can then be used for training in model.fit_generator\n\n    The map function must consist of tensorflow operators (not numpy).\n\n    On Windows machines this will lead to faster augmentation, as there are some\n    problems performing augmentation in parallel when multiprocessing is enabled in\n    in model.fit / model.fit_generator and the default Keras numpy-based augmentated is used,\n    e.g. in ImageDataGenerator\n\n    :param images: Images to augment\n    :param onehots: Onehot encoding of target class\n    :param batch_size: Batch size for training\n    :param map_fn: The augmentation map function\n    :param shuffle_size: Batch size of images shuffled. Smaller values reduce memory consumption.\n    :param num_parallel_calls: Number of calls in parallel, default is automatic tuning.\n    :return:\n    """"""\n    # Get shapes from input data\n    img_size = images.shape\n    img_size = (None, img_size[1], img_size[2], img_size[3])\n    onehot_size = onehots.shape\n    onehot_size = (None, onehot_size[1])\n    images_tensor = tf.placeholder(tf.float32, shape=img_size)\n    onehots_tensor = tf.placeholder(tf.float32, shape=onehot_size)\n\n    # Create dataset\n    dataset = tf.data.Dataset.from_tensor_slices((images_tensor, onehots_tensor))\n    if map_fn is not None:\n        dataset = dataset.map(lambda x, y: (map_fn(x), y), num_parallel_calls=num_parallel_calls)\n    dataset = dataset.shuffle(shuffle_size, reshuffle_each_iteration=True).repeat()\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(1)\n\n    iterator = dataset.make_initializable_iterator()\n    init_op = iterator.initializer\n    next_val = iterator.get_next()\n\n    with K.get_session().as_default() as sess:\n        sess.run(init_op, feed_dict={images_tensor: images, onehots_tensor: onehots})\n        while True:\n            inputs, labels = sess.run(next_val)\n            yield inputs, labels\n</code></pre>\n\n<p>Then train the model using <code>fit_generator</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8834}"
1152,50276275,"{'items': [{'owner': {'reputation': 111, 'user_id': 1663645}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1525967937, 'answer_id': 50276939, 'question_id': 50276275, 'body': ""<p>Tensorflow is having trouble locating the <code>NearestNeighbors</code> op, which is part of the graph you're loading. Ops defined in contrib are loaded dynamically when you import the corresponding contrib package in Python.</p>\n\n<p>So just add</p>\n\n<pre><code>import tensorflow.contrib.factorization\n</code></pre>\n\n<p>before loading the SavedModel.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8834}"
1153,67749813,"{'items': [{'owner': {'reputation': 17165, 'user_id': 3222797}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1622308047, 'answer_id': 67753961, 'question_id': 67749813, 'body': '<p>There\'s a few ways you can do this. One is using a <a href=""https://www.tensorflow.org/api_docs/python/tf/train/BytesList"" rel=""nofollow noreferrer"">BytesList</a> feature</p>\n<pre class=""lang-py prettyprint-override""><code>def _bytes_feature(value):\n  return tf.train.Feature(\n    bytes_list=tf.train.BytesList(value=[value]))\n</code></pre>\n<p>and the other is using a <a href=""https://www.tensorflow.org/api_docs/python/tf/train/FloatList"" rel=""nofollow noreferrer"">FloatList</a> feature</p>\n<pre class=""lang-py prettyprint-override""><code>def _float_feature(value):\n  return tf.train.Feature(\n    float_list=tf.train.FloatList(value=value))\n</code></pre>\n<p><strong>Example</strong>:</p>\n<pre class=""lang-py prettyprint-override""><code>import numpy as np\nimport tensorflow as tf\n\n\n# make some data\nimg = np.random.normal(size=(5, 3))\nimg = img.astype(np.float32)\n\nwriter = tf.io.TFRecordWriter(&quot;/tmp/data.tfrec&quot;)\n\nexample = tf.train.Example(\n  features=tf.train.Features(\n    feature = {\n      &quot;img_b&quot;: _bytes_feature(img.tobytes()),\n      &quot;img_f&quot;: _float_feature(img.flatten()),\n    }))\n\nwriter.write(example.SerializeToString())\nwriter.close()\n\ndef parse_fn(example):\n  features = {\n    &quot;img_b&quot;: tf.io.FixedLenFeature([], tf.string),\n    &quot;img_f&quot;: tf.io.FixedLenFeature([5, 3], tf.float32),\n  }\n  parsed_example = tf.io.parse_single_example(example, features)\n  img_b = tf.io.decode_raw(\n      parsed_example[\'img_b\'],\n      out_type=tf.float32)\n  img_b = tf.reshape(img_b, (5, 3))\n  img_f = parsed_example[\'img_f\']\n  return img_b, img_f\n</code></pre>\n<p>Let\'s import the data and see if it worked</p>\n<pre class=""lang-py prettyprint-override""><code>dataset = tf.data.TFRecordDataset([&quot;/tmp/data.tfrec&quot;])\ndataset = dataset.map(parse_fn).batch(1)\n\narr_b, arr_f = next(iter(dataset))\n\nnp.testing.assert_almost_equal(arr_b.numpy(), arr_f.numpy())\n# passes\n</code></pre>\n<p>This assumes that you know the shape of your images and that they are all the same shape.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8834}"
1154,51089334,"{'items': [{'owner': {'reputation': 3386, 'user_id': 7517192}, 'down_vote_count': 0, 'up_vote_count': 22, 'is_accepted': True, 'score': 22, 'creation_date': 1550277982, 'answer_id': 54718798, 'question_id': 51089334, 'body': '<p>Since TensorFlow 1.12, <code>tf.layers</code> are merely wrappers around <code>tf.keras.layers</code>.</p>\n\n<p>A few examples:</p>\n\n<p>Convolutional <code>tf.layers</code> just inherit from the convolutional <code>tf.keras.layers</code>, see source code <a href=""https://github.com/tensorflow/tensorflow/blob/a6d8ffae097d0132989ae4688d224121ec6d8f35/tensorflow/python/layers/convolutional.py#L217"" rel=""noreferrer"">here</a>:</p>\n\n<pre><code>@tf_export(\'layers.Conv2D\')\nclass Conv2D(keras_layers.Conv2D, base.Layer):\n</code></pre>\n\n<p>The same is true for all <a href=""https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/python/layers/core.py"" rel=""noreferrer"">core <code>tf.layers</code></a>, e.g.:</p>\n\n<pre><code>@tf_export(\'layers.Dense\')\nclass Dense(keras_layers.Dense, base.Layer):\n</code></pre>\n\n<p>With the integration of Keras into TensorFlow, it would make little sense to maintain several different layer implementations. <code>tf.keras</code> is becoming the de-facto high-level API for TensorFlow, therefore <code>tf.layers</code> are now just wrappers around <code>tf.keras.layers</code>.</p>\n'}, {'owner': {'reputation': 11055, 'user_id': 9758922}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': False, 'score': 7, 'creation_date': 1530213785, 'answer_id': 51089993, 'question_id': 51089334, 'body': '<p><code>tf.layers</code> module is Tensorflow attempt at creating a Keras like API whereas <code>tf.keras.layers</code> is a compatibility wrapper. In fact, most of the implementation refers back to <code>tf.layers</code>, for example the <code>tf.keras.layers.Dense</code> inherits the <a href=""https://github.com/tensorflow/tensorflow/blob/23c218785eac5bfe737eec4f8081fd0ef8e0684d/tensorflow/python/keras/_impl/keras/layers/core.py#L728"" rel=""noreferrer"">core implementation</a>:</p>\n\n<pre><code>@tf_export(\'keras.layers.Dense\')\nclass Dense(tf_core_layers.Dense, Layer):\n  # ...\n</code></pre>\n\n<p>Because the <code>tf.keras</code> compatibility module is checked into the Tensorflow repo separately, it might lack behind what Keras actually offers. I would use Keras directly or <code>tf.layers</code> but not necessarily mix them.</p>\n'}, {'owner': {'reputation': 3844, 'user_id': 6566268}, 'down_vote_count': 1, 'up_vote_count': 12, 'is_accepted': False, 'score': 11, 'creation_date': 1530211390, 'answer_id': 51089448, 'question_id': 51089334, 'body': '<p><code>tf.keras.layers.Conv2d</code> is a tensorflow-keras layer while <code>tf.layers.max_pooling2d</code> is a tensorflow \'native layer\'</p>\n\n<p>You cannot use a native layer directly within a Keras model, as it will be missing certain attributes required by the Keras API.</p>\n\n<p>However, it is possible to use native layer if wrapped within a tensorflow-keras <code>Lambda</code> layer. A link to the documentation for this is below.</p>\n\n<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8829}"
1155,57921463,"{'items': [{'owner': {'reputation': 2160, 'user_id': 5587428}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1568497035, 'answer_id': 57939445, 'question_id': 57921463, 'body': '<p>Part of the confusion may be that the output doesn\'t correspond to the example code. The actual output from this:</p>\n\n<pre><code>components = np.arange(100).astype(np.int64)\ndataset20 = tf.data.Dataset.from_tensor_slices(components)\ndataset20 = dataset20.apply(tf.data.experimental.group_by_window(key_func=lambda x: x%2, reduce_func=lambda _,els: els.batch(10), window_size=100))\nfor i, d in enumerate(dataset20): \n    print(i, d.numpy())\n</code></pre>\n\n<p>is</p>\n\n<pre><code>0 [ 0  2  4  6  8 10 12 14 16 18]\n1 [20 22 24 26 28 30 32 34 36 38]\n2 [40 42 44 46 48 50 52 54 56 58]\n3 [60 62 64 66 68 70 72 74 76 78]\n4 [80 82 84 86 88 90 92 94 96 98]\n5 [ 1  3  5  7  9 11 13 15 17 19]\n6 [21 23 25 27 29 31 33 35 37 39]\n7 [41 43 45 47 49 51 53 55 57 59]\n8 [61 63 65 67 69 71 73 75 77 79]\n9 [81 83 85 87 89 91 93 95 97 99]\n</code></pre>\n\n<p>As described in the documentation <a href=""https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/experimental/group_by_window"" rel=""nofollow noreferrer"">here</a>, the <code>key func</code> separates the data into groups with associated key values. In the example the <code>key func</code> separates the data [0, 99] into even and odd groups. The <code>reduce_func</code> then operates on the key, group pairs to produce another dataset. Note though that <code>reduce_func</code> only operates on groups of data no greater than <code>window_size</code>. In the example, the window size is greater than the two group sizes (100 vs 50 elements), so has no effect and all evens are given in batches of 10 followed by all odds. If <code>window size</code> is changed to a value less than 50 then it does have an effect. For example, if the window size is changed to 5 and also the batching is moved to outside the <code>group_by_window</code> function:</p>\n\n<pre><code>dataset20 = dataset20.apply(tf.data.experimental.group_by_window(key_func=lambda x: x%2, reduce_func=lambda _, els: els, window_size=5)).batch(10)\n</code></pre>\n\n<p>then the following output is produced:</p>\n\n<pre><code>0 [0 2 4 6 8 1 3 5 7 9]\n1 [10 12 14 16 18 11 13 15 17 19]\n2 [20 22 24 26 28 21 23 25 27 29]\n3 [30 32 34 36 38 31 33 35 37 39]\n4 [40 42 44 46 48 41 43 45 47 49]\n5 [50 52 54 56 58 51 53 55 57 59]\n6 [60 62 64 66 68 61 63 65 67 69]\n7 [70 72 74 76 78 71 73 75 77 79]\n8 [80 82 84 86 88 81 83 85 87 89]\n9 [90 92 94 96 98 91 93 95 97 99]\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8829}"
1156,61280184,"{'items': [{'owner': {'reputation': 589, 'user_id': 6068769}, 'down_vote_count': 0, 'up_vote_count': 4, 'is_accepted': True, 'score': 4, 'creation_date': 1587159898, 'answer_id': 61281219, 'question_id': 61280184, 'body': ""<p>With quick tests, I think I solved the problem by replacing:</p>\n\n<pre><code>        mean, variance = y_pred\n        variance = variance + 0.0001\n</code></pre>\n\n<p>With</p>\n\n<pre><code>        mean = y_pred[0]\n        variance = y_pred[1] + 0.0001\n</code></pre>\n\n<p>Unpacking <code>y_pred</code> (which is a Tensor) calls the method <code>Tensor.__iter__</code> which apparently yields an error, whereas I suppose that the method <code>Tensor.__getitem__</code> does not...</p>\n\n<p>I haven't got to the point when it start learning, I think my current dummy  x_train and y_train are not exactly of correct shape. If you notice that this problem happens again later, I will try to investigate.</p>\n\n<p>EDIT:</p>\n\n<p>I managed to make your code run by using</p>\n\n<pre><code>x_train = np.random.random((10000, 779))\ny_train = np.random.random ((10000, 1))\n</code></pre>\n\n<p>by changing the last line of the method <code>DeepEnsembles.call</code> with </p>\n\n<pre><code>        return tf.stack([mean_stack, variance_stack])\n</code></pre>\n\n<p>and by commenting out the metrics (necessary because the sizes of y_true and y_pred are expected to be different, so you might want to define your own versions of mse and mae to use as a metric):</p>\n\n<pre><code>model.compile(optimizer='adam',\n              loss=loss_fn,\n              # metrics=['mse', 'mae']\n)\n</code></pre>\n\n<p>I believe it is quite close to what you expect.</p>\n\n<p>The reason for not returning a tuple is that tensorflow will interpret each element of the tuple as an output of the network and will apply the loss independently on each of them.</p>\n\n<p>You can test it by keeping the old version of <code>DeepEnsembles.call</code> and instead use</p>\n\n<pre><code>y_train_1 = np.random.random ((10000, 1))\ny_train_2 = np.random.random ((10000, 1))\ny_train = [y_train_1, y_train_2]\n</code></pre>\n\n<p>It will execute, there will be 10 MLP, but MLP_1/2 will learn the mean and variance of y_train_1, MLP_6/7 the mean and var of y_train_2, and all other MLPs will not learn anything.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8829}"
1157,65525687,"{'items': [{'owner': {'reputation': 821, 'user_id': 14612449}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1609541629, 'answer_id': 65534415, 'question_id': 65525687, 'body': '<p>The object returned by the <em>fit_transform()</em> and <em>fit()</em> methods of <strong>TfIdfVectorizer</strong> are compressed sparse row format matrix. So in order to convert them into dense matrix use <code>.toarray()</code> function.</p>\n<p>Furthermore, you should fit your TfIdfVectorizer on the train_set only and then use it to transform your validation and test set without re-fitting it every time to avoid to use data from test set since it might introduce some <strong>data leakage</strong> and yield in too optimistic performances. Also, since the test and validation sets are usually small fitting a TfIdf solely on them will result in poor vectorization. Finally, and the Idf factor will be different for the same words in training, validation and test sets, and this is usually not desired.</p>\n<p>For the mentioned reasons <strong>I would suggest to fit the TfIdfVectorizer only on the training set</strong> and then use the fitted vectorizer to transform the validation and test sets.</p>\n<p>Here an example:</p>\n<pre><code> vectorizer = TfidfVectorizer()\n x_train_count = vectorizer.fit_transform(train_x).toarray()\n x_valid_count = vectorizer.transform(valid_x).toarray()\n x_test_count  = vectorizer.transform(test[&quot;text&quot;]).toarray()\n</code></pre>\n<p>If your data do not fit into memory, you could consider to iteratively convert to a dense matrix only one batch at the time. Here a function to create a batch generator from a sparse x_train matrix:</p>\n<pre><code>def sparse_matrix_batch_generator(X, y, batch_size=32):\n    num_samples = np.shape(y)[0]\n    shuffled_index = np.arange(num_samples)\n    np.random.shuffle(shuffled_index)\n    X =  X[shuffled_index, :]\n    y =  y[shuffled_index]\n    for n in range(num_samples//batch_size):\n        batch_index = shuffled_index[n*batch_size:(n+1)*batch_size]\n        X_batch = X[batch_index, :].todense()\n        y_batch = y[batch_index]\n        yield (X_batch, y_batch)\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8829}"
1158,75136950,"{'items': [{'owner': {'reputation': 365, 'user_id': 10545426}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1673885952, 'answer_id': 75136951, 'question_id': 75136950, 'body': '<p>First export the graph to a logdir that tensorboard can use!</p>\n<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf\n\n# Get the default graph\ngraph = tf.compat.v1.get_default_graph()\nwriter = tf.compat.v1.summary.FileWriter(&quot;logs&quot;, graph)\n</code></pre>\n<p>After that simply open tensorboard in the specified directory (here <code>logs/</code>)</p>\n<p><code>python -m tensorboard.main --logdir logs/</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8825}"
1159,61411259,"{'items': [{'owner': {'reputation': 588, 'user_id': 1986981}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1587743482, 'answer_id': 61412351, 'question_id': 61411259, 'body': '<p>As per my experience tf.data should be used because there is a lot of scope in optimization by tuning the number of parallel calls when doing the preprocessing using the <code>map</code> on the dataset.</p>\n\n<p>For example:  <a href=""https://www.tensorflow.org/guide/data#decoding_image_data_and_resizing_it"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/data#decoding_image_data_and_resizing_it</a></p>\n\n<p>Parallelizing data transformation: <a href=""https://www.tensorflow.org/guide/data_performance#parallelizing_data_transformation"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/data_performance#parallelizing_data_transformation</a></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8825}"
1160,48072635,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8823}"
1161,53272508,"{'items': [{'owner': {'reputation': 37, 'user_id': 7274120}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1543003749, 'answer_id': 53452436, 'question_id': 53272508, 'body': ""<p>Well, I eventually got this working.  The various documents referenced in the comment on my question had what I needed, and I gradually figured out which parameters passed to queuerunners corresponded to which parameters in the tf.data stuff.</p>\n\n<p>There was one gotcha that took a while for me to sort out.  In the inception implementation, the number of examples used for validation is rounded up to be a multiple of the batch size; presumably the validation set is reshuffled and some examples are used more than once.  (This does not strike me as great practice, but generally the number of validation instances is way larger than the batch size, so only a relative few are double counted.)</p>\n\n<p>In the tf.data stuff, enabling shuffling and reuse is a separate thing and I didn't do it on the validation data.  Then things broke because there weren't enough unique validation instances, and I had to track that down.</p>\n\n<p>I hope this helps the next person with this issue.  Unfortunately, my code has drifted quite far from Inception v3 and I doubt that it would be helpful for me to post my modification.  Thanks!</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8823}"
1162,68136894,"{'items': [{'owner': {'reputation': 1831, 'user_id': 6145945}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1624654783, 'answer_id': 68137009, 'question_id': 68136894, 'body': '<p><code>tf.one_hot</code> returns an <code>EagerTensor</code> just like <code>tf.zeros</code>:</p>\n<pre><code>a = tf.one_hot(1,2)\nprint(type(a))\nb = tf.zeros(2)\nprint(type(b))\n# tensorflow.python.framework.ops.EagerTensor\n# tensorflow.python.framework.ops.EagerTensor\n</code></pre>\n<p>I think your issue is that your <em>function</em> <code>input_preprocess</code> returns a <em>single value</em> if <code>label == 1</code> (first return) and a <em>tuple</em> otherwise (second return).</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8823}"
1163,38111170,"{'items': [{'owner': {'reputation': 899, 'user_id': 2084543}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1467245253, 'answer_id': 38112003, 'question_id': 38111170, 'body': ""<p>In your case, it looks like <code>batch_size = 1</code>, since you're looking at a single example.  So <code>max_time</code> is <code>n=8</code> and <code>input_size</code> is the input depth, in your case <code>e=3</code>.  So you would want to construct an <code>input</code> tensor which is shaped <code>[1, 8, 3]</code>.  It's batch_major, so the first dimension (the batch dimension) is <code>1</code>.  If, say, you had another input at the same time, with <code>n=6</code> words, then you would combine the two by padding this second example to <code>8</code> words (by padding zeros for the last 2 word embeddings) and you would have an <code>inputs</code> size of <code>[2, 8, 3]</code>.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8823}"
1164,65585095,"{'items': [{'owner': {'reputation': 1921, 'user_id': 9730862}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1609875042, 'answer_id': 65585367, 'question_id': 65585095, 'body': '<p><code>tf.keras.optimizers.Optimizer</code> and <code>tf.train.Optimizer</code> are two distinct classes. There was never <code>global_step</code> in <code>tf.keras.optimizers.Optimizer</code></p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8819}"
1165,70950860,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8819}"
1166,57872334,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8819}"
1167,60684241,"{'items': [{'owner': {'reputation': 1428, 'user_id': 10617503}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1584203139, 'answer_id': 60684867, 'question_id': 60684241, 'body': '<p>Given that your model has 1 input and 2 outputs, your <code>tf.data.Dataset</code> should have two entries:<br>\n1) Input array of shape <code>(window, 42)</code><br>\n2) Tuple of two arrays each of shape <code>(window, 22)</code> and <code>(window, 1)</code>  </p>\n\n<h3>EDIT: Updated answer - you already return two element tuple</h3>\n\n<p>I just noticed that your dataset has these two entries (similar to those described above) and the only thing that differs is the shape.<br>\nThe only operations you need to perfom is to batch your data twice:<br>\nFirst - to restore the window parameter.\nSecond - to pass a batch to a model.</p>\n\n<pre class=""lang-py prettyprint-override""><code>window_size = 1\nbatch_size = 10\ndataset = load_dataset(\'example.tfrecord\')\nmodel.fit(dataset.batch(window_size).batch(batch_size)\n</code></pre>\n\n<p>And that should work.  </p>\n\n<p>Below is an old answer, where I wrongfully assumed your dataset shape:</p>\n\n<h3>Old Answer, where I assumed you are returning three element tuple:</h3>\n\n<p>Assuming that you are starting from three element tuple of shapes <code>(42,)</code>, <code>(22,)</code> and <code>(1,)</code>, this can be achieved in the same batching operations, enriched with a <code>custom_reshape</code> function to return two-element tuple:</p>\n\n<pre class=""lang-py prettyprint-override""><code>window_size = 1\nbatch_size = 10\ndataset = load_dataset(\'example.tfrecord\')\ndataset = dataset.batch(window_size).batch(batch_size)\n\n# Change output format\ndef custom_reshape(x, y, vad):\n    return x, (y, vad)\n\ndataset = dataset.map(custom_reshape)\n</code></pre>\n\n<p>In short, given this dataset shape, you could just call:\n<code>model.fit(dataset.batch(window_size).batch(10).map(custom_reshape)</code><br>\nand it should work too.</p>\n\n<p>Best of luck. And sorry again for the fuss.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8819}"
1168,67563475,"{'items': [{'owner': {'reputation': 1428, 'user_id': 10617503}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1621248928, 'answer_id': 67568317, 'question_id': 67563475, 'body': '<p>If you are trying to register your own dataset the <a href=""https://www.tensorflow.org/datasets/add_dataset"" rel=""nofollow noreferrer"">TFDS Docs</a> seem to have what you are looking for.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8819}"
1169,38893526,"{'items': [{'owner': {'reputation': 5134, 'user_id': 6416660}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1470930342, 'answer_id': 38900894, 'question_id': 38893526, 'body': ""<p>The main difference between embedding lookup and embedding lookup sparse is that the sparse version expects the id's and weights to be of type SparseTensor.</p>\n\n<p>How embedding lookup works: </p>\n\n<p>You pass in a tensor of some size and the embedding_lookup_sparse will multiply the slices of the tensors (slices referenced by sp_ids parameter) by some weight (also passed in as sp_weight; defaults to value 1) then you are returned the new slices.  </p>\n\n<p>There is no bias term.  You can add the slices of the tensor together by referencing more than one to be included as an element in your output.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8814}"
1170,59166678,"{'items': [{'owner': {'reputation': 1431, 'user_id': 5922373}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1603887566, 'answer_id': 64572713, 'question_id': 59166678, 'body': '<p>As described in <a href=""https://www.tensorflow.org/api_docs/python/tf/shape"" rel=""nofollow noreferrer"">TF documents</a>,</p>\n<blockquote>\n<p>within <strong>@tf.function</strong> or within a compat.v1 context, not all dimensions\nmay be known until execution time. Hence when defining custom layers\nand models for graph mode, prefer the dynamic <strong>tf.shape(x)</strong> over the\nstatic x.shape</p>\n</blockquote>\n<p>Your code was ok. I just replaced np.zeros with tf.zeros. The @tf.function decorator means the code will run in <strong>graph mode</strong>. numpy is not allowed within graph. Tested in TF 2.x.</p>\n<pre><code>@tf.function\ndef train_step(padded_batch):\n    shape = tf.shape(padded_batch)\n    return tf.zeros((shape[0], shape[1]))\n</code></pre>\n'}, {'owner': {'reputation': 2724, 'user_id': 5024514}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1575414461, 'answer_id': 59166741, 'question_id': 59166678, 'body': ""<p>assuming you have a tensor named <code>a_tensor</code>:</p>\n\n<pre><code>this_is_a_regular_non_tensor_shape = a_tensor.shape.as_list()\n</code></pre>\n\n<p>(BTW: you don't seem to be using <code>np.zeros</code> correctly...you need to pass the shape as a single tuple/list argument. Not separate arguments for each dimension. For instance:  </p>\n\n<pre><code>shape = padded_batch.shape.as_list()\nx = np.zeros(shape)\n</code></pre>\n\n<p>Hope that helps.)</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8814}"
1171,63958998,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8814}"
1172,53032922,"{'items': [{'owner': {'reputation': 164, 'user_id': 4101431}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1540739944, 'answer_id': 53033052, 'question_id': 53032922, 'body': ""<p>The arguments that are passed on to the <code>condition</code> function are the arguments returned from your <code>body</code> function. So you just have to return that value that you want to base your condition on in the <code>body</code> function, then carry out the condition on that value in your <code>cond</code> function. Something like, </p>\n\n<pre><code>def body(image_shape, crop_shape, img_crop):\n    max_begin_index = np.array(IMAGE_SHAPE) - np.array(CROP_SHAPE)\n    crop_begin_index = tf.round(tf.random_uniform([2]) * max_begin_index)\n    img_crop = tf.slice(img, crop_begin_index, crop_shape + [-1])\n    return (image_shape, crop_shape, img_crop)\n\ndef cond(image_shape, crop_shape, img_crop):\n    return tf.count_nonzero(img_crop &gt; 0) &gt; 0.5 * tf.size(img_crop)\n\nimage_shape, crop_shape, img_crop = tf.while_loop(cond=cond, body=body, loop_vars=([960, 720], [320, 240], img_crop))\n</code></pre>\n\n<p>Don't have access to an interpreter right now, so there might be some syntax problems there, but something like that. </p>\n\n<p>Also, if I recall correctly, the body and the condition need to be pure functions, you cannot alter the outer state from within the functions.</p>\n\n<p>Also note, you'll need to specify some initial value for <code>img_crop</code> in the loop vars.</p>\n\n<p>Moreover, by default, <code>tf.while_loop</code> expects the shapes of all the <code>loop_vars</code> to remain the same across all loop runs. You can modify this through the <code>shape_invariants</code> argument. </p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8814}"
1173,58730460,"{'items': [{'owner': {'reputation': 171, 'user_id': 11841324}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': False, 'score': 2, 'creation_date': 1584030414, 'answer_id': 60658207, 'question_id': 58730460, 'body': '<p>You can use keras callbacks. If you want to freeze your first layer after some certain amount of epochs, add this callback</p>\n\n<pre class=""lang-py prettyprint-override""><code>\nclass FreezeCallback(tf.keras.callbacks.Callback):\n    def __init__(self, n_epochs=10):\n        super().__init__()\n        self.n_epochs = n_epochs\n\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch == self.n_epochs:\n            l = self.model.get_layer(\'first\')\n            l.trainable = False\n</code></pre>\n'}, {'owner': {'reputation': 834, 'user_id': 7248145}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': True, 'score': 1, 'creation_date': 1573047774, 'answer_id': 58731576, 'question_id': 58730460, 'body': '<p>Ok i came up with a solution.\nAn ""update"" function must be implemented inside the custom layer, which updates the inner layers so that they become non trainable.\nHere is a sample code:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nlayers = tf.keras.layers\n\nseq_model = tf.keras.models.Sequential\n\n\nclass MDBlock(layers.Layer):\n\n    def __init__(self):\n        super(MDBlock, self).__init__()\n        self.dense1 = layers.Dense(784, name=""first"")\n        self.dense2 = layers.Dense(32, name=""second"")\n        self.dense3 = layers.Dense(32, name=""third"")\n        self.dense4 = layers.Dense(1, activation=\'sigmoid\', name=""outp"")\n\n    def call(self, inputs):\n        x = self.dense1(inputs)\n        x = tf.nn.relu(x)\n        x = self.dense2(x)\n        x = tf.nn.relu(x)\n        x = self.dense3(x)\n        x = tf.nn.relu(x)\n        x = self.dense4(x)\n        return x\n\n    def updt(self):\n        self.dense1.trainable = False\n\n    def __str__(self):\n        return ""\\nd1:{0}\\nd2:{1}\\nd3:{2}\\nd4:{3}"".format(self.dense1.trainable, self.dense2.trainable,\n                                                         self.dense3.trainable, self.dense4.trainable)\n\n\n# define layer block\nlayer = MDBlock()\n\nmodel = seq_model()\nmodel.add(layers.Input(shape=(784,)))\nmodel.add(layer)\n\n# Use updt function to make layers non-trainable\nfor i, layer in enumerate(model.layers):\n    layer.updt()\n\nmodel.compile(optimizer=\'rmsprop\',\n              loss=\'binary_crossentropy\',\n              metrics=[\'accuracy\'])\n\n# Generate dummy data\ndata = np.random.random((1000, 784))\nlabels = np.random.randint(2, size=(1000, 1))\n\n# Train the model, iterating on the data in batches of 32 samples\nmodel.fit(data, labels, epochs=10, batch_size=32)\n\n# print block\'s layers state\nfor i, layer in enumerate(model.layers):\n    print(i, layer)\n\n\n</code></pre>\n'}, {'owner': {'reputation': 14062, 'user_id': 6117017}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1573049961, 'answer_id': 58732207, 'question_id': 58730460, 'body': ""<p>What you are doing in your update function is to replace the first <code>Dense()</code> layer with another <code>Dense()</code> layer, this time setting <code>trainable = false</code>.</p>\n\n<p>While this works, I would update the 'update' function as following:</p>\n\n<pre><code> def updt(self):\n     self.dense1.trainable = False\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8814}"
1174,56436701,"{'items': [{'owner': {'reputation': 30867, 'user_id': 4790871}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1559661522, 'answer_id': 56446816, 'question_id': 56436701, 'body': ""<p>@y.selivonchyk provided the correct answer that helped me understand this. I am adding a second example of using sliding window to help elucidate the correct approach for people who stumble upon this. Notice in particular that window size and batch size are equal.</p>\n\n<pre><code>import tensorflow as tf\n\nwindow_size = 3\nds = tf.data.Dataset.range(20)\nds = ds.window(size=window_size, shift=1, stride=1, drop_remainder=False)\nds = ds.flat_map(lambda x: x.batch(window_size))\n\nnext_sample = ds.make_one_shot_iterator().get_next()\n\nwith tf.Session() as sess:\n    while True:\n        try:\n            print(sess.run(next_sample))\n        except tf.errors.OutOfRangeError:\n            print('EOF')\n            break\n[0 1 2]\n[1 2 3]\n[2 3 4]\n[3 4 5]\n[4 5 6]\n[5 6 7]\n[6 7 8]\n[7 8 9]\n[ 8  9 10]\n[ 9 10 11]\n[10 11 12]\n[11 12 13]\n[12 13 14]\n[13 14 15]\n[14 15 16]\n[15 16 17]\n[16 17 18]\n[17 18 19]\n[18 19]\n[19]\nEOF\n</code></pre>\n""}, {'owner': {'reputation': 9218, 'user_id': 867889}, 'down_vote_count': 0, 'up_vote_count': 3, 'is_accepted': True, 'score': 3, 'creation_date': 1559617806, 'answer_id': 56436869, 'question_id': 56436701, 'body': '<p>Window produces dataset like structure that is supposed to be returning pairs {1, 2} in your case. Have no idea how to use it properly or why it exists, but managed to make it work like that:\nimport tensorflow as tf</p>\n\n<pre><code>import tensorflow as tf\n\nnxt = (tf.data.Dataset\n       .range(7)\n       .window(2, 1, 2, True)\n       .flat_map(lambda x: x.batch(2))\n       .make_one_shot_iterator()\n       .get_next()\n      )\n\nwith tf.Session() as sess:\n    print(sess.run(nxt))\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8809}"
1175,57014236,"{'items': [{'owner': {'reputation': 558, 'user_id': 8691571}, 'down_vote_count': 0, 'up_vote_count': 7, 'is_accepted': False, 'score': 7, 'creation_date': 1580415188, 'answer_id': 59993811, 'question_id': 57014236, 'body': '<p>It seems plenty of people as myself are having problems using Tensorboard Projector in TF2.x due to the lack of documentation. I have managed to make it work and in this <a href=""https://github.com/tensorflow/tensorboard/issues/2471#issuecomment-580423961"" rel=""noreferrer"">comment on GitHub</a> I provide some minimal code examples. I know the questions was also about using thumbnails (sprites), but I did not need it and wanted to keep the examples simple, so making sprites work is left as an exercise to the reader.</p>\n\n<pre class=""lang-py prettyprint-override""><code># Some initial code which is the same for all the variants\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorboard.plugins import projector\n\ndef register_embedding(embedding_tensor_name, meta_data_fname, log_dir):\n    config = projector.ProjectorConfig()\n    embedding = config.embeddings.add()\n    embedding.tensor_name = embedding_tensor_name\n    embedding.metadata_path = meta_data_fname\n    projector.visualize_embeddings(log_dir, config)\n\ndef get_random_data(shape=(100,100)):\n    x = np.random.rand(*shape)\n    y = np.random.randint(low=0, high=2, size=shape[0])\n    return x, y\n\ndef save_labels_tsv(labels, filepath, log_dir):\n    with open(os.path.join(log_dir, filepath), \'w\') as f:\n        for label in labels:\n            f.write(\'{}\\n\'.format(label))\n\nLOG_DIR = \'tmp\'  # Tensorboard log dir\nMETA_DATA_FNAME = \'meta.tsv\'  # Labels will be stored here\nEMBEDDINGS_TENSOR_NAME = \'embeddings\'\nEMBEDDINGS_FPATH = os.path.join(LOG_DIR, EMBEDDINGS_TENSOR_NAME + \'.ckpt\')\nSTEP = 0\n\nx, y = get_random_data((100,100))\nregister_embedding(EMBEDDINGS_TENSOR_NAME, META_DATA_FNAME, LOG_DIR)\nsave_labels_tsv(y, META_DATA_FNAME, LOG_DIR)\n</code></pre>\n\n<p>VARIANT A (Works in TF2.0 and TF2.1, but not in eager mode) </p>\n\n<pre class=""lang-py prettyprint-override""><code># Size of files created on disk: 163kB\ntf.compat.v1.disable_eager_execution()\ntensor_embeddings = tf.Variable(x, name=EMBEDDINGS_TENSOR_NAME)\nsess = tf.compat.v1.InteractiveSession()\nsess.run(tf.compat.v1.global_variables_initializer())\nsaver = tf.compat.v1.train.Saver()\nsaver.save(sess, EMBEDDINGS_FPATH, STEP)\nsess.close()\n</code></pre>\n\n<p>VARIANT B (Works in both TF2.0 and TF2.1 in Eager mode)</p>\n\n<pre class=""lang-py prettyprint-override""><code># Size of files created on disk: 80.5kB\ntensor_embeddings = tf.Variable(x, name=EMBEDDINGS_TENSOR_NAME)\nsaver = tf.compat.v1.train.Saver([tensor_embeddings])  # Must pass list or dict\nsaver.save(sess=None, global_step=STEP, save_path=EMBEDDINGS_FPATH)\n</code></pre>\n\n<p>I want to thank other developers for bits of code from their Stack answers, GitHub comments or personal blog posts, which helped me to put these examples together. You are the real MVP.</p>\n'}, {'owner': {'reputation': 94, 'user_id': 11843190}, 'down_vote_count': 1, 'up_vote_count': 8, 'is_accepted': True, 'score': 7, 'creation_date': 1564211942, 'answer_id': 57230031, 'question_id': 57014236, 'body': '<p>It seems there are some issues left in tensorboard. However, there are some\nworkarounds (for now) for preparing embeddings for projector with tensorflow2:\n(bug report at: <a href=""https://github.com/tensorflow/tensorboard/issues/2471"" rel=""noreferrer"">https://github.com/tensorflow/tensorboard/issues/2471</a>)</p>\n\n<p>tensorflow1 code would look something like that:</p>\n\n<pre><code>embeddings = tf.compat.v1.Variable(latent_data, name=\'embeddings\')\nCHECKPOINT_FILE = TENSORBOARD_DIR + \'/model.ckpt\'\n# Write summaries for tensorboard\nwith tf.compat.v1.Session() as sess:\n    saver = tf.compat.v1.train.Saver([embeddings])\n    sess.run(embeddings.initializer)\n    saver.save(sess, CHECKPOINT_FILE)\n    config = projector.ProjectorConfig()\n    embedding = config.embeddings.add()\n    embedding.tensor_name = embeddings.name\n    embedding.metadata_path = TENSORBOARD_METADATA_FILE\n\nprojector.visualize_embeddings(tf.summary.FileWriter(TENSORBOARD_DIR), config)\n</code></pre>\n\n<p>when using eager mode in tensorflow2 this should (?) look somehow like this:</p>\n\n<pre><code>embeddings = tf.Variable(latent_data, name=\'embeddings\')\nCHECKPOINT_FILE = TENSORBOARD_DIR + \'/model.ckpt\'\nckpt = tf.train.Checkpoint(embeddings=embeddings)\nckpt.save(CHECKPOINT_FILE)\n\nconfig = projector.ProjectorConfig()\nembedding = config.embeddings.add()\nembedding.tensor_name = embeddings.name\nembedding.metadata_path = TENSORBOARD_METADATA_FILE\n\nwriter = tf.summary.create_file_writer(TENSORBOARD_DIR)\nprojector.visualize_embeddings(writer, config)\n</code></pre>\n\n<p>however, there are 2 issues:</p>\n\n<ul>\n<li>the <code>writer</code> created with <code>tf.summary.create_file_writer</code> does not have the function <code>get_logdir()</code> required by <code>projector.visualize_embeddings</code>, a simple workaround is to patch the <code>visualize_embeddings</code> function to take the logdir as parameter.</li>\n<li>the checkpoint format has changed, when reading the checkpoint with load_checkpoint (which seems to be the tensorboard way of loading the file), the variable names change. e.g. <code>embeddings</code> changes to something like <code>embeddings/.ATTRIBUTES/VARIABLE_VALUE</code> (also there are additional variables in the map extracted by <code>get_variable_to_shape_map()</code>but they are empty anyways).</li>\n</ul>\n\n<p>the second issue was solved with the following quick-and-dirty workaround (and logdir is now a parameter of <code>visualize_embeddings()</code>)</p>\n\n<pre><code>embeddings = tf.Variable(latent_data, name=\'embeddings\')\nCHECKPOINT_FILE = TENSORBOARD_DIR + \'/model.ckpt\'\nckpt = tf.train.Checkpoint(embeddings=embeddings)\nckpt.save(CHECKPOINT_FILE)\n\nreader = tf.train.load_checkpoint(TENSORBOARD_DIR)\nmap = reader.get_variable_to_shape_map()\nkey_to_use = """"\nfor key in map:\n    if ""embeddings"" in key:\n        key_to_use = key\n\nconfig = projector.ProjectorConfig()\nembedding = config.embeddings.add()\nembedding.tensor_name = key_to_use\nembedding.metadata_path = TENSORBOARD_METADATA_FILE\n\nwriter = tf.summary.create_file_writer(TENSORBOARD_DIR)\nprojector.visualize_embeddings(writer, config,TENSORBOARD_DIR)\n</code></pre>\n\n<p>I did not find any examples on how to use tensorflow2 to directly write the embeddings for tensorboard, so I am not sure if this is the right way, but if it is, then those two issues would need to be addressed, and at least for now there is a workaround.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8809}"
1176,43261919,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8809}"
1177,58828768,"{'items': [{'owner': {'reputation': 386, 'user_id': 4715661}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1573633307, 'answer_id': 58832910, 'question_id': 58828768, 'body': '<p>Since TF tensor runs on GPU and numpy array runs on CPU, conversion from GPU to CPU needs memory allocation and content copy using CUDA API (see <a href=""https://documen.tician.de/pycuda/tutorial.html#transferring-data"" rel=""nofollow noreferrer"">pycuda</a> document), which causes a tiny delay. Such delay could be a problem in training because of the high throughput data stream, but I think it could be ignored in most inference usage case. Anyway, if the <code>selected_words</code> is the desired output, we normally would prefer to use <code>tf.argsort</code> to make an elegant end-to-end model. However, if the output would be used in multiple places like <code>logits</code>, use <code>np.argsort</code> in a specific situation is fine.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8809}"
1178,52090848,"{'items': [{'owner': {'reputation': 11863, 'user_id': 241013}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1535618555, 'answer_id': 52092675, 'question_id': 52090848, 'body': ""<p>So, 2**26 is about 64M. You want 95 embedding dimensions. Each will be a float32 by default. That is 4 bytes. 4 * 95 ~= 400 bytes per user_id. So you need 64M * 400 ~= 25.6 Gbytes of memory to store the embedding.</p>\n\n<p>Make sure you can allocate that much on your system. It should be all in ram (swap will make everything much slower). If you placed this on a GPU it won't work since most GPUs don't have so much memory available. An embedding of only 20 dimensions should use about 5Gbytes which is more likely to fit in memory.</p>\n\n<p>The easiest thing is to lower the number of embedding dimensions.\nIf you have multiple systems available you can shard the embedding (see partitioner parameter for variable related functions).</p>\n\n<p>Another thing you can do is cluster some user_ids together (lower the hash_bucket_size). Or replace user_ids by a combination of other features that would describe the user sufficiently for your model.</p>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8805}"
1179,54669282,"{'items': [{'owner': {'reputation': 58768, 'user_id': 1782792}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1550058273, 'answer_id': 54669386, 'question_id': 54669282, 'body': '<p>If you look at the <a href=""https://github.com/tensorflow/tensorflow/blob/v1.12.0/tensorflow/python/framework/ops.py#L5857-L5874"" rel=""nofollow noreferrer"">implementation of <code>tf.add_to_collections</code></a>, you will see that it just does:</p>\n\n<pre><code>get_default_graph().add_to_collections(names, value)\n</code></pre>\n\n<p>So it is exactly the same as calling <code>tf.get_default_graph().add_to_collections</code>. The collections are really associated with a graph, in most cases you are just interested in one graph, which is the default one, but sometimes you may want to manage different <a href=""https://www.tensorflow.org/api_docs/python/tf/Graph"" rel=""nofollow noreferrer""><code>tf.Graph</code></a> objects manually, and in that case you may prefer to use the methods of the graph class instead of relying on which one is the default one. If you are only working with one graph, though, <a href=""https://www.tensorflow.org/api_docs/python/tf/add_to_collections"" rel=""nofollow noreferrer""><code>tf.add_to_collections</code></a> is usually more convenient and readable.</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8805}"
1180,57083881,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8803}"
1181,57823210,"{'items': [{'owner': {'reputation': 39, 'user_id': 12030773}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': True, 'score': 0, 'creation_date': 1568361000, 'answer_id': 57919403, 'question_id': 57823210, 'body': ""<p>You need to use .batch on your database in order to have the right format.</p>\n\n<p>The following is working on my computer:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ndef basic_dataset(numPoints):\n    data = np.linspace(0,1,numPoints)\n    dataset = dict({'points': data})\n    labels = []\n    for d in data:\n        labels.append(1)\n    return tf.data.Dataset.from_tensor_slices((dataset, np.array(labels)))\n\ndef input_train_set():\n    dataset = basic_dataset(11)\n    return dataset.repeat(100).shuffle(1000).batch(1)\n\npoint = tf.feature_column.numeric_column('points')\nestimator = tf.estimator.DNNRegressor(feature_columns = [point],hidden_units = [100,100,100], label_dimension = 1)\n\nestimator.train(input_fn = input_train_set)\n</code></pre>\n""}, {'owner': {'reputation': 5966, 'user_id': 1190882}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1567782436, 'answer_id': 57824543, 'question_id': 57823210, 'body': ""<p>Main problem in your code was you were sending the data in dataset as simple tensors. But it input data in dataset should be dictionary with key name same as that with what was used in feature column. Apart, from that I have added extra dimension in input data. The following code will work.</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\n### DEFINE NEW MAP FUNCTION\ndef map_fn(d, l):\n    return {'points': d}, l\n\ndef input_evaluation_set():\n    data = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n    labels = []\n    for d in data:\n        labels.append(1)\n\n    ### CHANGE STARTS HERE\n    data = np.array(data)\n    data = np.expand_dims(data, axis=-1)\n    labels = np.array(labels)\n    labels = np.expand_dims(labels, axis=-1)\n    ### CHANGE ENDS HERE\n\n    dataset = tf.data.Dataset.from_tensor_slices((tf.constant(data), tf.constant(labels)))\n\n    ### CREATE DICTIONARY PAIR IN INPUT DATA\n    dataset = dataset.map(map_fn)\n    return dataset\n\npoint = tf.feature_column.numeric_column('points')\nestimator = tf.estimator.DNNRegressor(feature_columns = [point],hidden_units = [100,100,100])\n\nestimator.train(input_fn = input_evaluation_set)\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8803}"
1182,64837612,"{'items': [{'owner': {'reputation': 1461, 'user_id': 4375999}, 'down_vote_count': 0, 'up_vote_count': 1, 'is_accepted': False, 'score': 1, 'creation_date': 1605738488, 'answer_id': 64902411, 'question_id': 64837612, 'body': '<p>Cloud Storage is not a file system. Having this in mind you can perform <a href=""https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-code-sample"" rel=""nofollow noreferrer"">uploads</a>, <a href=""https://cloud.google.com/storage/docs/downloading-objects"" rel=""nofollow noreferrer"">downloads</a> or <a href=""https://cloud.google.com/storage/docs/deleting-objects"" rel=""nofollow noreferrer"">Deletion</a> operations in a bucket.</p>\n<p>What you are trying to do is to open a file and write into it. What you should do is to create your file locally and then upload it to your desired bucket.</p>\n<pre><code>from google.cloud import storage\n\n\ndef upload_blob(bucket_name, source_file_name, destination_blob_name):\n    &quot;&quot;&quot;Uploads a file to the bucket.&quot;&quot;&quot;\n    # bucket_name = &quot;your-bucket-name&quot;\n    # source_file_name = &quot;local/path/to/file&quot;\n    # destination_blob_name = &quot;storage-object-name&quot;\n\n    storage_client = storage.Client()\n    bucket = storage_client.bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name)\n\n    blob.upload_from_filename(source_file_name)\n\n    print(\n        &quot;File {} uploaded to {}.&quot;.format(\n            source_file_name, destination_blob_name\n        )\n    )\n</code></pre>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8801}"
1183,56621039,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8801}"
1184,48281583,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8801}"
1185,73451503,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8801}"
1186,76396532,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8801}"
1187,45172725,"{'items': [{'owner': {'reputation': 23445, 'user_id': 1735003}, 'down_vote_count': 0, 'up_vote_count': 30, 'is_accepted': True, 'score': 30, 'creation_date': 1500399698, 'answer_id': 45173679, 'question_id': 45172725, 'body': '<p>Tensorflow proposes on the one hand a low level API (<code>tf.</code>, <code>tf.nn.</code>...), and on the other hand, a higher level API (<code>tf.layers.</code>, <code>tf.losses.</code>,...).</p>\n\n<p>The goal of the higher level API is to provide functions that greatly simplify the design of the most common neural nets. The lower level API is there for people with special needs, or who wishes to keep a finer control of what is going on.</p>\n\n<p>The situation is a bit confused though, because some functions have the same or similar names, and also, there is no clear way to distinguish at first sight which namespace correspond to which level of the API.</p>\n\n<p>Now, let\'s look at <code>conv2d</code> for example. A striking difference between <code>tf.nn.conv2d</code> and <code>tf.layers.conv2d</code> is that the later takes care of all the variables needed for  weights and biases. A single line of code, and <em>voil</em>, you just created a convolutional layer. With <code>tf.nn.conv2d</code>, you have to take declare the weights variable yourself before passing it to the function. And as for the biases, well, they are actually not even handled: you need to add them yourself later.</p>\n\n<p>Add to that that <code>tf.layers.conv2d</code> also proposes to add regularization and activation in the same function call, you can imagine how this can reduce code size when one\'s need is covered by the higher-level API.</p>\n\n<p>The higher level also makes some decisions by default that could be considered as best practices. For example, losses in <code>tf.losses</code> are added to the <code>tf.GraphKeys.LOSSES</code> collection by default, which makes recovery and summation of the various component easy and somewhat standardized. If you use the lower level API, you would need to do all of that yourself. Obviously, you would need to be careful when you start mixing low and high level API functions there.</p>\n\n<p>The higher-level API is also an answer to a great need from people that have been otherwise used to similarly high-level function in other frameworks, Theano aside. This is rather obvious when one ponders the number of alternative higher level APIs built on top of tensorflow, such as keras 2 (now <a href=""https://blog.keras.io/introducing-keras-2.html"" rel=""noreferrer"">part of the official tensorflow API</a>), slim (in <code>tf.contrib.slim</code>), tflearn, tensorlayer, and the likes.</p>\n\n<p>Finally, if I may add an advice: if you are beginning with tensorflow and do not have a preference towards a particular API, I would personnally encourage you to stick to the <code>tf.keras.*</code> API:</p>\n\n<ul>\n<li>Its API is friendly and at least as good as the other high-level APIs built on top of the low-level tensorflow API</li>\n<li>It has a clear namespace within tensorflow (although it can -- and sometimes should -- be used with parts from other namespaces, such as <code>tf.data</code>)</li>\n<li>It is now a first-class citizen of tensorflow (it used to be in <code>tf.contrib.keras</code>), and care is taken to make new tensorflow features (such as <code>eager</code>) compatible with keras.</li>\n<li>Its generic implementation can use other toolkits such as CNTK, and so does not lock you to tensorflow.</li>\n</ul>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8796}"
1188,73744374,"{'items': [], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8796}"
1189,53649402,"{'items': [{'owner': {'reputation': 281, 'user_id': 1412727}, 'down_vote_count': 0, 'up_vote_count': 2, 'is_accepted': True, 'score': 2, 'creation_date': 1548764315, 'answer_id': 54420920, 'question_id': 53649402, 'body': '<p>Instantiating RunConfig for Estimator with <code>save_summary_steps=None</code> should fix this</p>\n'}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8796}"
1190,66570237,"{'items': [{'owner': {'reputation': 1030, 'user_id': 3926152}, 'down_vote_count': 0, 'up_vote_count': 0, 'is_accepted': False, 'score': 0, 'creation_date': 1615441585, 'answer_id': 66577096, 'question_id': 66570237, 'body': ""<p>Not sure why you had the &quot;for&quot;.</p>\n<p>Here is an example based on the keras documentation. I added a dense layer on the output.</p>\n<pre><code>import tensorflow as tf\n\n'''\nquery_layer = tf.keras.layers.Conv1D(filters=100, kernel_size=4, padding='same')\nvalue_layer = tf.keras.layers.Conv1D(filters=100, kernel_size=4, padding='same')\n\nattention = tf.keras.layers.Attention()\nconcat = tf.keras.layers.Concatenate()\n\ncells = [tf.keras.layers.LSTMCell(256), tf.keras.layers.LSTMCell(64)]\nrnn = tf.keras.layers.RNN(cells)\noutput_layer = tf.keras.layers.Dense(1)\n\nfor batch in ds['train'].batch(32):\n    text = batch['text']\n    embeddings = embedding_layer(vectorize_layer(text))\n    query = query_layer(embeddings)\n    value = value_layer(embeddings)\n    query_value_attention = attention([query, value])\n    attended_values = concat([query, query_value_attention])\n    logits = output_layer(rnn(attended_values))\n    loss = binary_crossentropy(tf.expand_dims(batch['label'], -1),\n                                               logits, from_logits=True)\n'''\n\nquery_input = tf.keras.Input(shape=(None,), dtype='int32')\nvalue_input = tf.keras.Input(shape=(None,), dtype='int32')\n\n# Embedding lookup.\ntoken_embedding = tf.keras.layers.Embedding(input_dim=1000, output_dim=64)\n# Query embeddings of shape [batch_size, Tq, dimension].\nquery_embeddings = token_embedding(query_input)\n# Value embeddings of shape [batch_size, Tv, dimension].\nvalue_embeddings = token_embedding(value_input)\n\n# CNN layer.\ncnn_layer = tf.keras.layers.Conv1D(\n    filters=100,\n    kernel_size=4,\n    # Use 'same' padding so outputs have the same shape as inputs.\n    padding='same')\n# Query encoding of shape [batch_size, Tq, filters].\nquery_seq_encoding = cnn_layer(query_embeddings)\n# Value encoding of shape [batch_size, Tv, filters].\nvalue_seq_encoding = cnn_layer(value_embeddings)\n\n# Query-value attention of shape [batch_size, Tq, filters].\nquery_value_attention_seq = tf.keras.layers.Attention()(\n    [query_seq_encoding, value_seq_encoding])\n\n# Reduce over the sequence axis to produce encodings of shape\n# [batch_size, filters].\nquery_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n    query_seq_encoding)\nquery_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n    query_value_attention_seq)\n\n# Concatenate query and document encodings to produce a DNN input layer.\ninput_layer = tf.keras.layers.Concatenate()(\n    [query_encoding, query_value_attention])\n\n# Add DNN layers, and create Model.\noutput_layer = tf.keras.layers.Dense(1)(input_layer)\n\nmodel = tf.keras.models.Model(inputs=[query_input, value_input], outputs = output_layer)\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\n\nmodel.summary()\n</code></pre>\n""}], 'has_more': False, 'quota_max': 10000, 'quota_remaining': 8796}"
