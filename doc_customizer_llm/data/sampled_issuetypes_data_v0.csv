QuestionId,Title,Body,QuestionURL,UserId,DocRelated
70163993,Replace tf.const with tf.variable in frozen graph for re-train frozen graph,"I got trouble to re-train frozen graph Due to Const in Graph Actually I checked out many reference codes like this and this Tried everything but no lock for me. My environment below My code below The problem is, When I replace variable by using below code The model is modified well but, I could not inference by using this model due to initialize problem I'm struggling few weeks, I never know how TensorFlow Graph has been working inside. There is no exact document about it also. I read every document on Tensorflow page relevant. Please help me out from the dark",https://stackoverflow.com/questions/70163993,4457567.0,1
42865818,"Tensorflow Serving - ""No versions of servable"" message for model trained with tf.contrib.learn.Experiment","I've trained a model using the Getting Started tutorial from Google Cloud ML Engine as a reference. I could manage to deploy and serve this model on Google Cloud ML without problems. Now I'm trying to serve it using Tensorflow Serving but I'm getting the message error below: The command line call I'm using to start de Tensorflow serving is: The content of the output folder is: UPDATE: I tried to use the frozen model (.pb file and variables folder) which are indeed the folder I use to deploy the model on Google Cloud ML Engine, but got the same error message. These files are located inside the folder below: The code I've used to train and export the model is: Does anyone have any tip about what I'm doing wrong? Best Regards!",https://stackoverflow.com/questions/42865818,3202362.0,1
44770980,Tensorflow - Retrieve each character in a string tensor,"I'm trying to retrieve the characters in a string tensor for character level prediction. The ground truths are words where each character has an id in dictionary. I have a tensor corresponding to the length of the string. Now, I have to get each character in the string tensor. After checking the related posts, a simple retrieval can be as follows. Example string is ""This"" Now I want to make a string with spaces in between the letters ""This"" i.e "" T h i s "". I need spacing at the start and the end too. How do I do this? I have tried to iterate through the characters like below But the loop expects an integer rather than a tensor. Any idea on how to do the above tasks? I couldn't find any documentation related to this (apart from the tf.string_split function). Any suggestions are welcome. Thanks",https://stackoverflow.com/questions/44770980,5470522.0,1
49930682,Getting InvalidArgumentError in softmax_cross_entropy_with_logits,"I'm pretty new to tensorflow and trying to do some experiments with the Iris dataset. I created following model function (MWE): Unfortunately I get the following error: Seems to be some problem with the shapes of the tensors. However both logits and labels have an equal shape of (256, 3) - as it is required by the documentation. Also both tensors have type float32. Just for the sake of completeness, here is the input function for the estimator: Dataset from UCI repo",https://stackoverflow.com/questions/49930682,8444976.0,1
60974077,How to save Keras model as frozen graph?,I am working with Tensorflow 2.0 and want to store the following Keras model as frozen graph. I can't find any good examples how to do this in Tensorflow 2.0. I have found the freeze_graph.py file in the Tensorflow Github repository but find it hard to wrap my head around it. I load the file mentioned above using: But what exactly do I have to provide to the freeze_graph function itself? Here I marked the arguments where I am not sure with a questionmark. Can someone provide a simple example that shows how I can store the model above as a frozen graph using the freeeze_graph function?,https://stackoverflow.com/questions/60974077,3861775.0,1
58918770,Tenforflow Sparse Arithmetic,"Hi I'm learning tensorflow right now and I am have a sparse dataset which is made up of three columns, date, bond, spread. I figured that storing this data in sparse tensor with bond as one dimension, and date as another will make operations on this tensor feel natural, do let me know if you think there is a better way. I am trying to perform arithmetic on two slices of the tensor where I add/subtract values on one date only if given tensor values is not empty, and while I found some functions that help me with that task I can't shake off the feeling that I'm missing a really simple solution to the problem. Using data bellow: In above example I intend to use dimension one for dates, and dimension two for bonds such that Gives me all spreads for date2, but apparently subtraction is not supported for SparseTensor, nor can I use tf.math.subtract. So I am no longer sure what is supported. Specifically what I want to accomplish in above example is subtract date 0 for all other dates only if bond has spread on both dates. For Example bond 0 shows up in date 0 and 1 but not date 2 so I want to subtract spread in date 0 from both dates 0 and 1. Final tensor would look like this: I guess easy solution would be to use tf.sparse.to_dense but that kind of defeats the whole point of using SparseTensor, so I'm not really sure if I missed something in API docs that makes my solution possible or did I got wrong completely by trying to use SparseTensor? At the end of the day I am just looking to perform some math for each value of a tensor if that value has a match in another tensor. UPDATE: I realized that I can apply tf.math/negative to one of the slices to subtract two slices problem is that output assumes that if value in one slice is missing then it can be assumed to be some default value(zero).",https://stackoverflow.com/questions/58918770,3324507.0,1
60701451,"In Tensorflow Classification, how are the labels ordered when using ""predict""?","I'm using the MNIST handwritten numerals dataset to train a CNN. After training the model, i use predict like this: and i get output as: In the output, there are 10 probabilities, one for each of numeral from 0 to 9. But how do i know which probability refers to which numeral ? In this particular case, the probabilities are arranged sequentially for numerals 0 to 9. But why is that ? I didn't define that anywhere. I tried going over documentation and example implementations found elsewhere on the internet, but no one seems to have addressed this particular behaviour. Edit: For context, I've defined my train/test data by: And my model consists of a a few convulution and pooling layers, then a Flatten layer, then a Dense layer with 128 neurons and an output Dense layer with 10 neurons. After that I simply fit my model and use predict like this: I don't see where I've instructed my code to output first neuron as digit 0, second neuron as digit 1 etc And if i wanted to change the the sequence in which the resulting digits are output, where do i do that ? This is really confusing me a lot.",https://stackoverflow.com/questions/60701451,11501160.0,1
58076296,How to export tensorflow_hub module to use it in an installer,"I'm working on a app that use a tensorflow module, currently i load tensorflow like this However i want to make my app usable for everyone, i plan to export my code to an exe (probably with pyinstaller), so i need to 'export' this model and make load it from the disk I didn't find any information on how to it online and i'm fairly new to tensorflow so i don't really get how to do it",https://stackoverflow.com/questions/58076296,8181833.0,1
63063260,Extracting features from EfficientNet Tensorflow,"I have a CNN model trained using EfficientNetB6. My task is to extract the features of this trained model by removing the last dense layer and then using those weights to train a boosting model. i did this using Pytorch earlier and was able to extract the weights from the layers i was interested and predicted on my validation set and then boosted. I am doing this now in tensorflow but currently stuck. Below is my model structure and I have tried using the code on the website but did not had any luck. I want to remove the last dense layer and predict on the validation set using the remaining layers. I tried using : layer_name = 'efficientnet-b6' intermediate_layer_model = tf.keras.Model(inputs = model.input, outputs = model.get_layer(layer_name).output) but i get an error "" ValueError: Graph disconnected: cannot obtain value for tensor Tensor(""input_1:0"", shape=(None, 760, 760, 3), dtype=float32) at layer ""input_1"". The following previous layers were accessed without issue: []"" Any way to resolve this?",https://stackoverflow.com/questions/63063260,5197636.0,1
76324768,clipnorm vs clipvalue vs global_clipnorm in tf.keras.optimizers.Adam,"I am looking at the definition of clipvalue, clipnorm, global_clipnorm arguments in tf.keras.optimizers.Adam here. I have some questions related to that. The description of the arguments mentions following: Questions:",https://stackoverflow.com/questions/76324768,7561372.0,1
68089330,TimeDistributed(Dense) vs Dense And TimeDistributed(Conv2D),I am trying to understand the how TimeDitributed() Layer works in keras!! I know that when we wrap Conv2D layer in TimeDitributed() it applies same Conv2D layer to all the time events of a video(or to different frames that are present in a video sequence). As mentioned here https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed. For the purpose of my project I am trying to build an LSTM model which is of the as follows: Here I am getting 99 parameters in the TimeDistributed() layer. Now when I am not using TimeDistributed() Layer I am getting same number of parameters i.e 99. I have read in the following posts that :- and Now According to me it makes sense that the dense layer when applied on the LSTM return_sequences=True should have the same weights for the all the timestamps. But I have few questions that are mentioned below.,https://stackoverflow.com/questions/68089330,16156882.0,1
45995471,How to get PI in tensorflow?,"I could not find any information about mathemtical constants in the Tensorflow API neither in Basic Math functions nor in Math Ops. I was able to get it by However, this would mean to include another library, - so I wonder if there is this functionallity for mathemtical constants like pi, or euler already provided inside tensorflow?",https://stackoverflow.com/questions/45995471,6786718.0,1
51668059,How to use PriorityQueue in TensorFlow?,"I seem to have an issue with using tf.PriorityQueue in tensorflow. The documentation says that the shapes argument is not required for initialization. I cannot specify the shape of the tensor as it is dynamic and the shape is determined at runtime. From the tensorflow documentation on tf.PriorityQueue: However, the following code produces a TypeError: Any ideas on what I am doing wrong?",https://stackoverflow.com/questions/51668059,8538168.0,1
56453002,Tensorflow handling arrays as feature_columns,I'm trying to build a classifier which takes an array of floats as an input. Despite following steps here and here to include an array as the input feature I keep getting an TypeError whereby the estimator doesn't recognise the shape of the input. How do you include an array as a feature for an estimator? Can you simply pass in the numeric_column with an appropriate shape as expected in the docs? Sample code here: which gives a stack trace of,https://stackoverflow.com/questions/56453002,6801991.0,1
74438455,How do I print elements of _VariantDataset?,"I'm working on formatting data for LSTM model. Here's what I'm doing: this outputs Instead, I would like to see, what data it contains. In documentation, they seem to do something like print(i.flat_map(lambda x:x)). For me, this fails with I have also found and tried following example: That also doesn't work How do I print data inside of _VariantDataset to see if I'm formatting it correctly?",https://stackoverflow.com/questions/74438455,847200.0,1
43779129,Store a tf.Saver.save checkpoint in a variable (or in memory),"I am using Tensorflow and storing the current ""best"" model on the hard drive for persistence, using tf.Saver: My network is rather small and very fast to run, a single epoch on the GPU runs in less than 10 seconds. However, saving the model to the hard drive takes between one to two minutes, taking up a lot time. Is it possible to store the model in memory, to avoid taking up such a big chunk of the overall run time? If I somehow could store the ""best"" model in memory for a while, and dump it once I tell the model to, I could cut down the overall run time by a big factor. I've looked at the tf.Saver documentation and implementation, and I can not see any way to achieve just what I want. Is there some other implementation or tool that can do what I want to?",https://stackoverflow.com/questions/43779129,921563.0,1
56430357,Tensorflow: sess.run([x]) not working but sess.run([y]) works with the same feed_dict,"I am learning Tensorboard, and I am following the code in this tutorial. Below is my code: I run into an error when I use this line: [s, train_accruacy] = sess.run([summ, accuracy], feed_dict={x:batch[0], y:batch[1]}) #error! This is the error message I get: You must feed a value for placeholder tensor 'x' with dtype float and shape [?,784] [[{{node x}} = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]] which I understand that the tensor which I fed in is not of the correct shape of (x, 784). However, I don't get why [train_accruacy] = sess.run([accuracy], feed_dict={x:batch[0], y:batch[1]}) # works. After all, I'm feeding in the same thing into the same placeholder variables, which are accepting tensors of the same shape. Unless I am completely mistaken, the first argument of sess.run([argument], feed_dict=...) describes the tensor to return. I don't see how that affects the shape of the data I'm feeding in. Also: this model is supposed to have an error in it. For those interested, the full code is here. Could it also be that the return datatype is different? tf.summary.merge_all() returns a string tensor, but I doubt that's what causing the issue. I can't seem to find any documentation of this problem online. Is this supposed to happen?",https://stackoverflow.com/questions/56430357,9721336.0,1
39112622,How do I set TensorFlow RNN state when state_is_tuple=True?,"I have written an RNN language model using TensorFlow. The model is implemented as an RNN class. The graph structure is built in the constructor, while RNN.train and RNN.test methods run it. I want to be able to reset the RNN state when I move to a new document in the training set, or when I want to run a validation set during training. I do this by managing the state inside the training loop, passing it into the graph via a feed dictionary. In the constructor I define the the RNN like so The training loop looks like this x and y are batches of training data in a document. The idea is that I pass the latest state along after each batch, except when I start a new document, when I zero out the state by running self.reset_state. This all works. Now I want to change my RNN to use the recommended state_is_tuple=True. However, I don't know how to pass the more complicated LSTM state object via a feed dictionary. Also I don't know what arguments to pass to the self.state = tf.placeholder(...) line in my constructor. What is the correct strategy here? There still isn't much example code or documentation for dynamic_rnn available. TensorFlow issues 2695 and 2838 appear relevant. A blog post on WILDML addresses these issues but doesn't directly spell out the answer. See also TensorFlow: Remember LSTM state for next batch (stateful LSTM).",https://stackoverflow.com/questions/39112622,1120370.0,1
38096689,Edit tensorflow inceptionV3 retraining-example.py for multiple classificiations,"TLDR: Cannot figure out how to use retrained inceptionV3 for multiple image predictions. Hello kind people :) I've spent a few days searching many stackoverflow posts and the documentation, but I could not find an answer to this question. Would greatly appreciate any help on this! I have retrained a tensorflow inceptionV3 model on new pictures, and it is able to work on new images by following the instructions at https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html and using the following commands: However, I need to classify multiple images (like a dataset), and am seriously stuck on how to do so. I've found the following example at https://github.com/eldor4do/Tensorflow-Examples/blob/master/retraining-example.py on how to use the retrained model, but again, it is greatly sparse on details on how to modify it for multiple classifications. From what I've gathered from the MNIST tutorial, I need to input feed_dict in the sess.run() object, but was stuck there as I couldn't understand how to implement it in this context. Any assistance will be extremely appreciated! :) EDIT: Running Styrke's script with some modifications, i got this This is the script: some functions are removed.",https://stackoverflow.com/questions/38096689,5766416.0,1
63583916,tensorflow 2.0: can't get started with Keras and dataset from disk files,"I've got a big data file, where each line consists of 7330 floats and one label. I write everything to a bunch of files train-00000-of-01024 etc using where _float_feature is just a call to tf.train.Feature(float_list=...) and _int64_feature is similar. This creates the files and I can read them in successfully into a dataset. I can then call map(parse_example_proto) on that dataset, where parse_example_proto is defined by So far, so good. If I define data = raw_dataset.map(parse_example_proto), I get an object which is what I expected. But I now can't push the data into Keras. If, for example, I create a simple model starting with inputs=tf.keras.Input(shape=(7330,),dtype='float32',name='floats'), and then compile the model I create, when I try model.fit(data,epochs=10), I get ValueError: Input 0 of layer dense_13 is incompatible with the layer: : expected min_ndim=2, found ndim=1. Full shape received: [None] I have a feeling I'm doing something fairly obviously dumb, but I can't figure out what and the Tensorflow documentation is surprisingly unhelpful at actually getting started if you don't want to use one of the canned datasets. Can someone please help me? Thanks!",https://stackoverflow.com/questions/63583916,7274120.0,1
38810424,How does one debug NaN values in TensorFlow?,"I was running TensorFlow and I happen to have something yielding a NaN. I'd like to know what it is but I do not know how to do this. The main issue is that in a ""normal"" procedural program I would just write a print statement just before the operation is executed. The issue with TensorFlow is that I cannot do that because I first declare (or define) the graph, so adding print statements to the graph definition does not help. Are there any rules, advice, heuristics, anything to track down what might be causing the NaN? In this case I know more precisely what line to look at because I have the following: when this line is present I have it that it returns NaN as declared by my summary writers. Why is this? Is there a way to at least explore what value Z has after its being square rooted? For the specific example I posted, I tried tf.Print(0,Z) but with no success it printed nothing. As in: I actually don't understand what tf.Print is suppose to do. Why does it need two arguments? If I want to print 1 tensor why would I need to pass 2? Seems bizarre to me. I was looking at the function tf.add_check_numerics_ops() but it doesn't say how to use it (plus the docs seem to not be super helpful). Does anyone know how to use this? Since I've had comments addressing the data might be bad, I am using standard MNIST. However, I am computing a quantity that is positive (pair-wise eucledian distance) and then square rooting it. Thus, I wouldn't see how the data specifically would be an issue.",https://stackoverflow.com/questions/38810424,1601580.0,1
66039309,How to use Early Stopping with KerasRegressor in gridsearch (withing sklearn pipeline)?,I used KerasRegressor within a sklearn pipeline and used GridSearchCV for hyperparam tuning. Now I want to add early stopping however I couldn't find a way. I read few older posts and no success. My code is the following which works without error but it seems early stopping doesn't work: The verbose looks like this: Does anybody know how to fix this?,https://stackoverflow.com/questions/66039309,5937757.0,1
71209058,Keras - Adding loss to intermediate layer while ignoring the last layer,I've created the following Keras custom model: The task is multi-class classification. Model consists of a dense layer with softmax activation and a lambda layer as a post-processing unit that converts the dense output vector to a single value (predicted class). The train targets are a one-hot encoded matrix like so: It would be nice if I could define a categorical_crossentropy loss over the dense layer and ignore the lambda layer while still maintaining the functionality and outputting a single value when I call model.predict(x). Please note My workspace environment doesn't allow me to use a custom training loop as suggested by @alonetogether excellent answer.,https://stackoverflow.com/questions/71209058,1115237.0,1
58100071,What is the correct way to implement a 'useless loss' with Keras?,"I have a Keras model that has two outputs: When I build the model, I write something like that: Since my Model has two outputs, I need to provide two losses when compiling the model so I created a useless loss like this: Which I integrate in the compile step like this: It works, but I feel it is a bit hackish, is there a correct way to implement this behavior? I didn't find any official useless loss in the Keras documentation.",https://stackoverflow.com/questions/58100071,2206908.0,1
44268206,How to get the list of uninitialized variables from tf.report_uninitialized_variables,"The documentation says it's a 1 d tensor, however, I have failed to figure out how to access the list. I would prefer the actual variables rather than names as I would like to initialize them via tf.variables_initializer()",https://stackoverflow.com/questions/44268206,4261647.0,1
59478115,Custom CTC loss function in Keras/Tensorflow,"I feel like I'm fundamentally misunderstanding something. I went through the Keras documentation to no avail. I'm trying to implement the ctc_batch_cost loss for my neural network. My neural network ends with an LSTM layer which returns sequences into a dense layer with 4+1 symbols softmax output. The output shape has 20 time steps and looks as follows: My labels are simply the string that should be output, of variable lengths. Here is my attempt at the CTC function: Now, of course, Tensorflow currently errors with the following: which is understandable since at compile time variables such as samples will be None. But I am at a loss about how to use this. Any hints are appreciated. I want to understand what's happening, not just get an easy fix. I tried testing for None and returning a placeholder but that didn't work either and felt like a hack to begin with. Thank you",https://stackoverflow.com/questions/59478115,5963142.0,1
48077625,Why match_filenames_once function returns a local variable,"I was trying to understand the mechanism of tensorflow for reading images using queues. I was using the code found here, whom basic parts are: which in reality does nothing special. I was getting an error: which lead to search for missing images, wrong folder, wrong glob pattern etc until I discovered that tensorflow basically meant this: ""You need to initialize local variables also""! Besides the fact that the code seemed to work in the original gist with just this substitution: instead of in my code it does not work. It produces the same error. I guess it has changed the implementation of initialize_all_variables() with tensorflow development (I am using 1.3.0), since in here it mentions that it initialize local variables also. So, the final conclusion I came with was that I should initialize local variables also. And my code worked. The error message is awfully misleading (which did not help at all) but anyway to the main part I am a bit confused why am I getting a local variable by match_filenames_once. In documentation there is no reference about this (I am not sure it should though). Am I always going to get local from this match_filenames_once? Can I control it somehow?",https://stackoverflow.com/questions/48077625,3584765.0,1
48206320,TensorFlow - `keys` or `default_value` doesn't match the table data types,"(Complete novice at python, machine learning, and TensorFlow) I am attempting to adapt the TensorFlow Linear Model Tutorial from their offical documentation to the Abalone dataset featured on the ICU machine learning repository. The intent is to guess the rings(age) of an abalone from the other given data. When running the below program I get the following: The error is being thrown in lookup_ops.py at line 220 and is documented as being thrown when: From debugging parse_csv() it seems to be the case that all the tensors are created with the correct type. Could you please explain what is going wrong? I believe I am following the tutorial code logic and cannot figure this out. Source Code: Here is the classification of the columns of the dataset from abalone.names: Dataset entries appear in this order as common separated values with a new line for a new entry.",https://stackoverflow.com/questions/48206320,7454312.0,1
65254938,Simple GAN predicts NaN in Tensorflow after 2 steps,"I'm implementing a basic GAN based on the one in the Tensorflow documentation. After 2 training steps, the prediction from the generator is all NaN. I don't know why it happens, but I noticed that the gradients of the 2nd convolution layer of the discriminator are all NaN since the first step: My loss functions: The training loop: I build the models exactly the same way as in the documentation. Things I tried: No matter what I do, calling the generator with any input will produce exclusively NaN elements. Example output:",https://stackoverflow.com/questions/65254938,6104191.0,1
51586121,"Although pc recognizes gpu, it uses a CPU in tensorflow-gpu","I am using tensorflow-gpu. I want to use GTX1070, but tensorflow-gpu uses my CPU. I don't know what to do. I use CUDA 9.0 and CUDNN 7.1.4. My tensorflow-gpu version is 1.9. After running this command on the official website",https://stackoverflow.com/questions/51586121,10153046.0,1
54098247,Trouble evaluating test data with Tensorflow's Object Detection API,"I'm working on an object detector using Tensorflow's Object Detection API using custom training data. My understanding so far has been that I can feed my training data into the model and then use a trained model[0] to evaluate test data, and that following that evaluation, I'd be able to see a set of images like the following to figure out what the trained model was able to detect in each image in my test data. Operating with this assumption, I've been able to create a training dataset in .tfrecord format, and I've been able to feed this into my model trainer using the following command: This gave me output that looks like this (repeated lots of times—this is just a representative sample): After this training session, I found a set of files in the object_detection/modeldir directory: What should I do with the contents of this directory to test my testing data? I assume I have to have a .tfrecord file for all the testing data (similar to the file I made before for training data). Based on the model's documentation, I've been trying to run the following command: but when I do this, I run into the following error (running with both Python 2 and Python 3): Does anyone know: Thanks. [0]: Is this the correct vocabulary, using model like this in two different ways?",https://stackoverflow.com/questions/54098247,3841018.0,1
55246768,Python: Multiply two or more numeric_column in tensorflow,"I am new to tensorflow and could not find any documentation on how to define operations on numeric_columns. I have 3 columns in my data (say) col1, col2, col3. All have numeric values. I want to multiply these and create a new column (say) 'product`. I tried the following. When I run the snippet (via a unittest), I get How else can I get it done?",https://stackoverflow.com/questions/55246768,1306819.0,1
58228821,Tensorflow gradientTape explanation,I am trying to understand an API from tensorflow tf.gradientTape Below is the code I get from the official website: I wanted to know how did they get dz_dx as 108 and dy_dx as 6? I also did another test like below: this time the dz_dx becomes 1458 and I do not know why at all. Could any expert show me how the calculation being done?,https://stackoverflow.com/questions/58228821,11634815.0,1
47871331,"Tensorflow with softmax, to implement word2vec: Value Error: No gradients provided for andy variable","I try to implement the Word2Vec Algorithm for learning in Tensorflow, but got stuck and have no idea how to solve that. The error I get is: I have created a simpler example of my code to show the error: My research makes me think that the placeholders in the softmax are the problem here, but I don't really understand why and I'm not really sure about this. What is it really I'm doing wrong? And how can I solve that? :-) Solutions, Ideas?",https://stackoverflow.com/questions/47871331,3803077.0,1
58527048,Accessing intermediate layers from a loaded saved_model in Tensorflow 2.0,"When using SavedModels in Tensorflow 2.0, is it possible to access activations from intermediate layers? For example, with one of the models here: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md, I can run, for example, to get output predictions and bounding boxes. I would like to be able to access layers other than the outputs, but there doesn't seem to be any documentation for Tensorflow 2.0 on how to do this. The downloaded models also include checkpoint files, but there doesn't seem to be very good documentation for how to load those with Tensorflow 2.0 either...",https://stackoverflow.com/questions/58527048,11357382.0,1
43284897,How can I multiply a vector and a matrix in tensorflow without reshaping?,This: results in: (not sure why the same exception is raised inside its handling) The solution suggested in Tensorflow exception with matmul is reshaping the vector to a matrix but this leads to needlessly complicated code - is there still no other way to multiply a vector with a matrix? Incidentally using expand_dims (as suggested in the link above) with default arguments raises a ValueError - that's not mentioned in the docs and defeats the purpose of having a default argument.,https://stackoverflow.com/questions/43284897,281545.0,1
42608175,What does tf.gather_nd intuitively do?,"Can you intuitively explain or give more examples about tf.gather_nd for indexing and slicing into high-dimensional tensors in Tensorflow? I read the API, but it is kept quite concise that I find myself hard to follow the function's concept.",https://stackoverflow.com/questions/42608175,5098762.0,1
58873635,What is tensorflow.matmul?,"From the output of print, it is function. But according to the official document: it is a constructor. So I think it is a class name. But, printing the return value of tf.matmul shows it is a tensor, not an ""Object of type Operation"". Is the class Tensor inherited from the class Operation? I tried to find the definition of tf.matmul in tensorflow source code but could not get it.",https://stackoverflow.com/questions/58873635,10142726.0,1
68123049,Tensorflow Autoencoder ValueError: No gradients provided for any variable,I'm trying to create a autoencoder using tensorflow that analyses a dataset of cars for a university project. However the code outputs a error when starting to train that I can't seem to find the solution for. First I tried reading the tensorflow documentation for the fit function but there was no reference to this error. Next I tried to search for similar errors on StackOverflow but I couldn't find anything that was related. The portion of the output with the error: Can anyone help me debug this? Thanks in advance,https://stackoverflow.com/questions/68123049,10754901.0,1
47231048,Converting from feed_dict to queues results in increasing loss,"I have a working tensorflow model that I am trying to convert to using queues. It may not be the best function but it works. The data comes in as a list(dict()) called 'rows' from a processing pipeline outside of TF in the form format [{'y1': 1, 'y2': 0, 'y3':1, 'y4':0, 'x1':...'x1182': 0}] (SPECIAL_FIELD_CHAR is 'y', meaning it's calculated from the 'xN' data). The features_outputs() just returns the xs and the ys as ['y1', 'y2', 'y3', 'y4'] and ['x1', ..., 'x1182']. The idea is that the xs determine the ys. There are 4 independent ys that are calculated per row of xs. This produces a model that converges. However with the queue based version it does not, and error increases rapidly: They are meant to be the same, but I've had to change a few things: 1. Add a tf.transpose() to the x_in for the matmul() 2. Queue the entire row of xs and ys, then pull apart using tf.gather(). I've searched a lot for examples that match mine, and I can find no documentation on how to restart a queue and continue the training from the beginning. It'll seemly train forever(not sure why, who is replenishing the queue?) It'll also never stop. But most of all I have no idea why given the exact same data, the first converges and the second does not?",https://stackoverflow.com/questions/47231048,3618212.0,1
59811773,How to use keras attention layer on top of LSTM/GRU?,"I'd like to implement an encoder-decoder architecture based on a LSTM or GRU with an attention layer. I saw that Keras has a layer for that tensorflow.keras.layers.Attention and I'd like to use it (all other questions and resources seem to implement it themselves or use third party libraries). Also I'm not using the network for sequence to sequence translation but for binary classification, therefore the example provided in the documentation is a bit confusing to me. I'm imagining a model like this. The decoder and attention part are of this network are unclear to me. I know that I need to create a context vector from the hidden states of the encoder and the decoders current hidden state. How would I implement the decoder and attention part of this network?",https://stackoverflow.com/questions/59811773,3666302.0,1
43457543,Building dynamic_rnn from scratch in tensorflow,"I am coding rnn similar to dynamic_rnn provided by tensorflow. I tried to see the code on GitHub but cannot understand how they have implemented it. I want to build it from scratch so that I can customize rnn from within. How to do that? Currently, my approach is thinking of a truncated time series as a tensor use tf.scan() and find the new hidden state for all time series. Then use tf.map_fn to find the output for the new stacked hidden variables. Finally, use tf.while_loop() to find the error for each tensor on the first dimension of stacked output and do back propagation with that loss. My concern will the graph be dynamic after doing this. I mean let say first I unrolled for 5 times and then 4 times will the graph erase that one node rolled before? Will this work? Please guide. Thank you,",https://stackoverflow.com/questions/43457543,7492728.0,1
57312524,Serving Tensorflow model for production,"I am using a tensorflow estimator model for multi-label text classification. After having the prediction, I need to serve the model for prediction, but I am not getting the correct path. I tried tensorflow serving but it didn't work.",https://stackoverflow.com/questions/57312524,11050535.0,1
57193336,"What is the return of ""tf.train.slice_input_producer()""?","I was interested in srgan, and I wanted to run the code with npy type input rather than png type input. However, since there is no function that accepts the npy format(such as ""decode_png()""), I was trying to fix the data_loader part. And I had difficulty in ""tf.train.slice_input_producer()"". In tensorflow, the return of ""tf.train.slice_input_producer()"" is described as ""A list of tensors, one for each element of tensor_list. If the tensor in tensor_list has shape [N, a, b, .., z], then the corresponding output tensor will have shape [a, b, ..., z]."" But, I do not fully understand this explanation. For example, if I have a list of 230 image tensors with a height of 100 and a width of 100([230,]), would I return one by one([1,])? Then, ""read_file()"" returns its entire contents for one image([100,100])?",https://stackoverflow.com/questions/57193336,11833477.0,1
64404009,"Keras ValueError: Dimensions must be equal, but are 9 and 400 for '{{node Equal}}' with input shapes: [?,9], [?,300,400]","I'm trying to train a very simple Keras network to classify some one-hot encoded images saved as np.array. The input data structure is made of a .npy file, with 500 images (3 arrays each one, as it's RGB) and a one-hot encoded array with each image to determine it's classification. Each image is 400x300 pixels (Width x Height), and the target output should be of 9 classes. Hence, each image has a shape of (300, 400, 3) and each one-hot encoded label list has a length of 9. This is the code that I am currently using: However, when I try to run model.fit(), I always face the same error: I have been reading Keras documentation and lots of SO questions, but I can't figure out what's wrong with the code. I think that the problem might be located in the definiton of the input layer, but I have tried other configurations and returns errors as well. Thanks in advance!!",https://stackoverflow.com/questions/64404009,13695889.0,1
53611227,Changing the shape of a new assigned variable in Tensorflow,"if you change a tf.Variable using tf.assign with validate_shape=False the shape is not updated. But if I use set_shape to set the new (correct) shape I get a ValueError. Here a quick example: How do I change the shape of the Variable? Note: I am aware that the code works if I use a = tf.Variable([3,3,3], validate_shape=False) but in my context I will not be able to initialize the variable myself.",https://stackoverflow.com/questions/53611227,10743551.0,1
63253714,"What numbers go into DCGAN Generator models, in order to produce larger images","I really have tried to do my due diligence here but I can't find a lot of documentation on why certain numbers are chosen. I'm also fairly hazy on how convolutions work in generators (have a better understanding in terms of classifiers) so that's not helping my case. I think my question should be pretty simple to address for some more experiences folks out there though. Take Google's tutorial for example, the Generator class: Where is 7x7x256 coming from? I understand that 7x7 is a multiple of the eventual 28x28 size, so that makes sense somewhat, but what is the 256 all about? And then in the following layers, I notice a pattern but I'm not sure how to re-write it so it works for a wholly different image size. Any help or direction is appreciated.Thanks! EDIT: Thanks to the helpful input I changed my gen to: and discriminator:",https://stackoverflow.com/questions/63253714,1135125.0,1
66654938,Tensorflow pruned model is the same size as original baseline model,"I have a baseline TF functional model that I want to prune. I have tried following the code in the documentation, but the size the compressed pruned model is the same size as the compressed baseline model. (https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide#export_model_with_size_compression) I don't believe there is anything wrong with my code, so why does this occur? Output: EDIT: I also tried this with the same model as in the documentation, and the pruned model is still the same size as the baseline: Output:",https://stackoverflow.com/questions/66654938,14565727.0,1
44839045,per_process_gpu_memory_fraction does not work as expected in tensorflow r1.0,"I want to limit the memory usage per gpu. As suggested in this answer, I do as following: But it still does not work (the GPU-Util of one of the GPUs has achieved to 100%). Could you please tell me how to fix this issue? Thanks in advance!",https://stackoverflow.com/questions/44839045,5779223.0,1
55421290,TensorFlow 2.0 Keras: How to write image summaries for TensorBoard,"I'm trying to setup an image recognition CNN with TensorFlow 2.0. To be able to analyze my image augmentation I'd like to see the images I feed into the network in tensorboard. Unfortunately, I cannot figure out, how to do this with TensorFlow 2.0 and Keras. I also didn't really find documentation on this. For simplicity, I'm showing the code of an MNIST example. How would I add the image summary here?",https://stackoverflow.com/questions/55421290,820833.0,1
44691406,How to understand tf.get_collection() in TensorFlow,"I am confused by tf.get_collection() form the docs, it says that And an example from the Internet is here Is it means that it collects variables from tf.GraphKeys.TRAINABLE_VARIABLES to from_scope? However, how can I use this function if I want to get variables from another scope? Thank you!",https://stackoverflow.com/questions/44691406,5046896.0,1
49150587,"Distributed TensorFlow [Async, Between-Graph Replication]: which are the exactly interaction between workers and servers regarding Variables update","I've read Distributed TensorFlow Doc and this question on StackOverflow but I still have some doubt about the dynamics behind the distributed training that can be done with TensorFlow and its Parameter Server Architecture. This is a snipped of code from the Distributed TensorFlow Doc: And here part of the answer of the StackOverflow question that I read: I have to reproduce this kind of parameter server architecture in another environment and I need to deeply understand how workers and PS tasks interact with each other inside the TensorFlow framework. My question is, does the PS task do some kind of merging or updating operation after receiving the value from the workers or it just store the newest value ? Can be something reasonable just storing the newest value ? Looking at the code from the TensorFlow documentation I see that the PS task just do a join() and I wonder behind this method call which are the complete behaviour of the PS task. One more question, what is the difference between compute a gradient and apply a gradient ?",https://stackoverflow.com/questions/49150587,9099269.0,1
48115096,Explicitly clear/reset a nested TensorFlow Graph scope,"So, I'm using a bunch of functions from OpenAI baselines for Reinforcement Learning. In those functions, policy nets are initialised using statements like: The problem is that the pointer to the output of those networks gets returned while still inside the scope, which means that when accessing those functions from another .py file I am still inside those scopes. Basically I want to run a first function train_policy(output_dir) that trains the net and dumps the checkpoint to disk using tf.Saver(). Next, I run a function run_policy(output_dir) that reinitializes the same tf Graph and loads it's pretrained values using the checkpoint dir. Right now, when I try this, I get a ValueError: ""Variable deepq/... already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?"" because at the point of running the second function, I'm still in the scope defined by the first.. I checked the code from OpenAI baselines (very nested code, hard to see everything that's going on), and reuse is already set to True. So I tried doing something like: tf.get_default_session().close() followed by: tf.reset_default_graph() after the first function call. (I don't need the session to remain active since I'm dumping everything to disk) But this gives me errors because I'm still inside a nested graph scope and so I can't reset the default graph... (see eg here) Alternatively I tried things like: or but the exit() function needs a whole bunch of args I don't know how to get... (and I can't find good documentation on how to use this function). My current solution is to run these functions in separate subprocesses in Python (and let the garbage collector do all the work), but this doensn't feel like a satisfactory solution.. Any ideas on how to deal with this? Ideally I'd need something like: tf.clear_all_graphs_and_sessions()",https://stackoverflow.com/questions/48115096,9088766.0,1
58672774,Training using tf.Dataset in TensorFlow 2.0,"I'm having difficulty training my TensorFlow model using a tf.Dataset rather than, say, a pd.DataFrame (which works fine). I have created a dummy example below that I would expect to work given what I have read online/on the TensorFlow website. which returns the following error message Is there anything obviously wrong in the above? Why is TensorFlow grabbing an input with shape (1,)?",https://stackoverflow.com/questions/58672774,11978086.0,1
73629508,Keras Model.fit() TypeError: __init__() missing 1 required positional argument: 'normalizer',"I am attempting to build a sequential model in Keras and use it to do image classification. I am getting the following error in the Anaconda3 (Python 3.9) terminal and haven't been able to track down the cause: So far, I haven't seen the 'normalizer' argument mentioned in the Tensorflow/Keras documentation or on the stackoverflow forums. Here is my source code:",https://stackoverflow.com/questions/73629508,19936707.0,1
51330841,How to save and restore a tf.estimator.Estimator model with export_savedmodel?,"I started using Tensorflow recently and I try to get use to tf.estimator.Estimator objects. I would like to do something a priori quite natural: after having trained my classifier, i.e. an instance of tf.estimator.Estimator (with the train method), I would like to save it in a file (whatever the extension) and then reload it later to predict the labels for some new data. Since the official documentation recommends to use Estimator APIs, I guess something as important as that should be implemented and documented. I saw on some other page that the method to do that is export_savedmodel (see the official documentation) but I simply don't understand the documentation. There is no explanation of how to use this method. What is the argument serving_input_fn? I never encountered it in the Creating Custom Estimators tutorial or in any of the tutorials that I read. By doing some googling, I discovered that around a year ago the estimators where defined using an other class (tf.contrib.learn.Estimator) and it looks like the tf.estimator.Estimator is reusing some of the previous APIs. But I don't find clear explanations in the documentation about it. Could someone please give me a toy example? Or explain me how to define/find this serving_input_fn? And then how would be load the trained classifier again? Thank you for your help! Edit: I discovered that one doesn't necessarily need to use export_savemodel to save the model. It is actually done automatically. Then if we define later a new estimator having the same model_dir argument, it will also automatically restore the previous estimator, as explained here.",https://stackoverflow.com/questions/51330841,8733572.0,1
49889153,How to retrieve intermediary state in TensorFlow RNN,"I am running an RNN on a signal in fixed-size segments. The following code allows me to preserve the final state of the previous batch to initialize the initial state of the next batch. This works when the batches are non-overlapping. For example, my first batch processes samples 0:124 and final_state is the state after this processing. Then, the next batch processes samples 124:256, setting init_state to final_state. My question is how to retrieve an intermediary state when the batches are overlapping. First, I process samples 0:124, then 10:134, 20:144, so the hop size is 10. I would like to retrieve not the final_state but the state after processing 10 samples. Is it possible in TF to keep the intermediary state? The documentation shows that the return value consists only of the final state. The image shows the issue I am facing due to state discontinuity. In my program, the RNN segment length is 215 and the hop length is 20. Update: the easiest turned out to be what David Parks described: and Now, after just a few iterations, the results look much better.",https://stackoverflow.com/questions/49889153,4008884.0,1
49178891,Filtering a Tensor using Tensorflow,"I'm attempting to filter a matrix that represents a point cloud in tensorflow. It is an n x 3 matrix. I only want to keep rows with z &gt; eps. This corresponds to column index 2 of the matrix. I have the following code: When I run the above code I get this: I don't understand the error message, having tried to specify shape in a number of places with no success, and the documentation seems to suggest the boolean_mask only works with np.arrays. Is there any way to do this entirely on the tensorflow graph?",https://stackoverflow.com/questions/49178891,1747088.0,1
47965551,Use tf.train.ExponentialMovingAverage() to Train the model,"I'm learning TensorFlow and trying to apply exponential moving average based gradient descent (instead vanilla gradient descent). Specifically I;m trying to use tf.train.ExponentialMovingAverage but the document doesn't seem to provide guide for how to use it to build model that drives optimization. Full code is available at - https://github.com/vibhorj/tf/blob/master/so/ema.py , but here's what i'm doing and the classifier isn't learning anything (after each epoch, w &amp; b still remain same .. no learning) STEP1: define weights &amp; biases STEP2: define error / loss / optimizer STEP3: Created ExponentialMovingAverage object, created training_op that (I expect) to update the moving averages after each training step. STEP4: Finaly run the iterations When I run it, weights &amp; biases stay the same with each successive iterations! I know there's something i'm missing (to update the parameters!) but unable to identify! The doc isn't much helpful either. Thanks a lot for any clue any guidance on how I can proceed further. Thanks!",https://stackoverflow.com/questions/47965551,4736890.0,1
71830863,MirroredStrategy causes IndexError: pop from empty list when using Keras Sequences as model input,"While the MirroredStrategy's IndexError: pop from empty list is now infamous and there are numerous possible causes for it, such as reported in the following questions: And so forth, but none apply to my use case. In my use case, I'm using Keras Sequence objects to generate the training inputs, as I'm working on large datasets (would not fit in RAM) with a single known positive class and unknown negatives. Following tutorials such as the one available on the Keras Documentation and TensorFlow documentation my code looks like the following: Any ideas on how to deal with this?",https://stackoverflow.com/questions/71830863,2550541.0,1
42164772,Tensorflow Estimator API: Summaries,"I can't achieve to make summaries work with the Estimator API of Tensorflow. The Estimator class is very useful for many reasons: I have already implemented my own classes which are really similar but I am trying to switch to this one. Here is the code sample: As you can see, I can create an Estimator and use it but I can achieve to add hooks to the fitting process. The logging hooks works just fine but the others require both tensors and a saver which I can't provide. The tensors are defined in the model function, thus I can't pass them to the SummaryHook and the Saver can't be initialized because there is no tensor to save... Is there a solution to my problem? (I am guessing yes but there is a lack of documentation of this part in the tensorflow documentation) Thanks in advance. PS: I have seen the DNNClassifier API but I want to use the estimator API for Convolutional Nets and others. I need to create summaries for any estimator.",https://stackoverflow.com/questions/42164772,5184894.0,1
63175471,How to control if input features contribute exclusively to one neuron in subsequent layer of a Tensorflow neural network?,"I'm trying to make the most basic of basic neural networks to get familiar with functional API in Tensorflow 2.x. Basically what I'm trying to do is the following with my simplified iris dataset (i.e. setosa or not) However, I can't figure out how to control one key aspect of the model. That is, how can I ensure that each feature from my input layer contributes to only one neuron in my subsequent dense layer? Also, how can I allow a feature to contribute to more than one neuron? This isn't clear to me from the documentation. Results:",https://stackoverflow.com/questions/63175471,678572.0,1
38190365,How does one initialize a variable with tf.get_variable and a numpy value in TensorFlow?,I wanted to initialize some of the variable on my network with numpy values. For the sake of the example consider: when I do that I get an error: why is it that I am getting that error? To try to fix it I tried doing: which yielded a even weirder error: I tried reading the docs and examples but it didn't really help. Is it not possible to initialize variables with numpy arrays with the get_variable method in TensorFlow?,https://stackoverflow.com/questions/38190365,1601580.0,1
51719099,"tf.placeholder(tf.random_normal([3,1]), name='weight') -> error","As it's written on the title, I got an error from When I input it, I got an error message which is Please, let me know what to do. Thanks.",https://stackoverflow.com/questions/51719099,10189928.0,1
55221080,softmax_cross_entropy_with_logits nan,"I have extracted CNN features from a pretrain vgg19 with size 4096. Then I am using a shallower architecture to train a classifier with softmax and center losses. Unfortunately, the softmax loss function returns nan. There is detailed discussion available here, however I am not able to resolve the problem with clip because labels and logits are in two different data format (int64, float32). Furthermore, I also changed the learning rate but still got the same error. Can some please let me know, how to resolve this situation. **************************retrieval_model********************************",https://stackoverflow.com/questions/55221080,8967121.0,1
44231072,Possible tensorflow cholesky_solve inconsistency?,"I am trying to solve a linear system of equations using tensorflow.cholesky_solve and I'm getting some unexpected results. I wrote a script to compare the output of a very simple linear system with simple matrix inversion a la tensorflow.matrix_inverse, the non-cholesky based matrix equation solver tensorflow.matrix_solve, and tensorflow.cholesky_solve. According to my understanding of the docs I've linked, these three cases should all yield a solution of the identity matrix divided by 2, but this is not the case for tensorflow.cholesky_solve. Perhaps I'm misunderstanding the docs? yielding output:",https://stackoverflow.com/questions/44231072,2467355.0,1
51777643,Tensorflow: Identifying the final state in MultiRNN,"I am new to TF and I am trying to implement multiple GRU cells into the NN. However, I am unable to identify the final state of the MultiRNN cell. For instance, when I use the following code: The output of the final line of code is: I believe that the format is: The documentation says that the output is in the format (output, state=[batch_size, cell.state_size]). However, I am unable to identify which of these is the final state of this memory cell. I think that it should be b. Also, when I run the same code above with 4 GRU cells: The output is even more confusing: I am confused about which one of the above is the final memory state which I could then process further for loss calculation and making predictions.",https://stackoverflow.com/questions/51777643,6657232.0,1
57009265,How transition from keras fit_generator() to the models input layer works exactly,"I am working with image data and some scalar meta-data (like hair-color, eye-color, ...). I am using a self-written generator to use the Keras .fit_generator() function. The process looks like the following: After applying some data augmentation I have the shape ((10,200,200,3),(10,),(10,),(10,),(10,)) of my dataset (For imagination: I extract images of shape (200,200,3) and stack together 10 of them -&gt; (10,200,200,3). Accordingly, I duplicate the metadata 10 times -&gt; shapes (10,) for each ) Afterwards I use the tensorflow function dataset = dataset.apply(tf.contrib.data.unbatch()) so that the shape of my dataset is ((200,200,3),(),(),(),()). From here I now share the code with you: Edit (more Code): Following code are the last line of my generator-function which will be called from the .fit_generator() function in the main() This tensor will now be fed into my network via the keras .fit_generator() function. The input layer looks like the following: Now I have some question: Can someone explain this issue with the shapes to me? And really I read a lot but I still do not get it. Thanks for your help :-)",https://stackoverflow.com/questions/57009265,11765047.0,1
66079584,tensorflow.dataset.shuffle = tensorflow.dataset.prefetch + then shuffle internally?,"According to the documentation of tf.dataset.shuffle, it will fill in a buffer with size k then shuffle inside of it. Tho I don't want the order of data to be changed, I want it to be buffered. Then I found there is tf.dataset.prefetch, which says ""This allows later elements to be prepared while the current element is being processed."" From the description I guess prefetch is what I want (i.e. pre-loading the data while the pervious data are being used in training), but while trying to look into the code of tf.dataset.shuffle to see if they actually call tf.dataset.prefetch, I got stuck in these lines (paste them below), cannot find where is shuffle_dataset_v3 defined. My major question is whether prefetch is the replacement of shuffle in terms of buffering the data, and it would also be nice if someone can point me to where shuffle_dataset_v3 was implemented?",https://stackoverflow.com/questions/66079584,13112529.0,1
36612247,Is it possible to make tensorflow raise an error on invalid flag?,"I can't find any documentation for tf.app.flags, but I see that the command line parser will happily accept invalid syntax, flags that have never been defined, etc. Is there a way to configure it to raise an error in these cases? I wasted a lot of time trying to figure out why decreasing my learning rate didn't help when the problem was just that I had typed ""-learning_rate"" instead of ""--learning_rate"".",https://stackoverflow.com/questions/36612247,378469.0,1
55298323,TensorFlow 2.0 returns unexpected output on dtype=int32 with GradientTape,"The following code should output the gradient of y=x*x for x=2, i.e. the value of 4. However the code prints a value of None when using TensorFlow 2.0.0-alpha0. When the definition of x changes to use tf.float32 instead of tf.int32 as shown in the next snippet, the output changes to the correct value of 4. Is there any documentation that clarifies the requirement for the data type to be a floating point number for GradientTape to work correctly in this scenario? outputs: Notice the change to tf.float32 in the next snippet: outputs:",https://stackoverflow.com/questions/55298323,3809616.0,1
50475348,How to save the model for text-classification in tensorflow?,"Reading tensorflow documentation for text-classification, I have put up a script below that I used to train a model for text classification (positive/negative). I am not sure on one thing. How could I save the model to reuse it later? Also, how can I test for the input test-set I have? Currently, if I run the above script it retrains the complete model. I want to reuse the model and have it output for some sample texts that I have. How could I do this? I have tried the following to save: but this throws an error, saying Value Error: No variables to save",https://stackoverflow.com/questions/50475348,9830669.0,1
76127890,Tensorflow federated prediction after the model is trained,I am new to Tensorflow federated and have trained a tff model. I want to use this model to predict on unseen data. Google colab has been used for this. I tried using the trainer object but it says 'AttributeError: 'LearningProcess' object has no attribute 'predict''. Went through the official documentation but couldn't find a solution. Here's my code:,https://stackoverflow.com/questions/76127890,21033120.0,1
38788912,Tensorflow 'features' format,"I'm a total begginer with AI and tensorflow, so please forgive if this is a dumb question. I've trained a tensorflow network using a script based on this tutorial: https://www.tensorflow.org/versions/r0.10/tutorials/wide_and_deep/index.html I believe training was ok. Now I whant to run this method to make a prediction for a single input: But I cannot find any documentation on how to build the ""x"" parameter... I tryed: Where: d_data is a dictionary containing about 150 key/value pairs. COLUMNS is a list with all the keys needed. This same setup was used to train the network. But got the error: So... x should not be a 'dict'... but what should it be then? Can anyone give me some directions? Thanks a lot.",https://stackoverflow.com/questions/38788912,6430078.0,1
50921379,What if stride size is same as input image height and width?,"In the following code I have set stride (1,4,4,1). According to my understanding if filter size is 2*2 then above stride is not possible. but still I am getting output. Any explanation with figure is appreciated.",https://stackoverflow.com/questions/50921379,9854153.0,1
41361766,tensorflow cifar10 tutorial fails,"I have downloaded the CIFAR10 code from the link in the tutorial here and am trying to run the tutorial. I run it with the command It starts ok and downloads the data file as expected. When it tries to open the input file it fails with the following trace: Sure enough, when I investigate the code there is a call in cifar10_input.py to strided_slice() with only 3 arguments: Whereas the tensorflow documentation does indeed state that there must be at least 4 arguments. What is going wrong? I have downloaded the latest tensorflow (0.12) and I'm running the master branch of the cifar code.",https://stackoverflow.com/questions/41361766,2467383.0,1
49416931,What does the tensorflow.python.eager.tape do in the implementation of tf.contrib.eager.custom_gradient?,"I am going through TensorFlow Eager Execution from here and find it difficult to understand the customizing gradients part. First, it is difficult to make sense what does dy do in the gradient function. When I read the implementation of tf.contrib.eager.custom_gradient. I can't really make sense the working mechanism behind tape. Following is the code I borrow from the implementation of tf.contrib.eager.custom_gradient. Can anybody explain what does tape do here? Even though I found the implementation of tape from here. But I can't really get much out of it due the poor documentation.",https://stackoverflow.com/questions/49416931,3744927.0,1
49785605,How does tensorflow connect the dimensions of linked convolutional layers?,"The is a very basic tensorflow question, but I haven't yet seen a clear explanation in the docs. Following the examples on the tensorflow site, we basically have these two layers connected: The shape at this point will be (28, 28, 32). The shape at this point will be (28, 28, 64). How does tensorflow take the (28, 28, 32) and turn it into (28, 28, 64) using a 2d kernel. Could you please explain or point me to the documentation? How about when the output dimension of the second layer is smaller, say How would tensorflow combine the 32 dimensions into 8?",https://stackoverflow.com/questions/49785605,1759909.0,1
48309631,TensorFlow - tf.data.Dataset reading large HDF5 files,"I am setting up a TensorFlow pipeline for reading large HDF5 files as input for my deep learning models. Each HDF5 file contains 100 videos of variable size length stored as a collection of compressed JPG images (to make size on disk manageable). Using tf.data.Dataset and a map to tf.py_func, reading examples from the HDF5 file using custom Python logic is quite easy. For example: This example works, however the problem is that it seems like tf.py_func can only handle one example at a time. As my HDF5 container stores 100 examples, this limitation causes significant overhead as the files constantly need to be opened, read, closed and reopened. It would be much more efficient to read all the 100 video examples into the dataset object and then move on with the next HDF5 file (preferably in multiple threads, each thread dealing with it's own collection of HDF5 files). So, what I would like is a number of threads running in the background, reading video frames from the HDF5 files, decode them from JPG and then feed them into the dataset object. Prior to the introduction of the tf.data.Dataset pipeline, this was quite easy using the RandomShuffleQueue and enqueue_many ops, but it seems like there is currently no elegant way of doing this (or the documentation is lacking). Does anyone know what would be the best way of achieving my goal? I have also looked into (and implemented) the pipeline using tfrecord files, but taking a random sample of video frames stored in a tfrecord file seems quite impossible (see here). Additionally, I have looked at the from_generator() inputs for tf.data.Dataset but that is definitely not going to run in multiple threads it seems. Any suggestions are more than welcome.",https://stackoverflow.com/questions/48309631,3419427.0,1
45362726,How to properly serve an object detection model from Tensorflow Object Detection API?,"I am using Tensorflow Object Detection API(github.com/tensorflow/models/tree/master/object_detection) with one object detection task. Right now I am having problem on serving the detection model I trained with Tensorflow Serving(tensorflow.github.io/serving/). 1. The first issue I am encountering is about exporting the model to servable files. The object detection api kindly included the export script so that I am able to convert ckpt files to pb files with variables. However, the output files will not have any content in 'variables' folder. I though this was a bug and reported it on Github, but it seems they interned to convert variables to constants so that there will be no variables. The detail can be found HERE. The flags I was using when exporting the saved model is as follows: It runs perfectly fine in python when I switch --export_as_saved_model to False. But still, I am having issue with serving the model. When I was trying to run: I got: I think the model was not properly loaded since it shows ""The specified SavedModel has no variables; no checkpoints were restored."" But since we have converted all variables into constants, it seems reasonable. I am not sure here. 2. I was not able to use client to call server and do detection on a sample image. The client scrip is listed below: To match request.model_spec.signature_name = 'predict_images', I modified the exporter.py script in object detection api (github.com/tensorflow/models/blob/master/object_detection/exporter.py) started at line 289 from: To: Since I have no idea how to call a default signature key. When I run the following command: I got following error message: Not quite sure what's going on here. Initially I though maybe my client script is not correct, after I found the AbortionError is from github.com/tensorflow/tensorflow/blob/f488419cd6d9256b25ba25cbe736097dfeee79f9/tensorflow/core/graph/subgraph.cc. Seems I got this error when building the graph. So it might be caused by the first issue I have. I am new to this stuff, so I am really confused. I think I might be wrong at start. Is there any way that I could properly export and serve the detection model? Any suggestions will be of great help!",https://stackoverflow.com/questions/45362726,7555390.0,1
71694574,Why does passing a KerasTensor to Sequential.add not raise a TypeError?,"In the definition of keras.Sequential.add, we have (in accordance with the docs) and yet, when I execute a TypeError is not raised. keras.Input returns a tensor, and the definition of a KerasTensor shows that it inherits from an Object, and not a Layer. Why can I add an Input to a Sequential, rather than being required to add an InputLayer as I would expect?",https://stackoverflow.com/questions/71694574,4552227.0,1
68208504,Control flow in Tensorflow 2 - gradients are None,"I have a Tensorflow 2.x model with the purpose of dynamically choosing a computational path. Here's a schematic drawing of this model: The only trainable block is the Decision Module (DM), which is essentially a fully connected layer with a single binary output (0 or 1; It's differentiable using a technique called Improved Semantic Hashing). Nets A &amp; B have the same network architecture. In the training progress, I feed forward a batch of images until the output of the DM, and then process the decision image-by-image, directing each image to the decided net (A or B). The predictions are concatenated into a single tensor, who's used to evaluate the performance. Here's the training code (sigma is the output of the DM; model includes the feature extractor and the DM): The problem - when running this code, gradients returns [None, None]. What I know for now is: My concern is that such thing might not be possible - quoting from the official docs: I'm not 100% sure that this is my case, but I wanted to ask here for the experts' opinion. Is what I'm trying to do possible? And if yes - what should I change in order for this to work? Thanks",https://stackoverflow.com/questions/68208504,5462551.0,1
50600661,Tensorflow TFRecordDataset.map Error,"I am making an input pipeline in tensorflow for a task I want to do. I have set up a TFRecord dataset which has been saved out to a file on disk. I am trying to load in the dataset (to be batched and sent to the actual ML algorithm) using the following code: However, I get an error on the dataset.map() line. The error I get looks like this: TypeError: Expected int64, got &lt;tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x00000000085F74A8&gt; of type 'SparseTensor' instead. The read_single_record() function looks like this: I'm not sure where the issue lies. I got the idea for this code from the tensorflow API documentation, slightly modified for my purposes. I really have no idea where to start trying to fix this. For reference, here is the code I have for generating the TFRecord file: Note that I've removed some code that isn't to do with the actual serialisation/creation of the TFRecords file.",https://stackoverflow.com/questions/50600661,5280140.0,1
60463215,Can we use Microsoft TensorFlow as regular TensorFlow?,"Most of the tutorials/guides I found on Microsoft ML are for sentiment analysis or image classification. For my project I need to use TensorFlow functions like it can be with Python. As TensorFlow nuget package is available I'm wondering if this can be used as original TensorFlow alternative. Asking reason of this question here is - I could not find a guide or documentation on this. I can import TensorFlow after getting it from nuget package manager. But I can't access its regular methods or constants like it can be with Python. The following code is valid: TensorFlow can be imported, but how can I use it in a regular way? For example:",https://stackoverflow.com/questions/60463215,7291498.0,1
54728905,Docker Tensorflow-Serving Predictions too large,"I'm trying to serve my model using Docker + tensorflow-serving. However, due to restrictions with serving a model with an iterator (using make_initializable_iterator() ), I had to split up my model. I'm using grpc to interface with my model on docker. The problem is that my predicted tensor is about 10MB and about 4.1MB serialized. The error I'm getting is: Is there a way to write out my predictions to disk instead of transmitting them in the grpc response? The output file is a 32-channel tensor so I'm unable to decode it as a png before saving to disk using tf.io.write_file. Thanks!",https://stackoverflow.com/questions/54728905,6693924.0,1
56976078,How do i load images dataset using tf.keras.utils.get_file,"I;m working with cifar-10 dataset and i need the dataset available publicly, so i pushed it to gitlab. i want to load this dataset in my code, after some digging i found an example where they used tf.keras.utils.get_file() which looked perfect but when i try to load my dataset i get a NotADirectoryError. but it loads just fine with the example i found online which is confusing, can someone please explain why it wouldn't work for my dataset? here's the example i found that works, the is_dir() returns true here's my dataset I'm trying to load. Initially throws train_data is not a directory, when i try again it seems to work but is_dir is false and i'm unable to get to the files in my dataset",https://stackoverflow.com/questions/56976078,3810448.0,1
52254721,Tensorflow - Map-Function,"I have a question concerning tf's map function. I encounter weird behavior with this function. If I do as stated in manual however, if i want to implement my own function it doesn't seem to work. It just always passes a tensor to the specified function which is not made to handle tensors. I am somehow not seeing the issue here. Also if I try something like: tmp_label_list = tf.Session().run(label_tensor) print(tmp_label_list) # prints out an evaluated list, [1, 2, 3, 3, 1, 2, 2,...] But if I then pass [special_fun(i) for i in tmp_label_list] it raises the Type-Error again, that it expected no 'Tensor' What am I missing or doing wrong? Thanks in advance.",https://stackoverflow.com/questions/52254721,8799635.0,1
37910592,Accessing values from a restored Tensorflow variable,"I have a simple recurrent network example, with a tf.Saver and weight, bias and state variables being saved. When the example is run with no options, it will initialise the state vector to contain zeros, but I want to pass a load_model option and it to use the last values of the state vector to as a feed for the session.run invocation. All documentation I see insists that one must invoke session.run to retrieve stored values from variables, but in this case I want to retrieve the values so that I can initialise the state variable. Do I need to do a separate graph just to retrieve the initialization values? Example code below: note at lines 124-126 the commented lines for ways that I tried to initialise the feed dictionary values. None of them work.",https://stackoverflow.com/questions/37910592,1792701.0,1
38510339,the usage or API of tf.app.flags,"When reading the cifar10 example, I can see the following code segment, which is said to follow the google commandline standard. But in specific, what does this code segment do? I did not find the API document to cover something like tf.app.flags.DEFINE_string",https://stackoverflow.com/questions/38510339,288609.0,1
36227354,Saving tensorflow model after training is finished,"I have finished running a big model in tensorflow python. But I have not saved it inside the session. Now that the training is over, I want to save the variables. I am doing the following: This returns : ValueError: No variables to save. According to their website what is missing is initialize_all_variables(). The documentation says little about what exactly that does. The word ""initialize"" scares me, I do not want to reset all my trained values. Any way to save my model without re-running it?",https://stackoverflow.com/questions/36227354,3761534.0,1
74818306,Issues with using Tensorflows preprocessing function for InceptionV3,"So this is my setup. At first I had it without the cast, then I would get a different error - since the documentation mentions the cast, I will discuss it like that. Documentation does it as follows (https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input): which is kinda hard to translate into my real application. I get the following Error: Now this is more or less useless, except for the last line. Anyone has a clue what I have done wrong? Do I need to resize anything or something like that? As far as I understood, the preprocessing function would do that for me.",https://stackoverflow.com/questions/74818306,19409269.0,1
44107208,In tf.nn.dropout what is the effect of keep_prob argument?,"I am learning tf.nn.dropout command. Documentation says that with probability keep_prob, outputs the input element scaled up by 1 / keep_prob, otherwise outputs 0. The scaling is so that the expected sum is unchanged. Can someone please explain that why we take 1/keep_prob. And if I set its value 0.1. Does it mean that I am keeping only 10 percent nodes?",https://stackoverflow.com/questions/44107208,7997184.0,1
74297504,Understanding Keras Constraints,"I have a question about tf.keras.constraints method. Do (1) and (2) perform the same process? The reason why I ask the question is that Keras Documentation said that Unlike (1), I think that the constraint is applied before each gradient update in case of (2). In my opinion, the gradients of weights of (1) and (2) are different, because the softmax is applied before the gradient calculation in the second case, but after the gradient calculation in the first case. If I am wrong, I would appreciate it if you point out the wrong part.",https://stackoverflow.com/questions/74297504,7229276.0,1
66685673,tf.io.decode_raw return tensor how to make it bytes or string,"I'm struggling with this for a while. I searched stack and check tf2 doc a bunch of times. There is one solution indicated, but I don't understand why my solution doesn't work. In my case, I store a binary string (i.e., bytes) in tfrecords. if I iterate over dataset via as_numpy_list or directly call numpy() on each item, I can get back binary string. while iterating the dataset, it does work. I'm not sure what exactly map() passes to test_callback. I see doesn't have a method nor property numpy, and the same about type tf.io.decode_raw return. (it is Tensor, but it has no numpy as well) Essentially I need to take a binary string, parse it via my x = decoder.FromString(y) and then pass it my encoder that will transform x binary string to tensor. Thank you, folks.",https://stackoverflow.com/questions/66685673,9063497.0,1
50164090,Tensorflow ServingInputReceiver input shape error in client,"I'm currently working with tensorflow Estimator API and have problems with the confusing serving options that are available. My confusion comes from the very undetailed tensorflow documentation. This is my goal: Use tensorflow-serving prediction_service_pb2 by sending a serialized proto message as string to the ServingInputReceiver function of my exported Estimator model. I expect the ServingInputReceiver function to receive the serialized proto string on the ""input"" tensor which then will deserialize it to the features ""ink"" (=varlength float array) and ""shape"" (=fixedlength int64). This is my (implementation of google quickdraw model) estimator Input function: This is my Serving Input Function: This is my client.py request: And this is the error I get after calling the Predict function in client.py I tried the following Servingfunctions: ServingInputReceiver and build_raw_serving_input_receiver_fn give me the same grpc error. When I use build_parsing_serving_input_receiver_fn it wont even export my model. I tried to wrap my head around the documentation but it is very undetailed and I don't understand when to use which serving input function.",https://stackoverflow.com/questions/50164090,8804834.0,1
58675856,Why does stacking CNN wreck reproducibility (even with seed & CPU)?,"REPRODUCIBLE: NOT REPRODUCIBLE: The difference amplifies substantially when using a larger model, and actual data instead of random noise - up to 30% difference in accuracy (relative) within a single small epoch. Environment setup, considered sources, and full minimal reproducible example below. Relevant Git What is the problem, and how to fix it? POSSIBLE SOURCES: ([x] = ruled out) ENVIRONMENT: OBSERVATIONS: CODE: Imports / setup:",https://stackoverflow.com/questions/58675856,10133797.0,1
63012878,model_main.py fails to traing mobilenet ssd v2 - tensorflow object detection api,"I am using TensorFlow 1.15 and trying to fine-tune mobilenetSSDv2 using TensorFlow object detection API with my own dataset. I created my tf records the way stated in the tf repo here and read the images like this I have divided my points by the width and height like needed, then I tweaked the config to fit my number of classes but when I run the train process I still get this error (I unsuccessfully tried a lot of things to make it work) My config file and pbtxt Edit: Here's the conversion to tf records code",https://stackoverflow.com/questions/63012878,7350027.0,1
48174988,Tensorflow: how to create a local variable?,"I'm trying to understand how local and global variables are different in tensorflow and what's the right way to initialize the variables. According to the doc, tf.local_variables_initializer: So the essential part is tf.local_variables. The doc: It sounds logical, however, no matter how I tried, I couldn't make any variable local. The output is always an empty list. How and should I create local variables?",https://stackoverflow.com/questions/48174988,9127536.0,1
72140192,NumPy array value error from training in Auto-Keras with StratifiedKFold,"My sentiment analysis research comes across a variety of datasets. Recently I've encountered one dataset that somehow I just cannot train successfully. I mostly work with open data in .CSV file format, hence Pandas and NumPy are heavily used. During my research, one of the approaches is trying to integrate automated machine learning (AutoML), and the library I chose to use was Auto-Keras, mainly using its TextClassifier() wrapper function to achieve AutoML. I've verified with official documentation, that the TextClassifier() takes data in the format of the NumPy array. However, when I load the data into Pandas DataFrame and used .to_numpy() on the columns that I need to train, the following error kept showing: The sector where I drop the unneeded Pandas DataFrame columns using .drop(), and convert the needed columns to NumPy Array using the to_numpy() function that Pandas has provided. The main error code part, where I perform StratifedKFold() and at the same time, use TextClassifier() to train and test the model. I am sharing the full code related to the error through Google Colab, which you can help me diagnose here. I have tried the potential solution, such as: or However, the problem remains.",https://stackoverflow.com/questions/72140192,16709449.0,1
53122412,AOT compilation of an Estimator,"I find it very challenging to find in the documentation any help on this important issue.. Indeed, after creating an estimator (canned or custom), one wants to tf.compile the resulting predictor, produce the .so and link it to one's project.. So I have my calib class in which I define a simple linear estimator After training, I want to 1- get the trained model with optimal parameters (load it in my variable self.model) 2- extract the graph and freeze it 3- tf.compile that graph I could not find any way to do parts 1- and 2-. Once I have them, part 3 is solved by using tf.compile Can you please point me to a good way to it?",https://stackoverflow.com/questions/53122412,886724.0,1
50953190,"NotFoundError :Tensor name ""prediction/InceptionResnetV2/AuxLogits/Conv2d_1b_1x1/BatchNorm/beta"" not found in checkpoint files","Trying to run the Inceptionv2 Tensorflow model with the architecture and the checkpoint inception_resnet_v2_2016_08_30.ckpt. And my code is for predicting the probability of each classification, for a given image. I try to construt the tensorflow code using class according to the awesome blog here. But we had error: NotFoundError (see above for traceback): Tensor name ""prediction/InceptionResnetV2/AuxLogits/Conv2d_1b_1x1/BatchNorm/beta""not found in checkpoint files inception_resnet_v2_2016_08_30.ckpt. My error code as follows. from inception_resnet_v2 import * import functools import inception_preprocessing import matplotlib.pyplot as plt import os import numpy as np import tensorflow as tf from scipy.misc import imread os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' def doublewrap(function): """""" A decorator decorator, allowing to use the decorator to be used without parentheses if no arguments are provided. All arguments must be optional. """""" @functools.wraps(function) def decorator(*args, **kwargs): if len(args) == 1 and len(kwargs) == 0 and callable(args[0]): return function(args[0]) else: return lambda wrapee: function(wrapee, args, *kwargs) return decorator @doublewrap def define_scope(function, scope=None, args, *kwargs): """""" A decorator for functions that define TensorFlow operations. The wrapped function will only be executed once. Subsequent calls to it will directly return the result so that operations are added to the graph only once. The operations added by the function live within a tf.variable_scope(). If this decorator is used with arguments, they will be forwarded to the variable scope. The scope name defaults to the name of the wrapped function. """""" attribute = '_cache_' + function.__name__ name = scope or function.__name__ @property @functools.wraps(function) def decorator(self): if not hasattr(self, attribute): with tf.variable_scope(name, args, *kwargs): setattr(self, attribute, function(self)) return getattr(self, attribute) return decorator class Inception(object): def __init__(self, image): self.image = image self.process_data # call function process_data self.prediction @define_scope def process_data(self): image_size = inception_resnet_v2.default_image_size image = inception_preprocessing.preprocess_image(self.image, image_size, image_size, is_training=False, ) image1 = tf.expand_dims(image, 0) return image1 @define_scope def prediction(self): '''Creates the Inception Resnet V2 model.''' arg_scope = inception_resnet_v2_arg_scope() with tf.contrib.slim.arg_scope(arg_scope): logits, end_points = inception_resnet_v2(self.process_data, is_training=False) probabilities = tf.nn.softmax(logits) return probabilities def main(): tf.reset_default_graph() image = tf.placeholder(tf.float32, [None, None, 3]) model = Inception(image) saver = tf.train.Saver() with tf.Session() as sess: saver.restore(sess, 'inception_resnet_v2_2016_08_30.ckpt') probabilities = sess.run(model.prediction, feed_dict={image: data}) print(probabilities) if _name_ == '__main__': data = imread('ILSVRC2012_test_00000003 .JPEG', mode='RGB').astype(np.float) main() However, if we don't construct the code using class as above, and we just run sucessfully. The following is the code which ran without errors. from inception_resnet_v2 import * import inception_preprocessing import os import numpy as np import tensorflow as tf from scipy.misc import imread os.environ['TF_CPP_MIN_LOG_LEVEL']='2' slim = tf.contrib.slim tf.reset_default_graph() # prepare data data = imread('ILSVRC2012_test_00000003.JPEG', mode='RGB').astype(np.float) image = tf.placeholder(tf.float32, [None, None, 3]) # pre-processing image image_size = inception_resnet_v2.default_image_size processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False,) processed_image = tf.expand_dims(processed_image, 0) # Creates the Inception Resnet V2 model. arg_scope = inception_resnet_v2_arg_scope() with slim.arg_scope(arg_scope): logits, end_points = inception_resnet_v2(processed_image, is_training=False) probabilities = tf.nn.softmax(logits) saver = tf.train.Saver() with tf.Session() as sess: saver.restore(sess, './inception_resnet_v2_2016_08_30.ckpt') print(sess.run(probabilities, feed_dict={image:data})) Any help would be appreciated!",https://stackoverflow.com/questions/50953190,7309971.0,1
41613767,tf.parse_example used in mnist export example,"I am new to tensorflow and are reading mnist_export.py in tensorflow serving example. There is something here I cannot understand: Above, serialized_tf_example is a Tensor. I have read the api document tf.parse_example but it seems that serialized is serialized Example protos like: So how to understand tf_example = tf.parse_example(serialized_tf_example, feature_configs) here as serialized_tf_example is a Tensor, not Example proto?",https://stackoverflow.com/questions/41613767,5685754.0,1
54539396,Distributing a Keras Model Across Multiple GPUs,I'm trying to create a very large Keras model and distribute it across multiple GPUs. To be clear I'm not trying to put multiple copies of the same model on multiple GPUs; I'm trying to put one large model across multiple GPUs. I've been using the multi_gpu_model function in Keras but based off a lot of the out of memory errors I've gotten while doing this it seems like it's just replicating the model rather than distributing it like I'd like. I looked into Horovod but because I have a lot of windows specific logging tools running I'm hesitant to use it. This seems to leave only tf.estimators for me to use. It's not clear from documentation though how I would use these estimators to do what I'm trying to do. For example which distribution strategy in tf.contrib.distribute would allow me to effectively batch out the model in the way I'm looking to do? Is what I'm seeking to do with estimators possible and if so which strategy should I use?,https://stackoverflow.com/questions/54539396,8401815.0,1
52731624,"""A nested structure of tf.Tensor objects"" for Iterator.get_next() result type","When I write Tensorflow code, I try to keep in mind the type of different things, e.g. tuple of two Tensors, or list of Tensors. This is important because when the types/shapes don't match, Tensorflow emits an error. The text of the title of this question shows up a lot in the documentation especially when describing the result of some function, e.g. for Iterator.get_next(), but I find it too vague. It doesn't tell me exactly what to expect, a list of tuples? a tuple of tuples? What exactly is this 'nested structure'? Right now, the only way I can track this is to print the result after Session.run(). Is there a cleaner and more definitive way? Also, it seems that the value of Iterator.get_next() is always a list of one element; I haven't been able to make it return a non-list, an empty list or a list with multiple elements. When does Iterator.get_next() return something that's not a list of one element? If never, then the wrapping of the content in a list seems superfluous -- why was Iterator.get_next() designed this way? This is example code showing I mean: Output: Why not just the following?",https://stackoverflow.com/questions/52731624,679688.0,1
48153624,How to convert the CIFAR10 tutorial to NCHW,"I'm trying to convert the Tensorflow CIFAR10 tutorial from NHWC to NCHW, but can't figure out how to do so. I have only found answers such as this, which is a couple of lines of code without an explanation of how it works and where to use it. Here are a couple of unsuccessful attempts I have made using this approach: Which get the errors (respectively): Can someone please provide a set of steps I can follow to convert this example to NCHW successfully.",https://stackoverflow.com/questions/48153624,4134062.0,1
52451656,Custom metric across rows in TensorFlow,"I'm trying to calculate metrics for my TensorFlow model across rows with a common key -- specifically precision at k for an information retrieval task -- and I'm finding this extremely nontrivial. My data include a field that indicates the session ID of each row, and there are variable number of rows for each session ID (but small, under 100). My task is to train across the rows as independent observations, so I don't want to group on the session ID and train per-session as it will bias the model. The entire point of the model is to train and evaluate on individual items independently of context, but evaluate the quality of that evaluation within the context, by session IDs. As a side note, part of the challenge I'm concerned about is data locality as I'm performing distributed training. However it seems that there may be a single evaluator? (""Evaluator is a special task that is not part of the training cluster."") Once I realized that tf.metrics.precision_at_k calculates precision at k within class predictions for a given row / data point and not , I have considered writing a custom metric function to call from within the Estimator train_and_evaluate method that keeps an internal dict of session ID to tuples of labels and predictions, and transforms these into Tensors to feed to tf.metrics.precision_at_k. Caveats: I haven't had much luck finding any examples or more information online about anything like this, and the TF code and docs can be somewhat unhelpful, so I'd appreciate any advice! Thanks!",https://stackoverflow.com/questions/52451656,5026110.0,1
39251552,"TensorFlow first attempt, bad results","I can't solve my problem, help me please. It's my first attempt of neural networks, i tried to make nn which can check is number betwen (3:6) or not. I used several docs in internet and make some listing. But it has not working results. It's always ""not in (3:6)"". And I can't to understand what I'm doing wrong.",https://stackoverflow.com/questions/39251552,3178853.0,1
48940091,DNNClassifier model to TensorFlow Serving model,I am a newbie in ML and TF and I am trying to host primitive TensorFlow model on GCP using TensorFlow Serving. For do that I need to convert DNNClassifier model to TensorFlow Serving model. According to Get Started guide I need to use SavedModelBuilder method but I can't figure out how to define input/outputs in the case with Iris Flower example. Could anybody post an example code for this case? Full code:,https://stackoverflow.com/questions/48940091,2876310.0,1
68353106,Why does the numpy dot product function returns an error when passed two TensorFlow Variable objects?,"The above code returns the error: I understand that TensorFlow has a builtin method for matrix multiplication, but I was curious why the np.dot method does not work, specifically with tensorflow Variable objects (it seems to do fine with tensorflow.constant objects). Other methods, such as np.square, np.sqrt, etc. all work with this, but it seems that only np.dot in particular does not. Edit: I was wondering why these objects in particular do not work when passed to the np.dot function. I realize that there are a variety of ways to find the dot product between two tf.Variable objects",https://stackoverflow.com/questions/68353106,15180247.0,1
67194970,Cannot load Tensorflow (Keras) Saved Model because file does not exist (whereas it does exist),"I never had problem loading h5 models, but now I'm trying to load the first two saved models (.pb) from here here but I keep on getting this error: I load it by execution a python file containing (removed imports for the sake of clarity), just like it is suggested in the doc: I just extracted the files into a folder of the same name, I don't understand what's going on.",https://stackoverflow.com/questions/67194970,15651162.0,1
44464055,How the cell state size and cell output size is determined in BasicRNNCell?,"Consider the following code: According to the documentation of dynamic_rnn, the output and state have shapes [batch_size, max_time, cell.output_size] and [batch_size, cell.state_size], respectively. The question: how the cell.state_size and cell.output_size is determined in BasicRNNCell? What is the relationship between num_units = rnn_size in the initilizer of BasicRNNCell and its state_size and output_size?",https://stackoverflow.com/questions/44464055,5617507.0,1
69693757,Loading checkpoints while training a Faster-RCNN model on a custom dataset,"I'm trying to load checkpoints and populate model weights using The Faster-RCNN architecture (Faster R-CNN ResNet50 V1 640x640 to be precise, from here. I'm trying to load the weights for this network similar to how it's done in the example notebook for RetinaNet, where they do the following: I'm trying to get a similar checkpoint loading mechanism going for the Faster-RCNN network I want to use, but the properties like _base_tower_layers_for_heads, _box_prediction_head only exist for the architecture used in the example, and not for anything else. I also couldn't find documentation on which parts of the model to populate using Checkpoint for my particular use case. Would greatly appreciate any help on how to approach this!",https://stackoverflow.com/questions/69693757,6274300.0,1
47951994,Unable to print tf.zeros in tensorflow,This is a part of the code I encountered to minimize loss using Gradient Descent in tensorflow. I understood what is going on and what tf.zeros is doing but when I tried to run the follwing code it showed an error:: An error occured in print(tensor.eval()). Can someone point out where I understood the things wrong?,https://stackoverflow.com/questions/47951994,8259521.0,1
49716186,What's the difference between tf.train.ExponentialMovingAverage and tf.train.MomentumOptimizer?,"I have seen the doc, tf.train.ExponentialMovingAverage implement this formula: I didn't find the formula of tf.train.MomentumOptimizer. But I think it may be: I think this two function have similar effect, so can they exchange each other?Or they have different application scenarios? Or I'm totally wrong? And does the shadow_variable is equivalent to θ? Thanks for any guidance.",https://stackoverflow.com/questions/49716186,9589731.0,1
38902433,TensorFlow strings: what they are and how to work with them,"When I read file with tf.read_file I get something with type tf.string. Documentation says only that it is ""Variable length byte arrays. Each element of a Tensor is a byte array."" (https://www.tensorflow.org/versions/r0.10/resources/dims_types.html). I have no idea how to interpret this. I can do nothing with this type. In usual python you can get elements by index like my_string[:4], but when I run following code I get an error. It says Also I cannot convert my string to tf.float32 tensor. It is .flo file and it has magic header ""PIEH"". This numpy code successfuly convert such header into number (see example here https://stackoverflow.com/a/28016469/4744283) but I can't do that with tensorflow. I tried tf.string_to_number(string, out_type=tf.float32) but it says So, what string is? What it's shape is? How can I at least get part of the string? I suppose that if I can get part of it I can just skip ""PIEH"" part. UPD: I forgot to say that tf.slice(string, [0], [4]) also doesn't work with same error.",https://stackoverflow.com/questions/38902433,4744283.0,1
35384624,Rank Mismatch error in TensorFlow concat,"I have been trying to make a simple 2 layered neural network. I studied the tensorflow api and official tutorials, I made the one layered model, but am having trouble in the neural network. Here is a section of my code that is causing the error: the error is: Here is the full code: http://pastebin.com/sX7RqbAf I have used TensorFlow and Python 2.7. I am quite new to neural nets and machine learning so pardon me for any mistakes, thanks in advance.",https://stackoverflow.com/questions/35384624,5096669.0,1
49592724,How to load a graph checkpoints (.ckpt) and use SavedModelBuilder to save it as protobuf without declaring any tf.Variables?,"Currently I have resnet_v2_50.ckpt from tensorflow's open sourced pretrained model. I am trying to serve this model in Go cause my backend for my web app is going to be in Go. If I were to create my own model and train it, and then save it. I have no trouble with serving it in Go but I am trying to use pre-trained model to save time on my end. Here's a simple example of how I save my model I can load it using tensorflow in Go But now when it comes to pretrained model, I am dealing with ckpt files. One solution I have is to load it up in Python and then save it as protobuf. However, this gives me an error saying that ValueError: No variables to save. I can fix it by declaring a variable But here comes my question, does that mean I must declare EVERY variable in the ResNet50 and have tensorflow load the values from ckpt file into those variables and then I perform save? Is there a shortcut to do this?",https://stackoverflow.com/questions/49592724,7359470.0,1
46080421,"Tensorflow, printing loss function causes error without feed_dictionary","I am just reading Tensorflow documentation. In following code, I just changed last line. I pushed last line in iteration, to see what exactly is going on... Please check the very last line: print(sess.run([W,B,loss], {x:X_train, y:y_train})) Why do I need to include in order to print statement out? If you exclude this from the last line, you will get error. It makes no sense, because loss is already calculated in line before. Thanks",https://stackoverflow.com/questions/46080421,6709460.0,1
47058158,restoring two Tensorflow models,"I have trained two separate Tensorflow models and would like to use them both in one Jupyter notebook. I am following the following SO post. However, I would like to avoid using with statement as it obscures my understanding of what is happening. Here is my code and error messages: Here is error message: How can I fix it? I already re-read multiple times google docs on interaction between graph and session, but I am still unclear what is missing. Inserging as_default() as some places produced different errors (too many to reproduce here)",https://stackoverflow.com/questions/47058158,1700890.0,1
54837529,Tensorflow : IOU per class,"I'm trying to use deeplab for semantic segmentation. I'd like to calculate IOU per class(IOU for person only) instead of mean IOU. At L142 of https://github.com/tensorflow/models/blob/master/research/deeplab/eval.py, I tried to get confusion matrix instead of mean IOU by but it did not work. I'd appreciate if someone suggest me how to get around.",https://stackoverflow.com/questions/54837529,11056858.0,1
56767629,How to convert VGG from darknet to tensorflow?,"I am trying to convert an existing VGG model (trained on 1 class) from Darknet format (including a .cfg file and .weights file) to the TensorFlow format. The end goal is to use the files in TensorFlow format with the Intel OpenVINO Toolkit. As an initial attempt, I have tried using the DW2TF but encountered errors while running the program. I first attempted with the official files provided on pjreddie's website and was met with the following error. I am not specifically looking for a direct solution to the error below, instead I am looking for the best way I can convert VGG in Darknet format to TensorFlow, or any other pathways so that I can use the model with the Intel OpenVINO Toolkit. Any comments or suggestions are welcome. Thanks for reading. Command used: Error received:",https://stackoverflow.com/questions/56767629,6407367.0,1
64092664,"KerasClassifier fails to fit model, despite everything working fine otherwise","I'm trying to use a KerasClassifier wrapper in order to make my workflow scikit-friendly. However, when I try to use it with the following function, it gives an error; training the model using native Keras model fit() works. (this is Tensorflow 2.2.0, running in a conda environment) The following works: However, when I try to use KerasClassifier wrapper, I get an error: Every example I have seen on the internet seems to do the same as I: define a function that returns a compiled keras model, then pass it to the wrapper, and fit it or use in a pipeline. The only difference I notice is that most (if not all) examples use the Sequential API instead of the functional API, but afaik that should not be a problem, right? Tensorflow documentation doesn't seem to give any example of what kind of function we should pass to the wrapper, but since every example uses one similar to mine, I think that's correct. Can anyone shed some light? Thanks. EDIT (after comments): I import the KerasClassifier like this: Error log:",https://stackoverflow.com/questions/64092664,6560267.0,1
70644285,Loading binary data with FixedLengthRecordDataset in TensorFlow,"I'm trying to figure out how to load binary data file using FixedLengthRecordDataset: This code throws: numpy() is available if I try to iterate over the dataset: By reading the Tensor type description, I realized that numpy() is available only during eager execution. Thus, I can deduce that during the map() call the elements are not provided as EagerTensor. How to load this data into a dataset? I'm using TensorFlow 2.4.1",https://stackoverflow.com/questions/70644285,3055724.0,1
57579686,tensorflow create variable during map_fn step,"is there some way to create variables in a map_fn loop like shown in the code beneath? how can I solve this error while keeping a variable in the loop? the info log does not really help me either, so am I getting any concept of tensorflow fundamentally wrong here? [tensorflow 1.14.0, python 3.6.8] leads to this error:",https://stackoverflow.com/questions/57579686,11909156.0,1
64025732,How to use random zoom in keras tensorflow 2.3,"I am trying to add random zoom to my images that are tiff files with 128x160 resolution 1 channel but new version of random zoom for keras tensorflow has gotten me confused, i don't understand how should be the tuple format it expects as the zoom range arguement. From the documentation. I need to add some random zoom to my image, and i am trying like this: The output is: How exactly should i pass as parameter any random zoom amount to my images? Public kaggle notebook here: https://www.kaggle.com/puelon/notebook75c416766a TypeError: in user code:",https://stackoverflow.com/questions/64025732,,1
62490870,How to add random noise to the labels using DNNLinearCombinedClassifier for tf1.15?,"Currently, I am working with the wide and deep classifier in tf1.15 (DNNLinearCombinedClassifier), and defined the following function to add random noise to the labels: This function is then applied to the dataset using map and applied only to the target column. However when I train my model, it generates the following output: As far as I understand, DNNLinearCombinedClassifier is calculating the number of unique values in target and generated the error due to the difference between n_classes and the number of unique values. I reviewed the documentation of DNNLinearCombinedEstimator, but it uses MSE as loss, and I would definetely like to train my model using cross entropy as it is done in DNNLinearCombinedClassifier. I would like to ask you if there is a way to use wide and deep classifier with this perturbed label column and cross entropy as my training loss function.",https://stackoverflow.com/questions/62490870,997333.0,1
64747663,How to apply Attention layer to LSTM model,"I am doing a speech emotion recognition machine training. I wish to apply an attention layer to the model. The instruction page is hard to understand. How can I apply it to fit for my model? And are use_scale, causal and dropout all the arguments? If there is a dropout in attention layer, how do we deal with it since we have dropout in LSTM layer?",https://stackoverflow.com/questions/64747663,14128879.0,1
72346635,translate CSRA from pyTorch to TensorFlow,"I'm trying to implement the CSRA module from this paper in TensorFlow instead of PyTorch, using MobileNetV3 as a feature extractor. I'm only versed in TensorFlow, and I'm running into some trouble translating from PyTorch to TensorFlow. The official source code implementing the module uses some functions that are not commonly used in TensorFlow, and the tf docs for those functions offer little help. The source code is the following: I don't need to define CSRA as a class, I'm trying to stitch the module together as a keras functional model. This is the code I've managed to put together: The major problem I'm having is the step to obtain a score in TensorFlow. The current problem I'm facing seems to be that the object returned by head.get_weights() is an empty list. I understand that because head is 'empty', its weights are zeroes, but how to define score then? Besides this, I have many doubts regarding the translation. Since pyTorch works with ""channels first"" and TensorFlow with ""channels last"", I had to change the dims that are affected in each step, but I don't know if I'm doing it right and if all operations in PyTorch are necessary for TensorFlow.",https://stackoverflow.com/questions/72346635,15451065.0,1
57377829,How to implement tf.nn.sigmoid_cross_entropy_with_logits,"I am currently learning tensorflow, and I have run into an issue with tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=logits). The function description says that both labels and logits must be of the same type. I have the function below that I am using to classify MNIST images. The following are key section of my code I get the error: input 'y' of 'Mul' Op has type int32 that does not match type float32 of argument 'x if I change y=tf.placeholder(tf.float32,shape=(None),name=""y""). I get the error Value passed to parameter 'targets' has DataType float32 not in list of allowed values: int32, int64. Yet logits can only be float32 or float64. Please help me fix the issue. Thanks",https://stackoverflow.com/questions/57377829,10561436.0,1
62270283,Tensorflow - Custom loss function with sample_weight,"I'm trying to run a custom function that accepts sample_weights. I'm following this documentation https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss. However, when I try to use the following cost function: I get this error on the Model.fit method. I'm using a generator that yields a tuple of length 3 just as required. I've checked that. That's working properly. The cost function works fine too. When I use the code below, the model trains without problems. If someone has any clue. I'd appreciate it. Thanks in advance!",https://stackoverflow.com/questions/62270283,6509883.0,1
65449280,Tensorflow giving Unknow Dtype Policy,I Am trying to train a model in Colab and then transferring it to Kaggle. The Model seems to Work fine in Colab as a .h5 model. The problem seems to be with Efficient net B4 and after in Kaggle. There is No Documentation about This. I am training this model on a TPU and doing the inference on a GPU but even if i train the model on GPU this problem is There. My error Log My model Training Code: Inference Code,https://stackoverflow.com/questions/65449280,14750340.0,1
45288297,Meaning and dimensions of tf.contrib.learn.DNNClassifier's extracted weights and biases,"I relatively new to tensorflow, but even with a lot of research I was unable to find a documentation of certain variable meanings. For my current project, I want to train a DNN with the help of tensorflow, and afterwards I want to extract the weight and bias matrices from it to use it in another application OUTSIDE tensorflow. For the first try, I set up a simple network with a [4, 10, 2] structure, which predicts a binary outcome. I used 3 real_valued_columns and a single sparse_column_with_keys (wrapped in an embedding_column) as features: I called this function with default arguments and used estimator.fit(...) to train the DNN. Aside from some warnings concerning the deprecated 'scalar_summary' function, it ran successfully and produced reasonable results. I printed all variables of the model by using the following line: I expected to get a weight matrices of size 10x4 and 2x10 as well as bias matrices of size 10x1 and 2x1. But I got the following: Is there any documentation what these cryptic names mean and why do the matrices have these weird dimensions? Also, why are there references to the Adagrad optimizer despite never specifying it? Any help is highly appreciated!",https://stackoverflow.com/questions/45288297,8334261.0,1
70894266,minimize method not taking argument,"From the tensorflow doc i have read here, I have tried to minimise the adam optimizer. But I receive this error below from the code. Even though I have passed through the 'loss' argument. I think it may be due to using Tensorflow 2?",https://stackoverflow.com/questions/70894266,12164928.0,1
74339733,output_shape of custom keras layer is None (or cannot be determined automatically),"I am building a custom Keras layer that it is essentially the softmax function with a base parameter which is trainable. While the layer works on its own, when placed inside a sequential model, model.summary() determines its output shape as None and model.fit() raises a presumably linked exception: In other custom layers (including obviously the Linear example from keras) the output shape can be determined after .build() is called. By looking at model.summary()'s source code, as well as keras.layers.Layer, there is this @property Layer.output_shape that fails to automatically determine the output shape. Then I tried overwriting the property and manually returning the input_shape argument passed to my layer's .build() method after saving it (softmax does not change the shape of the input), but this didn't work either: If i make a call to super().output_shape before returning my value, model.summary() determines the shape as ?, while if I don't, the value may be shown seemingly correct, but in both cases, I get the exact same error during .fit(). Is there something special about the code iside call() that prevents keras from understanding the shape of the output? Alteratively, is there a piece of documentation I have missed? My layer: The layer works on its own: But when I try to include it inside a model, the summary doesn't look right: And training fails:",https://stackoverflow.com/questions/74339733,6942918.0,1
60424568,Kernel Crashes while Loading data using tf.data.Dataset.take() from a CSV file,"I wanted to Load a CSV file with a Target column and 25 feature columns.I have loaded it via pd.read_csv() as a pandas.Dataframe: Then I used the standard Tensorflow 2.0 procedure to read values from pandas.Dataframe: As the Docs said,I have to load features and targets seperately from the TensorflowSliceDataset. But as soon as i run the for loop, it freezes for couple of seconds and suddenly kernel dies without any specific reason. I have tried to run the code without the for loop but the same thing happens with: I don't know what is causing this problem. I have also re-installed the pandas as well.",https://stackoverflow.com/questions/60424568,10372264.0,1
57438371,tf.global_variable_initializer() with regard to session?,"My understandings on Sessions in Tensorflow still seem to be flawed even after reading the official documentation and this tutorial. In particular, does tf.global_variable_initializer() initialize global variables with regard to a particular session, or for all the sessions in the program? Are there ways to ""uninitialize"" a variable in / during a session? Can a tf.variable be used in multiple sessions? The answer seems to be yes (e.g. the following code), but then are there good cases where we want multiple sessions in a program, instead of a single one?",https://stackoverflow.com/questions/57438371,3736306.0,1
48680776,How to use a restored graph while training the current graph,"I'm currently working on complex models (too complex for my weak brain) and I begin with tensorflow in the same time. So, this is my function to load the previously saved and trained model. Apparently, it seems to work fine and to load the operations that I need. Now, I want to create my main model : The thing is that I want to be able to use fake_Y as an input of the loaded model. fake_Y is generated at each step during the training phase. With the obtained output, I want to compute a new loss and integrate it in the total loss of my main model. I know that fake_Y doesn't exist in the graph loaded_graph. And tensorflow returns me this error : So I think my problem is really basic. I just need to find a way to connect these two graphs. But the tensorflow's workflow is not super clear in my mind. In the easier case of two disconnected graphs, I could just call sess.run on fake_Y. But here, it's not possible since I'm still building my main model, so I can't call a session with a bunch of things not initialized yet. So, is there a way to share fake_Y between my two graphs (one initialized and the other one not) ? Any help would be appreciated ! Thank you EDIT: I've found a solution to load the model directly inside the current graph (then I don't need to create a new graph anymore). I don't know which solution is the best. But anyway, the problem remains the same : How to run the loaded/initialized model (which share the current graph with the main one) on fake_Y : a call to sess.run in the function in which we build the model is pretty weird and not feasible since some objects are not initialized yet.",https://stackoverflow.com/questions/48680776,9331794.0,1
66554207,Calculating micro F-1 score in keras,"I have a dataset with 15 imbalanced classes and trying to do multilabel classification with keras. I am trying to use micro F-1 score as a metric. My model: For F1 score I use the custom metric from this question I use binary cross-entropy and a custom F-1, while compiling a model I monitor F-1 for early stopping How to update this custom function and get micro F-1 as a metric? Also appreciate tips about my approach. There is information in scikit-learn documentation, but not sure how to incorporate it in keras",https://stackoverflow.com/questions/66554207,7484093.0,1
73691788,Tensorflow dataset not saved in multiple shards,"I want to use the tensorflow dataset saving and loading functions but I am not sure to understand the sharding method. The documentation indicates : But when I save a dataset through the save function, it seems that only one huge shard is generated. generated dataset screenshot Am I missing something ? I use Tensorflow 2.10.0 and Python 3.9.7",https://stackoverflow.com/questions/73691788,5130199.0,1
58933545,Using Tensorflow 2.0 and eager execution without Keras,"So this question might stem from a lack of knowledge about tensorflow. But I am trying to build a multilayer perceptron with tensorflow 2.0, but without Keras. The reason being that it is a requirement for my machine learning course that we do not use keras. Why you might ask? I am not sure. I already have implemented our model in tensorflow 2.0 with Keras ease, and now I want to do the exact same thing without keras. Here is my problem. Whenever I look up the documentation on Tensorflow 2.0, then even the guides on custom training are using Keras. As placeholders and sessions are a thing of the past in tensorflow 2.0, as I understand it, then I am a bit unsure of how to structure it. I can make tensor objects. I have the impression that I need to use eager execution and use gradient tape. But I still am unsure of how to put these things together. Now my question is. Where should I look to get a better understanding? Which direction has the greatest descent? Please do tell me if I am doing this stack overflow post wrong. It is my first time here.",https://stackoverflow.com/questions/58933545,12397330.0,1
54228062,Is there a tf.gather() equivalent for TF datasets?,"I'm currently trying to use precomputed word embeddings, loaded from an h5py file. The embeddings are precomputed for each example in the dataset, so I'm trying to retrieve the embeddings by their example/sequence ID. However, the embeddings are quite large, so I've run into the problem where I can't just run tf.gather() directly on the embeddings to get the ones I want after I retrieve them from the file, since TF won't generate a tensor greater than 2GB. As a result, I'm trying to use the following code: However, since precompute_ds is an h5py dataset, I'm not sure how to initialize an iterator for it and get the following error: So, I also tried using the following code, following this example on the TF website: However, there are two problems with this: for one, I'm pretty sure that even if tf.gather did work on TF Datasets, this wouldn't properly populate word_emb. What I'm thinking now is that I could populate ds properly using the second method, but I then don't know how to get exactly the sequence_ids I want for this particular batch. Are there any suggestions for either of these two approaches to get this working? Thanks!",https://stackoverflow.com/questions/54228062,10408530.0,1
46180019,Can't run a command line prediction against a saved Tensorflow model,"I'm having trouble exporting and running a simple example from the command line. The example just trains on random numbers 0-99 and labels the values 0 if less than 50, otherwise the label is 1. I want to be able to save the model then use it later to generate a prediction against a value entered via the command line. Here is the rough guide I am using for model saving and CLI. The environment is the Tensorflow Docker image. Here is the program - it takes around 10 seconds to run in my environment. After running the program I have a model saved in the model directory. To see the model interface, I run the following command: and I get this: Next I run this to get a prediction on the number input: and I get this: I've tried many variations for the input for the model and this one seems to get the furthest in the code before erroring out. Any ideas what I'm doing wrong? Is there a better way to accomplish something similar?",https://stackoverflow.com/questions/46180019,2036097.0,1
37902705,How to manually create a tf.Summary(),"I often want to log python variables --as opposed to tf tensors. In the docs it says that ""you can pass a tf.Summary protocol buffer that you populate with your own data"" but there is no docs for tf.Summary and i could not figure out how to use it. Anyone knows how to create a Scalar summary this way?",https://stackoverflow.com/questions/37902705,6108836.0,1
47254513,"Tensorflow, trouble with looping/feeding/training","so I know the code is a bit messy, I hope everyone can forgive me. I'm trying to define a pretty simple model, my inputs to the model are of shape [1,9], but the batch size that gets fetched from the input pipeline is of size [batch_size, 9], I'm familiar with the slicing mechanism, but I don't really know where any actual loop has to go (I understand I would probably want to slice according to the iteration). something like tf.slice(input_batch, [i,0],[i,10]) would do the trick, but I'm still confused as to where to pass my input batch to, and how whether I have to define my graph in a special way to handle the batch. I don't think that I do, because the tensors that I'm feeding to the graph should somehow end up in the defined placeholder. Any help would be greatly appreciated, also any advice on how to approach this problem for a more robust and workable solution.",https://stackoverflow.com/questions/47254513,8846220.0,1
51004961,Add SERVING meta tag to frozen model in TensorFlow,"How is it possible to prepare a frozen Tensorflow model to serving? Note that the official guide only demonstrates how to use a checkpoint, but I'd like to use the frozen model. Using the frozen inception_v3 model I'd like to add the SERVING meta tag, such that the model can be used with Tensorflow Serving. Inspecting the frozen model inception_v3_2016_08_28_frozen.pb with summarize_graph the model input and output tensors can be found: Which yields the input tensor input:0 and the output tensor InceptionV3/Predictions/Reshape_1:0. In my script I use both of them to create a signature definition and save a so updated version. Unfortunately I cannot get the so created protobuffer file to work. The test tool label_image.py does not yield correct results, although it does work with the original inception_v3_2016_08_28_frozen.pb file. But the tag is set What is wrong with the so changed frozen model? And how would this be done correctly?",https://stackoverflow.com/questions/51004961,434227.0,1
44223796,How to enlarge a matrix in tensorflow without duplicating values?,"What I am trying to do is have a weight matrix for my neural network which grows in size (i.e. a neuron is added to it each iteration). However, I do not want to use tf.Variable again as this will waste memory by copying the values in the previous matrix not expanding the matrix itself. I have seen that people use tf.assign with validate_shape set to False, however, this does not change the shape of the variable correctly which I believed was a bug but the tensorflow GitHub did not seem to agree (I don't understand why from their reply). Below is a simplified example of the problem. x is the matrix that I want to expand so that it can be added to z. If anyone knows a solution to what I am trying to achieve here I would be very grateful =) Note: I realize that if I initialized z to the shape (2, 4) and then expanded it with tf.assign (as I do with x) the above example will work. But due to another constraint, I cannot control the original shape of z.",https://stackoverflow.com/questions/44223796,8076280.0,1
71555548,"ValueError: `logits` and `labels` must have the same shape, received ((100, 28, 28, 10) vs (100, 10))","I am attempting to do an anomaly detection NN with the MNIST fashion dataset as my input. Currently, my model is as such The summary is the following I keep getting this error May I know how this error is produced, like where, and how may I fix it. The code is based on an article i found, but as it was incomplete, along with my inexperience in this type of Neural Network, I do not know how to fix it. Here is how I transformed the data Here is how I am trying to train the model (where the error occurs)",https://stackoverflow.com/questions/71555548,18527813.0,1
40731433,Understanding tf.extract_image_patches for extracting patches from an image,"I found the following method tf.extract_image_patches in tensorflow API, but I am not clear about its functionality. Say the batch_size = 1, and an image is of size 225x225x3, and we want to extract patches of size 32x32. How exactly does this function behave? Specifically, the documentation mentions the dimension of the output tensor to be [batch, out_rows, out_cols, ksize_rows * ksize_cols * depth] , but what out_rows and out_cols are is not mentioned. Ideally, given an input image tensor of size 1x225x225x3 (where 1 is the batch size), I want to be able to get Kx32x32x3 as output, where K is the total number of patches and 32x32x3 is the dimension of each patch. Is there something in tensorflow that already achieves this?",https://stackoverflow.com/questions/40731433,1252766.0,1
41156460,tensorflow doing gradients on sparse variable,"I am trying to train a sparse variable in tensorflow, As far as I know current tensorflow doesn't allow for sparse variable. I found two threads discussing similar issue: using-sparsetensor-as-a-trainable-variable and update-only-part-of-the-word-embedding-matrix-in-tensorflow. I am not quitely understand the answer, and it would be good if there is any example code one way I have tried is: when compute the gradients, according to the second link using tf.IndexedSlices the above code of course don't work, and I am confused here. tf.IndexedSlices make the input to be IndexedSlices instance, how to use it to update the gradients given the indices? Also, many people mentioned using tf.scatter_add/sub/update. The official document doesn't contain any example code on how to use and where to use for gradient update. should I use tf.IndexedSlices or tf.scatter? it would be much helpful if there is any example code. Thank you!",https://stackoverflow.com/questions/41156460,6233298.0,1
53905146,How to make predictions in Keras using Tensorflow's Dataset API,"I was trying to build model in Keras using Tensorflow's Dataset API. I successfully able to train model in keras. But for making a prediction for test data. it need to be in numpy array. https://keras.io/models/model/ x needs to be numpy array. So i done something like this it successfully made predictions, but i was thinking if there is any method where i able to insert tensor to a function for predictions. And not first converting it to numpy array. I found this https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#predict But even whenever I input the tensor , this error comes",https://stackoverflow.com/questions/53905146,9293927.0,1
61767723,get_config missing while loading previously saved model without custom layers,I have a problem with loading the previously saved model. This is my save: After this I can see that auditor_model is saved in model directory. now I would like to load this model with: but I get: I have read about custom_objects in TensorFlow docs but I don't understand how to implement it while I use no custom layers but the predefined ones. Could anyone give me a hint how to make it work? I use TensorFlow 2.2 and Python3,https://stackoverflow.com/questions/61767723,1394504.0,1
51016991,How to customize a RNN cell,"I would like to implement a custom LSTM or GRU cell in TensorFlow (Python 3). For example, I want to scale the cell state signal from the cell at time step T before entering the cell at time step T+1. I've tried searching in TensorFlow documentation without a success. Could you give me a hint? Thank you. EDITHaving checked the answer given by @vijay m, I create my model as follows: In the code above, timescale is a tensor of shape [batch_size, sequence_length, 1] and I want to scale the cell state using this tensor. Even though the code can run, it returns nan for cost function. If I uncomment the line init_state = state, it works, but it won't scale the cell state. My question, for now, is that: Why I get nan values for cost function?",https://stackoverflow.com/questions/51016991,2241766.0,1
59365505,How to calculate class activation map in TensorFlow?,"I understand the definition of class activation map and how to generate it in Numpy. However, I am not sure how to calculate it in TensorFlow, especially when the batch_size dimension is unknown. Current, I have obtained the activation of my last convolution layer ""activation"". And the weight matrix for the last fully connected layer after GAP is ""last_fc_w"". I wanted to calculate class activation map like this: However, I got the following error: *** ValueError: Shape must be rank 2 but is rank 4 for 'MatMul' (op: 'MatMul') with input shapes: [?,10,10,576], [576,2]. The shape of activation tensor is [?,10,10,576], where ? is the batch_size dimension. The shape of fully connect layer weight is [576, 2], where 2 is the number of classes, 576 is the number of channels of the last convolution layer. The expected output will be a tensor of size [?, 10,10,2], which is the class activation map for these 2 classes. Could anyone provide some guidance on how to achieve that?",https://stackoverflow.com/questions/59365505,10881963.0,1
43834529,"Tensorflow - dimensions of data, placeholder","I am a complete beginner in Tensorflow, and I apologize if my question is trivial, but I have looked into both the documentation and Google and I couldn't find the answer. (I also apologize for my english) I'd like to do something like where x_train is an array of size 3190 containing my input data (arrays of dimension 60*4) My question is, should x be : or ? The first one gives the following error : and if I use the second one, how can I reach x[i][j] with 0&lt;=i&lt;60 and 0&lt;=j&lt;4 if I want to compute for example ? Thanking you in advance for your answer.",https://stackoverflow.com/questions/43834529,7976712.0,1
53284674,Tensorflow serving with contrib operations,"How can I serve model with tensorflow-serving, if there are tf.contrib operations. I use Tensorflow Serving via Docker (latest) (version of tf 1.11) and when I serve model there is the next message: I also built with bazel but there was the same error I use tf.contrib.image.transform If I delete this operation during exporting model it can be served by tensorflow serving",https://stackoverflow.com/questions/53284674,9702962.0,1
53000921,Tensorflow Sequence to Sequence CustomHelper,"There are limited amount of documentation on Sequence to Sequence CustomHelper helper = tf.contrib.seq2seq.CustomHelper(initialize_fn = initialize_fn,sample_fn = sample_fn, next_inputs_fn = next_inputs_fn) in Tensorflow. Would anyone explain the inputs of the Custom-helper, in terms of the input data X = tf.placeholder(tf.float32, [batch_size x time_steps x features]) and encoder, encoder_cell = tf.contrib.rnn.BasicLSTMCell(hidden_size) initial_state = encoder_cell.zero_state(batch_size, dtype=tf.float32) and/or possibly rnn_output, rnn_states = tf.nn.dynamic_rnn(encoder_cell, X, dtype=tf.float32) ?",https://stackoverflow.com/questions/53000921,7644642.0,1
41705377,What is the right initializer one should give to the tf.contrib.layers.convolution2d function in TensorFlow?,"I was reading the documentation for making 2d convolutional layers in tensorflow from the contrib section and was wondering what was the right or best way to initialize the weights when using the tf.contrib.layers.convolution2d function. Unfortunately they don't really say explicitly nor provide an example, so it was unclear to me what is the intended way to use this. The function has a weights_initializer parameter which can be set. I have tried setting it to both: neither seem to return an error and the first one seems to train fine (as far as I can tell). However, it would be awesome to check if this is the right way of using this contrib layer (or maybe since it seems to be a contrib function, how does one check the ""official"" source code maybe to see their docs or test cases or maybe address the my question in their gitissues, if appropriate).",https://stackoverflow.com/questions/41705377,1601580.0,1
53820713,Automatically tuning the batch size by catching out of memory errors,"I would like my application to automatically find the maximum batch size possible so I set up a binary search that catches OOM exceptions like this: Using the official TensorFlow 1.12 Docker image, it starts to converge to the actual batch size discarding sizes that are too large to fit on the current hardware. However, it fails on this internal error at the 6th iteration: What is the cause of this error, given the process I described above? Are OOM errors generally not safe to recover from? How can I work around it to achieve my initial goal within the application and not by running scripts? Thanks!",https://stackoverflow.com/questions/53820713,2529808.0,1
46735542,How to interpret histogram plot in tensorflow/tensorboard?,"I compute (n_samples,1) rotation angles and pass them to histogram summary and pass it to writer with the following command Angles are in radians and in docs it is said that all values are used to build histogram. Unfortunately, I see nothing similar to what I would expect How to interpet this plot?",https://stackoverflow.com/questions/46735542,258483.0,1
65633944,CRNN get accuracy from keras.backend.ctc_decode,"I have a CRNN fitted model with CTC loss output. I have the prediction and I use keras.backend.ctc_decode to decode it. As written in documentation (https://code.i-harness.com/en/docs/tensorflow~python/tf/keras/backend/ctc_decode), the function will return a Tuple with the decoded result and a Tensor with the log probability of the prediction. keras.backend.ctc_decode can accept multiple values for its prediction but I need to pass it once at time. This is the code: Output: The prediction is always correct. However what I think it's the probability seems not to be what I expect. They looks like completely random numbers, even grater than 1 or 2! What am I doing wrong?? Thank you in advance! PS: during the training part, the final CTC loss was around 0.1",https://stackoverflow.com/questions/65633944,14967854.0,1
66015216,How can I save a Tensorflow Core model?,"I'm a beginner in Tensorflow and I found this neural network for binary classification which is giving me decent results, I would like to know after I run the session how can I save the model? I already try from the official website but nothing is working.",https://stackoverflow.com/questions/66015216,14473036.0,1
65264697,How to set signature in keras.models.save_ model,"tf:2.3 system:ubuntu 18 I updated from tf14 to tf2.3. The model I used is a model of keras type. After viewing the official document, adding signature failed This function has the input of signature, but I don't know how to organize it So, what's the right way to keep it",https://stackoverflow.com/questions/65264697,14812957.0,1
45734487,tensorflow: Error multiplying a sparse matrix with a dense matrix using tf.matmul,"In the following code, I want dense matrix B to left multiply a sparse matrix A, but I got errors. The error message is as follows: What's wrong with my code? I'm doing this following the documentation and it says we should use a_is_sparse to denote whether the first matrix is sparse, and similarly with b_is_sparse. Why is my code wrong? As is suggested by vijay, I should use C = tf.matmul(B,tf.sparse_tensor_to_dense(A),a_is_sparse=False,b_is_sparse=True) I tried this but I met with another error saying: Thank you all for helping me!",https://stackoverflow.com/questions/45734487,5005808.0,1
46353964,Tesorflow Deep Learning from CSV...trouble with gradients,"I'm new to Tensorflow. After looking at the tf documentation, multiple tutorials, and StackOverflow questions, I can't seem to find an answer, yet. I'm reading in features and label from a CSV. Here is the error I receive: So, here is my question, am I better off defining my own cost/optimizer algorithm or am I simply missing a simple way to add gradients to the existing values? If i'm missing the way to add gradients, can you point me in the right direction?",https://stackoverflow.com/questions/46353964,4143242.0,1
43132224,GPU does not work on the distributed tensorflow cluster,"I am testing distributed tensorflow using the official code, I have two servers with one K80 GPU and one M40 GPU on them, but running the code on the clusters, only the worker that is specified ""is_chief=True"" can use the GPU to compute, and the other one is just using CPU, even I have specified the GPU device on it. Part of my code is like below: And the server of ipaddress0 with task_index 0 can use the K80 GPU to compute, the other is using CPU. Does anyone know how to resolve this problem? Please offer some help, THANKS",https://stackoverflow.com/questions/43132224,7795558.0,1
37126108,How to read data into TensorFlow batches from example queue?,"How do I get TensorFlow example queues into proper batches for training? I've got some images and labels: (feel free to suggest another label format; I think I may need another dense to sparse step...) I've read through quite a few tutorials but don't quite have it all together yet. Here's what I have, with comments indicating the steps required from TensorFlow's Reading Data page. And after the example queue I need to get this queue into batches for training; that's where I'm stuck... 1. List of filenames files = tf.train.match_filenames_once('*.JPG') 4. Filename queue filename_queue = tf.train.string_input_producer(files, num_epochs=None, shuffle=True, seed=None, shared_name=None, name=None) 5. A reader reader = tf.TextLineReader() key, value = reader.read(filename_queue) 6. A decoder record_defaults = [[""""], [1]] col1, col2 = tf.decode_csv(value, record_defaults=record_defaults) (I don't think I need this step below because I already have my label in a tensor but I include it anyways) features = tf.pack([col2]) The documentation page has an example to run one image, not get the images and labels into batches: for i in range(1200): # Retrieve a single instance: example, label = sess.run([features, col5]) And then below it has a batching section: My question is: how do I use the above example code with the code I have above? I need batches to work with, and most of the tutorials come with mnist batches already.",https://stackoverflow.com/questions/37126108,464273.0,1
63574871,How to get the Keras history object when you abort training?,"When I train with tensorflow 2.0 / Keras APIs, I usually do something like this But sometimes things in life don't work out how I planned and I need to abort with ctrl-c or pressing stop in Jupyter notebook. How can I still get the history object when I abort training early? I can't find any detailed documentation for how to get history.",https://stackoverflow.com/questions/63574871,8202708.0,1
51066299,Multi gpu is not working in keras. Getting error,"I was trying to enable support for multiple gpu training in my model. The code is as follows: Now when I try to run it, I get an error as follows: I think that I have read the documentation correctly. My keras package is up to date. I have opened an issue on Github as well. What is it that I am doing wrong? Note: I am using Jupyter Notebook and have 4 gpus available to me each having 12 GB of Ram. I have limited the Jupyter Notebook to use only 2 GPUs (GPU number 2 and 3) by using the command",https://stackoverflow.com/questions/51066299,5847849.0,1
49543158,How to use weights in tf.metrics.auc?,"The docs for the tf.metrics.auc function in tensorflow say and Suppose I want to use the weights to measure two AUCs: one for men, one for women. Can you give an example of how to do that? EDIT: And suppose I have enough classes that I don't want to divide the data into all the different classes, and enough data that I don't want to read it all into memory. That is, I want to do it in a streaming fashion.",https://stackoverflow.com/questions/49543158,34935.0,1
59968630,Tensorflow one custom metric for multioutput models,"I can't find the info in the documentation so I am asking here. I have a multioutput model with 3 different outputs: The predicted labels for validation are constructed from these 3 outputs to form only one, it's a post-processing step. The dataset used for training is a dataset of those 3 intermediary outputs, for validation I evaluate on a dataset of labels instead of the 3 kind of intermediary data. I would like to evaluate my model using a custom metric that handle the post processing and comparaison with the ground truth. My question is, in the code of the custom metric, will y_pred be a list of the 3 outputs of the model?",https://stackoverflow.com/questions/59968630,7483509.0,1
47774994,The difference between `sess.graph` and `tf.get_default_graph()`?,sess.graph and tf.get_default_graph() gives the same results in tensorboard. It is not very clear to me what is the difference between them according to the manual. Could anybody help explain the difference? Could anyboby provide an example for which sess.graph and tf.get_default_graph() can not be used interchangeably?,https://stackoverflow.com/questions/47774994,1424739.0,1
58273615,"ValueError: Argument must be a dense tensor...got shape [80, 3, 8, 8], but wanted [80] with estimator.predict","I'm trying to generate some images using TPUEstimator.predict method. Here is my code It gives me error in the title and then several more exceptions like this: and got shape [80, 3, 8, 8], but wanted [80] in the end. As I understood there's something wrong with convert_to_rgb function but I can't understand exactly what. Here is the function itself. Calling it inside model_fn works fine but after model.predict it gives an error. What am I missing?",https://stackoverflow.com/questions/58273615,12174084.0,1
44482637,How to use Tensorflow queues in real example,"I have a Tensorflow DNN model in with I use feed_dict to feed the Input Training and Test data and the labels that belongs to them. To keep things simple this the important part of the code: I've been reading about the TF queue are a way more efficient, I've have huge difficulties get them running, here is what I've done so far: My question is how can I ""feed"" data in train and testing. I've been reading TF docs but it didn't help. Ref: The code I wrote is based on this great tutorials",https://stackoverflow.com/questions/44482637,1563123.0,1
49607071,use of updated weights in tensorflow,"I have tried a sample example in tensorflow. My question is when I run y_pred with the same initial features x, does it use weights updated in the preceding for loop or it just uses the initialized weights. My confusion arises from the documentation when it says that, to calculate the output of an operation it backtracks. So, to calculate y_pred, it backtracks and initialize the weights and calculate y_pred using x? or does it use already updated weights of the Dense layer? The output of the above code is:",https://stackoverflow.com/questions/49607071,4985049.0,1
49050674,sampled_softmax_loss complains about a misshapen tensor (but it doesn't seem to be),"I'm trying to build a model that uses sampled_softmax_loss and I can't seem to get the input tensors shaped properly for the function. Here is an example that as best I can tell should match the documentation, but throws this exception: Code: If anyone could give me some pointers, I'll owe you virtual beer eternally.",https://stackoverflow.com/questions/49050674,9429078.0,1
63578833,tf.keras.backend.function for transforming embeddings inside tf.data.dataset,"I am trying to use the output of a neural network to transform data inside tf.data.dataset. Specifically, I am using a Delta-Encoder to manipulate embeddings inside the tf.data pipeline. In so doing, however, I get the following error: I have searched the dataset pipeline page and stack overflow, but I could not find something that addresses my question. In the code below I am using an Autoencoder, as it yields an identical error with more concise code. The offending part seems to be [[x,]] = tf.py_function(Auto_Func, [x], [tf.float32]) inside tf_auto_transform. The above code yields the following error: I tried to eliminate the error by running the commented out section of the tf_auto_transform function, but the error persisted. SideNote: While it is true that the Delta encoder paper has code, it is written in tf 1.x. I am trying to use tf 2.x with the tf functional API instead. Thank you for your help!",https://stackoverflow.com/questions/63578833,11064604.0,1
42509462,"tensorflow in R got ""invalid version specification""","I'm a newbie R-lang and want to execute tensorflow in mac(OS Sierra 10.12.2) and RStudio(v1.0.136) According to the manual, I wrote below code. code: but I got this error: To confirm env, Sys.getenv() got below code. but python in console if I execute: got Does anyone have solutions to remove error in R?",https://stackoverflow.com/questions/42509462,2640926.0,1
46646736,Applying custom learning rates to variables in Tensorflow,"In Tensorflow, after I obtain my loss term, I give it to an optimizer and it adds the necessary differentiation and update terms to the computation graph: I want a small modification to this process. I want to scale the learning_rate differently for my every distinct parameter in the network. For example, let A and B two different trainable parameters in the network and let dL/dA and dL/dB the partial derivatives of the parameters with respect to the loss. The momentum optimizer updates the variables as: I want to modify this as: Where ca and cb are special learning rate scales for different parameters. As far as I understand, Tensorflow has compute_gradients and apply_gradients methods we can call for such cases, but the documentation is not very clear about how to use them. Any help would be much appreciated.",https://stackoverflow.com/questions/46646736,1538049.0,1
60607402,Style Transfer : Save&Restore checkpoint/model in tensorflow 1.15.0,"i am a bit frustrated about saving and restoring models in tensorflow 1.15.0. I want to achieve it in a jupyter notebook / google colab notebook environment. The application is style-transfer of images. I simply want to save the model and restore it in order to apply the style transfer for a larger number of images. The tensorflow documentation is a bit confusing, (i did not find examples for this), so i never really know what the right syntax looks like. I am at a point now where i want to achieve 1 thing: I will write the relevant lines now: When i want to restore the model, i use the command: How can i fix this issue, and load my checkpoint files correctly? Thank you The google colab project is here: https://colab.research.google.com/drive/12hTitoQ2-tH8pYEsfMDR5jtsg8a96PgC",https://stackoverflow.com/questions/60607402,8092502.0,1
52082728,Tensorflow custom gradient with different dimension of input and output,"I try to define new op and gradient for Tensorflow. I found the following link: https://gist.github.com/harpone/3453185b41d8d985356cbe5e57d67342 It works fine, as long the input dimension equals to the output dimension. I want to send 2 parameters of size (1,) and get op of size N=(65536,) for each and gradient of the same size N=(65536,) for each. my input is: x (1,) ,y (1,) output: or input par (2,) output grad N=(65536,2) in the training, I will use reduce_sum, so I will get 2 numbers (as the parameters) and the gradient descent should works correctly. But it doesn't work and I get the following message: My code: important note: I don't want to do the reduce_sum in the gradient because that I will use the Automatic differentation, so I want to get for the following cost function: sum((ref-OP(x,y))^2) the gradient -2 * sum((ref-OP(x,y)) * dOp/dx)) , -2 * sum((ref-OP(x,y)) * dOp/dy)) so dOp/dx should be the same as Op , i.e N=(65536,)",https://stackoverflow.com/questions/52082728,9234723.0,1
53194918,Tensorflow tf.layers Dense Neural Net function vs. Class Interface,"I am trying to implement a helper class to create a standard Feedforward Neural network in python. Since I want the class to be general, there is a method called addHiddenLayer() which should append layers to the Flow Graph. To add layers to the flow graph I went through the tf.layers module which provides two options tf.layers.dense : A function which returns an object which can act as the input to the next layer. There is also tf.layers.Dense : A class which has almost identical attributes as the parameters of tf.layers.dense(), and implements essentially the same operation on the inputs. After going through the documentation for both, I fail to see any extra functionality added by using the class version. I think the function implementation should suffice for my use case the skeleton for which is given below. Can someone give an example of a situation where the class version would be required? References: Related question on SO Example of function usage",https://stackoverflow.com/questions/53194918,3642162.0,1
67603990,"How to make a neural network of nodes with equal weights in Keras, preferably functional API","I want to make a model like the below picture. (simplified) So, practically, I want the weights with the same names to always have the same values during training. What I did was the code below: But when I try to run this code I get this error: (please don't pay attention to numbers as they are from my real code) this is because it gets the whole data including the labels as an input, but shouldn't Keras only feed the features itself? Anyway, if I write the marked line as below: it doesn't give me the above error anymore. But, then I get another error which I know why happens but I don't know how to resolve it. This is because keras is feeding again the whole batch array, whereas in Keras documentation it is written you shouldn't specify the batch dimension for the program as it understands itself, so I expected Keras to feed the data one by one for my code to work. So I appreciate any ideas on how to resolve this or on how to write a code for what I want. Thanks.",https://stackoverflow.com/questions/67603990,12663901.0,1
50220191,How to import(restore) Neural network model built by tflearn from files,"I am referring to this tutorial on text classification and built a custom training set for a text classification. I am saving the model with below code. This generates below files. I want to use the model built in different iteration for testing purpose. I tried , but I get; I know from documentation that tflearn.DNN(network).load('file_name') loads a model , but we need to create and pass the network instance, to build a network we again go through same code from scratch which takes time since it will do training which I want to avoid. Code for building network tflearn.input_data has shape input as mandatory , so we would again need training data to be fed again.So it causes rebuilding model. I checked the documentation , could not find what I need (2-3 lines of code which would import build neural network model to save retraining time. Please let me know if you guys know solution for this. Similar question but its not duplicate",https://stackoverflow.com/questions/50220191,7907591.0,1
65006011,Size of output of a Conv1D layer in Keras,"I am trying to understand the output of a 1D convolution layer applied on a number of batches (3 in this case) of 2D input shapes (6x6). The output of the code below is (4, 10, 32). This answer is quite straight-forward for the first 2 indices. By the documentation this should be the output shape",https://stackoverflow.com/questions/65006011,7450491.0,1
44742878,Reading CSV files in Tensorflow 1.2.0,"I am trying to read heart.csv file data in batches. Following the documentation from tensorflow website, I have the following code working to read row by row Output: But when i try to read in batches as showed in the tensorflow documentation, i get Batch processing code Reading CSV files using tensorflow seems bit cumbersome but I am sure it has its importance in the library being a distributed system. I found it confusing and took more than 60 mins to read and get a grasp on how the reading feed pipeline worked for csv files. May be documentation should be better and more visuals are needed.",https://stackoverflow.com/questions/44742878,471384.0,1
65663116,Target array shape in Keras,"I am trying to build a model which classify network attacks (DDoS or BENIGN attack). For this, I am using ""ISCX 2017"" dataset from https://www.unb.ca/cic/datasets/ids-2017.html. Everything goes fine until I fit the model. I am getting this error ValueError: A target array with shape (180568, 80) was passed for an output of shape (None, 8, 80) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output. I can not find any information online on how to resolve it. I am brand new to Keras and I will appreciate any guidance or advice. Here is my code snippet model.fit(X_train, y_train, epochs=10, verbose=1)",https://stackoverflow.com/questions/65663116,6113143.0,1
45074049,Tensorflow: How does tf.get_variable work?,"I have read about tf.get_variable from this question and also a bit from the documentation available at the tensorflow website. However, I am still not clear and was unable to find an answer online. How does tf.get_variable work? For example: Does it mean that var2 is another variable with initialization similar to var1? Or is var2 an alias for var1 (I tried and it doesn't seem to)? How are var1 and var2 related? How is a variable constructed when the variable we are getting doesn't really exist?",https://stackoverflow.com/questions/45074049,6687875.0,1
70405190,Why do I get this error when trying to fit a tensorflow model: list index out of range,"I've been trying to create a face classification program using the data pipeline on tensorflow. The images I am using are all colored and there are only two classes ""me"" and ""not_me""; I am trying to make a personal face classifier for my face! Here is the code I have used: I start off by loading the dataset and splitting it into train and validation. These first two functions are used to get the labels and decode the images from my validation and training sets. Then I make a training tuple with two lists, one for the labels and one for the image itself. I feel as if this is where I go wrong as the documentation asks for the data to be a tuble of (x, y) and not ([x], [y]) for fitting but I am not so sure. Then I do this for the validation set! Now it's all model work. I am using ResNet50 and doing a bit of transfer learning. I get this error when trying to compile:",https://stackoverflow.com/questions/70405190,12305872.0,1
51783265,in add_summary for value in summary.value: AttributeError: 'Tensor' object has no attribute 'value',"This is a very basic tensorboard scalar log: However, I get an error in add_summary for value in summary.value: Any solution for this? TensorFlow documentation says ValueError is raised when the summary tensor has a wrong shape or type. When I print x_summ it shows: I don't understand why is the shape NULL here.",https://stackoverflow.com/questions/51783265,8713329.0,1
49020732,What is the difference between the trainable_weights and trainable_variables in the tensorflow basic lstm_cell?,"While trying to copy the weights of a LSTM Cell in Tensorflow using the Basic LSTM Cell as documented here, i stumbled upon both the trainable_weights and trainable_variables property. Source code has not really been informative for a noob like me sadly. A little bit of experimenting did yield the following information though: Both have the exact same layout, being a list of length two, where the first entry is a tf.Variable of shape: (2*num_units, 4*num_units), the second entry of the list is of shape (4*num_units,), where num_units is the num_units from initializing the BasicLSTMCell. The intuitive guess for me is now, that the first list item is a concatenation of the weights of the four internal layers of the lstm, the second item being a concatenation of the respective biases, fitting the expected sizes of these obviously. Now the question is, whether there is actually any difference between these? I assume they might just be a result of inheriting these from the rnn_cell class?",https://stackoverflow.com/questions/49020732,6917400.0,1
38678820,How do I create a single script file for when I do and don't want to collect TensorBoard statistics?,"I want to have a single script, that either collects tensorboard data or not, depending on how I run it. I am aware that I can pass flags to tell my script how I want it to be run. I could even hard code it in the script and just manually change the script. Either solution has a bigger problem. I find myself having to write an if statement everywhere on my script when I want the summary writer operations to be ran or not. For example I find that I would have to do something like: and then depending on the value of tb_sys_arg run the summaries or not, as in: this seems really silly to me. I'd rather not have to do that. Is this the right way to do this? I just don't want to collect statistics each time I run my main script but I also don't want to have two separate scripts either. As an anecdotical story, few months ago I started using TensorBoard and it seems I have been running my main file as follow: so that it collects tensorboard data. But realized that I don't think I need that last flag to collect tensorboard data. Its been so long that now I forget if I actually need that. I've been reading the documentation and tutorials but it seems I don't need that last flag (its only needed to run the web app as in tensorboard --logdir=path/to/log-directory, right?) Have I been doing this wrong all this time?",https://stackoverflow.com/questions/38678820,1601580.0,1
58352491,How to use Cudnn LSTM instead of a normal LSTM,"I have been working on a named entity recognition task. I have the following piece of code in between Now I want to use a Cudnn LSTM instead of the normal LSTM. In the documentation of Cudnn LSTM, there is an additional argument ""num_layers"". I did not understand what this is and how I have to proceed further",https://stackoverflow.com/questions/58352491,10791002.0,1
57023418,Problem converting keras model to estimator model using tf.keras.estimator.model_to_estimator,"I'm trying to convert my custom keras model to an estimator model and it is giving me a ValueError: ('Expected model argument to be a Model instance, got ', &lt;keras.engine.training.Model object at 0x0000024FB198EEF0&gt;). I've read in other posts that I'm supposed to use the functional API but I think that is what the code I'm using is doing. The model code is pretty long but is available here: https://github.com/dlpbc/keras-kinetics-i3d/blob/master/i3d_inception.py Here it is: My code to initialize the model and convert to an estimator model: But it gives me this error: I'm not sure what the next step is; I could try to refactor the code by subclassing it (to the Model class) but that would take a while to do and I'm not even sure that would solve anything. Any help is appreciated, thanks! Edit: I found this link to this github issue with the same problem as me. I tried ""casting"" the keras model to a tensorflow model but that did not work.",https://stackoverflow.com/questions/57023418,5078799.0,1
63771148,Can't access keras model's weight with tensorflow's build error,"The log was like follow: I installed TensorFlow with pip install TensorFlow I will explain the problem with the example from the official site Code: Then the above error showed, my question is: How to complier TensorFlow with another flag? And with what kind of flag can I solve this problem?",https://stackoverflow.com/questions/63771148,14232877.0,1
74278898,How to mask inputs with variable size in transformer model when the batches needs to be masked differently?,"I'm making a transformer using tensorflow.keras and having issues understanding how the attention_mask works for a MultiHeadAttention layer. My input is 3-dimensional data. For example, let's assume my whole dataset has 10 elements, each one with length no more than 4: So, my mask looks like: So the shape of the mask til now is [10, 4, 3]. Let's say I use batch_size = 5. Now, according documentation, attention_mask shape should be [B, T, S] (batch_size, query_size, key_size). In the example case should be [5, 4, 4]? If the mask is calculated only once, what 5 items should I give as a mask? This sounds counterintuitive to me. How should I build the mask? According this answer, head_size should be also taken in account, so they also do: The only time I manage to run the transformer successfully using the attention_mask is when I do: Obviously that mask makes no sense, because it is all ones, but it was just to test if it had the correct shape. I'm using practically the same code from the keras example transformer for time series classification",https://stackoverflow.com/questions/74278898,11915595.0,1
49159715,Add custom pre-process within the Tensorflow graph,"I have a meta and checkpoint files from which I load the weights of a pre-trained model. This works fine. To test this model with a new image I need to do some pre-processing for the image (converting from grayscale to RGB, etc) which is basically done using opencv library. Doing this I do get my desired output. But now what I want to do is add this pre-processing code to tensorflow itself so that when I save this model and re-use it I can only pass the image path as an argument and I don't need to do any pre-processing before passing it to tensorflow. I want tensorflow to handle all this. I have tried the following already The following I have used to implement the preprocessing the images within the tensorflow itself and save the new meta and checkpoint files The below code I use to restore my previous model This all works fine Next, I use the newly created meta and checkpoint files to test for an image(path) Using I get the following error input_1 corresponds to the above input of the graph So I am assuming I am not passing the path to the correct place I am new to tensorflow and there is pretty less documentation regarding this Thank you",https://stackoverflow.com/questions/49159715,2805758.0,1
75135220,"How to define positional arguments: 'op', 'value_index', and 'dtype' in a tensor?","when I run the below piece of code I receive: TypeError: init() missing 3 required positional arguments: 'op', 'value_index', and 'dtype' . I understand why this is happening as I didn't define values for 'op', 'value_index', and 'dtype' amd that tensorflow cant produce tensors. Basically I want to use flat_map function to create tensors with shape = (1,) and dtype = tf.float64 such that when I run the below code the printed tensors look like: How can I specify those values inside flat_map function or any other function which I can pass into flat_map function? I checked here https://www.tensorflow.org/api_docs/python/tf/Tensor but unfortunately I couldn't come up with a solution. Thanks!",https://stackoverflow.com/questions/75135220,13841479.0,1
53501315,How to understand tensorflow error message?,"I found that the error message from TensorFlow, especially at run time (i.e. in sess.run()). There'is few document explaining how to understand the error message. For example, there is a error message: I have two questions:",https://stackoverflow.com/questions/53501315,5634636.0,1
43394152,Tensorflow: What exact formula is applied in `tf.nn.sparse_softmax_cross_entropy_with_logits`?,"I tried to manually recompute the outputs of this function so I created a minimal example: Now according to my own calculation I only get [1.23] When manually calculating, I'm simply applying softmax and cross-entropy: where q(x) = sigma(x_j) or (1-sigma(x_j)) depending whether j is the correct ground truth class or not and p(x) = labels which are then one-hot-encoded I'm not sure where the difference might originate from. I cannot really imagine that some epsilon causes such a big difference. Does someone know where I can lookup, which exact formula is used by tensorflow? Is the source code of that exact part available? I could only find nn_ops.py, but it only uses another function called gen_nn_ops._sparse_softmax_cross_entropy_with_logits which I couldn't find on github...",https://stackoverflow.com/questions/43394152,2191652.0,1
62234764,Unable to limit Memory,"I'm trying to train a model using Tensorflow 2. I'm getting resource out of memory error. After going through various docs, I used the following code to fix it, Unfortunately, it still does not work. any other workaround?",https://stackoverflow.com/questions/62234764,13037510.0,1
56672695,How to specify variables in tensorflow simple save,"I am trying unsuccessfully to save my tensorflow model using the simple save method. I have built a model using keras and trained it successfully, with an accuracy of 88%. I am now trying to save this model so we can serve it, but the function I need, simple save, isn't clear about how to specify the variables that get passed in. The the session and the export directory is clear enough, but the inputs and outputs are mysterious. I believe that because I've used Keras, these variables are hidden by the abstraction of keras and the documentation from Tensorflow on simple save offers no explanation. As a hailmary, I set Z equal to y just to put something in there, but obviously that is wrong. Do I need to set up an output variable Z, and if so, what type is it? Not sure if this is enough code to get to the bottom of this. Even getting pointed at the right docs would be a big boost. X is my dataset -- an array of all independent variables. Y is the outcome (dependent variable). I don't have another candidate for z, so I set it to an empty array. I get AttributeError: 'numpy.ndarray' object has no attribute 'get_shape'",https://stackoverflow.com/questions/56672695,914863.0,1
48092772,Add operation to graph without with-as-clause,"Since you are able to do a but also I was wondering whether it is possible to do a similar thing with Graph creation, like: The conventional way to add a node/operation to a graph is of course... I couldn't read anything about this in the docs.. and dir(a_graph) does not show me a simple .add() method. The only thing I could think of are add some operation to a collection... but I am not sure how to do that.",https://stackoverflow.com/questions/48092772,6329284.0,1
64941830,Tensorflow strategy error: Mixing different tf.distribute.Strategy objects with overrides train_step keras model,"I am having difficulties to implement a distributed strategy on my TensorFlow v2 model and I am looking for some help. The main difference with the documentation is that my model overrides keras train_step function. I got the distribute strategy to work with simple model or with custom training loop but I would like to avoid the latest as I prefer using model.fit which let me use keras callbacks out of the box. There is a link to a collab model with custom train_step similar to my model https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/dcgan_overriding_train_step.ipynb To reproduce the error, I modified the init of the model to get the network initialization and compile steps inside the strategy scope Then run the code with: The full error message :",https://stackoverflow.com/questions/64941830,1946989.0,1
61561253,AttributeError: module 'tensorflow' has no attribute 'RunOptions',"I'm a beginner. I'm working with python - TensorFlow '2.2.0' on python IDLE. I got the following error while running the previous code.: however, according to example 18 from this link on the official page on Tensorflow, there's no error! what's wrong in my case? How should I resolve this issue?",https://stackoverflow.com/questions/61561253,13454942.0,1
37001686,Using SparseTensor as a trainable variable?,"I'm trying to use SparseTensor to represent weight variables in a fully-connected layer. However, it seems that TensorFlow 0.8 doesn't allow to use SparseTensor as tf.Variable. Is there any way to go around this? I've tried By the way, my ultimate goal of using SparseTensor is to permanently mask some of connections in dense form. Thus, these pruned connections are ignored while calculating and applying gradients. In my current implementation of MLP, SparseTensor and its sparse form of matmul ops successfully reports inference outputs. However, the weights declared using SparseTensor aren't trained as training steps go.",https://stackoverflow.com/questions/37001686,3134471.0,1
38381887,How to read json files in Tensorflow?,"I'm trying to write a function, that reads json files in tensorflow. The json files have the following structure: I only need the bounding box information. There are a few examples on how to write read_and_decode-functions, and I'm trying to transform these examples into a function for json files, but there are still a lot of questions...: I've done research on the internet for hours, but can't find anything really detailled on how to read json in tensorflow... Maybe someone can give me a clue...",https://stackoverflow.com/questions/38381887,6539009.0,1
66149002,How to convert .pb file to .tflite. in tensorflow 2.1.0,"I have trained my model using SSD MobileNet V2 FPNLite 640x640 and tensorflow 2.1.0. To create .pb file used file export_tflite_graph_tf2.py. Now , want to convert .pb file to .tflite. I used following code code recommended by tensorflow community .But it is converting the model to 1kb tflite file. I tried also using tf-nightly but same converts into 1kb",https://stackoverflow.com/questions/66149002,11311304.0,1
55271842,Tensorflow Serving Transform data from input function,"Currently I am working on a tensorflow model. This model classifies a situation based on 2 string and a number. So my placeholders look as follows: I want to serve this model with Tensorflow Serving with this code: But the model I wrote want the strings as one_hot coded input. Does someone knows how to transform the input tensors to one_hot coded ones, and feed those to my model? While training my model, I just transformed them with a function before feeding them. This seems not possible while serving because I can only define a input function, not the flow of the inputdata.",https://stackoverflow.com/questions/55271842,9016494.0,1
47515377,TF namescope vs. variable_scope and how they impact variable sharing,"I would like to understand how/why name_scope and variable_scope are both used in the code below. I have looked at the Tensorflow documentation for these methods and I have also looked at this very helpful SO post: Difference between variable_scope and name_scope in TensorFlow but that has not cleared up my confusion. I am trying to reuse some code from this paper, and in particular I'm looking at how they coded up an autoencoder. input_param is a tensor passed in to a function, and the code is inside the function. This code works fine BUT I would like to understand why modifications I made caused errors: (1) if I delete the name_scope portion of the code then my model doesn't really train and keeps printing out zeros. (2) If I also delete the variable_scope portion of the code, then my code won't even run as tensorflow throws some name conflict error. Here are my questions: (1) What is going on with error (1) described above? How this name_scope help with the ""sharing"" of the frednet variable? (2) Is there a reason they used first sc and then scb for the variable scope (first one matches the name scope but second doesn't). My understanding of Python is that these names are scoped only within the with clause so why don't all 3 just use the same? (3) For error (2), is it correct that this is happening because MultiRNNCell has default names that it uses, and these are in conflict if I call that function multiple times? Is it always necessary to use variable_scope in the event of multiple uses of MultiRNNCell? Thanks.",https://stackoverflow.com/questions/47515377,8762321.0,1
72128138,How tensorflow.nn.ctc_loss works in tensorflow 2 and how to use it for handwritting recognition?,I try to create a simple model for handwritting recognition with tensorflow 2.8 based on this keras example but I have trouble understanding how the CTC loss tensorflow.nn.ctc_loss works and how to use it in my code. I use images representing words from the IAM dataset : I tried to reuse the CTCLayer from the keras example : But when I try to construct a model with it I get an error : The error : I also tried to use the tf.nn.ctc_loss function with simple tensors but I do not get how it works. How could I use the CTC loss for my model in this use case ? EDIT : If I remove the CTCLayer this is what I obtain with model.summary() :,https://stackoverflow.com/questions/72128138,7685195.0,1
66320198,Keras fit with generator function always execute in the main thread,"How can I make Keras Models fit method execute a generator in the main thread? From the docs, it looks like that setting workers=0 would execute the code in the main thread. However when I do: I get Which I interpret as only the first step in the iterator has been executed in the main thread. In my use case this is problematic because I need that the code inside the generator to always be executed in the main thread otherwise the program crashes.",https://stackoverflow.com/questions/66320198,3297472.0,1
71543827,understanding tensorflow Recommending movies: retrieval / usage of : in python class /usage of : in python function,I was reading and trying to work with below documentation from tensorflow https://www.tensorflow.org/recommenders/examples/basic_retrieval?hl=sl In this we have implementation of MovielenseModel class. Let me provide snippet of same code below In this one usages are not clear and could not find much help in any online documentations,https://stackoverflow.com/questions/71543827,12271381.0,1
56413873,How BatchToSpaceND actually works?,"I'm trying to figure out how BatchToSpaceND permutes the input matrix. One of the examples is the following: Anyone know how the output tensor is derived? How come the first row is [[1], [2], [3], [4]] and not [[1], [3], [9], [11]] instead? I've also tried some code: which isn't quite the result in the doc.",https://stackoverflow.com/questions/56413873,233798.0,1
58525373,TensorFlow 2.0 clip_by_value change parameter,Hello I have an model that uses the tf.clip_by_value method: Documentation tf.clip_by_value After training I would like to change the clipping parameters. But this seems to be not possible: Is there a way to access and change the parameter of the clipping layer within a model?,https://stackoverflow.com/questions/58525373,12214381.0,1
48091693,tensorflow Dataset API diff between make_initializable_iterator and make_one_shot_iterator,"I want to know the difference between make_initializable_iterator and make_one_shot_iterator. 1. Tensorflow documentations said that A ""one-shot"" iterator does not currently support re-initialization. What exactly does that mean? 2. Are the following 2 snippets equivalent? Use make_initializable_iterator Use make_one_shot_iterator",https://stackoverflow.com/questions/48091693,2641038.0,1
56490000,Read values of tensor in tensorflow,"I'm working with Python 3.6 in PyCharm. In the file site-packages/tensorflow/python/ops/nn_ops.py, I find after line 838 I want to know the values of input, filter and the returned tensor. I tried, according to https://www.tensorflow.org/api_docs/python/tf/InteractiveSession to do Then, I got the error: What am I doing wrong?",https://stackoverflow.com/questions/56490000,8516342.0,1
67180606,In live camera object detection how to swich off the camera and leave the boxes,"first question here. Not waiting an anwer but a bit of direction on how to solve it or documentation to read I'm learning Tensorflow and I'm working with basic examples of live camera objet detection, and want to input the output in other software (GIS) Can I alter the final image coming form the camera.OR even turn the image coming from the camera off and leave only the squares and labels This is the code that draws the rectangles The function visualize_boxes_and_labels_on_image_array is part of Tensorflow models/research/object_detection/utils/visualization_utils.py My first guess was to modify image_np_with_detections to a blank image but it does not work. I have tried to modify directly the visualization utils but it generates an error as is using the image to process the detection. The other option is to dive into opencv documentation Any clue? Thanks in advance",https://stackoverflow.com/questions/67180606,15662858.0,1
45496277,Having trouble understanding lstm use in tensorflow code sample,"Why is the pred variable being calculated before any of the training iterations occur? I would expect that a pred would be generated (through the RNN() function) during each pass through of the data for every iteration? There must be something I am missing. Is pred something like a function object? I have looked at the docs for tf.matmul() and that returns a tensor, not a function. Full source: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py Here is the code:",https://stackoverflow.com/questions/45496277,8133943.0,1
56141142,"How to pass ""step"" to ExponentialDecay in GradientTape","I tried to use an optimizers.schedules.ExponentialDecay isntance as the learning_rate to Adm optimizer, but i don't know how to pass ""step"" to it when train the model in GradientTape. I use tensorflow-gpu-2.0-alpha0 and python3.6. And i read the doc https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/optimizers/schedules/ExponentialDecay but with no idea how to tackle it.",https://stackoverflow.com/questions/56141142,3167681.0,1
40524009,Strange output of embedding_lookup_sparse,"Consider such code: Output: According to the documentation the shape of output must be [3, 3, 3], since shape(sp_id) = [3, 3, 2] and shape(w) = [4, 3], but it doesn't :( Can someone explain why it works in this way? Because I expected behavior simple embedding_lookup, but with aggregation on the last axes.. EDIT For each object I have 2 features and each represent by one word, since that I want represent each object with two concat embeddings, I can do this by: Output So, now I still have 2 features, but each one can be represent with several words, and I want to aggregate embeddings for words corresponding to one feature. It looks like embedding_lookup_sparse should work in such way, but I don't understand why my code doesn't work. Thanks!",https://stackoverflow.com/questions/40524009,6618884.0,1
48944611,How can I read binary file in Tensorflow,"I'm trying to read binary file in tensorflow. I want to ask, which method should I use, and how for reading binary file. In tensorflow, they recommends use dataset in tf.data. But I can't find simple example of using dataset, especially FixedLengthRecordDataset. I think I should use this method, but I don't know how to use. This is the format of my binary file. Please give me some advice for this work. EDIT : All images have different size. So maybe I can't use FixedLengthRecordDatasest. I think I have to convert all images to same size of dataset",https://stackoverflow.com/questions/48944611,9400682.0,1
44769958,Tensorflow: sum over non-NaNs of 2-dimensional tensor in axis 1?,"Let tensor be a tensor where len(tensor.get_shape()) == 2. How to do np.nansum(tensor, axis=1)? From the documentation, nansum ""returns the sum of array elements over a given axis treating Not a Numbers (NaNs) as zero"". I can see how to do this using: But this seems overly complicated. Is there a better method?",https://stackoverflow.com/questions/44769958,4521118.0,1
54505853,How are the weights updated in this code?,"I am reading this code, but can't figure out how the weights get updated in its logic: Is that because in this line, the weights are updated implicitly in the function ""apply_gradients""?",https://stackoverflow.com/questions/54505853,3943868.0,1
51195017,tf.keras.backend way of replacing a tensors value if it's less than 1,I am using Keras with the Tensorflow backend. In my loss function I have a tensor where I need to replace the elements that are less than 1 with a 1. I can see loads of functions available to me in the docs https://www.tensorflow.org/api_docs/python/tf/keras/backend but I'm not sure how to go about this. If I do: I get the shape as: I need to essentially iterate through this tensor replacing elements that are less than 1 with a 1. How would I do this using the keras tensorflow API? Thanks -,https://stackoverflow.com/questions/51195017,7582019.0,1
58254297,How to check gradient computation via unit test,"I am trying to unit-test a custom layer. Writing the feed-forward test was pretty straight forward, but I have no idea how to implement the test for gradients. I found out there is a function in the tensorflow test package called compute_gradient but I can't find any resource on how to use it. The documentation basically says it computes the gradients (jacobian matrix) which is what I want, but when I try to use it, I get EagerTensor is not callable This I the code that fails: I would expect the test to either pass or fail at the assertion but I get a TypeError: 'tensorflow.python.framework.ops.EagerTensor' object is not callable from compute_gradient Edit: Of course gradients need a loss function, I'm an idiot... but still the output is of nonsense shape. I now use the following code: The input's shapes to my layer are (1, 2, 2, 3) and (1, 2, 2, 2) but the gradients are a zip object of 4 12x4 matrices but since I have no parameters in my layer I expected to get the error values at the input. Please correct me if I messed something up again. Just to clarify, my layer is just transforming data and therefore has no gradients on its own but must propagate them backwards correctly.",https://stackoverflow.com/questions/58254297,12044023.0,1
46848023,How to find if a data set can train a neural network?,"Some experimental data contains 512 independent boolean features and a boolean result. There are about 1e6 real experiment records in the provided data set. In a classic XOR example all 4 out of 4 possible states are required to train NN. In my case its only 2^(10-512) = 2^-505 which is close to zero. I have no more information about the data nature, just these (512 + 1) * 1e6 bits. Tried NN with 1 hidden layer on available data. Output of the trained NN on the samples even from the training set are always close to 0, not a single close to ""1"". Played with weights initialization, gradient descent learning rate. My code utilizing TensorFlow 1.3, Python 3. Model excerpt: I suspect two cases: How to evaluate if it is possible at all to train a neural network (a 2-layer perceptron) on the provided data to forecast the result? A case of aceptable set would be the XOR example. Opposed to some random noise.",https://stackoverflow.com/questions/46848023,556876.0,1
60660900,Adding custom metric Keras Subclassing API,"I'm following the section ""Losses and Metrics Based on Model Internals"" on chapter 12 of ""Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition - Aurélien Geron"", in which he shows how to add custom losses and metrics that do not depend on labels and predictions. To illustrate this, we add a custom ""reconstruction loss"" by adding a layer on top of the upper hidden layer which should reproduce the input. The loss is the mean squared difference betweeen the reconstruction loss and the inputs. He shows the code for adding the custom loss, which works nicely, but even following his description I cannot make add the metric, since it raises `ValueError"". He says: This is the code(I have added #MINE for the lines I have added myself) Then compiling and fitting the model: Which throws: Having read that, I tried similar things to solve that issue but it just led to different errors. How can I solve this? What is the ""correct"" way to do this? I'm using conda on Windows, with tensorflow-gpu 2.1.0 installed.",https://stackoverflow.com/questions/60660900,12400631.0,1
49883631,Logits representation in TensorFlow’s sparse_softmax_cross_entropy,"I’ve a question regarding to the sparse_softmax_cross_entropy cost function in TensorFlow. I want to use it in a semantic segmentation context where I use an autoencoder architecture which uses typical convolution operations to downsample images to create a feature vector. This vector is than upsampled (using conv2d_transposeand one-by-one convolutions to create an output image. Hence, my input consists of single channel images with shape (1,128,128,1), where the first index represents the batch size and the last one the number of channels. The pixel of the image are currently either 0 or 1. So each pixel is mapped to a class. The output image of the autoencoder follows the same rules. Hence, I can’t use any predefined cost function than either MSE or the previously mentioned one. The network works fine with MSE. But I can’t get it working with sparse_softmax_cross_entropy. It seems like that this is the correct cost function in this context but I’m a bit confused about the representation of the logits. The official doc says that the logits should have the shape (d_i,...,d_n,num_classes). I tried to ignore the num_classes part but this causes an error which says that only the interval [0,1) is allowed. Of course, I need to specify the number of classes which would turn the allowed interval to [0,2) because the exclusive upper bound is obviously num_classes. Could someone please explain how to turn my output image into the required logits? The current code for the cost function is: The squeeze removes the last dimension of the label input to create a shape for the labels of [1 128 128]. This causes the following exception: Edit: As requested, here's a minimal example to verfiy the behavior of the cost function in the context of fully-convolutional nets: constructor snipped: build_model() snipped: init_optimizer() snipped:",https://stackoverflow.com/questions/49883631,2832960.0,1
73090681,IndexError: tuple index out of range while doing prediction in tensorflow model,"I am trying to implement deep ranking model on using listwise loss. The main reference document used is here I have created the model successfully but while trying to make prediction on an sample data it is giving me error as IndexError: tuple index out of range Below is the detailed code for creating the model Now model is created, if we try to do prediction this fails Any suggestion what could be going wrong Below is the trace log",https://stackoverflow.com/questions/73090681,12271381.0,1
51196986,FailedPreconditionError Tensorflow when reloading session,"For some reason, after reloading the model I trained and saved using tr.train.Saver(), I am getting a FailedPreconditionError. This is the code I use for reloading the session I trained the model in. After using some print statements to debug my code, I realized the following 1) All the variables in the generator_1(), discriminator_1(), and train_1() functions were added to the graph 2) Only the variables declared in the train_1() function, the function where the training takes place and where the saver is instantiated, were initialized with the previous values when calling saver.restore() 3) If I uncomment the two commented lines above, the FailedPreconditionError isn't called, and the variables in both generator_1() and discriminator_1() become initialized, but the values of the variable tensors are different from the ones they were saved as. The third one seems especially strange to me, as I don't run any variable initializer here. If anyone understands how the saver.restore() function works, and why all the variables in the graph aren't all being initialized, as suggested by the documentation here (https://www.tensorflow.org/api_docs/python/tf/train/Saver), any help would be great. Here's a link to my full code, if it helps at all: https://github.com/vdopp234/Text2Image/blob/master/model.py Thank you!",https://stackoverflow.com/questions/51196986,9943232.0,1
55844700,GradientDescentOptimizer requiring a loss function without arguments in eager mode,"The API for tf.train.Optimizer says: ""When eager execution is enabled, loss should be a Python function that takes no arguments and computes the value to be minimized."" I'm confused, how can a loss function compute a loss without being given the prediction and the labels? I tried tf.losses.mean_squared_error but this, as expected, doesn't work because it requires arguments.",https://stackoverflow.com/questions/55844700,6899576.0,1
59406059,Tensorflow Keras GPU uses,I'm trying to make tensorflow and keras go on GPU in my code but I'm having problem that the uses are partially (the CPU is still used by both) for tensorflow I installed tensorflow-gpu then i run this code as mentioned in the tensorflow official page tensorflow official the problem persist and the use of the GPU is not passing 15% and the cpu is at 40% of uses. tensorflow is runing GPU 15% tensorflow is runing CPU 40%,https://stackoverflow.com/questions/59406059,7479290.0,1
46396094,Python and TensorFlow for Live Video Frame Classification,"I'm trying to get on_the_fly object recognition working in Python+OpenCV+TensorFlow as follows. The session runs but as soon as it reaches the (now commented-out) part for translating findings to human readable format at the function named run_inference(), it stops working. Online documentation at various sites mentions that in the case of video frames (not static jpeg images) Mul:0 should be used instead of softmax. But those are not interchangeable and I surely miss some steps between these two. Thanks for any hints to get this working.",https://stackoverflow.com/questions/46396094,8666973.0,1
55006469,tensorflow GradientDescentOptimizer not updating variables?,"I'm new to machine learning. I started with the simplest example of classification mnist handwritten images with softmax and gradient descent. By referencing some other examples, I came up with my own Logistic regression below: I tried to run the optimizer some iterations, feeding data with train image data and labeles. In my understanding, during the optimizer run, the variables of 'W' and 'b' should be update so the model would produce different result before and after training. But with this code, the printed costs of the model before and after optimizer run were the same. What can be wrong to make this happen?",https://stackoverflow.com/questions/55006469,11154785.0,1
59141956,What is the argument `serving_input_fn` of method `export_savedmodel`?,"I am trying to train a Char RNN and export/save the model after training, so that I can use it at inference. Here's the model: and the training part: (x_train is a uint8 array of shape (16639, 100)) Tensorflow documentation tells about the method export_savedmodel that seems to do what I want. But I don't understand the second argument serving_input_fn. What should it be ? classifier.export_savedmodel(output_dir, ???) I am using Tensorflow 1.8.0 and python 2.7.14. This is in relation with this thread. ============ EDIT ============ I tried both solutions suggested in this thread: but I get the following error But again I obtain an error:",https://stackoverflow.com/questions/59141956,4248384.0,1
75364751,'Generator' object has no attribute 'shape' when trying to training model on data from generator,"I have been trying to train a simpletf.keras.Sequential() model with the help of a custom generator. According to this I can pass a generator to model.fit() like so: However I keep getting the following error. The model I was trying to train: The generator I use to yield the inputs: The generator outputs a tuple of length 2 (as specified in ""Unpacking behavior for iterator-like inputs"" in the documentation), consisting of two numpy arrays. The shape of x is (32, 100, 40) and that of y is (32, 1). I am cofused about what shape attribute model.fit() expects the generator to provide. Any help is greatly appreciated.",https://stackoverflow.com/questions/75364751,18073394.0,1
56003567,How to find cube root of value using Tensorflow?,"I have tried the following: I know that sqrt is used for square root. But if I need the cube root of a number, how I can calculate it with tensorflow?",https://stackoverflow.com/questions/56003567,9396051.0,1
73569804,Dataset.batch doesn't work as expected with a zipped dataset,"I have a dataset like this: When I apply batch(4) to it, the expected result is an array of batches, where each batch contains four tuples: But this is what I receive instead: I'm following this tutorial, he does the same steps but gets the correct output somehow. Update: according to the documentation this is the intended behavior: But it doesn't make any sense. To my understanding, dataset is a list of pieces of data. It doesn't matter the shape of those pieces of data, when we are batching it we are combining the elements [whatever their shape is] into batches, therefore it should always insert the new dimention to the second position ((length, a, b, c) -&gt; (length', batch_size, a, b, c)). So my questions are: I wonder what is the purpose of batch() being implemented this way? And what is the alternative that does what I described?",https://stackoverflow.com/questions/73569804,12694438.0,1
46647760,What is input and data parameters in tf.Print function?,"There are input and data parameters in tf.Print function. What do they mean? I don't understand this from documentaion. Suppose I wish to print tensor A. Should I pass it as input, data, both or someother way?",https://stackoverflow.com/questions/46647760,258483.0,1
44191070,"Tensorflow, update the Variable to have arbitrary shape","So, according to the documentation, we can use tf.assign with validate_shape=False to change the shape. It does change the shape of the content of the variable, but the shape you can get from get_shape() doesn't get updated. For example: It's pretty annoying that the later layers of the network base their shapes on the get_shape() value of this variable. So, even though the actual shape is correct, Tensorflow will complain the dimensions doesn't match. So any ideas on how to update the ""believed"" shape of each Variable?",https://stackoverflow.com/questions/44191070,4434038.0,1
64203611,tf.keras.layers.BatchNormalization with trainable=False appears to not update its internal moving mean and variance,"I am trying to find out, how exactly does BatchNormalization layer behave in TensorFlow. I came up with the following piece of code which to the best of my knowledge should be a perfectly valid keras model, however the mean and variance of BatchNormalization doesn't appear to be updated. From docs https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization I expect the model to return a different value with each subsequent predict call. What I see, however, are the exact same values returned 10 times. Can anyone explain to me why does the BatchNormalization layer not update its internal values? I use TensorFlow 2.1.0",https://stackoverflow.com/questions/64203611,3399825.0,1
52311186,How model.fit works in Keras?,"My previous post or error is this one. So, I found a different way of writing the function so it will be Tensorflow compatible. I tested it and it was working fine. However when I want to integrate it into the keras ,I couldn't. This is the solution for my previous post: This is how I call it in my model: then I get again this error So, I want to know how model.fit works in keras ? Does it instantiate the graph ? I didn't find any clear documentation about how it works, so I can integrate my loss function accordingly.",https://stackoverflow.com/questions/52311186,5159740.0,1
60879109,How to update parameter at each epoch within an intermediate Layer between training runs ? (tensorflow eager execution),"I have a sequential keras model and there i have a custom Layer similar to the following example named 'CounterLayer'. I am using tensorflow 2.0 (eager execution) when i run this for example epoch=5 or something, the value of self.count does not get updated with each run. It always remains the same. I got this example from https://stackoverflow.com/a/41710515/10645817 here. I need something almost similar to this but i was wondering does this work in eager execution of tensorflow or what would i have to do to get the expected output. I have been trying to implement this for quite a while but could not figure it out. Can somebody help me please. Thank you...",https://stackoverflow.com/questions/60879109,10645817.0,1
51767758,TensorFlow: Softmax applied to each entry,"I have a tensor x of type tf.float32 and I would like to apply softmax over all entries. Unfortunately, the built-in function can apply softmax along a specified axis only. The solution I thought of: does not work - if x has too big entries (e.g. 100), then e cannot be calculated properly.",https://stackoverflow.com/questions/51767758,10159948.0,1
44311820,Tensorflow tanh with quantized values,"I am experimenting with the quantization of a neural network in Tensorflow 1.1. According to the documentation, the tanh operation supports floating point inputs as well as fixed point inputs of type qint32. However, I can't get this to work: The code yields an error message: Is there a way out or is it just a bug in the docs?",https://stackoverflow.com/questions/44311820,1095888.0,1
66439296,Load and use BoostedTreesClassifier saved model,"I'm trying to use a BoostedTreesClassifier saved model in TensorFlow but I can't figure out how to use the loaded model to make predictions. I'm using the sample code from the tutorial here. This is the minimal code I'm working with: Edit: The last two commented lines are just to show what I ultimately would like to achieve. They will not run correctly nor are they meant to because loaded_est is a different kind of object than est. I don't know how I can use loaded_est to make predictions as I would with est. I have looked at the documentation for saving and loading models here where they do it on an image but I couldn't transpose that to this data, where the input would just be a vector (i.e. a row from the dfeval DataFrame).",https://stackoverflow.com/questions/66439296,6298040.0,1
51907487,How to use TensorFlow with Flask,"I am building a multi threaded rest api with using flask, tensorflow and keras models. After getting this error, I did some research and came up with the following solution: Basically, I submit each new post request to executor. And in each request, I build model with given parameters, producing model, predict and store result for another GET request. I omitted irrelevant parts of the code. It works good, after processing data and getting results, I save it to dictionary. I create new graph and new session for each post request. After reading this and this github discussions, I produced my solution. My question is, is that solution safe and correct usage of tensorflow? In documentation, it says graph is not thread safe, but I did some load test and it can handle simultaneous requests with no problem.",https://stackoverflow.com/questions/51907487,6002951.0,1
43621637,Tensorflow input pipeline error while loading a csv file,I am experimenting loading csv files using input pipelines. I followed a few documentations online and failed to replicate them due to the error below. It seems like I am having trouble with newline delimiters. I would appreciate any feedback. Please see the steps below for replicating the problem. I downloaded iris dataset to my local using the link https://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv and removed the header CSV format below: My code below: I am using tensorflow version: 1.0.0-rc2,https://stackoverflow.com/questions/43621637,7921773.0,1
48022794,Tensorflow: difference get_tensor_by_name vs get_operation_by_name?,"The answer here says that one returns an operation while the other returns a tensor. That is pretty obvious from the name and from the documentation. However, suppose I do the following: I am following the pattern described in Tensorflow Mechanics 101. Should I restore it as an operation or as a tensor? I am afraid that if I restore it as a tensor I will only get the last computed values for the logits; nonetheless, the post here, seems to suggest that there is no difference or that I should just use get_tensor_by_name. The idea is to compute the logits for a new set of inputs and then make predictions accordingly.",https://stackoverflow.com/questions/48022794,4833773.0,1
62704943,Tensorflow Custom Gradient in a Custom Layer,"I am setting up a custom layer with a custom gradient. The inputs are a single 2-D tensor of shape (?, 2). The outputs are also a single 2-D tensor with shape (?, 2). I am struggling with understanding how these objects behave. What I've gathered from the documentation is that for a given input, the gradient will have the same shape as the output and that I need to return a list of gradients for each input. I've been assuming that since my inputs look like (?, 2) and my outputs look like (?, 2), then the grad function should return a length-2 list: [input_1_grad, input_2_grad], where both list items are tensors with the shape of the output, (?, 2). This is not working, which is why I'm hoping someone here could help. Here is my error (appears to occur at compile time): The other wrinkle is that the input to the custom layer is itself also a custom layer (though without a custom gradient). I will provide the code for both layers, in case it's helpful. Also, note that the network compiles and runs if I don't try to specify a custom gradient. But, since my functions need help differentiating themselves, I need to manually intervene, so having a working custom gradient is critical. First Custom Layer (no custom gradient): Second Custom Layer (with the custom gradient): The Custom Function: Any help would be much appreciated!",https://stackoverflow.com/questions/62704943,13855733.0,1
48458509,Strange behavior of tensorflow when dividing by 0 in tf.metrics.mean_absolute_error,"So I do not know if is a bug or the problem is in my code, but I am trying to understand what is happening. when I run the model and got to estimate the accuracy using Mean Relative Error. I know in my validation data I have 0s so I was expecting to get some error or some inf. However this is not the case. This is my code: This is the output: When I run it on a data that has values bigger than 0, my MANUAL_MRE and MRE values are the same like it should be. I checked the documentation of TF and the first case does not make sense. Can someone tell me where I am wrong or I just found a bug/ new feature.",https://stackoverflow.com/questions/48458509,4898951.0,1
44217076,tf.extract_image_patches for 3D images,"The documentation of tf.extract_image_patches It is only for 2D image, could it be expand to 3D images, which is useful for the implementation for SSIM loss function? I cannot find the source code. There is a similar function skimage.util.view_as_windows, however, when I try to use this function with the tensorflow as backend in keras, there are errors. The transition from numpy array to tensor confused me a lot.",https://stackoverflow.com/questions/44217076,7845074.0,1
38461214,how to increment matrix element in tensorflow using tf.scatter_add?,"tf.scatter_add works nicely for 1d (shape 1) tensors: But how can I increment, say [0,0] element of to make it [[2, 2], [3, 4]] using tf.scatter_add? the official documentation is kind'a cryptic. And I tried different arg values, say and haven't succeeded. Btw, in my case, M is quite large and is resized dynamically. So adding zero-but-one equal to 1 element matrix to M is not the case.",https://stackoverflow.com/questions/38461214,3301357.0,1
48067854,Trouble understanding tensorflow shuffle_batch enqueue_many=False,"I am reading the Tensorflow documentation and the code for the Cifar10 example. This bit is currently racking my brain: We are passing in a single image, and somehow a batch of images results?? What is going on here?",https://stackoverflow.com/questions/48067854,2886575.0,1
53470714,image classify and tensorflow serving,"First of all sorry I am not prcise for this question but I am studying the tensorflow-serving and how to put in production my cnn. sincerely the documentation is quite confuse to me. I hope you can help to understand better the save model architecture. So please reply to me as teacher, i would like to know more about the whole flow. I am developping a simple cnn to classify an image to 4 output. I need tensorflow-serving to put it in production. The image in input can be watherver size, the CNN should resize it first and predict. Here the code the code will take the picture from a cam http://192.168.3.21:7451/shot.jpg and then it will predict it When I compile the code it return a lot of errors when it try to save the model. can you please check it and tell me if the save model instructions are right? I use x = model.input as input from the serving but I would like it take the picture as input from the server. I am quite confuse actually, sorry. The scope is when I request by gRPC to predict the image the model can give me the prediction result Thanks",https://stackoverflow.com/questions/53470714,10675469.0,1
47120680,Why can't the output of the network go through a softmax when using softmax_cross_entropy_with_logits?,"I want to use the tensorflow built-in cross-entropy function. However, in the documentation, I'm reading https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits Like it is done often, I am using the softmax activation in my last output layer, however: Is it, therefore, incorrect to use this function, or is the documentation incorrect? I don't understand this, I would be thankful for a short explanation. (Which TensorFlow cost function would be correct to use for a softmax output layer then?)",https://stackoverflow.com/questions/47120680,5919010.0,1
58259247,"object is not callable, when using tf.optimizers.Adam.minimize()","I am new to tensorflow (2.0), so i wanted to ease with a simple linear regression. I have the following code but i dont know why it is wrong . I have tried with the documentation but so far i have no answer. I get the following error, If it helps i have a tensorflow 1 code:",https://stackoverflow.com/questions/58259247,10942287.0,1
68593102,TensorFlow classifies all images as same class,"I've created an Image Classifier CNN in TensorFlow to classify a graph into one of three classes: Linear, Quadratic, or Cubic. I followed the documentation at https://www.tensorflow.org/tutorials/images/classification. I've unit-tested all previous sections of the code, and they work perfectly fine. But when it comes to labeling the images of graphs, every graph is classified as This image most likely belongs to Cubic Sinusoidal with a 88.71 percent confidence. The exact same classification and probability for any image. I've compared my code with the documentation, and there doesn't seem to be anything wrong. If anyone can help, that would be great. I even found a similar Q&amp;A here. My code is below. The Colab Notebook is here. I've included all my code because I'm not sure what the issue is:",https://stackoverflow.com/questions/68593102,14217707.0,1
72484718,"Tensorflow tf.dataset won't iterate with multiple inputs of different sizes ""Shapes of all inputs must match""","I am trying to make a tensorflow model with two different inputs, one will have shape [9,10], the other will just have shape [8]. I am furthermore trying to use tf.dataset to iterate over my inputs. However, whenever I try to do so it fails with the following error: But surely it is possible to have differently sized inputs into different branches! This is exactly the case in the example in tensorflow's functional API guide, however they do not use tf.dataset so I can't simply follow their example. To give a little more specifics into the problem I am trying to solve and why I am using the tf.dataset api: I am doing a time-series problem over multiple sites where my inputs are of two types: those that vary with time, and those that do not but do vary by site. For the time being, I'm just trying to estimate the next time step. First, I get my dynamic covariates and targets in a sliding window using the timeseries_dataset_from_array util. This works perfectly and I can train models using this dataset as is. However, I want to also use the static covariates from the specific site that the time series data is coming from. The site id is included in the window input data in its own column, though it gets removed before training. Thus, what I am trying to do is grab the static covariates for the site and attach it as a separate input to my dataset. The code for the attach_static_covariates method is: I've confirmed that my code can run and train on multiple inputs provided by the above method provided they are the same size (e.g. if I return (x, x) I can run my model on two copies of the dynamic covariates inputted into two different branches of my model). The problem is not due to a mismatch or a bad model definition because I get the same error from the following code: I've looked everywhere on google and the tensorflow git and I can't find anyone else with this problem, and yet it surely MUST be possible to have differently shaped inputs using tf.dataset! I can't imagine that such an incredibly common use case would be completely unsupported. However, I can't find any examples online where someone has multiple inputs of different shapes and uses tf.dataset api. Any help or links to such examples would be greatly appreciated. Colab notebook to illustrate issue: https://colab.research.google.com/drive/1EnaJoUULl-fyAwlcG_5tcWfsRFVCOMtv#scrollTo=PHvsIOx6-Uux",https://stackoverflow.com/questions/72484718,15913381.0,1
45521499,legacy_init_op in TensorFlow Serving,I've noticed every example on TensorFlow Serving uses legacy_init_op parameter in SavedModelBuilder but I have not found any clear explanations on what this is and why it is called legacy. Anyone knows the purpose of this argument? Example:,https://stackoverflow.com/questions/45521499,539617.0,1
59137101,'tuple' object has no attribute 'gpu_fraction',"I am now using colab for my reproduction of saliency detection! I'm a student, so please understand that my knowledge is not enough,,, I found the code using tensorflow, so I am trying to use that code to reproduce the project. However, the author said the code was written on tensorflow 1.00 but I don't know the version of tensorflow if I just import tensorflow as tf from colab. I am getting the error and Here is my source code please see what's my problem",https://stackoverflow.com/questions/59137101,12467715.0,1
50312519,"Dimensions must be equal, but are 1 and 2 for 'Conv2D' (op: 'Conv2D') with input shapes: [2,2,2,1], [1,1,2,1]","I am trying to learn Conv2d by this code. Based on conv2d doc: shape of input = [batch, in_height, in_width, in_channels] shape of filter = [filter_height, filter_width, in_channels, out_channels] When I try to run it , it sends me the wrong message. The wrong message:",https://stackoverflow.com/questions/50312519,8874295.0,1
76447111,where is the documentation of keras.engine.sequential.Sequential?,"I got &lt;class 'keras.engine.sequential.Sequential'&gt;. I need documentation of keras.engine.sequential.Sequential, but can't locate it.",https://stackoverflow.com/questions/76447111,3646484.0,1
74002101,Why my model using a custom layer does not work properly?,"I am working on customizing a layer to use in my model. The core part is the ""call"" function as, and it is used in a simple model. It is supposed to print like this: But prints this: The first summary is what I got from author's repository and the second summary is from my run of the same code without changing anything.. The code is not a complex one but it is weird why there is no parameters at all. My question is that what is wrong here.",https://stackoverflow.com/questions/74002101,4665371.0,1
53124755,How to prevent Tensorflow from allocating the totality of a GPU memory when using eager execution?,"I have pretty much the same question that has already been answered here, with a slight difference though: I'm working on a server with a few GPUs that I share with my colleagues for training our deep learning models. The server should also run a small web application that samples from our models. The sampling script uses the relatively new eager execution. In theory it allows me to stop Tensorflow from allocating all the GPU memory by providing a configuration like this: In practice this does not work though. The documentation of the eager execution also states that not all the configuration options that work for sessions will work in eager execution (here). But how can I limit the used memory then? I know that I can limit the visible devices like this: But I don't want to constantly block an entire GPU for a task that gets called very occasionally and actually needs way less memory.",https://stackoverflow.com/questions/53124755,4528518.0,1
44131998,Effect of batch size on Input Dimension of maximum pooling layer?,"In the following code batch size is 10 ,input channel are 2 and output channels are 32. I know that the output of the convolution act as input of maximum pooling layer whose output act as the input of fully connected layer. According to my understanding image heightimage widthoutput channels (2*2*32) act as the input of maximum pooling layer. Means 32 images of size 2 by 2. But there are 10 images in input layer. Does input of max pooling will be 10*2*2*32?",https://stackoverflow.com/questions/44131998,7997184.0,1
48035125,Speed of Logistic Regression on MNIST with Tensorflow,"I am taking the CS 20SI: Tensorflow for Deep Learning Research from Stanford. I have question regarding the following code: On this code, logistic regression with MNIST dataset is performed. The author states: However, when I run it, each epoch takes around 2 seconds, giving a total execution time of around a minute. Is it reasonable that this example takes that time? Currently I have a Ryzen 1700 without OC (3.0GHz) and a GPU Gtx 1080 without OC.",https://stackoverflow.com/questions/48035125,8480308.0,1
43353588,"Keras - Exception: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None","Getting this issue (using Keras and Tensorflow), any help would be greatly appreciated. My directory is set to be folder/folder/images - for both training and testing data. I made a loop to test the different depths/nb_layers in a Resnet, as well as some hyper parameters like learning rate, batch size, etc. The test went from 4, 6, 8, 10 - all the way to 20, then gave me: I don't understand why it can work for a handful of the iterations, then fail. I read here to update keras to 2.0, but was told not to change the version of keras by my boss. I'm on version 1.2.0. I read here to convert all labels to a numpy array, but keras documentation states this already happens to labels while using the 'categorical' attribute in flow_from_directory Then I read here to put my train_generator in a function, then create an infinite while loop and yield the results, but this results in the data to be loaded over and over at the start of the program. ""Found 350 images belonging to 7 classes"" (repeated 10 times), which then results in an error Here's my stack trace for the original error: Here's the code other than vars",https://stackoverflow.com/questions/43353588,3798748.0,1
67496007,how to create the feature column in tensorflow?,"i am working on the feature_column construction following the tensorflow document, but i met some problem, can anyone help me? THX! this my code below: #data is the dictionary of the train dataset #train the estimator and got an error listed below: the list in the valueError is the age_fea, when i delete the age_fea from estimator construction, the valueError lists the the list of gender_fea. as the demo returns an numpy ndarray rather than tensor, i am confused about what to feed into the feature_columns when constructing the model.",https://stackoverflow.com/questions/67496007,15525911.0,1
39564964,How to correctly create a batch normalization layer for a convolutional layer in TensorFlow?,I was looking at the official batch normalization layer (BN) in TensorFlow however it didn't really explain how to use it for a convolutional layer. Does someone know how to do this? In particular its important that it applies and learns the same parameters per feature map (rather than per activation). In other order that it applies and learn BN per filter. In a specific toy example say that I want to do conv2d with BN on MNIST (2D data essentially). Thus one could do: Where z = BN(z) applies the BN to each feature created by each individual filter. In pseudocode: we have a proper batch norm layer applied to it (in pseudocode omitting important details): i.e. for each filter f we apply BN.,https://stackoverflow.com/questions/39564964,1601580.0,1
72669152,"in creating a custom layer, when the build method is called in Keras","Sorry, I am new to deep learning and keras. I am trying to define a layer myself. I looked into the keras document, https://keras.io/api/layers/base_layer/#layer-class I understand when I create linear_layer, the __init__ method is called, and when I put inputs into linear_layer, the call method is called. But I don’t get when the build method is called, more specifically, how is input_shape in build method specified? What is the input_shape here? I don’t know when the build method is called so I don’t know what arguments are put in as input_shape argument. Besides, I want to specify a parameter with a fixed size, which is (1,768) in my case. So in this case, should I still use input_shape in build method?",https://stackoverflow.com/questions/72669152,15770551.0,1
64797750,How to use own environment for DDPG without gym,"I'm using Keras to build a ddpg model,I followed the official instruction from here enter link description here But I want to my own environment, not gym,here is my own environment: When I use my own environment as above,there is an error: Following is the whole code: After I run the whole code error: Any friend can help?It is real hard for me.",https://stackoverflow.com/questions/64797750,7984318.0,1
41216576,Tensorflow: transfer learning from vgg16 .tfmodel file,"I'm trying to make a TF implementation of an image classifier (with py3.5 and Windows 10, TF 0.12), so I'm re-using existing models as described here but without all the weird Bazel stuff. After fixing a py2-to-3 bug on this line (wrapping the keys() in list()), it ran nicely on my 10 folders of different categories. However, the performance is lacking; the training success rate is around 83% and the validation set is never above 60% at best. So I'd like to do some transfer learning from a vgg16 model (which is one I've used before in Caffe/ubuntu); one I've found is here ready to be downloaded. My question now is, how do you load a .tfmodel file in Tensorflow? The script is expecting a tar.gz to be downloaded, fair enough. It apparently contains a file called classify_image_graph_def.pb, which is not a .tfmodel file. Looking in some example code I see that it's pretty easy to load a .tfmodel file, so I've modified the create_inception_graph function to point straight at the vgg16-20160129.tfmodel file. Upon running this, I get this error: And this is the loading code: Something seems to be going awry in the tf.import_graph_def call but there's no documentation for that function, weirdly. Is what I'm trying even possible? There's a whole bunch of bottleneck tensor and jpeg data and resized input tensor names that I don't know what they're there for, which the example doesn't replicate.",https://stackoverflow.com/questions/41216576,3234562.0,1
67847040,Resize all images in a subdirectory,"I have a directory named TRAIN, and it has 37 subdirectoris which contains images of different size, I wanted to load those images with TensorFlow's ImageDataGenerator, but it needs images of same size. I want to add padding to those images to resize them. I found this above code on internet but I don't know how to use it.",https://stackoverflow.com/questions/67847040,15964159.0,1
54887445,Tensorflow tf.hessian returns only zeros,"I have a trained keras model of which I need to compute both the gradients and hessian of the output respect to the input. The input X is a 5000x3 numpy array and the output y is 5000x1. The gradient computation works fine both using keras' gradients and tensorflow's gradients functions, and I get an array 5000x3 with the correct values in it, but the hessian using tf.hessian() returns only zeros. This should not be the case as my model is approximating a highly nonlinear function, so that second derivatives are well expected to be nonzero. The code is the following (I simplified some parameters for redeability): The output is (truncating my copy-paste): There are two problems with this: 1) The size of the hessian doesn't really make sense to me. I expected a (5000, 3, 3) array, or a (5000,9) at most, while I get a (5000, 3, 5000, 3); 2) The values are all zeros, I have checked with np.count_nonzero(evaluated_hessian) which returns 0. I would understand if both the gradient and the hessian calculation failed, then it would be clear I have made something silly... but gradients works fine while hessians fails, and the docs seem to indicate they both obey to the same syntax call, which is what I have done here. Any help as to why this is happening? EDIT: If I use the calculated gradient as input for another get_derivative_NN call I get the correct value for the second derivative out, so this proves that there is something strange going on with the tf.hessians() function.",https://stackoverflow.com/questions/54887445,2924735.0,1
59549667,How to use Tensorflows GradientTape() to compute biases,"I'm looking to implement GradientTape() on a custom NN architecture but I don't see an explanation anywhere on how to use this to compute biases. A similar question was answered here, but it was not answered fully. As a simple example, I have the training step for my NN like so: Put simply, I cannot evaluate the gradients with respect to the biases as nowhere in any documentation or tutorial do I see the bias term included. So, how do I go about implementing the bias term as a trainable variable in my code? I'm not looking to implement this with keras, so do not suggest I use trainable_variables as I want to do it from scratch.",https://stackoverflow.com/questions/59549667,11065415.0,1
65922990,"Nan losses using ""Learning Rate Step Decay"" Scheduler with Adam Optimizer in Keras?","I have this very deep model: and I'm trying to use Learning rate Step Decay to see if I can improve my validation loss function during training. I'm defining the class for the scheduler as follows: and then I run my training: but when I train I get ""nan"" losses: and I don't understand why. The problem could be the decay rate which is a parameter present in the SGD optimizer but that from the documentation does not exists for Adam, but I get no error that so..any ideas?",https://stackoverflow.com/questions/65922990,12863152.0,1
67594693,Tensorflow - ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list). Please read details,I'm using a LSTM for multi class text classification. I tried a lot of solutions to the problem mentioned in the header but I cant get it working. Code : The error is as follows:,https://stackoverflow.com/questions/67594693,15300444.0,1
62912769,Min_delta on callbacks function of Keras model seems to not take effect,"I am using the following callbacks function on a Keras model and I initialize the minimum delta to 0.002, so based on the documentation of Tensorflow/Keras any improvement in the validation loss function less than 0.002 won't be counted for an improvement. However, this seems to not get implemented in my case. callback function: The output per training epoch You can see that in two highlighted epochs the validation loss improved from What is going wrong? Please also check my colab notebook, in order to check the whole training process",https://stackoverflow.com/questions/62912769,10623444.0,1
64194339,GCP ML Tensorflow serving with authorization for GRPC,I needed help in setting up GRPC for an ML model deployed on GCP. I have deployed the model and want to serve it using GRPC but not able to find any documentation on how to do that. Does anyone have any info on the below:- Currently there is sufficient documentation for serving with JSON requests but these requests are becoming very big and I need an alternative for reducing size and thats why needed to find more doc on it. right now I am getting error let me know if you would need more info. this the code i am using,https://stackoverflow.com/questions/64194339,9063834.0,1
46708822,returned size of tensorflow's dataset API is not constant,"I am using tensorflow's dataset API. And testing my code with simple case. Below shows the simple code I used. The problem is, when the dataset size is small, it seems the returned size from dataset API is not consistent. I'm sure there is a proper way to deal with it. But even though I read all the function in that page and tutorial, I could not find that. The dataset is grayscale video. There are totally 24 sequence of video and step size is all 200. Frame size is 64 by 64 and single channel. I set batch size as 16 and buffer size as 100. But the result of the code is, The returned size of video is either 16 or 8. I guess it is because the original data size is small, 24, when it reaches the end of data, the API just returns what is left. But I don't understand. I also set buffer size as 100. That means the buffer should be filled in advance with small dataset. And from that buffer, the API should select next_element whose batch size if 16. When I used queue-type API in tensorflow, I didn't have this problem. Whatever the size of original data is, anyway there is an moment when the iterator reaches the end of dataset. I wonder how this problem is solved by other people using this API.",https://stackoverflow.com/questions/46708822,5621202.0,1
66740049,'Sequential' object has no attribute '_compile_metrics',My tensorflow is version 2.4.1 i imported modules like this Then i try to create simple compile model like this So my testing function is like this After i ran above code blocks i got this error AttributeError: 'Sequential' object has no attribute '_compile_metrics' But i can't seems find any actual document about _compile_metrics Am i missing something or is it about tensorflow version? Please help. Thanks!,https://stackoverflow.com/questions/66740049,3403614.0,1
63546697,"Building a Generator with Tensorflow 2.3 for array shape (200, )","I am having trouble finding a Generator architecture for a simple array. The ideas is the following, My current generator Model: The train steps, losses and cycleGAN tensorflow documentation are same. Since I am using this generator for a cycle-GAN project, I thought i would get good results after 100 epochs, but it was the opposite. I used a Generator without skip connections but the results were much worse than the one above. I searched for RES-Net and U-Net Architecture but since they require Convolutional layers, I haven't tried them yet. My Questions:",https://stackoverflow.com/questions/63546697,13140685.0,1
67170370,a problem and how to deal with batch while creating a Model,"I try to construct a network to implement the part circled in the image. The output from LSTM **(1,256) and from the previous Mobilenet (batch,7,7,256). Then the output of LSTM is transformed to a weights matrix in form of (7,7). But the problem is that the input shape of the output from mobilenet has a attribute batch. I have no idea how to deal with ""batch"" or how to set up a parameter to constraint the batch? Could someone give me a tip? And if I remove the function compute_output_shape(), one error unimplementerror occurs. the keras official doc tells me that I don't need to overwrite the function. Could someone explain me about that?",https://stackoverflow.com/questions/67170370,9636252.0,1
76187146,Gather elements from tensor with an inner batch dimension in tensorflow,"I'll present my actual problem, and then a simpler version that is more easily reproducible. I have a tensor that represents a batch of images from my training data. Its shape is: The 64x64x4 images are pixel art character sprites, and the domains dimension represent images of them in: back, left, front, and right poses. The reason that the batch_size dim is not the outer-most is that the images are read from a tf.data.Dataset that produces a 4-tuple for each sample (character in the back, left, front, and right poses). And when I do next(iter(dataset)), what I get is a tensor with the mentioned shape ([domains, batch_size, image_size, image_size, channels]). At each training step, I need to randomly pick a target pose for each image in the batch, so I can ask a generator to translate them from their source into a target pose. I am using tf.gather for this, but it does not correctly select images the way I need. My code: I need the resulting target_images to have a shape of [4, 64, 64, 4], which would be 1 image for each character sprite in the randomly picked target pose. But as per the documentation of tf.gather, ""the output shape has the same shape as the input, with the indexed-axis replaced by the shape of the indices."" One option is to use the batch_dims=1 argument of tf.gather, doing: ...that does yield a tensor with the correct shape, but not with the correctly gathered subtensors: in the simplified example I show next it is easier to see what is going on. The reason is that although the batch_dims argument exists, it seems to require the batch dimension(s) to be the outer-most one(s). Let' move on to a simpler problem. Suppose we have a tensor with a shape of: I want to be able to gather one element (content, axis=2) for each element in the batch (axis=1) according to some random domain (axis=0). Let's try some code: As we can see, permuting the tensor to put the batch dimension as the outer-most allows me to use batch_dims=1, axis=1 for tf.gather and yields the correct result. However, I'm a bit afraid of the performance of tf.transpose. My question: is there some way I can gather the desired elements of a tensor that has a batch dimension as an inner dimension?",https://stackoverflow.com/questions/76187146,1783793.0,1
63758810,Use my model to predict output in tensor flow 2 without using keras,"I am new to TensorFlow and I have a very basic question. I have found several posts regarding this question for the previous TensorFlow versions but I could not use the answer for TensorFlow 2 which I am using. The examples I found in the documentation in the original site use Keras. Now, about my question, say, I have built my own model using only TensorFlow without using Keras. I have finished training my model and now I want to use my trained model to predict output for some input I give. I am starting out very simple in order to learn to use TensorFlow 2. I am stuck here and it would be of great help if someone provides me a solution. I have attached my snippet of code herewith.",https://stackoverflow.com/questions/63758810,7341905.0,1
53816414,TensorFlow Operation and cannot be found in official API,"recently I try to repeat and learn the code posted on GitHub by Nvidia--progressive_growing_of_gans. However, I find that there are several operations that I can not find reference based on official API as the following. What does the setter.op.inputs mean? What does the v.shape.ndims mean? By the way, how can I get the reference for such class method? It seems that they are not included in official API. Thank you, everybody!",https://stackoverflow.com/questions/53816414,9881203.0,1
51266268,Exception thrown when running tf.app.run(),"I am toying around with flags at the moment and came across some weird behavior when using tf.app.run(). The following code snippet should simply print the string given via the command line. During execution, this error is thrown: ...which is strange because I do not give a single argument to main(). However, if I add an underscore def main(_):, it works without any errors. I couldn't find a doc where this is use of the underscore is described. Does anybody know what happens here? Thank you!",https://stackoverflow.com/questions/51266268,8334261.0,1
76245374,Converting keras to .tflite - unreal classifying results,"I’m working on a university project aiming to create an image classifier app on Android. Apart from using Tflite Model Maker, I wanted to try Keras as well - Sequential model, converted to .tflite afterwards. I get strange classification results however on my app and cannot really understand why: Here is a simple example, based mostly on official tutorial (assume that path to dataset contains directory with 8 subdirectories containing photos of respective objects - .jpg extensions, 400px height, 300px width). My Android app uses Kotlin API just like here, in official example. This API demands .tflite to provide metadata - for normalization. If I understood documentation, for my case mean = 0,.0 std = 255.0 so that (x - mean)/std results in range [0, 1]. Therefore I use official TF tutorial to add metadata to the model .tflite file: I will omit desciption lines for clarity. Once again please assume that /content/labels is a path for object type labels in appropriate format. I’m nearly sure that something is wrong with conversion process, because: → models made by Tflite model maker work just fine on my app → my .tflite models achieved in process described above fail on my app and on official app as well → for sure as you know, the Sequential model is in general fine (I mean here that its form is taken from official documentation) What really goes wrong with my .tflite models: After equipping .tflite model with metadata in the way I described, the android app will not throw any errors anymore - it gives prediction on images, but: The predictions seem to be sort of constant and out of the world: they do not change much among photos and .score is always way above 1 for each photo. Let’s say I take three photos and have three candidate labels. The .score attributes might be: The .score field is for every label around the very same level more or less between two consecutive integers (label1 - [14, 15] and so on). The range does not vary among photos. It looks like as if the order of probabilities would always be the same, no matter what photo is being processed. (What worries me as well is the violation of .score being under 1 - if it describes probability - how is it even possible to give such outcomes Third issue is that some labels seem to be missing in app - the size of List is below number of labels, despite setting .setMaxResults() properly). I would be extremly grateful for a feedback of yours",https://stackoverflow.com/questions/76245374,12320729.0,1
48976538,Tensorflow AttributeError: 'module' object has no attribute 'manip',I try to roll a tensor and in the Tensorflow documentation i found a function called tf.manip.roll() but when i use it i get the error message: AttributeError: 'module' object has no attribute 'manip' Has someone an idea where this function has moved?,https://stackoverflow.com/questions/48976538,7487368.0,1
49012907,How to initialize intitial_state for LSTM in tf.nn.dynamic_rnn?,"I am not sure how to pass a value for initial_state when the cell is a LSTMCell. I am using LSTMStateTuple as it is shown in the following piece of code: However, the execution returns this error: Here is the link of the documentation for dynamic_rnn",https://stackoverflow.com/questions/49012907,8628566.0,1
70368770,How to create checkpoint filenames with epoch or batch number when using ModelCheckpoint() with save_freq as interger?,"I have tensorflow 2 v. 2.5.0 installed and am using jupyter notebooks with python 3.10. I'm practicing using an argument, save_freq as an integer from an online course (they use tensorflow 2.0.0 where the following code runs fine but it does work in my more recent version). here's the link to relevant documentation without an example on using integer in save_freq. https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint here is my code: I want to create and save the checkpoint filenames including the epoch and batch number. However, the files are not created and it writes 'File not found'. After I create manually the directory, model_checkpoints_5000, no files are added in. (we can check the directory contents by running ' ! dir -a model_checkpoints_5000' (in windows), or 'ls -lh model_checkpoints_500' (in linux)). I have also tried to change to 'model_checkpoints_5000/cp_{epoch:02d}', it still does not save the files with every epoch's number. Then I have tried to follow the example from Checkpoint Callback options with save_freq, which saves files with me. https://www.tensorflow.org/tutorials/keras/save_and_load yet, it is still not saving any of my files. any suggestions how to make it work? other than downgrading my tensorflow.",https://stackoverflow.com/questions/70368770,11028689.0,1
70056573,Tensorflow data set encoding issue for labels,"I'm trying to find code in text documents. I got a data frame with code and text. My input for the model is text+mixed code, and the output is just the code inside the text so I could clean that later. I assume that I have quite a few issues here. My obvious one is that I don't encode the labels part of my data set. My current error is: This happens when I run model.fit().",https://stackoverflow.com/questions/70056573,237745.0,1
71315426,Using TFDS datasets with Keras Functional API,"I'm trying to train a neural network made with the Keras Functional API with one of the default TFDS Datasets, but I keep getting dataset related errors. The idea is doing a model for object detection, but for the first draft I was trying to do just plain image classification (img, label). The input would be (256x256x3) images. The input layer is as follows: Then I'm trying to use the voc2007 dataset as available in TFDS (a very old and light version to make it faster) then preprocessing the data as follows: And then fitting the model like: And after doing this is when I get an error saying that my model expects an input of shape [None, 256, 256, 3] but it's getting an input of shape [256, 256, 3]. I think it's an issue to do with the label. Before I got problems with the extra keys from the dictionary-like format of the data you get from tfds and tried to remove everything except the label, but now I'm still getting this and don't know how to go forward. I feel like after getting the dataset prepared with tfds it should be ready to be fed to a model, and after looking through the documentation, tutorials and stack overflow I haven't found the answer, I hope someone who comes across this can help. Update: To give a bit more of information, this is the model I'm using: TLDR: Image input 256x256x3, a succession of convolutions and residual blocks, and an ending with average pooling, fully connected layer, and softmax that results in a (None, 1280) tensor. Using sparse categorical cross-entropy as loss and accuracy as metric. After trying the solution proposed by AloneTogether I'm getting the following errors (I tried changing the axis in the tf.one_hot() function many times and same result): Which seems to be related to the batching, but don't know exactly how to fix it. The whole issue really seems related to the labels encoding, because when running that line without the tf.reduce_sum() function I get the same but with: And if I run the same without the one-hot encoding line, I get this error: ´´´ Node: 'IteratorGetNext' Cannot batch tensors with different shapes in component 1. First element had shape [4] and element 1 had shape [1]. [[{{node IteratorGetNext}}]] [Op:__inference_train_function_18534] ´´´",https://stackoverflow.com/questions/71315426,15934211.0,1
54282753,How to input 2d numpy array into Tensorflow? (also on how to get matrix input and output working with TF),"I'm new to Tensorflow and I'm trying to understand how it processes data. Currently, this is what I want to have as my input. My full code is up on github should you want to download it. So basically I have 11645 pieces of data in my dataset. For the input, I wish to have 26 inputs normalized from 0 to 1. For the output, I wish to have 80 binary outputs. I don't think TF can give binary outputs, so I probably will use a sigmoid activation function. How do I get Tensorflow to understand that I have 11645 pieces of data I want to process and that the input shape should be 26x1 and the output 80x1? There are some pieces of Tensorflow and Keras that I don't understand how they fit together. For instance, if I want Tensorflow to understand that my input should be 1x26 and not some other input shape, should I use x_train = tf.reshape(x_train, [-1,1*26]) and y_train = tf.reshape(y_train, [-1,1*80])? From the documentations it seems like it will shape x_train into a tensor of only 1 row and 26 columns, and I will have 11645 of those. But does that specify to Tensorflow that the input should only be 1x26 and it won't go off grabbing some other number (eg. 26x2). Or do I have to do something more explicit like this where I specify the input shape into the model? model.add(tf.keras.layers.Dense(26, activation=keras.activations.relu, input_shape=(26,)))? Again, for my output, I want to have a 1x80 tensor that I can reshape and stuff. Do I have to specify to tensorflow explicitly? Or will something like model.add(tf.keras.layers.Dense(80, activation=keras.activations.sigmoid)) be enough to tell Tensorflow that I want a 1x80 matrix, and (for eg, using the sigmoid function) that it should compare every piece of data in that predicted 1x80 with the 1x80 matrix I have in y_train to calculate the loss function? Basically, I am confused as to how Tensorflow 'knows' what data to accept as an individual input and output. Is there a way to specify it or is it a step one can omit? EDIT: Based on the answers, I have used the code: I'm getting the following matrix: This is a far cry from the 0 and 1 matrix I want. What should I do to get closer to that? I've tried Googling my problem, but to no avail. Should I simply apply a threshold to this (eg. 0.4?) and convert it to a binary matrix that way?",https://stackoverflow.com/questions/54282753,9721336.0,1
44381879,Training and Predicting with instance keys,"I am able to train my model and use ML Engine for prediction but my results don't include any identifying information. This works fine when submitting one row at a time for prediction but when submitting multiple rows I have no way of connecting the prediction back to the original input data. The GCP documentation discusses using instance keys but I can't find any example code that trains and predicts using an instance key. Taking the GCP census example how would I update the input functions to pass a unique ID through the graph and ignore it during training yet return the unique ID with predictions? Or alternatively if anyone knows of a different example already using keys that would help as well. From Census Estimator Sample Update: I was able to use the suggested code from this answer below I just needed to alter it slightly to update the output alternatives in the model_fn_ops instead of just the prediction dict. However, this only works if my serving input function is coded for json inputs similar to this. My serving input function was previously modeled after the CSV serving input function in the Census Core Sample. I think my problem is coming from the build_standardized_signature_def function and even more so the is_classification_problem function that it calls. The input dict length using the csv serving function is 1 so this logic ends up using the classification_signature_def which only ends up displaying the scores (which turns out are actually the probabilities) whereas the input dict length is greater than 1 with the json serving input function and instead the predict_signature_def is used which includes all of the outputs.",https://stackoverflow.com/questions/44381879,6520820.0,1
63155929,How can I train a TensorFlow Quantum model that outputs a state vector?,"I want to train a simple circuit in TFQ using a Sequential model as follows: But instead of performing a readout op, I'd like the model to output the state vector so I can do some post-processing on it before I feed it into my loss function. In principle, tfq.layers.State looks like it's appropriate for this task, but it is not clear to me from the examples how I would use the State layer in a model context, vs just using it to generate the state vector as shown in the docs: So my questions:",https://stackoverflow.com/questions/63155929,13568630.0,1
66441365,Keras: which version started to support the Saved Model format?,"I'm trying PlaidML, which requires keras==2.2.4. And I'm having difficulty loading the Saved Model format. I'm sure the model path exists, and files in it are readable. I think Keras v2.2.4 isn't able to load Saved Model format. Here is my keras\engine\saving.py: It seems that it just loads the path as a HDF5 file? I also tried to convert the saved model to a .h5 file. Then load it in keras v2.2.4, still not working: Any way to find out what's wrong without v2.2.4 documentation? (I can't find it online) Thanks. Update I think I known what the problem is, but I don't know how to solve it for now. I'll try to find a solution. I'm wondering whether it's possible to run a tf2 model on PlaidML / old Keras.",https://stackoverflow.com/questions/66441365,4586967.0,1
62529415,TensorFlow 2.0 - Begineer Implementing simple CNN,"I just finished DL specialization from Coursera and I am trying to implement a CNN with TensorFlow 2.0 and my own collected data. I followed the guide and documentation from tensorflow.org and was able to set up a pipeline to load my image. However, when I ran the model I kept running into memory/resource-related issues. My model should do a multi-label classification with 30 categories. below is my code: the below code is from https://www.tensorflow.org/tutorials/load_data/images the model is from the tutorial: https://www.tensorflow.org/tutorials/images/classification at first I ran into Input ran out of data, so i changed my input dataset into train_ds.repeat() instead of x=x_train, y=y_train. next issue I encountered is at this point I am completely lost, I suspect the prepare_for_training function I copied is not suitable for my application but I don't understand enough to make changes. It explicitly said that it is for a data set of 1000+ images while I'm working with 90k training and 10k validation data sets. I try to change the batch_size yet the issue persists. I am using TensorFlow-gpu with GTX 1050 Ti. May I ask for a pointer on how to proceed with this? Thank you in advance. Edit 1: Changed my batch_size to 10 and this error appeared",https://stackoverflow.com/questions/62529415,13796686.0,1
66420994,How to use tfa.metrics.F1Score with image_dataset_from_directory correctly?,"Colab code is here: I am following the docs here to get the result for multiclass prediction When I train using I get When I do: I get I would like to use the metric.result as in the official website. When I load the below code, I get 0.4875028 which is wrong. How can I get the correct predicted_categories and true_categories? Here is how I loaded my data",https://stackoverflow.com/questions/66420994,10868301.0,1
45437572,Tensor Shape Error: Must be rank 2 but is rank 3,"I am having difficulty searching for documentation, studies, or blogs that can help me in building text sequence (features) classifier. The text sequence that I have contains logs of network. I am building a GRU model using TensorFlow, with an SVM as the classification function. I am having trouble with the tensor shapes. It says ValueError: Shape must be rank 2 but is rank 3 for 'MatMul' (op: 'MatMul') with input shapes: [?,23,1], [512,2]. Here is a sample of the data I am using for training my neural network. The goal of my project is to use this GRU-SVM model for intrusion detection on Kyoto University's honeypot system intrusion detection dataset. The dataset has 23 features, and a label (if there is an intrusion in the network or none). Note: The reason why I built my MultiRNNCell as I did (snippet isolated below) is because I was having an error similar to this post. Thank you in advance for your response! Update 08/01/2017 The source was improved based on @jdehesa's sugestions: My next move is to validate if the results I'm getting are correct.",https://stackoverflow.com/questions/45437572,6838049.0,1
39770254,Fast softmax regression implementation in tensorflow,I am trying to implement the softmax regression model in tensorflow in order to make a benchmark with other mainstream deep-learning frameworks. The official documentation code is slow because of the feed_dict issue in tensorflow. I am trying to serve the data as tensorflow constant but I don't know the most efficient way to do that. For now I just use the single batch as constant and trained through that batch. What are the efficient solutions of making minibatched solution of that code? Here is my code:,https://stackoverflow.com/questions/39770254,5251987.0,1
73433868,"""SystemError: google/protobuf/pyext/descriptor.cc:358: bad argument to internal function"" while using Audio Transformers in Hugging Face","I am trying to do a task of ""Speech2Text"" using transformer model in Hugging Face. I tried the code in this documentation on hugging face but when I tried to run this code in Google Colab I am receiving the following error : SystemError: google/protobuf/pyext/descriptor.cc:358: bad argument to internal function On checking the other error lines it seems that on calling processor(), return_tesnors is None even though it is specified as pt. Due to which code is importing tensorflow and that error is coming. (know issue) Full error message : here's my colab link for reference Let me know what can be done to resolve this error Thank you",https://stackoverflow.com/questions/73433868,13871346.0,1
44560549,Unbalanced data and weighted cross entropy,"I'm trying to train a network with an unbalanced data. I have A (198 samples), B (436 samples), C (710 samples), D (272 samples) and I have read about the ""weighted_cross_entropy_with_logits"" but all the examples I found are for binary classification so I'm not very confident in how to set those weights. Total samples: 1616 A_weight: 198/1616 = 0.12? The idea behind, if I understood, is to penalize the errors of the majority class and value more positively the hits in the minority one, right? My piece of code: I have read this one and others examples with binary classification but still not very clear.",https://stackoverflow.com/questions/44560549,1405024.0,1
75305082,Tensorflow dataset crashing VsCode,"So I'm trying to make a simple image classifier using a CNN and an already labeled data set called ""places 365"". However, whenever I run model.fit() my RAM usage maxes out and vsCode crashes or I restart the kernel. In the past, I have gotten model.fit() to work just fine when I imported the cifar10 dataset for a previous model with tensorflow.keras.datasets.cifar10.load_data() so I am pretty sure I am missing something with how tfds.load() formats the dataset. Here is my entire setup: I essentially followed the instructions here: Official TensorFlow documentation All I really changed was: Everything else is the same, and all code blocks compile and run in jupyter except for model.fit() so I have no idea why this stupid function is just gobbling my RAM and crashing VsCode. Any help would be greatly appreciated!",https://stackoverflow.com/questions/75305082,21122083.0,1
76103475,tensorflow dataset builder that runs download_and_prepare with multiprocessing,"The TensorFlow Datasets guide on creating a dataset suggests subclassing the tfds.core.DatasetBuilder. Below is my subclass; it reads NetCDF files and extracts the relevant variables as examples. How can I improve performance with parallel processing? When executing the download_and_prepare pethod, I'm only ever at 100% CPU and can't find any documentation on using multiple threads or cores. The fact that the class utilizes iteration in Python over a generator makes me afraid it's not possible. Is there an alternative approach?",https://stackoverflow.com/questions/76103475,687112.0,1
47585864,What's the difference between get_collection and get_collection_ref?,"I have checked the documentations of both methods but they look the same, except that get_collection can take an additional scope parameter. What's the difference between the two and when to use which one?",https://stackoverflow.com/questions/47585864,3552975.0,1
63908516,Storing Trainable Values in TensorArray for While_loop - tensorflow,"I'm working on a small Tensorflow model using Tensorflow 2.3.0. in the model I use several tf.while_loops and TensorArray. The model is not working as expected. I tried to troubleshoot the issue but unfortunately not all Tensorflow behavior is documented and I'm not sure if there is a bug in my model or it is Tensorflow behavior I'm unaware of. For example in my model I multiply my data with some weights inside a tf.while_loop. I then store the result in TensorArray . The TensorArray content is again used in the same fashion until I minimize the loss to train the model. my problem is that the model does not train as expected . I suspect that tensorflow is freezing the weights and not updating them as I would expect. How can I make sure that the content of the last TensorArray remains trainable since it is produced using data with trainable weight variables . I'm trying to avoid the issue mentioned here but not sure if I have. below is a simple example ( dummy model ) just to clarify what I'm doing : In the above example the content of array2 should be the predictions. how can I make sure that the loops and the tensorArray did not affect the train-ability of my variables ? If what I did was incorrect. whats the best approach to achieve the same thing but keeps my result trainable. Update :: Ok , So I ran the my model for some times and monitored the loss, accuracy and other scaler metrics. And found a general trend in loss decrease and accuracy and other accuracy related metric increase. the Accuracy and loss are also inverse of each other , to my understanding this indicates that the updates are not random and the model is learning something. Additionally I monitored the weights and gradients distributions are changing which confirms that variables are being trained. Can you some please confirm my conclusion and understanding ? Thanks for your help in Advance.",https://stackoverflow.com/questions/63908516,4821136.0,1
49393659,tf.Data: what are stragglers in parallel interleaving?,"interleave is a tf.Data.Dataset method that can be used to interleave together elements from multiple datasets. tf.contrib.data.parallel_interleave provides a parallel version of the same functionality with the help of apply. I can see that reading from many datasets in parallel and having buffers for them as allowed by the parallel version will improve throughput. But the documentation also has this to say about how parallel_interleave can increase data throughput: What exactly are stragglers, and why does parallel_interleave work especially well in terms of throughput in their presence?",https://stackoverflow.com/questions/49393659,5471520.0,1
53931748,Keras/TensorFlow - numpy vs tensor performance,"I am trying to train neural networks using TensorFlow 1.12.0 and Keras API. The setup is as follows. I have a large number of data points: each point consists of a context (call it 24 floats) and a label (1 float). The total amount of data is O(10^7) points. Test networks vary, but a fairly simple one might look like so I've been getting decent results keeping the data in numpy arrays and passing them to model.fit() as-is. However, I am not happy with the performance. It appears to bottleneck in Python code (I even tried to profile it and the Python method slice_arrays in python/keras/utils/generic_utils.py comes up as the primary bottleneck, with up to half of all time spent there.) The GPU (GeForce 1080 Ti) is in use, but its utilization (as reported by nvidia-smi) is rarely above 10-15%. Looking for a way to speed things up, I tried to convert the data into tensors: model.fit requires an argument batch_size when passed numpy arrays, but steps_per_epoch when passed tensors. Documentation isn't clear, but it seems that I should set steps_per_epoch to the number of data points divided by batch_size. This way I get comparable convergence rates. Whatever the value, GPU utilization is 100%, which is good. But now there's a problem. With numpy arrays, run time per epoch is relatively independent of the batch size. I see 8 seconds per epoch at batch size 10k, 5 seconds at batch size 100k, and 7 seconds per epoch at batch size 1M. Convergence is generally way better if the batch size is small. So, I'd typically start with batch size 100k or less. On the other hand, with tensor input, run time per epoch goes up exponentially with steps_per_epoch. With batch size 1M (10-20 steps per epoch), I'm at 2 s / epoch, but the convergence rate is abysmal. With batch size 10k, the convergence rate is good, but the time is up to 30 s / epoch (actually slower than with numpy, despite 100% GPU utilization.) Basically, the only scenario where tensor input actually ends up faster is the one where I don't care to use it in the first place. What is going on and is there any way to get around this?",https://stackoverflow.com/questions/53931748,434507.0,1
43841463,Why did I receive lots of warning message when running the TensorFlow example?,"I am following the tutorial: https://www.tensorflow.org/get_started/get_started Why did I receive lots of errors as below? Also, the final loss score is different. The documentation says: while my loss is: {'loss': 6.3995182e-09, 'global_step': 1000}",https://stackoverflow.com/questions/43841463,697911.0,1
41265035,"TensorFlow, why there are 3 files after saving the model?","Having read the docs, I saved a model in TensorFlow, here is my demo code: but after that, I found there are 3 files And I can't restore the model by restore the model.ckpt file, since there is no such file. Here is my code So, why there are 3 files?",https://stackoverflow.com/questions/41265035,5046896.0,1
49944223,Tensorflow Hub Image Modules: Clarity on Preprocessing and Output values,"Many thanks for support! I currently use TF Slim - and TF Hub seems like a very useful addition for transfer learning. However the following things are not clear from the documentation: 1. Is preprocessing done implicitly? Is this based on ""trainable=True/False"" parameter in constructor of module? When I use Tf-slim I use the preprocess method: 2.How to get access to AuxLogits for an inception model? Seems to be missing: The output is",https://stackoverflow.com/questions/49944223,6147954.0,1
50245039,record_defaults of tf.decode_csv in tensorflow,"I used tf.decode_csv in tensorflow as decoder to parse training examples in a tab-delimited file into cnn models. For every training example, the features are 2 dimensions (100 columns, 2000 rows). After reading the document in tensorflow official site, I still have two questions. code Thanks for your time!",https://stackoverflow.com/questions/50245039,9378677.0,1
42848641,How to balance the classes with the code of Inception-v3 model?,"I am a beginner in tersorflow. I am using the implementation of Inception-V3 expressed in TF-Slim, training from scratch with a different dataset. I am trying to solve a problem of 5 classes, and the dataset is completely unbalanced. The first class has more data than the total of the other 4 classes. The loss doesn't fall, and as expected, unfortunately all the images are classified as ""1"". I am understanding partially how the tensorflow works, but am facing a problem now and don't know how to solve it. How could we construct batches balanced by classes? The most simple way, I believe, would be to address the class balancing in parallel with the data augmentation. That consist of applying oversampling, duplicating the images of the less favored classes (before distorting them) in order to balance with the most populated. But I don't want to do this manually (that would occupy a large extra space in disk), and I prefer to do dynamically. For brevity, suppose we have 2000 images, 500 images and 100 images for classes 1, 2, and 3 respectively. To balance the classes, we would repeat each data from the class 2 with (3 copies) and class 3 (19 copies). The copies (or repetitions) would be done before applying image distortions. The data is in the native TFRecord format. Could someone help me solve this problem? Code: https://github.com/tensorflow/models/blob/master/inception/inception/image_processing.py UPDATE: Thanks to other two similar threads (Online oversampling in Tensorflow input pipeline and How to duplicate input tensors conditional on a tensor attribute (""oversampling"") in a Tensorflow queue?), I have a solution to the problem. Like @citrusvanilla, I've tried to use tf.case(), but it didn't work. tf.cond() was enough. In my case, I'd need to apply some random perturbations to each version of the image. I don't know if that is most suitable option, but I'm using tf.map_fn() to solve this.",https://stackoverflow.com/questions/42848641,7724826.0,1
52864435,Measuring GPU memory usage with TensorFlow profiler,Is there a way to properly measure GPU usage of tf.Estimator model using TensorFlow profiler? I've followed the documentation: But the printed result is always 0.,https://stackoverflow.com/questions/52864435,5991102.0,1
76200709,"Convert Pytorch model into Tensorflow, loading .pb file problem","I work on TF 2.11 and python3.8 I tried to convert pytorch model (best.pt) to TF light as the documentation says I used the command: So, I get a folder named ""best_saved_model"" with .pb file and one .tflight file While I am loading the saved_model.pb into my code : I get an error, why is this happening? Isn't the .pb file the converted Tensorflow model?",https://stackoverflow.com/questions/76200709,17069977.0,1
65440993,how strides effect input shapes in keras?,I'm making a simple image classification in keras and I used MaxPooling2D to reduce image sizes. Recently I learned about strides and I want to implement them but I run into errors. Here's a piece of code which gives errors: Here's the error: when I remove 'strides = 2' everything works just fine. Why is strides option causing input shape error and how can I prevent it? I couldn't find any info about that.,https://stackoverflow.com/questions/65440993,13565936.0,1
60106829,Cannot build custom Keras model with custom loss,"I encountered this problem after running through the VAE example in the documentation, which cannot be built before fitting it data. Apparently, it draws the following error: ValueError: Expected a symbolic Tensors or a callable for the loss value. Please wrap your loss computation in a zero argument `lambda`. Here is a simple MWE: If I remove the self.add_loss from the model, then the model can build properly. Is there a way to build the model before fitting it with custom loss self.add_loss()? Thanks!",https://stackoverflow.com/questions/60106829,4807847.0,1
59516770,Roi pooling and backpropagation,"I have implemented ROI pooling at my graph. The code is as follows. The graph has a few convolution layers before ROI pooling and ctc loss is used for optimization. The concern is whether convolution layers before ROI pooling are optimized in back propagation. According to discussion here, ROI pooling layer itself is differentiable. But when the graph is plotted in tensorboard, the graph is disconnected after ROI pooling layer. How can I check and make sure the conv layers before ROI pooling are update in optimization?",https://stackoverflow.com/questions/59516770,2467772.0,1
44975585,Reading data in tensorflow,"I am learning how to use tensorflow from the documentation. But, I cannot understand the below two functions. I've tried searching the documentation but, I could not get a clear answer. Also, it would be great if you could explain what the parameters in the functions are. Thanks in advance!",https://stackoverflow.com/questions/44975585,5459235.0,1
76440119,Can't fold BatchNorm with Conv2D in Keras QAT basic example,"I'm currently trying to use Keras' Quantization Aware Training, specifically because I need to do 8bit inference on a low-precision device. For this reason, I need to fold the batch norm onto the Convolution to avoid having the 32-bit moving mean and variance. The sample code I'm starting with is the following (tf1.15, tensorflow-model-optimization 0.6.0): The documentation states that 'Conv2D+BN+ReLU' should have the BatchNorm folded but that isn't the case in the .h5 file produced.",https://stackoverflow.com/questions/76440119,21807405.0,1
47231777,how to use tf.metrics.__ with estimator model predict output,"I try to follow the tensorflow API 1.4 document to achieve what I need in a learning process. I am now at this stage, can produce a predict object for example: how can I use predict and label in tf.metrics.auc for example: I have tried so many different options. there are no clear documentation how these tensorflow APIs can be should be used.",https://stackoverflow.com/questions/47231777,1203186.0,1
65815375,"I am getting ""Requested tensor connection from unknown node: ""keras_layer_input:0"""". error while loading keras model",I had Saved model using This model have custom layers and loss function. Loading model using It is working fine if i remove Graph and Session but I want to serve this model with API.,https://stackoverflow.com/questions/65815375,12635565.0,1
37096225,How to understand static shape and dynamic shape in TensorFlow?,"In TensorFlow FAQ, it says: But I still cannot fully understand the relationship between static shape and dynamic shape. Are there any examples showing their differences? Thanks.",https://stackoverflow.com/questions/37096225,4794308.0,1
59231031,Tensorflow: creating a diagonal matrix with input on the sub/superdiagonals,"I have the following code: which, based on the TF2 documentation, I expect to return an 11x11 tensor with X inserted on the first superdiagonal (even without the optional num_rows and num_cols arguments). However, the result is Is there something obvious that I am missing?",https://stackoverflow.com/questions/59231031,1799323.0,1
43647029,Tensorboard embedding visualization hanging when passed metadata (class labels),"Working with the new embedding visualisation capability in tensorboard (TF v1.0.1) I am having difficulty adding labels to the points it displays. Basically when I try to add this metadata the embedding tool hangs and never loads. Unfortunately the documentation for this tool is, at present, quite minimal. I have a 250 class supervised classification being trained (on something like AlexNet) and I can visualise the final fc layer (fc8) fine during training using the embedding tool. But as soon as I add some code to add labels to the plot i.e. to get the points in different colours by class (rather than all blue) the tab never loads (stuck on a message stating 'loading points' forever) The code I add prior to the epoch/training loop is: where fc8 is the tensor I want to visualise obtained earlier from the default graph. All the checkpoints, tensorboard events and now the metadata (labels) itself are being written into a subfolder called 'snapshots' The config file is being written out as projector_config.pbtxt as it should be, and contains If I delete this file then the embedding tab will load fine and won't hang i.e. I get to the dimmed screen and little white central box with 'loading tensors..' etc in it and an (unlabelled) point cloud is shown. Am I misconfiguring this? I don't get any errors logged to the console in which I invoke the tensorboard server even when I raise the GLOG level. Many thanks for any pointers.",https://stackoverflow.com/questions/43647029,3561741.0,1
59262869,Kernel Constraint usage in Tensorflow v1.14,"I am implementing a custom dense layer with weights of dimension 12x12 in which not all the neurons from one layer are connected to another layer. So I have defined a projection matrix like below: And then the idea is to multiply the weight matrix with this projection matrix: I was going through the documentation of tf.layers.dense from here. There is a parameter called kernel_constraint, whose description reads: My question is, does passing the projection_matrix to this parameter (kernel_constraint) achieve what I intend to achieve (connect only specific neurons defined by projection_matrix)?",https://stackoverflow.com/questions/59262869,6997665.0,1
57244733,Where does the documentation point to a list of values for the loss property of the compile function?,"I'm following the Tensorflow documentation for creating a simple neural network. One of the steps is When I look at the documentation for the loss parameter, it says Based on this documentation of the compile function, how would I find a list of the strings and/or objective functions that I can pass for the loss parameter? I found the tr.keras.losses that has the objective functions by Googling, but it seems like there should be a link or mention of that in the documentation for Sequential.compile. Am I missing something?",https://stackoverflow.com/questions/57244733,4820436.0,1
55368272,"How do you index a RaggedTensor along the ragged dimension, in TensorFlow?","I need to get values in a ragged tensor by indexing along the ragged dimension. Some indexing works ([:, :x], [:, -x:] or [:, x:y]), but not direct indexing ([:, x]): The documentation explains why this fails: This makes sense, but how do I actually implement options 1, 2 and 3? Must I convert the ragged array into a Python array of Tensors, and manually iterate over them? Is there a more efficient solution? One that would work 100% in a TensorFlow graph, without going through the Python interpreter?",https://stackoverflow.com/questions/55368272,38626.0,1
63869134,Converting TensorFlow tensor into Numpy array,"I am trying to write a custom loss function in TensorFlow 2.3.0. To calculate the loss, I need the y_pred parameter to be converted to a numpy array. However, I can't find a way to convert it from &lt;class 'tensorflow.python.framework.ops.Tensor'&gt; to numpy array, even though there seem to TensorFlow functions to do so. gives the error message: AttributeError: 'Tensor' object has no attribute 'make_ndarray after printing the type of the y_pred parameter: &lt;class 'tensorflow.python.framework.ops.Tensor'&gt; Looking for a solution I found this seems to be a common issue and there a couple of suggestions, but they did not work for me so far: 1. "" ... so just call .numpy() on the Tensor object."": How can I convert a tensor into a numpy array in TensorFlow? so I tried: giving me AttributeError: 'Tensor' object has no attribute 'numpy' 2. ""Use tensorflow.Tensor.eval() to convert a tensor to an array"": How to convert a TensorFlow tensor to a NumPy array in Python so I tried: giving me one of the longest trace of error messages I ever have seen with the core being: also having to call TensorFlow Compatibility Functions from Version 1.x does not feel very future-proof, so I do not like this approach too much anyhow. 3. Looking at the TensorFlow Docs there seemed to be the function I needed just waiting: tf.make_ndarray Create a numpy ndarray from a tensor. so I tried: giving me AttributeError: 'Tensor' object has no attribute 'tensor_shape' Looking at the example in the TF documentation they use this on a proto_tensor, so I tried converting to a proto first: but already the tf.make_tensor_proto(y_pred) raises the error: TypeError: Expected any non-tensor type, got a tensor instead. Also trying to make a const tensor first gives the same error: There are many more posts around this but it seems they are all coming back to these three basic ideas. Looking forward to your suggestions!",https://stackoverflow.com/questions/63869134,12207268.0,1
71158558,"rescale image in tensorflow to fall between [0,1]","I am fairly new to tensorflow and I have a tflite model which needs inference on a single image (ie no datasets). The docs say the input should be 224,224,3 and scaled to [0,1] (https://www.tensorflow.org/lite/tutorials/model_maker_image_classification#advanced_usage), but I am having trouble doing this rescaling to [0,1]. Currently I have something like so: The min and max and 0 and 255 respectively. I would like to scale this to [0,1] I am on tf 2.5 and I do not see a builtin method to do this.. I tried doing this: and I get thrown: I think there is some casting error :(",https://stackoverflow.com/questions/71158558,1115833.0,1
62785177,"TPU training error: ""No registered 'Cumsum' OpKernel for XLA_TPU_JIT devices compatible with node {{node RaggedConcat/Cumsum""","I am trying to train a model with a custom train step on TPU. The training works fine on GPU, but not on TPU. I believe I am not using a tensorflow operation that is not supported, according to this [ https://cloud.google.com/tpu/docs/tensorflow-ops ] but the list for both the supported and unsupported functions are not exhaustive, and I am using functions not listed on either. The error message mentions a ragged tensor, and there are only two lines of code where I have ragged tensors, which are in train_step specifically I couldn't find anything online about ragged tensors being supported or unsupported. I am trying to figure out how to fully interpret the error message.",https://stackoverflow.com/questions/62785177,3259896.0,1
43189003,Missing kernel for GPU with a tf.int64 variable,"I am using TensorFlow and Python for implementing a simple competitive neural network. Running epoch k, I need to store the index of the winner node and use it in epoch k+1. I am having an issue with variable types, whose solution confuses me. Actually, I understand the main problem since I have read the answer to this question, but I think I need to save that value somewhere on the GPU. I prepared a simple example for showing what I am talking about: Let's say that, at the end of the epoch k, I have the vector vec and I need to store the index of the location with the maximum value, corresponding to var1. Before moving to epoch k+1, I want to store the value of var1 in the variable var2. If I run the previous code I get error: Cannot assign a device to node 'variable2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available. I can provide the full stack trace but I think it is not needed here. So the question is: am I forced to use a tf.float64 variable and cast the values from/to tf.int64 every time I use it? Do you know other possible ways to solve the problem described above?",https://stackoverflow.com/questions/43189003,774133.0,1
46414647,feeding data into an LSTM - Tensorflow RNN PTB tutorial,"I am trying to feed data into an LSTM. I am reviewing the code from Tensorflow's RNN tutorial here. The segment of code of interest is from the reader.py file of the tutorial, in particular the ptb_producer function, which ouputs the X and Y that is used by the LSTM. raw_data is a list of indexes of words from the ptb.train.txt file. The length of raw_data is 929,589. batch_size is 20, num_steps is 35. Both batch_size and num_steps are based on the LARGEconfig which feeds the data to an LSTM. I have walked through the code (and added comments for what I've printed) and I understand it up till tf.strided_slice. From the reshape, we have a matrix of indexes of shape (20, 46497). Strided slice in the first iteration of i, tries to take data from [0, i * num_steps + 1] which is [0,1*35+1] till [batch_size, (i + 1) * num_steps + 1] which is [20, (1+1)*35+1]. Two questions: I guess what I am not understanding is how you would feed data into an LSTM, given the batch size and the num_steps (sequence length). I have read colahs blog on LSTM and Karpathy's blog on RNN which helps greatly in the understanding of LSTMs, but don't seem to address the exact mechanics of getting data into an LSTM. (maybe I missed something?)",https://stackoverflow.com/questions/46414647,7897529.0,1
48481873,how to set stride to zero when using tf.layers.conv2d,"is there a way that I can turn off stride in tensor flow when using: tf.layers.conv2d()? According to the docs, the default is (1,1) but when I try to change this to (0,0) I get an error telling me that it has to be a positive number. Thanks.",https://stackoverflow.com/questions/48481873,9278090.0,1
48038883,Could we always use the list type as the function parameter when the tuple type parameter is expected?,"I have been studying the Tensorflow API written in Python. I have two questions. 1. Can we always use a list type as a function parameter when a tuple is expected? If we look at the official API definition about the tf.placeholder and its examples (https://www.tensorflow.org/api_docs/python/tf/placeholder), we see that the second parameter of this function is the ""shape"". In the example code, we can see that a tuple is used to provide the shape information as a parameter as shown below. However, in the official tutorial page (https://www.tensorflow.org/get_started/mnist/beginners), the example uses the list as the shape rather than using the tuple as shown below. I know that there are some differences between list and tuple such as being immutable vs mutable. If the list supports all the functionality of a tuple, then could we always use the list instead of the tuple safely as a function parameter? And is it recommended? 2. What's the meaning of [None, 10] in the above example code? In the above example code, [None, 10] is used. Are such expressions normally used? If so, then is ""None"" also considered as a kind of number?",https://stackoverflow.com/questions/48038883,735008.0,1
46821855,Got error when setting read_batch_size in tf.contrib.learn.read_batch_examples. default is ok,"I modified code of the wide &amp; deep tutorial for reading large input from file using tf.contrib.learn.read_batch_examples. For speeding up the training process, I set the read_batch_size and got an error ValueError: All shapes must be fully defined: [TensorShape([]), TensorShape([Dimension(None)])] My piece of code： while using the default parameter setting is ok: There is not enough explanation in the tensorflow doc.",https://stackoverflow.com/questions/46821855,3004058.0,1
39657063,Is the collection in tensorflow.get_collection() cleared?,"I'm learning about neural nets using Tensorflow through the Stanford course. I found this while implementing a RNN and did not quite understand why the losses are accumulated: The documentation for get_collection() here doesn't mention anything about clearing the variables. Since this is run for every training step, are the losses incremented every epoch / minibatch of training and carried over? I am still new to NNs so do correct any misunderstanding I have on this!",https://stackoverflow.com/questions/39657063,4207476.0,1
71520085,Tensorflow 2.8 GPU out_of_mem when using multiprocessing,I'm trying to convert .ogg files to tfrecords. I'm running the below code on my GPU using multiprocessing but my GPU RAM gets allocated 100% and the program crashes. Anyone have some input on using multiprocessing with tensorflow or any documentation to best practices? I haven't been able to find what I'm looking for. Think i figured it out. I added the below code to the _write_tfrecord_file function:,https://stackoverflow.com/questions/71520085,15891508.0,1
38060825,What is the purpose of the tf.contrib module in Tensorflow?,"I'm curious about what tf.contrib is, and why the code would be included in TensorFlow, but not in the main repository. Furthermore, looking at the example here (from the tensorflow master branch), and I want to find the source for tf.contrib.layers.sparse_column_with_hash_bucket. It seems like some cool routines, but I wanted to make sure they were properly using queues, etc, for pre-fetching/pre-processing examples to actually use them in a production setting. It appears to be documented here, but it is from the tflearn project, but tf.contrib.layers.sparse_column_with_hash_bucket doesn't seem to be in that repository either.",https://stackoverflow.com/questions/38060825,712997.0,1
42419837,Tensorflow tf.matmul example is incorrect?,"I read the official document for tf.matmul and I understand the first example. It is a simple [2,3] x [3,2] operation: However, the second example seems very strange : Why the matrix with shape [2,2,3] is allowed to multiply with [2,3,2] ?",https://stackoverflow.com/questions/42419837,7611906.0,1
46964597,Tensorflow TypeError: Input 'pred' of 'Switch' Op has type float32 that does not match expected type of bool,"I'm currently working on building a deep neural network using Tensorflow, and encountering some issues implementing a regularization technique called dropout (check out the original paper by Geoffrey Hinton here). Tensorflow has a function to take care of this, and I'm following a tutorial by Aurelien Geron's book Hands-On Machine Learning with Scikit-Learn &amp; Tensorflow (which, by the way, is incredible). In it, his sample code to implement dropout consists of declaring a training placeholder: and then creating the hidden layer dropout object: However, when I execute this, I receive an error pointing to the above line. I looked into the Tensorflow documentation regarding dropout, tf.layers.dropout() method's training parameter is defined as However, in the code above, I'm clearly passing in tf.float32. I suspect this is the cause of my error- it's even stated in the error message itself. So was this simply a typo by the author, or am I not understanding what is happening behind the scenes? Should I just replace the hidden layer declaration with this line instead? I've also looked into other SO posts with similar errors, like this one, but the answers seem to suggest that the error stems from an outdated version of Tensorflow, which is not the case- I only recently installed on my machine a few weeks ago.",https://stackoverflow.com/questions/46964597,5865514.0,1
64231624,Where does a TensorFlow model instance get `input` property from?,"I am not talking about how to pass an input to a model. If you make a model, e.g. from the docs: model actually has a few properties (or attributes) which are not listed in the documentation... These include input, inputs, name, and much more. I've listed them with dir(), but surely its documented somewhere. I would like to know what exactly these are. It really seems like a silly question. Maybe there is a different document I cannot find?",https://stackoverflow.com/questions/64231624,7365866.0,1
46920414,type mismatch using sparse_precision_at_k from tensorflow.metrics,"I am working with a toy example to check how tensorflow.metrics.sparse_precision_at_k works From the documentation: So I have written a following example accordingly: However, I am getting an error:",https://stackoverflow.com/questions/46920414,1716733.0,1
61872515,Tensorflow: Why does Modulo (i.e. tf.math.floormod) not support unsigned integers?,From the Docs: Example:,https://stackoverflow.com/questions/61872515,6920649.0,1
55319623,Large dataset processing for Tensorflow Federated,What is the efficient way to prepare ImageNet (or other big datasets) for Tensorflow federated simulations? Particularly with applying custom map function on tf.Dataset object? I looked into the tutorials and docs but did not find anything helpful for this usecase. This tutorial (https://www.tensorflow.org/federated/tutorials/custom_federated_algorithms_2) shows MNIST processing but this dataset is relatively small.,https://stackoverflow.com/questions/55319623,10966395.0,1
66565894,BERT Encoder layer is non-trainable,"I am trying to fine-tune a BERT model from TensorFlow hub. I loaded the preprocessing layer and the encoder as follow : And this is my model definition : But I get the following error : ERROR:absl:hub.KerasLayer is trainable but has zero trainable weights. In the official website, the model is fine-tunable.",https://stackoverflow.com/questions/66565894,9308543.0,1
75956407,tf.GradientTape().gradient() is returning None,"I am trying to generate heatmaps of an input image for a model that I have created using the pretrained tensorflow XceptionNet. My model structure is: Model Structure [Output of model.summary()] I have tried to use the same format as mentioned in the keras documentation (https://keras.io/examples/vision/grad_cam/) to generate the heatmaps for an image in my dataset. So based on the documentation, the displaying image part for my model is: This above part is working perfectly. But now when I am executing the part: I am getting the error in the line pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)) saying that grad is None. Below is the error message that I am receiving: I am pretty new to this stuff so can someone please help.",https://stackoverflow.com/questions/75956407,21586993.0,1
67504225,Horovod and Tensorflow ambiguous error (train_on_batch),I'm trying to run distributed training with tensorflow.keras and horovod using a custom training loop (train_on_batch) with nvidia-docker on AWS p2.8xlarge. My code is a mess so posting it wouldn't be too useful. Here is a link to the output which doesn't appear very informative to me. The code runs without error using using python run_trn.py. Any advice on how to probe this error? Relevant Horovod code Here are my commands: At some point the gpus are being utilized.,https://stackoverflow.com/questions/67504225,7048409.0,1
42953781,How to restore variables in Tensorflow r1.0,"After upgrading Tensorflow to r1.0, the restore command does not seem to work. For example, can anyone tell me what is wrong with the following? From the last line, I got an error: Tensorflow documentation still holds the explanation of old versions for this matter.",https://stackoverflow.com/questions/42953781,3755060.0,1
46870058,Calling TensorFlow's Dataset.from_generator method,"The TensorFlow 1.4 documentation provides code that demonstrates the usage of Dataset.from_generator. When I run the code, I get an InvalidArgumentError:0-th value returned by pyfunc_0 is int32, but expects int64. I'm using Python 3.6.1. Here's the code: Any ideas?",https://stackoverflow.com/questions/46870058,934904.0,1
67103766,bounding box format in tensorflow object detection api,"thanks in advance. I try to use tensorflow object detection api with manual and web. But I confused about bounding box format in tensorflow object detection api. in tutorial, TODA(tensorflow object detection api) serve several pretrained model, and its trained with coco dataset. in coco dataset, bbox foramt is [xmin, ymin, width, height], there are many bbox format, centerx, centery, width, height, or xmin, ymin, xmax,ymax which bbox format should I use for TODA?? (should I use coco format??) I cant find any info regarding this. and x axis and y axis, this is also confused. I understand X means width, Y means height. bun TODA code, I found this. def assert_or_prune_invalid_boxes(boxes): ... ymin, xmin, ymax, xmax = tf.split( boxes, num_or_size_splits=4, axis=1) why x, y switching?? TODA axis is different from others?? thanks.",https://stackoverflow.com/questions/67103766,10748392.0,1
61994141,Loss and learning rate scaling strategies for Tensorflow distributed training when using TF Estimator,"For those who don't want to read the whole story: TL; DR: When using TF Estimator, do we have to scale learning rate by the factor by which we increase batch size (I know this is the right way, I am not sure if TF handles this internally)? Similarly, do we have to scale per example loss by global batch size (batch_size_per_replica * number of replicas)? Documentation on Tensorflow distributed learning is confusing. I need clarification on below points. and BATCH_SIZE to the best of my understanding is defined above as per replica batch size. To complicate things further, the scaling is handled automatically if you are using Keras (for reasons I will never understand, it would have been better to keep everything consistent).",https://stackoverflow.com/questions/61994141,1586200.0,1
62206004,ValueError showing up while using tensorflow's keras,"I am new to to machine learning and am trying a simple program with keras. When I run the following code, I get an error saying ""ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape [32, 28, 28]"". Could someone help me with this? I am trying to follow along with this video:https://www.youtube.com/watch?v=tjsHSIG8I08, but it doesnt seem to work. Thanks in advance!",https://stackoverflow.com/questions/62206004,13622796.0,1
55537333,How to use tensorflow sequence_numeric_column with an RNNClassifier?,"I was looking throw the tensorflow contrib API and I wanted to use the RNNClassifier available with Tensorflow 1.13. Contrary to non sequence estimators, this one needs sequence feature columns only. However I was not able to make it work on a toy dataset. I keep getting an error while using sequence_numeric_column. Here is the structure of my toy dataset: where idSeq allow us to see which rows belong to which sequence. I want to predict the ""kind"" column thanks to the ""size"" column. Below there is my code about make my RNN training on my dataset. But I only got the following error : So I don't understand what I've done wrong because on the documentation, it is written that we have to give a sequence column to the RNNEstimator. They do not say anything about giving sparse tensor. Thanks in advance for your help and advices.",https://stackoverflow.com/questions/55537333,5218377.0,1
65441499,Tensorflow: Too many dimensions,I'm trying to create a TensorFlow (2.0) variable like this: the shape variable is this: I'm getting this error message: I did not know there is a limit in the number of dimensions. I did not see anything in TensorFlow documentation about it. Is there any way to get around this limitation?,https://stackoverflow.com/questions/65441499,67120.0,1
65835572,Using tf.data.Dataset with Keras on a TPU,"I am training a model with Keras which constitutes of a Huggingface RoBERTa model as a backbone with a downstream task of span prediction and binary prediction for text. I have been training the model regularly with datasets which are under 2 Gb in size, which has worked fine. The dataset has grown in size in recent weeks and now recently, it has gotten to around 2.3 Gb in size which makes it over the 2 Gb google protobuf hard limit. This makes it impossible to train the model with keras with numpy tensors without a generator on TPUs as tensorflow uses google protobuf to buffer the tensors for the TPUs, and trying to serve all the data without a generator fails. If I use a dataset under 2 Gb in size, everything works fine. TPUs don't support Keras generators yet, so I was looking into using the tf.data.Dataset api instead. After seeing this question I adopted code from this gist trying to get this to work, resulting in the following code: The model is created and compiled for TPU use as before which has never caused any problems and then I create the generators and call the fit function: This results in the following error: edit: Colab with bare minimum code and a dummy dataset - unfortunately, b/c of Colab RAM restrictions, building a dummy dataset exceeding 2 Gb in size crashes the notebook. But still, displays code that runs and works on CPU/TPU with a smaller dataset. This code does however work on a CPU. I can't find any further information on this error online and haven't been able to find more detailed information on how to use TPUs with Keras servicing training data using generators. Have looked into tfrecords a bit but also find documentation on TPUs missing. All help appreciated!",https://stackoverflow.com/questions/65835572,1180286.0,1
46444018,"Meaning of buffer_size in Dataset.map , Dataset.prefetch and Dataset.shuffle","As per TensorFlow documentation , the prefetch and map methods of tf.contrib.data.Dataset class, both have a parameter called buffer_size. For prefetch method, the parameter is known as buffer_size and according to documentation : For the map method, the parameter is known as output_buffer_size and according to documentation : Similarly for the shuffle method, the same quantity appears and according to documentation : What is the relation between these parameters ? Suppose I create aDataset object as follows : What role is being played by the buffer parameters in the above snippet ?",https://stackoverflow.com/questions/46444018,8530591.0,1
71594268,Tensorboard not updating by batch in google colab,"I'm using tensorboard in google colab, it's works fine if i want to track the epochs. However, i want to track the accuracy/loss by batch. I'm trying it using the getting started at documentation https://www.tensorflow.org/tensorboard/get_started but if i change the argument update_freq by update_freq=""batch"" it doesn't work. I have tried in my local pc and it works. Any idea of what is happening? Using tensorboard 2.8.0 and tensorflow 2.8.0 I've tried to use a integer and it doesn't work either. In my local computer i've no problems.",https://stackoverflow.com/questions/71594268,18418531.0,1
65716925,Tensorflow dataset from numpy array,"I have two numpy Arrays (X, Y) which I want to convert to a tensorflow dataset. According to the documentation it should be possible to run When doing this however I get the error: ValueError: Shapes (15, 1) and (768, 15) are incompatible This would make sense if the shapes of the numpy Arrays would be incompatible to the expected inputs/outputs. But if I run it with the numpy arrays by using model.fit(X,Y) it runs without any problems, so the shapes seem to be okay. In a next step I checked the output sizes: The input layer for the neural network expect (None, None) and the output (None, 15). So this also seems to match. My dataset is rather large, so it's difficult to share that, but here is a minimal reproducible example which shows the problem. It's the same error, and the fit with just the numpy arrays works. Can someone point me into the right direction on how to solve this? Tensorflow version is 2.3.1.",https://stackoverflow.com/questions/65716925,5632058.0,1
66667080,Convert a KerasTensor object to a numpy array to visualize predictions in Callback,"I am writing a custom on_train_end callback function for model.fit() method of tensorflow keras sequential model. The callback function is about plotting the predictions that the model makes, so it involves converting the inputs of the model to a numpy array and feeds it into model.predict(). I use self.model.inputs to access the inputs, which is a list of KerasTensor objects and the one at 0th index is what I want. I tried the following approach but got the error So this method is for another type of tensor rather than KerasTensor. Other solutions I found work for tensorflow's Tensor object but not keras' KerasTensor object, and I did not find any mentioning of the ways to achieve the desired feature in keras documentation. Thanks for your help!",https://stackoverflow.com/questions/66667080,12345152.0,1
55868173,Accepting base64-images as input for TensorFlow model,"I am trying to export my TensorFlow image-classifying model such that it accepts base64 strings as input. I have tried to implement the solution that is provided on this question, however I am getting the following error: The error appears as a result of the code on line 4. Also, I see that on line 5, ""scores"" provides the output of the model based on the build_model function. However, I can't find in the original question's answers or in the TensorFlow documentation where this function comes from.",https://stackoverflow.com/questions/55868173,11415897.0,1
61649200,Tensorflow 2.0 ImageAugmentation using tf.keras.preprocessing.image.ImageDataGenerator and tf.datasets: model.fit() is running infinitely,I am facing issue while running the fit() function in TensorFlow with augmented images(using ImageDataGenerator) passed as a dataset. The fit() function is running infinitely without stopping. I tried it with the default code which was shared in Tensorflow documentation. Please find the code snippet below:,https://stackoverflow.com/questions/61649200,7336434.0,1
44266187,TensorflowOnSpark returning hdfs scheme not implemented,"I just setup the tensorflowOnSpark API on my server machine and am running the sample mnist examples that come with the library. Running the simple RDD with Spark works perfectly fine, but when I run the TF records example, I get the error: as per https://www.tensorflow.org/deploy/hadoop i have set all the env variables but no luck. The program fails at: it is not able to identify hdfs as a scheme. i saw a similar question here https://github.com/tensorflow/tensorflow/issues/4480 but that doesn't work either. Any help would be appreicated.",https://stackoverflow.com/questions/44266187,5397509.0,1
61817055,Why BinaryCrossentropy as loss and metrics are not identical in classifier training using tf.keras (Tensorflow 2.0)?,"I am using BinaryCrossentropy as both a loss and one of the metrics: Since they are the same thing, I think they should produce the same result. However they shows slightly different values on both training set and validation set respectively. Why is this? Shouldn't BinaryCrossentropy has the same value on the same data? Is it possible that, the loss value is the loss on the final batch, and the metric value is calculated on all batches of the epoch (average?)? I tried to find relevant information on tf.keras.Model.compile, but I couldn't confirm this yet.",https://stackoverflow.com/questions/61817055,1516331.0,1
53175991,How can I make predictions from a trained model inside a Tensorflow input pipeline?,"I am trying to train a model for emotion recognition, which uses one of VGG's layer's output as an input. I could manage what I want by running the prediction in a first step, saving the extracted features and then using them as input to my network, but I am looking for a way to do the whole process at once. The second model uses a concatenated array of feature maps as input (I am working with video data), so I am not able to simply wire it to the output of VGG. I tried to use a map operation as depicted in the tf.data.dataset API documentations this way : But I'm getting this error : Tensor Tensor(""fc1/Relu:0"", shape=(?, 4096), dtype=float32) is not an element of this graph which is pretty explicit. I'm stuck here, as I don't see a good way of inserting the trained model in the same graph and getting predictions ""on the fly"". Is there a clean way of doing this or something similar ? Edit: missed a line. Edit2: added details",https://stackoverflow.com/questions/53175991,10563517.0,1
63417610,How to fit basic custom built model in tensorflow,"I am used to working in PyTorch but now have to learn Tensorflow for my job. I am trying to get up to speed by creating a simple dense network and training it on the MNIST dataset, but I cannot get it to train. My super simple code: When I run this I get This does not really make sense to me because my train_data and train_label are just regular tensors and per the Tensorflow documentation in this case it should default to the number of samples in the dataset divided by the batch size (which would be 200 in my case). At any rate, I tried specifying steps_per_epoch = 200 when I call mnist_model.fit() but then I get a different error: I can't seem to discern where a size mismatch would come from. In PyTorch, I am used to manually creating batches (by subindexing my data and label tensors) but in Tensorflow this seems to happen automatically. As such, this leaves me quite confused about what batch has the wrong size, how it got the wrong size, etc. I hope this simple model is way easier than I am making it and I just do not know the Tensorflow tricks yet. Thanks for the help.",https://stackoverflow.com/questions/63417610,11870534.0,1
59906819,What is the correct explanation for tf.dense?,"I am using a tutorial to learn RNN. As shown in the image below, it has used tf.dense and given an explanation which I cannot understand. (As a newbie to stackoverflow, I cannot insert images, hence the link) The documentation at tensorflow.org also does not help much and it is so bad for a beginner like me that I've given a 1-star rating. It says the following (which does not make sense to me) The explanation at tensorflow.org Can someone kindly explain it to me. Thank you Excerpt from the tutorial I am using to learn.",https://stackoverflow.com/questions/59906819,12483947.0,1
58573710,Converting a TensorFlow sess.run to a @tf.function,"How can I edit the sessions.run function so that it runs on Tensorflow 2.0? I read the documentation over here and learned that you have to change a function like this: to this: but I'm unable to figure out how to change the first one. Here's a bit of context, I was trying out this code lab, and in this found that the sess.run, that was giving me trouble. This is the command line output when running the label_images file. And this is the function that gave errors.",https://stackoverflow.com/questions/58573710,5805695.0,1
73374580,optimize data input pipeline with keras datagenerator by using tf dataset,"i want to train my autoencoder with ~100k hdf5 files. I wrote a datagenerator using keras.utils.Sequence. Everything works fine, but now im getting a data bottleneck. I watched some documentation on the tf datasets and how they perform much faster. Normally I would use my generator like this: Now I'm using the Dataset.from generator method: Unfortunately my basic approach need 20s per epoch, the from_generator approach takes 31s. Does anyone of you had similar problems on how to get your datagenerator much faster? Thanks, Lukas",https://stackoverflow.com/questions/73374580,19264587.0,1
49575909,Is there a way to reverse a graph in TensorFlow?,"As the title says, I'm looking for a way to reverse the flow of a TensorFlow graph. The reason for this, is that I want to visualize the hidden layers of the graph given a logit vector for the output of the trained graph. For example, say that I have a fully connected graph given as follows (inspired by MNIST): Suppose I now train this graph and want to visualize hidden 1 when only the first output neuron is activated. The way I would do this would be to reverse the flow of the graph and feed a tensor [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] from the output layer back through the reversed graph until I finally got the output of the hidden1 layer. I have tried to see if there is a way to do this in TensorFlow, but there seems to be little information about this. The way I would inutitively construct it is to add an operation sess.run_reverse() when running the graph as follows: If this sort of operation doesn't exist or even is possible to get, however, I would instead construct separate operators for reversing the flow of the graph as follows: I realize that there might be logical flaws to this method that wouldn't make it possible. A couple of things I've overlooked is singular matrices and undefined inversion of ReLu when input is below 0 (ReLu, though, can be replaced by sigmoid for theoretically defined inversion of the entire input space). The core idea, though, is to visualize a feature map given a category - something I believe should be possible if a few assumptions are allowed. Anyways, please tell me if I'm thinking wrongly here, and if there is a way to reverse the graph!",https://stackoverflow.com/questions/49575909,8353218.0,1
49114306,Avoiding duplicating graph in tensorflow (LSTM model),"I have the following simplified code (actually, unrolled LSTM model): Whenever I run the last line, it seems that it changes the graph. But I don't want the graph changes. Actually my code is different and is a neural network model but it is too huge, so I've added the above code. I want to call the func without changing the graph of model but it changes. I read about variable scope in TensorFlow but it seems that I've not understand it at all.",https://stackoverflow.com/questions/49114306,9422652.0,1
57082918,Tensorflow: AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'softmax_cross_entropy_with_logits_v2',"When I run this, I get AttributeError: AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'softmax_cross_entropy_with_logits_v2'. May I get any help? In the line 64, in , cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output_layer, labels=labels)) AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'softmax_cross_entropy_with_logits_v2'. I tried to find some help from Google, but I didn't get any useful information. Thank you for your help.",https://stackoverflow.com/questions/57082918,11678039.0,1
47035862,How does tensorflow's tf.contrib.training.batch_sequences_with_states API work?,"I am dealing with long sequential data which has to be passed to an RNN. To do truncated BPTT and batching, seems like there are two options: I came across tf.contrib.training.batch_sequences_with_states which seems to be doing one of the two. The documentation is confusing to me and hence I want to be certain which way does it generate the batches. My guess is it does it the first way. That’s because, if the batching is being done the second way, then we cannot leverage the benefits of vectorization, since, to preserve the state between the last time step of one segement to the first time step of the next segment, RNN should process one token at a time sequentially. Question: Which of these two batching strategies are implemented in tf.contrib.training.batch_sequences_with_states?",https://stackoverflow.com/questions/47035862,3001665.0,1
38312094,How to create a recurrent variable with TensorFlow,"This sounds super easy but I cannot find any info on the internet. I am probably lacking some fundamental understanding. I would like to do something simple: a recurrent variable. Say: with some fixed (but trainable) W. I tried things like: But of course, within a session, if I do Z.eval(), it gives a coherent value of Z, but Z itself is not updated. Hence my question: how do you create a recurrent variable that gets updated when running the graph with TensorFlow? Thank you very much for your help!",https://stackoverflow.com/questions/38312094,6575619.0,1
49770934,Prevent a Variable from being converted into a Const when freezing a TensorFlow graph,"I'm trying to use the freeze_graph.py tool to save a model, but have run into an issue. There is a variable in my tensorflow graph which I either assign to using tf.assign, or feed before each inference. I need it to remain a variable because tf.assign requires a mutable tensor and you also can't feed to a const, but the freeze_graph script converts all variables into constants. I've noticed that freeze_graph has whitelist and blacklist parameters, but I can't for the life of me find any documentation on what these are or how to use them. What can I do here? edit: single_c and single_h are the variables I'd like to preserve: because I assign them using: and I feed state using I can't assign or feed if single_c and single_h become constants",https://stackoverflow.com/questions/49770934,6936275.0,1
50395479,How to add feature column names to Keras Estimator,"I would like to add feature column names to the inputs of a Keras model that I have converted to an Estimator. This will allow me to send a JSON message to a serving model where I can specify the feature names. My model is as follows, which has 3 input nodes: I then create an estimator: My custom input function is: However, when I try to evaluate the model, I get the following error: model.input_n returns [dense_4_input], where dense_4 is the name of the first layer. So how do I configure my model such that the feature names in my input function will match the input names of my model? I've looked at the documentation, but its no help.",https://stackoverflow.com/questions/50395479,1753640.0,1
45551656,How to run a pre-trained model on tensorflow attention_ocr?,"I have managed to train attention_ocr on my data, and I am now trying to do an inference run (tensorflow version 1.2.1). I use the following code based on what is mentioned on the git README to use a pre-trained model, but I always get a list of repeating characters, that changes on each run (like [38,38,38...] ). This is obviously wrong as according to the evaluation on a test set during training, I should have a character accuracy of above 90%! Has anybody tried this before? Or can somebody provide me with some hints on fixing it?",https://stackoverflow.com/questions/45551656,2046399.0,1
74971952,"keras binary_crossentropy loss works well even with a shape mismatch in y_true and y_pred, while it throws error if from_logits = True?","--&gt; Throws shape mismatch error: --&gt; 0.998 (some value for random labels and preds), works well! Why??? Keras Documentation statest the shape of logits and targets must be same for loss functions to work properly. Then why is it that there is no shape mismatch error on from_logits = False!",https://stackoverflow.com/questions/74971952,16900069.0,1
41164274,Creating a Tensor using a pre-populated pd dataframe?,"I am trying to create a item-item based collaborative filtering recommendation engine. Because of the large volume of data flowing through, I have had to use TensorFlow. However I even after spending hours on the documentation and on the internet, I am unable to figure out how to create a tensor using a pre-populated ndarray. I am trying to transpose a ndarray with user item actions to record the information in a tensor. I have debugged multiple errors including shape mismatches only to find a new error I can't find any information around. Below is the code. Any help/suggestions is highly appreciated. TypeError: Input 'ref' of 'ScatterAdd' Op requires l-value input user_item_action.head(): user_id product_id action_score 1354 76864 196823 10 2626 23364 234437 10 6422 8055 231014 10 9877 81965 200476 10 13334 88132 240015 10",https://stackoverflow.com/questions/41164274,4425827.0,1
47912161,Tensorflow : serving model return always the same prediction,"I need your help I'm a little bit stuck right now. I retrain a classification tensorflow model that gives quite nice results. Now I want to serve it through tensorflow serving. I managed to serve it but when i'm using it, it always gives me same results no matter what the input is. I think there is something wrong the way I export the model but I can't figure what. Below is my code. Can somebody help me ? Thanks a lot guys This is the function that transform my input image into a readable object for tf: And this is how I export my model: predict_inputs_tensor_info=tf.saved_model.utils.build_tensor_info(predict_inputs_tensor) classes_output_tensor_info=tf.saved_model.utils.build_tensor_info(classes_output_tensor) scores_output_tensor_info=tf.saved_model.utils.build_tensor_info(scores_output_tensor) tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:classification_signature, }",https://stackoverflow.com/questions/47912161,7719915.0,1
40668712,Enqueue and increment variable in Tensor Flow,"How can I make a Tensor Flow graph push an incrementing number to a queue? I am just doing this for learning purposes, so I'd prefer if you kept it similar to what I'm doing (and correct what I'm doing wrong). This is my code: Output: I'm expecting it to be 2 random numbers between 2 and 8. Instead, it always is popping the current value of the variable. Is this because instead of pushing the actual value of the variable I am instead pushing a pointer to the variable? Tensor Flow's documentation says assign_add returns Again, I'm trying to learn about Tensor Flow. I'd appreciate any learning resources (besides the TensorFlow website) if you have any! Thanks. EDIT: Changing push = queue.enqueue(add) to push = queue.enqueue(add + 0) results in expected behavior. Could someone explain this?",https://stackoverflow.com/questions/40668712,877651.0,1
72522220,how to use tensorflow saved_model.load to do prediction,I need to do prediction using a saved model in TensorFlow. Here I export the model: Lets say I have saved model saved_model.pb. Now I need to load it and do predictions. It raises this error: return self._signatures[key] KeyError: 'predict' I reviewed this link and this link but was not successful to get it work.,https://stackoverflow.com/questions/72522220,7934786.0,1
76225743,TypeError: 'AutoTrackable' object is not callable when loading BERT module from TF Hub,"In my code I wish to create a tokenizer from a pretrained TF Hub BERT module. Following is my code: The following function call... tokenizer = create_tokenizer_from_hub_module() ...gives the following error I am working on Google Colab with TF version 2.12.0 and the code was originally written and tested in TF version 1.X. Pretty new to TensorFlow so I'm not sure what to do. Followed these questions and answers: SO1, SO2, SO3, but I don't seem to understand. Also tried downgrading TF version and subsequently Python version even though it is not the best option to follow. Still no success.",https://stackoverflow.com/questions/76225743,13871286.0,1
44563648,How to effectively use tf.bucket_by_sequence_length in Tensorflow?,"So I'm trying to use tf.bucket_by_sequence_length() from Tensorflow, but can not quite figure out how to make it work. Basically, it should take sequences (of different lengths) as input and have buckets of sequences as output, but it does not seem to work this way. From this discussion: https://github.com/tensorflow/tensorflow/issues/5609 I have the impression that it needs a queue in order to feed this function, sequence by sequence. It's not clear though. Function's documentation can be found here: https://www.tensorflow.org/versions/r0.12/api_docs/python/contrib.training/bucketing#bucket_by_sequence_length",https://stackoverflow.com/questions/44563648,8165188.0,1
52428112,What information does the Weight matrix provide?,I am dealing with binary classification problem. I just printed a part of the code. I am familiar with softmax function that it gives probability of belonging to certain class. At W_fc I can not get any information about classes. So I was wondering what information does W_fc provide? What is the significance of the values printed in W_fc? Can I plot histogram of W_fc? How I will do that?,https://stackoverflow.com/questions/52428112,10333833.0,1
45204898,what TensorFlow hash_bucket_size matters,"I am creating a DNNclassifier with sparse columns. The training data looks like this, The following snippet can run successfully, However, I have a question from this sentence, where 3 means hash_bucket_size=3, but this sparse tensor includes 4 non-zero values, It seems has_bucket_size does nothing here. No matter how many non-zero values you have in your sparse tensor, you just need to set it with an integer &gt; 1 and it works correctly. I know my understanding may not be right. Could anyone explain how has_bucket_size works? Thanks a lot!",https://stackoverflow.com/questions/45204898,5878281.0,1
66778153,How exactly does tf.data.Dataset.interleave() differ from map() and flat_map()?,"My current understanding is: Different map_func: Both interleave and flat_map expect ""A function mapping a dataset element to a dataset"". In contrast, map expects ""A function mapping a dataset element to another dataset element"". Arguments: Both interleave and map offer the argument num_parallel_calls, whereas flat_map does not. Moreover, interleave offers these magical arguments block_length and cycle_length. For cycle_length=1, the documentation states that the outputs of interleave and flat_map are equal. Last, I have seen data loading pipelines without interleave as well as ones with interleave. Any advice when to use interleave vs. map or flat_map would be greatly appreciated //EDIT: I do see the value of interleave, if we start out with different datasets, such as in the code below However, is there any benefit of using interleave over map in a scenario such as the one below?",https://stackoverflow.com/questions/66778153,2135504.0,1
58571072,How to load local images in tensorflow?,"I found from the tensorflow documentation that the code to load a dataset named ""flower_photos "" is I'm having some images in my local machine and want to load and use it for doing some neural network algorithms like CNN. How to load and preprocess a locally stored image in tensorflow?",https://stackoverflow.com/questions/58571072,6733836.0,1
52975843,Comparing Conv2D with padding between Tensorflow and PyTorch,"I am trying to import weights saved from a Tensorflow model to PyTorch. So far the results have been very similar. I ran into a snag when the model calls for conv2d with stride=2. To verify the mismatch, I set up a very simple comparison between TF and PyTorch. First, I compare conv2d with stride=1. The result of this execution is: When I change stride to 2, the results start to vary. The result of this execution is: According to PyTorch documentation, conv2d uses zero-padding defined by the padding argument. Thus, zeros are added to the left, top, right, and bottom of the input in my example. If PyTorch simply adds padding on both sides based on the input parameter, it should be easy to replicate in Tensorflow. The result of this comparison is: What this tells me is that if I am somehow able to replicate the default padding behavior from Tensorflow into PyTorch, then my results will be similar. This question inspected the behavior of padding in Tensorflow. TF documentation explains how padding is added for ""SAME"" convolutions. I discovered these links while writing this question. Now that I know the padding strategy of Tensorflow, I can implement it in PyTorch.",https://stackoverflow.com/questions/52975843,1840086.0,1
47193290,Servers and sessions,"I'm learning about distributed TensorFlow applications, and I understand jobs, tasks, and servers. A server's target identifies its gRPC location, as in grpc://localhost:1234. I don't understand what happens when you create a session with a server's target, as in the following code: The documentation states that server.target identifies the session's execution engine. Another page says that the constructor creates a session on the server. This isn't clear to me. How exactly does a server's target affect the session's execution?",https://stackoverflow.com/questions/47193290,934904.0,1
45012534,What is an epoch and how is related to steps and batch_size?,"I have looked through other solution to the similar questions but none gave a complete explanation. For my understanding, the epoch is a test round in which the test-set divided in 'm' batch_size goes under 'n' steps. And in this case, no of epochs will be the size(data-set)/m. Ok, but what if the batch_size was equal to the size(data-set), then how to decide the number of the epochs.I faced the similar problem when going through the documentation. Here the batch_size is equal to the size(data-set). So what's the real related behind these terms.Please explain with a well-defined example..",https://stackoverflow.com/questions/45012534,7369870.0,1
73840190,Why is StringLookup from producing an extra label?,"From TF documentation: ""one_hot"": Encodes each individual element in the input into an array the same size as the vocabulary. As far as I understand it it should encode to a 26 shaped tensor. Why does it encode to a 27 shaped one? Should there be an extra label to represent ""no class""?",https://stackoverflow.com/questions/73840190,14742134.0,1
65611125,OCR with CRNN. How to get prediction score,"I have a CRNN fitted model with CTC loss output. I have the prediction and I use keras.backend.ctc_decode to decode it. As written in documentation (https://code.i-harness.com/en/docs/tensorflow~python/tf/keras/backend/ctc_decode), the function will return a Tuple with the decoded result and a Tensor with the log probability of the prediction. keras.backend.ctc_decode can accept multiple values for its prediction but I need to pass it once at time. This is the code: Output: The prediction is always correct. However what I think it's the probability seems not to be what I expect. They looks like completely random numbers, even grater than 1 or 2! What am I doing wrong?? Thank you in advance!",https://stackoverflow.com/questions/65611125,14958144.0,1
41666964,model variables in Tensorflow's batch_norm,"The documentation online says moving_average and moving_variance are both model_variables, and tf.model_variables() returns tensors of the type local_variables. Does that mean model_variables are not saved when I save my state? I'm trying to apply batch normalization to a couple of 3D convolution and fully connected layers. I trained my network with batch_norm and saved a checkpoint file, but when I went to restore my saved state, it said moving_mean could not be located. The exact error was, when TF went to assign the restored value to moving_mean, the shape of the lhs tensor, [], could not be reconciled with the that of the rhs, [20]. The graph restores fine when I don't add batch_norm around my layers. I'm planning to add a global variable at the end of training that saves my moving_mean and moving_variance values. Is this the way TF intended for me to use batch_norm? Thanks!",https://stackoverflow.com/questions/41666964,3873000.0,1
73796337,is it possible to create a layer that perform only Pointwise Convolution part of keras.layers.SeparableConv2D,"I created the following CNN model: My intension was that the seperableConv2D layer will create a single 3x3 kernel that will operate separately on each one of the 16 3x3 input images and will result in 16 single numbers. However, the result was that it learned 3x3x16 kernel and resulted in a single number. After reading the explanation regarding Seperable2D in here, I understood that it is training different 3x3 for each one of the channels (which I could live with) but then merges these 16 numbers to 1. My questions are:",https://stackoverflow.com/questions/73796337,20049055.0,1
45134654,Easily switching between feed_dict and queues for input to TensorFlow model,"Right now I have a model configured to take its inputs with feed_dict. The code looks something like this: For performance reasons, I'd like to switch to using queues for training. But I'd like to maintain the ability to use feed_dict, e.g. for inference or testing. Is there an elegant way to do this? What I'd like to do is, when using queues, 'swap out' the placeholder variables for the tensors returned by my queue's dequeue op. I thought that tf.assign would be the way to do this, i.e.: But this raises AttributeError: 'Tensor' object has no attribute 'assign'. The API docs for tf.assign describe the first argument as: ""A mutable Tensor. Should be from a Variable node. May be uninitialized."" Does this mean my placeholders aren't mutable? Can I make them so? Or am I approaching this the wrong way? Minimal runnable example here.",https://stackoverflow.com/questions/45134654,262271.0,1
49603346,Understanding how tf.gradients evaluates,"I'm studying how to break linear classifiers, but I'm having trouble understanding tf.gradients. The point of the project is to take a model and train it on the mnist dataset. Once it is trained, I am taking an image, slightly changing it, and feed it back to the model. However, when I feed it back, the prediction should be different. For example, if I have an image of a 2 and I want the model to predict a 6, I will change the image slightly so that the image still looks like a 2 but the model will think its a 6. How this is done is a simple equation. We take the derivative of the loss function and take the sign of it and apply it to the image multiplied by some epsilon value. For example, the equation is something like this... The part that confuses me is tf.gradients. I am looking at an example but I am having a hard time understanding it. First, 10 images of a number 2 are extracted. Next, 10 labels are created representing the label 6. So the labels looks as follows... And then to the derivative of the cost function looks as so (cross_entropy is the cost function)... x0 is are the 10 images of a 2 and y_six are the labels representing the number 6. The sign of this derivative is then used in the equation I demonstrated above. My question is this, what exactly is the tf.gradients returning and why is the derivative being evaluated with a label of 6 rather than a label of 2? I'm having a hard time understanding what is being returned and why a fake label is being used. I understand that a fake label is probably necessary to trick the classifier but it is hard to see this because I don't understand what tf.gradients is returning.",https://stackoverflow.com/questions/49603346,4333347.0,1
63063208,How to make custom non-linear convolution-like layer to be fast in Tensorflow 2?,"I need to make convolution-like layer in tensorflow2 (and then export graph to neural accelerator). Filter takes 7x7 area and produces one pixel, but it is non-linear and uses abs function, so it's impossible to directly utilize optimized nn.conv2d function. I've tried to make the custom layer, code works, but its an abysmally slow code (10-20 sec for one image row!) for the filter that should run only a bit slower than convolution one. When I tried to make the convolutional layer the same way, it also was too slow. What is the best way to implement filter as in the code below? This is the minimal example of filter that is non-linear and slow: For comparison, ordinary convolution executes almost instantly (example is taken from documentation, it differs from this filter) P.S. I don't need to use back-propagation nor training for this filter, all coefficients are known",https://stackoverflow.com/questions/63063208,5547064.0,1
64451250,How to load a Tensorflow model saved with make_image_classifier tool,"I've made a custom image classifier model using a Tensorflow tool called make_image_classifier https://github.com/tensorflow/hub/tree/master/tensorflow_hub/tools/make_image_classifier Now the model is exported into a .pb file and also 2 folders, assets and variables. The question is how can I use this custom model to make predictions? I've gone through all TF documentation and have tried many different things over these days but found no solution. Someone wrote about it when he found no clear information, so he created a guide but it also doesn't work for me. In ""step 3"" its all the code required to load the module and classify an image using the custom model. The problem with this is I need to know the name of the input and output node, and I don't have them. I've tried to find them using Netron but it didn't work. https://heartbeat.fritz.ai/automl-vision-edge-exporting-and-loading-tensorflow-saved-models-with-python-f4e8ce1b943a Can someone please give me a clue about how to load a saved model and use it to make predictions?",https://stackoverflow.com/questions/64451250,14351825.0,1
46781847,How periodicaly evaluate the Performance of Models in TF-Slim?,"I am trying to use DensNet for regression problem with TF-Slim. My data contains 60000 jpeg images with 37 float labels for each image. I divided my data into three different tfrecords files of a train set (60%), a validation set (20%) and a test set (20%). I need to evaluate validation set during training loop and make a plot like image. In TF-Slim documentation they just explain train loop and evaluation loop separately. I can just evaluate validation or test set after training loop finished. While as I said I need to evaluate during training. I tried to use slim.evaluation.evaluation_loop function instead of slim.evaluation.evaluate_once. But it doesn't help. I tried evaluation.evaluate_repeatedly as well. In both of these functions, they just read the latest available checkpoint from checkpoint_dir and apparently waiting for the next one, however when the new checkpoints are generated, they don't perform at all. I use Python 2.7.13 and Tensorflow 1.3.0 on CPU. Any help will be highly appreciated.",https://stackoverflow.com/questions/46781847,8161718.0,1
42628141,AttributeError: module 'tensorflow' has no attribute 'streaming_accuracy',"For the above code, I have received the same error in past few days. Isn't the syntax same as it is in the API documentation for tensorflow?",https://stackoverflow.com/questions/42628141,5540592.0,1
56262735,how to see tensor value of a layer output in keras,"I have a Seq2Seq model. I am interested to print out the matrix value of the output of the encoder per iteration. So for example as the dimension of the matrix in the encoder is (?,20) and the epoch =5 and in each epoch, there are 10 iteration, I would like to see 10 matrix of the dimension (?,20) per epoch. I have gone to several links as here but it still does not print out the value matrix. With this code as mentioned in the aboved link: I got: Is there any straightforward way of showing the tensor value of each layer in Keras? Update 1 by trying this code: K_value = K.eval(encoded) it raises this error:",https://stackoverflow.com/questions/56262735,7934786.0,1
56459677,"AssertionError when using MirroredStrategy: isinstance(x, dataset_ops.DatasetV2)","I am trying to use MirroredStrategy to fit my sequential model using two Titan Xp GPUs. I am using tensorflow 2.0 alpha on ubuntu 16.04. I successfully run the code snippet from the tensorflow documentation: However, when I try to train on my data, which is a sparse matrix of shape (using adam optimizer and binary crossentropy): I receive an assertion error in _distribution_standardize_user_data at In the TensorFlow code, line 2166 in training.py seems to be causing this assertion error. Can someone explain to me what the problem with my data could be?",https://stackoverflow.com/questions/56459677,5924132.0,1
55145913,How do I verify images in a TensorFlow Dataset?,I am creating a tensor flow dataset of labels and images using the following code taken from TensorFlow documentation here. I now want to verify that the images have been added to the dataset and check the dimensions. How do I go about doing that?,https://stackoverflow.com/questions/55145913,11198116.0,1
43634968,Parallelizing a tensorflow operation across multiple GPU's,In below code of a single hidden layer neural network I'm attempting to parallelize the gradient descent operation across two GPU's. I'm just attempting to thinking about this conceptually at the moment. There does not appear to be very much literature on how to perform this. Reading Training Multi-GPU on Tensorflow: a simpler way? does not provide a concrete answer. In below code I've added two functions runOnGPU1() &amp; runOnGPU1() which is a conceptual idea of how to split the training of the network across two GPU's. Can these two loops be split in order to share the computation across multiple GPU's ?,https://stackoverflow.com/questions/43634968,470184.0,1
67754649,Mean of Tensorflow Keras's Glorot Normal Initializer is not zero,"As per the documentation of Glorot Normal, mean of the Normal Distribution of the Initial Weights should be zero. But it doesn't seem to be zero, am I missing something? Please find the code below:",https://stackoverflow.com/questions/67754649,10016590.0,1
42140211,Tensorflow - eval() error: You must feed a value for placeholder tensor,"I'm trying to use eval() to understand what is happening in each learning step. However, if I use eval() on an tf.matmul operation, then I would get an error You must feed a value for placeholder tensor. If I removed the eval(), then everything would work properly as expected. The exact error is: Does anyone have a better way to log the variables? I've tried tensor_summary, but it doesn't show it on the website. Thanks all",https://stackoverflow.com/questions/42140211,1157751.0,1
62833142,How to check the training accuracy in K fold validation,"I am using k fold validation in my model in which user scans the historical places and our app will show all the details of it. The technologies i am using are SIFT and MLP. However, I am unable to find the training accuracy in k fold and also one more thing that i am unable to use tensor board in it , because i found on internet that it'll be used in model.fit( ) function but in K fold I am not using Code is shown below .",https://stackoverflow.com/questions/62833142,14978092.0,1
59695014,Tensorflow Keras Dataset Load Huge Multiple Numpy Files,"How to load multiple numpy files into dataset? I'm following this article but got this error AttributeError: 'function' object has no attribute 'ndim' File ""train.py"", line 27, in model.train()",https://stackoverflow.com/questions/59695014,5079849.0,1
54162343,"tensorflow: object has no attribute 'matrix_inverse', how to verify it should be supported?","I am running the following code on a server with a gpu, using tensorflow-gpu version=1.2: When running the same code on my laptop (no gpu) with tensorflow version=1.8 it works. As I see in the documentation, this is implemented for the tensorflow version I am using, so it should be supported. yet I get the following error: so to my question - Can it be that the matrix_inverse() is not supported in tensorflow-gpu 1.2 but is supported in tensorflow 1.2? and if so, where can I see the correct documentation?",https://stackoverflow.com/questions/54162343,9610896.0,1
65693622,How can I Train a Functional Keras Model with Large Amounts of Image Data and Metadata?,"I am trying out the HAM10000 challenge and I have gotten some things nailed down such as building a Functional Model for the first time, categorizing, etc. What I haven't gotten figured out is how to train my model with both image data and patient metadata. Before I talk any further, here is my model structure so that you may understand what I'm trying to do here: https://i.stack.imgur.com/ppQkm.png What the model is doing is that it takes an image and passes it through several convolutional and max pooling layers, and then flattens it. The model also takes in patient metadata which include age, sex, location of pigment, etc. These values are then concatenated together and passed through three dense layers and out comes the output of the model with 7 categories (akiec, bcc, bkl, df, mel, nv, vasc). This is the code for the model: I can successfully pass in the metadata with fit(), but passing in image data is the hardest part. When I try to load roughly 9000 images' RGB matrixes (600x450 resolution) onto system memory with a dtype of float64, my PC obviously crashes. I was, however, able to succeed with this technique with a much smaller amount of images loaded to memory (roughly 100), but it is not enough data to make an accurate model. I have tried to ImageDataProcessing, but the issue is that it doesn't seem that fit_genearator() can't accept my metadata data. One person has told me to ""Create a pipeline that would load images one at a time(or in batches) as the model needs it."" The problem with this is that I couldn't find much helpful documentation that can do this. If you have a solution to this dilemma, I am all ears. Thanks!",https://stackoverflow.com/questions/65693622,7795568.0,1
59120814,Tensorflow-serving Doesn't Find Meta Graph Def,"I'm trying to serve a trained Tensorflow model using tensorflow-serving (loaded on a docker, if that makes any difference) After training my model, I've saved it using the following code: And after running saved_model_cli with the --all flag on the version folder I get this response: However - when trying to serve, I still get the following error: Any ideas what could be causing this? Thanks",https://stackoverflow.com/questions/59120814,2871164.0,1
61333991,Normalizing windows in tensorflow dataset,"I am trying to build a windowed dataset from a univariate time series. The idea is if the series looks like [1, 2, 3, 4, 5, 6] and the window length was 2, then I'd take windows of length 3 to account for 2 X features and Y target output, so [[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6]] then I'll shuffle them up to avoid bias from that, and split out the input features from target output for each window: [[[1, 2], [3]], [[2, 3], [4]], [[3, 4], [5]], [[4, 5], [6]]] However I'd like to add some normalization. For example if my window is w=[1, 2, 3] then I'd like to normalize according to [p/w[0] - 1 for p in w] I thought I could achieve this with ds.map and because map is supposed to apply the function to each window in the dataset, but this didn't work. All the example in tensorflow dataset docs use map with lambda functions but I presume it works with regular functions too Does anyone know how it should be done? EDIT The traceback I get is",https://stackoverflow.com/questions/61333991,1349569.0,1
58353887,Alternatives to LSTMCELL because tensorflow_core.compat.v1' has no attribute 'contrib',I am running tensorflow 2.0 on fedora I am trying to run some code which contains the line: This is producing the error The tensorflow documentation here says that 'rnn' has been replaced with 'RNN API'. What can I do to solve this issue without changing the code significantly? How do I use the RNN API?,https://stackoverflow.com/questions/58353887,11983010.0,1
43406876,Can't use float64 in keras with tensorflow backend,"In my .keras/keras.json file I have set ""floatx"": ""float64"", but I got the following error. Input 'filter' of 'Conv2D' Op has type float32 that does not match type float64 of argument 'input' I have done some research and found a link saying that ""You can monkey-patch tf.get_variable and add dtype=tf.float64 whenever dtype is None."", but I don't really get it, and can't fit it in my program. My program is below (simplified version) Can anyone give some advice about how to implement it? Thanks in advance.",https://stackoverflow.com/questions/43406876,6355435.0,1
59596940,How to use Automatic Mixed Precision in tensorflow 2.0 with hub.KerasLayer,"According to the tensorflow documentation, I tried to use Automatic Mixed Precision (AMP) in tensorflow 2.0 in keras style. Here is my code: What I expect : bert_sequence_output.dtype should be float16, because it is the output of a layer (i.e. the bert_layer) that uses the mixed_float16 policy. But what I actually get: the code above tells me bert_sequence_output.dtype is float32, and here is the full log: When I change the policy to float32, the several print give me these info (other parts of log is the same as mixed_float16): According to the log, here is my conclusion: Personally, I think this is due to the layer definded in Bert have been hard-coded to have a dtype float32, so we cannot use mixed_float policy to change its behavior. Is it right? What else could have caused the problem and how to fix it? Thanks to all kindly help in advance!",https://stackoverflow.com/questions/59596940,11909692.0,1
59616311,How to scale a gradient norm in Keras,"In the pseudocode for MuZero, they do the following: From this question about what this means, I learned that this was likely a gradient norm scaling. How can I do a gradient norm scaling (clipping the gradient norm to a particular length) on a hidden state in Keras? Later on they also do the same scaling on a loss value: This site says that I should use the clipnorm parameter on the optimizer. But I don't think that will work, because I'm scaling the gradients before using the optimizer. (And especially since I'm scaling different things to different lengths.) Here is the particular code in question from the paper, in case it is helpful. (Note that scale_gradient is not an actual Tensorflow function. See the previously linked question if you are confused, as I was.) (Note that this question is different from this one which is asking about multiplying the gradient by a value, not clipping the gradient to a particular magnitude.)",https://stackoverflow.com/questions/59616311,5049813.0,1
53149059,Why do these two fc api act differently?,"I was implementing the resnet and training on cifar-10 dataset. After ""global average pooling"" layer, I add 10-way fully connected layer. I used two tensorflow API to implement fc layer. However, the method 2 works to me, but the method 1 doesn't work. The method 1 is according to tensorflow official api: tf.contrib.layers.fully_connected. The second method is according to tf.layers.dense. I'm so confused why the first method doesn't work here. FYI, the output of global average pooling layer is [batch_size, 1, 1, 64]. Looking for some help! Thanks in advance! Edit: Doesn't work means if I use the first method, all output logit of fc become zero, which doesn't make any sense to me.",https://stackoverflow.com/questions/53149059,7212365.0,1
48947083,Re-train pre-trained ResNet-50 model with tf slim for classification purposes,"I would like to re-train a pre-trained ResNet-50 model with TensorFlow slim, and use it later for classifying purposes. The ResNet-50 is designed to 1000 classes, but I would like just 10 classes (land cover types) as output. First, I try to code it for only one image, what I can generalize later. So this is my code: I am a bit confused about what comes next (I should open a graph, or I should load the structure of the network and load the weights, or load batches. There is a problem with the image shape as well. There are a lot of versatile documentations, which aren't easy to interpret :/ Any advice how to correct the code in order to fit my purposes? The test image: AnnualCrop735",https://stackoverflow.com/questions/48947083,4569591.0,1
48558181,variables_to_train flag in Tf-slim,"I am fine-tuning my model from a pretrained model using TF-Slim. When I used the create_train_op, I found that it has a parameter that is variables_to_train. In some tutorial, it used the flag as follows: But in the official TF-Slim, it does not use So, what is different between with and without using variables_to_train?",https://stackoverflow.com/questions/48558181,2938494.0,1
34902782,Interpolated sampling of points in an image with TensorFlow,"Given is a grayscale image I as 2D Tensor (Dimension W,H) and a Tensor of coordinates C (Dim. None,2). I want to interpret the rows of C as coordinates in I, sample I at those coordinates using some kind of interpolation (bilinear would probably be fine for my use case), and store the resulting values in a new Tensor P (of dimension None, i.e. 1-dimensional with as many entries as C has rows). Is this possible (efficiently) with TensorFlow? All I can find are functions for resizing (equidistant resampling if you like) of images. But I can't find anything out-of-the-box to sample at a list of coordinates. I.e. I would have expected to find something like a tf.interpolate() function: Ideally I would be looking for a solution that would allow me to interpolate in an N dimensional tensor I along M dimensions using a C with shape (None, M) and produce an N-M+1 dimensional output, as indicated by the ""axis"" parameter in the code above. (The ""image"" in my application isn't a picture btw., it's sampled data from a physical model (when used as placeholder) or an alternative learned model (when used as variable). Right now this physical model has 2 degrees of freedom, thus interpolating in an ""image"" is sufficient for now, but I might look into higher dimensional models in the future.) In case something like that is not possible with existing TensorFlow features: Where should I start when I'd like to implement something like this tf.interpolate() operator? (documentation and/or simple example code)",https://stackoverflow.com/questions/34902782,2213720.0,1
42323640,Tensorflow: AttributeError: module 'tensorflow' has no attribute 'Supervisor',"I'm trying to use the Supervisor class to create checkpoints that can be used to save/load partial trainings, as mentioned in the TensorFlow documentation - https://www.tensorflow.org/programmers_guide/supervisor . But when I try to use it as mentioned in the docs - It throws the below error - Whats am I missing?",https://stackoverflow.com/questions/42323640,4993842.0,1
61875007,How to find input and output tensors for my tensorflow model?,"I am trying to convert my saved tensorflow model into a .pb format. But when I see the available methods online they define an input tensor and output tensor inside the sess.run but I am not. Is there any way to find the input and output tensors? Also, why is the output tensor not getting passed in the sess.run unlike the ones that done by others? And is this prediction or classification task? My model is shown below:",https://stackoverflow.com/questions/61875007,13510173.0,1
44921911,Shuffling the training dataset with Tensorflow object detection api,"I'm working on a logo detection algorithm using the Faster-RCNN model with the Tensorflow object detection api. My dataset is alphabetically ordered (so there are a hundred adidas logo, then hundred apple logo etc.). And i would like it to be shuffled while training. I've put some values in the config file: However whatever are the values, I'm putting in, algorithm is at first training on all of the a's logos (adidas, apple and so on) and only a lapse of time after starting to see the b's logos (bmw etc.) and the c's one etc. Of course I could just shuffle my input dataset directly, but I would like to understand the logic behind it. PS: I've seen this post about shuffling and min_after_dequeue, but I still dont quite get it. My batch size is 1 so it shouldn't be using tf.train.shuffle_batch() but only tf.RandomShuffleQueue My training dataset size is 5000 and if I write min_after_dequeue: 4000 or 5000 it is still not shuffled right. Why though? Update: @AllenLavoie It's a bit hard for me; as there is a lot of dependencies and I'm new to Tensorflow. But in the end the queue is constructed by It seems that when I'm putting num_readers = 1 in the config file the dataset is finally shuffling as I want, (at least in the beginning), but when there are more somehow on the start the logos are getting in the alphabetical order.",https://stackoverflow.com/questions/44921911,6805141.0,1
45299192,Trouble with understanding how TensorFlow receives and processes data,"I have recently begun studying Deep Learning and am confident of my understanding of both the theory and the in-depth practical implementations of RNNs and LSTMs. I have written a very simple RNN which learns to add together two binary numbers, using only numpy. I am now trying to become familiar with the TensorFlow API so that I no longer have to build my models from scratch. Despite my confidence in my understanding of NNs and in my programming ability, I am becoming very frustrated as I keep hitting walls when it comes to understanding the high-level that TensorFlow abstracts the models, and how data to be used should be structured. An example of a wall I have hit is in the code below, where I am attempting to implement a simple RNN that takes in a list of lists/sequences of integers, and will then learn how to classify a single sequence as either increasing or decreasing. generate_data() outputs two lists: x is the placeholder for the input sequences and y is the placeholder for the corresponding labels. My thought process is for each input sequence to be received by the RNN as x, a single column tensor with each row being a single integer of the sequence - a single time step in the unrolled RNN. The RNN will then output a single integr (0 or 1) after each full forward propogation of the RNN (after one entire x tensor has been processed. I am getting an error that on the last line that inputs must be a sequence. I am failing to understand how this single column tensor is not considered a sequence, and how it needs to be shaped in order for it to be a sequence. As a side note, the next biggest misunderstanding I have is that in all the theoretical explanations I have read of RNNs, there are 3 weighted matrices - one from input to hidden state, one from hidden state to output, and one between the hidden states of each time step. All coded examples I have seen using TensorFlow only seem to have a single weighted matrix. How is this so? How does TensorFlow use this single matrix as an abstraction of the 3 deep levels ones? And am I shaping this matrix correctly in the line W = tf.Variable(tf.random_normal([sequence_len, output_dim]))?",https://stackoverflow.com/questions/45299192,4564080.0,1
51058476,why the parameter 'scale' of tf.layers.batch_normalization is disabled when next layer is relu?,"In the tensorflow documentation of tf.layers.batch_normalization,it is said"" When the next layer is linear (also e.g. nn.relu), this(the parameter of 'scale' ) can be disabled since the scaling can be done by the next layer."" ? It seems wrong because when the next layer is nn.relu, the linear coefficient is an invariant constant(1), and the value won't be sacled.",https://stackoverflow.com/questions/51058476,9155944.0,1
45127850,Questions on the use of tf.contrib.layers.embedding_column in tensorflow,"I have some questions on the use of the embedding columns implemented in tensorflow in tf.contrib.layers.embedding_column. I'm training a binary classifier for a two player game (tennis, in this case). My features that I pass to the DNNClassifier as feature_columns look as follows: What I'm wondering about is this: am I now learning two different embeddings for the same set of players? And if so, is there a way to use one embedding layer for both players? Or is there nothing wrong with doing it the way I'm currently doing it? A second question regarding the embedding_column: the docs mention this, as possible arguments for embedding_column: Does this imply that if none of these is provided, the embedding layers are initialized randomly again when restoring my model from a checkpoint? And then one final question: The two embedding columns for court and surface have a dimension of 1, as they only have very few options. Is this a bad use of an embedding column? Or is it okay to use it like that? Thanks in advance!",https://stackoverflow.com/questions/45127850,2903625.0,1
56678776,Why do we have to import keras from tensorflow if we have already imported tensorflow in python?,"I'm now learning tensorflow and keras and I see all tutorials have these two imports: Based on my understanding of python import, I thought the second line was an extra, since if we have already imported tensorflow in the first line, then we shall have imported every module in tensorflow. Just like if we have then we shouldd have math.log(), math.sqrt() available. However, if I comment then this line of code would return NameErrorTraceback (most recent call last) Why can't we directly use tf.keras if we only have import tensorflow as tf? What's special about this import compared to the import in import math? Thanks",https://stackoverflow.com/questions/56678776,2850815.0,1
64239696,Understanding Gradient Tape with mini batches,"In the below example taken from Keras documentation, I want to understand how grads is computed. Does the gradient grads corresponds to the average gradient computed using the batch (x_batch_train, y_batch_train)? In other words, does the algorithm computes the gradient, with respect to each variable, using every sample in the mini batch and then average them to get grads?",https://stackoverflow.com/questions/64239696,13299451.0,1
71891557,"ValueError: Input 0 of layer sequential_3 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 224, 256)","I am new to Keras and I am attempting to create a CNN that takes a (224,256,1) sized image as an input. Here is the error I keep getting: My interpretation of the error is that the data the layer got had 3 dimentions and the layer needs atleast 4 dimensions. According to the keras documentation, the input shape should be (batch size, x , y , channels). I am only using a single image as I believe the batch size should just be 1. Here is the code for making the model: Here is the prediction code: let me know if you need anymore info, thanks!",https://stackoverflow.com/questions/71891557,18821695.0,1
49711343,Sigmoid in logistic regression (Tom Hope's Guide to Building Deep Learning Systems),"I am following Tom Hope's book to learn Tensorflow and I arrived upon this Logistic Regression Example: The example runs as described in the book, however, there is one thing I do not understand, why has the author not used tf.sigmoid() for the inference? Is there something obvious that I have overlooked? Also the results look largely similar with and without the said modification.",https://stackoverflow.com/questions/49711343,5466307.0,1
52867244,How to read csv in TensorFlow?,I just start using TensorFlow. I am trying to read csv file in TensorFlow. This is an example I found online: But I have the error: The data is iris dataset. It looks like: You can see that the error info said that it is not a valid float. But all the data are float64. I am not even sure where to start with this.,https://stackoverflow.com/questions/52867244,4827407.0,1
41714318,Input parameters of tf.contrib.learn.read_batch_features,"I am working through these tensorflow codes which implement a LSTM in tensorflow. While going through the codes, I came across this function (in input_fn code - line 38) tf.contrib.learn.read_batch_features. I looked up the documentation of tf.contrib.learn.read_batch_features here. This is what I got - There are few input parameters that I am not able to understand and was hoping someone could help me with it. Would appreciate any help around these questions. Thanks in advance!",https://stackoverflow.com/questions/41714318,2324298.0,1
70495270,"ValueError: Dimensions must be equal, but are 100 and 19 with input shapes: [?,100], [?,100,19]","I have an error in my code, and I've done read the documentation but it still error, How this error can be fixed? Code: and here is the model summary: Here is the code to fit in training data: And I got this error: ValueError: in user code:",https://stackoverflow.com/questions/70495270,3499140.0,1
46165406,tensorflow tf getting error cross entropy in built function,"I have two functions as below, they come from Andrew Ng is deep learning course on coursera. The first function runs, but the second doesn't. logits and labels variables have the same shape as per the document requirements I changed cost to [0.0,0.0,1.0,1.0], but it didn't help :( in case of the first function I am directly passing variables from the function call into the function 1) 2) The error is",https://stackoverflow.com/questions/46165406,2543622.0,1
46020389,Problems using TensorFlow with ndarray,"I wrote this code, but receive this error: ""TypeError: x must be dict; got ndarray"" and This error occurs on model.training I'm find on internet, but not understanding this solution. Thank you",https://stackoverflow.com/questions/46020389,6661532.0,1
52482459,Job failed on Google Cloud ML Engine,"I wanted to do a classification model using Google ML Engine. I took this documentation as reference and successfully followed this post till preprocessing step. After executing the training command, I'm getting the following error message: Kindly help me out with this..",https://stackoverflow.com/questions/52482459,7779311.0,1
66937155,What is the issue with my last dense keras layer?,I am working on a small NN in keras for multi-class classification problem. I have 9 different labels and my features are also 9. My train/test shapes are the following: But when I try to make them categorical: I get the following error: Here is more info about the y_train Anyone would know what the problem is?,https://stackoverflow.com/questions/66937155,10168730.0,1
70808125,Generate .record files from xml from labelImg (pascal voc like format) in tensorflow 2,"I am trying out Tensorflow Object Detection API with a custom dataset and currently hitting a wall with several tutorials at the same place of generation of .record files from xml files. For image labelling I have used labelImg set in Pascal VOC format There are several scripts out there for a such conversion like in a documentation titled generate_tfrecord.py (it's written as text) but it and a few others fails to run with tensorflow 2 at two outdated lines: I could fix first with but the last one fails even when you use app.run() with error TypeError: run() missing 1 required positional argument: 'main' Since I just have a simple custom dataset, I figured I cannot use object_detection/dataset_tools/create_pascal_tf_record.py since it requires a year of the pascal dataset and probably also requires specific dataset structure. Is there a script to generate .record that is working with Tensorflow 2 or could you please point me how to fix those scripts to work with Tensorflow 2 ?",https://stackoverflow.com/questions/70808125,13158157.0,1
41886506,How do I access the value of a label in Tensorflow during training/eval?,"I'm working on a neural network in Tensorflow with a custom loss function, which based on the label of the input image I sample a vector (from another data set corresponding to the label) and take the dot product of the input image's embedding (the softmax preactivation) and the sampled vector. I also negatively sample a mismatch vector that conflicts with the input label, along with another random training input image embedding whose label differs from the current input label. Obviously these are all constructed as same-dimensional tensors, and the custom loss is: That was mainly for background, but the issue I'm having is how to access the values of labels corresponding to the input images? I need to be able to access these labels' values in order to sample the correct vectors and compute my loss. I read in documentation that you can use .eval() to get the value of a tensor by running in a session, but when I tried this my terminal just hung... Technically I'm already running a session when I'm training my neural network, so not sure if there is an issue with running a second session inside another session and trying to evaluate values that are technically part of the other running session. Anyway, I'm completely out of ideas as to how I can make this work. Any help would be greatly appreciated! Here's my original attempt that proved problematic:",https://stackoverflow.com/questions/41886506,3296050.0,1
51144993,Tensorflow: Is the learning rate you set in Adam and Adagrad just the initial learning rate?,"I'm reading this blog https://smist08.wordpress.com/2016/10/04/the-road-to-tensorflow-part-10-more-on-optimization/ where it mentions all the tensorflow's learning rates It says that the learning rate you input is only the starter learning rate. Does that mean that if you change the learning rate in the middle of training, that change will have no effect because it's not using the starter learning rate anymore? I tried looking at the API docs and it doesn't specify this.",https://stackoverflow.com/questions/51144993,3259896.0,1
65814700,Hyperparameter tuning with tensorboard HParams Dashboad does not work with custom model,"I got a custom keras Model which I want to optimize for hyperparameters while having a good tracking of whats going on and visualization. Therefor I want to pass hparams to the custom model like this: I followed the guide from TF: Now my training fuction calls the model with my training procedure which looks like this (simplified): The actual optimization starts here: However, if I run this, an error occures when I want to instantiate my model: I´m not sure why this happens and I cannot get it to work. I cannot find anything in the docs. Is there anything I´m missing?? Thanks for the support.",https://stackoverflow.com/questions/65814700,13799627.0,1
60595140,tensorflow: save model and load model,"Currently trying to make this repo works. I'm trying to save the trained model in the local machine so can be applied later. I read in tensorflow's doc, seems pretty intuitive to save the model, by calling tf.save_model.save(object). But I'm not sure how to apply. Original code is here: model.py Following is my changes: The code above produces ValueError as following: ValueError: Tensor(""ICON/CNN/embedding_matrix:0"", shape=(16832, 300), dtype=float32_ref) must be from the same graph as Tensor(""saver_filename:0"", shape=(), dtype=string).",https://stackoverflow.com/questions/60595140,10029273.0,1
48250510,"ValueError: Cannot feed value of shape (100, 1) for Tensor 'Placeholder_1:0', which has shape '(?, 10)'",I was learning Tensorflow from the Tensorflow documentation and was trying to implement MNIST but i keep getting this error. Here's the code,https://stackoverflow.com/questions/48250510,7291866.0,1
52157213,Tensorflow tf.placeholder with shape = [],"I am looking at a Tensorflow code that has learning rate input to the graph using placeholder with shape = [], as below: I looked at the official documentation page of Tensorflow (https://www.tensorflow.org/api_docs/python/tf/placeholder) to understand what would shape=[] mean, but could not get an explanation for the shape set to empty list. If someone can explain what does this mean.",https://stackoverflow.com/questions/52157213,7561372.0,1
52073590,Serving a trained object detection model with tensorflow serve,"I'm having a hard time to serve a tensorflow model, that I've trained from a pretrained model with tensorflow's object detection API. I've trained a model (Resnet101) with the model_main.py script and performance seems to be ready for production use. Thus, I've created a docker container which runs tensorflow-serve. I've managed to serve the model which was created at the end of the the training process. I guess that feature is quiet new, but it seems, that the model_main.py script creates a servable at the end of training. (I found a new folder called ""export"" in my ""train_dir"" which contains a saved_model.pb and the variables variables.data-00000-of-00001 and variables.index). However, I've managed to serve this model and the output form the tensorflow_model_server looks like this: So serving seems to work. The Porblem is, that I'm struggeling to connect to the server with a python client. I've modified the client file that comes with the tensorflow serve inception example and looks like this: If I run this script with properly set ports, I get the error message from inside the modle server: The client returns some random binary strings. But there is clearly a connection and the request reaches the server. It seems to me, that something's wrong with the request by the client, but I have no idea how to set it properly. I didn't find any information on the default signature key, that the model_main.py script uses to export a trained model and trying to create a new servable by using training checkpoints and a modified exporter.py script failed. Does someone know how to set up the client's request properly in this case?",https://stackoverflow.com/questions/52073590,9751892.0,1
51179394,"How can I, with TFLearn, interact with the metrics of the training (current validation accuracy, training accuracy etc?","This is an example from the TFLearn documentation. It shows how to combine TFLearn and Tensorflow, using a TFLearn trainer with a regular Tensorflow graph. However, the current training, test and validation accuracy calculations are not accessible. How do I access the calculated training and validation accuracy at each step in the nested FOR loop? UPDATE FOR CLARITY: A solution might be as follows: Using the fit_batch method of the Trainer class, I believe I am calculating the training and validation accuracy during the nested loop. Does this code calculate the running accuracies as the model trains? Is there a better way of doing this with TFLearn? I understand that tensorboard uses these values. Could I retrieve the values from the eventlogs?",https://stackoverflow.com/questions/51179394,4642684.0,1
52246415,Dense vector on sparse matrix multiplication in tensorflow,"What is proper way of dense vector on sparse matrix multiplication in tensorflow? According to documentation tf.matmul support sparse matrix multiplication, so do I need to use tf.sparse_matmul? (And also tf.sparse_tensor_dense_matmul exist, so in which cases each of them should be used?) Also do I need to convert my sparse matrix to tf.SparseTensor ? Also it not obvious what tf.convert_to_tensor_or_sparse_tensor is doing and how to convert dense numpy matrix or scipy sparse matrix for tensorflow suitable input. Here what I have tried(timing are for CPU): Also I can't see any improvement using sparse matrices, what I'm doing wrong?",https://stackoverflow.com/questions/52246415,1179925.0,1
42470319,Output of Tensorflow LSTM-Cell,"I've got a question on Tensorflow LSTM-Implementation. There are currently several implementations in TF, but I use: Then to get my output I call: I expect rnn_outputs to be of shape (batch_size, time_steps, n_units, input_length) as I have not specified another output size. Documentation of nn.dynamic_rnn tells me that output is of shape (batch_size, input_length, cell.output_size). The documentation of tf.contrib.rnn.BasicLSTMCell does have a property output_size, which is defaulted to n_units (the amount of LSTM-cells I use). So does each LSTM-Cell only output a scalar for every given timestep? I would expect it to output a vector of the length of the input vector. This seems not to be the case from how I understand it right now, so I am confused. Can you tell me whether that's the case or how I could change it to output a vector of size of the input vector per single lstm-cell maybe?",https://stackoverflow.com/questions/42470319,6917400.0,1
70982709,Tensorflow save and load_model not working but save and load_weights does,"I am using tensorflow version 2.8.0: I have seen this issue from multiple sources all over forums, githubs, and even some here for the past 5 years with no definitive answer that has worked for me... For some reason, in certain situations, a loaded model from a previous save yields very different results from the original model evaluation. I haven't seen any well documented and investigative questions about this so I thought I'd show my full code below (simple illustration of the issue). This is an application of transfer learning from a pre-trained tensorflow model. The model is first trained through 5 epochs on train_data, then fine tuned (with more trainable params) for 5 more. Evaluating the model on test_data shows an accuracy of 0.5671. The model is then saved and loaded in .h5 format (I have also tried the tf SavedModel format and the result is the same). The resultant loaded_model yields an evaluation accuracy on the same, unaltered test_data of 0.4535. The result should be the same (0.5671)... so to further investigate I decided to save the fine tuned model's weights independently, construct and compile the same model architecture in new_model, and load the saved model's weights into new_model. Evaluating new_model yields the correct result, an accuracy of 0.5671. ----- Okay, so it must be the weights not saving properly right? I pulled the weights from each of these three models (model, loaded_model, new_model) and compared their flattened results. They are all the same. I really have no idea what's going on here but I'm assuming it is not random initialization, because the loaded_model evaluation results really did not perform anywhere near the fine tuned model - I would assume they would converge much closer.",https://stackoverflow.com/questions/70982709,13978305.0,1
68509390,How to determine the proper dimension of a TensorFlow embedding_column,"I'm new to tensorflow and trying to understand embedding_column. It takes a parameter dimension that isn't totally making sense to me. In this example (from a Google tutorial), dimension = 8 Which I had assumed was 2^3, since there are 3 possibilities and each can be ""on"" or ""off"". However in the documentation example: I'm not tracking why dimension is 9 here. Can anyone explain what the rule should be?",https://stackoverflow.com/questions/68509390,9078185.0,1
50066313,Tensorflow - 2D convolution with mutliple channels,"I am defining my input and my kernels in this way And convolve the two using Yielding a result of What I want to do is to perform one convolution with one ""subfilter"" over the input at the time. Doing it myself with pen and paper, I get All other permutations of the ""reshape-parameters"" yield errors and I cannot find what I am doing wrong in the TF documentation. Does anyone know what I am doing wrong?",https://stackoverflow.com/questions/50066313,4308982.0,1
63407673,How can I add trainable weights while concatenating layers,I am trying to concatenate two layers in such a way that layers are assigned trainable weights while concatenating. The idea behind this is that my model can determine which layer should be given higher weights while concatenating. I have read this code [https://stackoverflow.com/a/62595957/12848819][1] but this one performs the weighted average of the layers. Please help. Let me know if you more questions. Thanks.,https://stackoverflow.com/questions/63407673,12848819.0,1
59438904,Applying callbacks in a custom training loop in Tensorflow 2.0,"I'm writing a custom training loop using the code provided in the Tensorflow DCGAN implementation guide. I wanted to add callbacks in the training loop. In Keras I know we pass them as an argument to the 'fit' method, but can't find resources on how to use these callbacks in the custom training loop. I'm adding the code for the custom training loop from the Tensorflow documentation:",https://stackoverflow.com/questions/59438904,7694977.0,1
68651758,Printing outcome probabilities from a trained Keras Model,"I am attempting to print the predicted probabilities of each class outcome from my trained model, when I present new raw data. This is a multi-class classification problem, with 8 outputs and 21 inputs. I am able to print 1 outcome when I present new data, for example: Instead, I would expect to see something similar to the below. Where the probabilities of each class (0, 1, 2, 3, 4, 6, Wide, Out) are shown: Please note I have tried searching for similar issues including here, here and here as well as consulted the TensorFlow documentation. However, these mainly discuss alterations to the model itself e.g. softmax activation on the final layer, categorical crossentropy as the loss function etc. so that probabilities are generated. I have included the model architecture as well as the prediction code for full visibility. Model: Making predictions: Output: I have tried making changes to the for loop which makes use of TensorFlow's logits, but I am still unable to get it to print each outcome and associated probability. Any guidance is much appreciated.",https://stackoverflow.com/questions/68651758,16306039.0,1
51063631,How to create correctly an estimator with TensorFlow,"I would want to create a neural network with Python and I have some problems with the estimator. First, I read some documentation about estimators specification, and I think I created my estimators type correctly: But when I want to create the estimator that will be used to train my network: There is the following error: Here is my complete code: Can you help me ? EDIT Following the answer of @f4, I corrected my code but I have still the same error: What's wrong again ?",https://stackoverflow.com/questions/51063631,9529736.0,1
53580335,Group by Regression in TensorFlow,"I am very new to TensorFlow - so please bear with me if this is a trivial question. I'm coding in Python+TensorFlow. I have a dataframe with the following structure - Y | X_1 | X_2 | ... | X_p | Grp where Y is the continuous response, X_1 through X_p are features, and Grp is a categorical value indicating group. I want to fit a separate linear regression of Y on (X_1,...,X_p)for each Grp and save the weights/coefficients. I do not want to use the out of the shelf tf.estimator.LinearRegressor. Instead I want to go the loss function-optimizer-session.run() route. The relevant tutorial pages on internet talk about linear regression but not per group. I would appreciate any suggestions. I am thinking to do this - For each g in Grps : 1. Call the optimizer by passing the data for Group g as the placeholders. 2. Get the estimated weights (for Group g) and save them in a dataframe : Grp | weights Another approach that sounds reasonable is to have separate graphs for each group and kick them all together using various ""sessions"". Are these reasonable and feasible in TF? Which one is easier or are there better approaches? Thank you, Sai",https://stackoverflow.com/questions/53580335,4857940.0,1
50361661,Producing summary for gradients via cloud TPU's host_call_fn()?,"My understanding is that host_call and host_call_fn() transfer stats from the TPU to the host. However, the instructions are not very clear on how to generate summary for anything non-scalar. For example, I've tried to modify the official mnist_tpu.py to produce a summary for the gradients produced during training. The model_fn() is where the changes are added: Unfortunately, the addition above doesn't seem to do the trick as with the histogram generation during CPU-based training. Any idea how to properly generate histogram on non-scalar tensors?",https://stackoverflow.com/questions/50361661,9221608.0,1
60106201,Tensorflow 2.0.0 MirroredStrategy NCCL problem,"I'm trying to train with multi-gpu using tf.distribute.MirroredStrategy(). After several attempt to apply to my custom code, it has some error about NcclAllReduce. So I copied mnist tutorial using tf.distribute from tensorflow page, running it has same error. logs and my environments are below",https://stackoverflow.com/questions/60106201,12855597.0,1
67275213,3d input for Dense Layer Keras,"Is there any example of how Keras Dense layer handles 3D input. The documentation explains the following: But I could not understand the internal matrix calculation For example: based on the documentation for a 3D input of shape (m,d0,d1), the shape of Layer's weight_matrix (or) kernel will have the shape (d1, units) which is (2,5) in this case. But I don't understand how the op is calculated to have the shape (m,d0, units)",https://stackoverflow.com/questions/67275213,5927701.0,1
66878893,Tensorflow TextVectorization layer: How to define a custom standardize function?,"I try to create a custom standardize function for the TextVectorization layer in Tensorflow 2.1 but I seem to get something fundamentally wrong. I have the following text data: I basically want to lower the text, remove punctuation and remove some words. The default standardize-Function of the TextVectorization layer (LOWER_AND_STRIP_PUNCTUATION) lowers and removes punctuation, but afaik there is not way to remove whole words. (If you know a way to do so, an alternative approach to mine as described below is of course also very much appreciated) First, find an example of a working custom standardiazion function from the tensorflow documentation when I pass it to the TextVectorization and adapt in on my_array, it works just fine However, my custom standardization keeps raising an error. Here is my code: However, once I try adapting, I keep running in an error: And I really do not understand why. In the documentation it says: I thought maybe thats what is causing the error. but when I look at the shapes, everything seems correct: I am really lost here. What am I doing wrong? am I not supposed to use list comprehensions?",https://stackoverflow.com/questions/66878893,10465165.0,1
51501348,"Tensorflow pipeline, preprocesing on batches : Beginner issue","I'm currently trying to implement my first Tensorflow pipeline, and i have many questions about it works even if i've tried to understand the tf documentation. For the moment, my code looks like : It works well because i obtained what i wanted, that means a array of shape [10,6,4,128,128,3]. But i have no idea about : Thanks a lot for any help that can be useful !",https://stackoverflow.com/questions/51501348,9731056.0,1
48283090,Inverted Colours when Writing an Image using TensorFlow and PIL,"I am trying to save images with bounding boxes displayed on them, just to test that my annotations file is working correctly. Everything works out fine: the image is written to disk, the bounding box is there in the right place and so on. Except all the colours are inverted. So it looks like a negative of the original image. Here is my code: ``` ``` I have searched the tensorflow documentation to no avail. I have also attempted np.roll() and the other suggestions from PIL rotate image colors (BGR -&gt; RGB) again with no luck; those methods were able to change the colour, but not to the correct colours. https://i.stack.imgur.com/N23ia.jpg shows the original image (without bounding box) at the top, and the resulting image (with the colour issue, as well as bounding box) below.",https://stackoverflow.com/questions/48283090,5280140.0,1
48814591,Too many values to unpack in TensorFlow KMean Class,I'm currently using the KMeans Class from tensorflow.contrib.factorization module. My input is (assuming all variables are defined): I'm following the documentation at https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeans to unpack the values like: I get the error: I'm strongly guessing that the documentation in the link stated above isn't updated because the output of kmeans.training_graph() is : Please let me know what is the extra returned valued that I'm not aware of by reading the documentation.,https://stackoverflow.com/questions/48814591,3749292.0,1
40418038,Tensorflow Custom Piecewise Cost Function,"I need to define a custom cost function in tensorflow, which is piecewise in nature, something like this: I am aware that tf.py_func exists, but I am unsure exactly how to use it in the above case. In essence, for each value in each of the tensors (predicted vs target), I need the predicted and the target values to be passed through a function defined by me, which will return slightly different results depending on the values passed through (I have two strictly different learning cases). Then the training step would be defined like this:",https://stackoverflow.com/questions/40418038,1834057.0,1
50255035,Tensorflow dataset with partial shuffle,"I am playing with TensorFlow's dataset API, and I am confused by the shuffle() method, according to the docs: If I only 'partially' shuffle my dataset (e.g. buffer_size &lt;= no. of elements), I'd expect only the first buffer_size elements will be shuffled, however this is not the case, see example: output: why is 5 here? as the buffer size is only 4? the first 2 elements should be within 1~4 right? what am I missing here? Thanks",https://stackoverflow.com/questions/50255035,1182671.0,1
66269271,How to extract weights of DQN agent in TF-Agents framework?,"I am using TF-Agents for a custom reinforcement learning problem, where I train a DQN (constructed using DqnAgents from the TF-Agents framework) on some features from my custom environment, and separately use a keras convolutional model to extract these features from images. Now I want to combine these two models into a single model and use transfer learning, where I want to initialize the weights of the first part of the network (images-to-features) as well as the second part which would have been the DQN layers in the previous case. I am trying to build this combined model using keras.layers and compiling it with the Tf-Agents tf.networks.sequential class to bring it to the necessary form required when passing it to the DqnAgent() class. (Let's call this statement (a)). I am able to initialize the image feature extractor network's layers with the weights since I saved it as a .h5 file and am able to obtain numpy arrays of the same. So I am able to do the transfer learning for this part. The problem is with the DQN layers, where I saved the policy from the previous example using the prescribed Tensorflow Saved Model Format (pb) which gives me a folder containing model attributes. However, I am unable to view/extract the weights of my DQN in this way, and the recommended tf.saved_model.load('policy_directory') is not really transparent with respect to what data I can see regarding the policy. If I have to follow the transfer learning as I do in statement (a), I need to extract the weights of my DQN and assign them to the new network. The documentation seems to be quite sparse for this case where transfer learning needs to be applied. Can anyone help me in this, by explaining how I can extract weights from the Saved Model method (from the pb file)? Or is there a better way to go about this problem?",https://stackoverflow.com/questions/66269271,14451326.0,1
75298969,OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed when using a dataset with tuples,"I am trying to create my own transformer with tensorflow and of course I want to train it. For the purpuse I use dataset to handle my data. The data is created by a code snippet from the tensorflow dataset.from_tensor_slices() method documentation article. Nevertheless, tensorflow is giving me the following error when I call the fit() method: Here is the code that I am using: The code is reduced significantly just for the purpuse of reproducing the issue. I've tried passing the data as dictionary instead of tuple and couple more things but nothing worked. It seems that I am missing something.",https://stackoverflow.com/questions/75298969,5757458.0,1
61137759,ValueError: Cannot reshape a tensor (BERT - transfer learning),"I'm building a multiclass text classification model using HuggingFace's transformers library, using Keras and BERT. To convert my inputs to the required bert format, I'm using the encode_plus method found in the BertTokenizer class found here The data is a paragraph of sentences per feature, and has a single label (of 45 labels in total) The code to convert the inputs is : The model in it's most basic form which still reproduces the error: Compile and fit: The error when I run this : I understand that BERT converts every token into a 768 value array, but that is the only knowledge I have of that particular number, so I'm stuck on how to proceed. If anyone has experience with the HuggingFace library, I would also appreciate your thoughts on whether TFBertForSequenceClassification is appropriate for paragraph classification. Many thanks.",https://stackoverflow.com/questions/61137759,7605543.0,1
47856852,Estimator predict infinite loop,"I don't understand how to make a single prediction using TensorFlow Estimator API - my code results in an endless loop that keeps predicting for the same input. According to the documentation, the prediction is supposed to stop when input_fn raises a StopIteration exception: Here's the relevant part in my code: What am I missing?",https://stackoverflow.com/questions/47856852,2375105.0,1
69623404,tf optimizer compute_gradients error Dimension size,"I am trying to utilize DPGradientDescentGaussianOptimizer to calculate compute_gradients. By followed the documents, sparse_softmax_cross_entropy_with_logits is used then applied to tf.reduce_mean() to calculate the loss. which, But, when I tried to calculate optimizer gradients compute_gradients, it shows dimension error. Error: I did google and looked through StackOverflow with related topics, however, I still don't quite get the issue. My code is only able to execute when the batch size is 1. May I ask for some advice or some help? In addition, why my loss is in shape 0 or None, then it will show the error? Version: Tensorflow-1.15 Python 3.8.10 Thanks!",https://stackoverflow.com/questions/69623404,5238467.0,1
50997293,tf.reduce_mean prints strange results when reduction_indices is specified,"tf.reduce_mean command is used to take mean along specified axis. But if don't specify axis and use reduction indices zero then it prints middle row. Why is it so? How this reduction indices effects output values? If I print sum.eval() command why it prints [[4,5,6]]? I also go through the documentation but it doesn't give any explanation for reduction_indices.Please clear my concept about this command.",https://stackoverflow.com/questions/50997293,9854153.0,1
42453138,Tensorflow automatically deletes old model files,"I use tf.train.Supervisor to start a session to train my model, and save model parameter every 1000 steps. But it seems that tensorflow would automatically delete old model files. Only 5 recent models were saved. Once model.ckpt-6000 is produced, the model.ckpt-1000 is deleted. But I can not find any documents on this operation.",https://stackoverflow.com/questions/42453138,7620627.0,1
60418931,How to create a custom pyfunc to make predictions using a model that requires an input shape with more than two dimensions using MLflow?,"I'm new to TensorFlow and MLFlow and I have a similar problem to the one asked in here. I am implementing a TensorFlow model to predict timeseries values. With that aim, I used MLFlow's mlflow.tensorflow.autolog() to track and serve the models in my instance. Nevertheless, since my input shape has more than 2 dimensions, I was not able to use that method. As previously suggested, I've tried to encode/decode the input data in prediction by using a custom pyfunc to do it. In this way, I have a function model_test.py with a predict method that decode its input data that is: And a run.py file to train and save the model: When I execute the run.py I get the next errors when the model is going to be saved: I have looked at different documentation related to save and serialize TensorFlow models, but there is not so much documentation about TensorFlow models and custom pyfunc functions in MLFlow. Could anyone help me or give me any hint? Thanks in advance!! :D",https://stackoverflow.com/questions/60418931,8338272.0,1
51765061,Display realtime Training of model using tensorboard Python Tensorflow,"I am unable to the documentation of the Tensorboard as there are many confusing stuffs for me. I want to know how I can display the complete training and validation movements of my model in tensorboard. I want to display values and how they are playing as input and what output is getting generated and the MSE error loss for the training and validation. Here is what tried till now. It only gives me the training loss result per iteration in an epoch. Training starts like this: Please anyone please guide me what I can do to see my training and validation lively. I just cannot understand whether my data is making any sense to the model or not. Hence, visualization can become a better option for me. Please help me.",https://stackoverflow.com/questions/51765061,4948889.0,1
48354243,"tensorflow estimator from_generator, how to set TensorShape?","I am trying use a generator to feed data into estimator. The following is the code. However, when try to run, I got the following error: Update2: I finally made it work. So the correct tensorshape is ([], [], []) Update: I added tensorshape ([None], [None], [None]), then I changed ds.batch(10), to an assignment ds = ds.batch(10) but still got error. So my question, how to set the TensorShape? The from generator takes a third argument of TensorShape but I cannot find any example/doc on how to set it. Any help? Thanks,",https://stackoverflow.com/questions/48354243,9243582.0,1
67068742,ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 0,"I am new to TF and Keras. I have model trained and saved using following code Then this model is converted to tflite using Then model is tested for single image using main.py But I am getting even though I resized the image to 200 by 200 If I do print(interpreter.get_input_details()) So it seems shape of input is 'shape': array([ 1, 200, 200, 3] I do get the part 200, 200, 3 it seems 1 is batch size according to docs? How could I remove batch size from input shape?",https://stackoverflow.com/questions/67068742,7356355.0,1
67801758,tf.Variable gets converted to normal tensor in loop,"I have a custom layer in Keras in which I define some variables to which I assign some values in the call section. this works but if i try to utilize a for loop over all the indeces: this gives me an error saying that ""'Tensor' object has no attribute 'assign'"". Why does this happen? How can I solve it? I tried looking at the documentation but I still don't get it. Thanks in advance to anyone who may answer.",https://stackoverflow.com/questions/67801758,10067045.0,1
60248322,Parse field names and types from TFRecord,"I am trying to build a generic utility functions to help me work with TFRecord objects. For this, I am looking to parse field names and types from a TFRecord object (in Python). The TF documentation gives some example on how to print these. This prints output such as: I can even print the individual field info (knowing the name) as Which prints out So most of the information seems to be there. This data has two fields ""class"" (type tf.int64) and ""image"" (type tf.string). The Example object seems to be of type tensorflow.core.example.example_pb2.Example. Which has some functions such as keys(), items(), ... but none of these give me access to the feature names and types as far as I can see. There also seems to be some kind of generic ""id"" field in the output that is not part of the original list of fields. And the type tf.int64 seems to appear as a list with one item. So it is close but not quite. And I have trouble accessing the field names and types through the Python objects. I'd rather not start parsing the string output, and guessing type mappings from it. So I guess the question is, is it possible for me to parse the actual TFRecord format from the file itself?",https://stackoverflow.com/questions/60248322,1187237.0,1
47432870,Can tf.contrib.training.batch_sequences_with_states handle input sequences with variable lengths?,"I was trying to use tf.contrib.training.batch_sequences_with_states to create padded batches of variable length input sequences in order to train an LSTM network. While reading the documentation I stumbled upon contradicting statements, concerning the capabilities of this function. Specifically the parameter input_sequences is confusing to me. How do I supply this function with multiple examples? Executing this code snippet leads to the following error message: An example showing how to correctly supply this function with multiple examples of varying input_sequence lengths would be really helpful!",https://stackoverflow.com/questions/47432870,5970048.0,1
65943540,How to preprocess a pandas dataset for TensorFlow,"I'm trying to do an experiment with using svg data on the mnist images as an input into a fullyconnected Neural Network in Tensorflow I've parsed the images and put them into a csv file with each row a different image, the first column is the classifier (0-9) and the remaining columns are the coordinates (x1,y1,x2,y2 etc) What I'm trying to do next is use pad_sequences to add zeros and truncate each ""image"" to 70 coordinates and then use keras preprocessing to normalize the data so that it can be effectively intput into the NN. The details of the above is pretty arbitrary. I've tried many variations of the above only to get a variety of TypeErrors. I've gone through the pandas dataframe documentation and the pad_sequences documentation, but I feel I'm missing something more basic, namely, in layperson's terms: how do I pull out a row of this dataframe (minus the classifier) to pad and how do I pull out a column (minus the labels) to normalize?",https://stackoverflow.com/questions/65943540,13412712.0,1
57206247,How to fix ‘RuntimeError: The Session graph is empty. Add operations to the graph before calling run().”,"I just simply typed the code given in tf.Tensor Tensorflow 2.0, and here is my code: But it raised an error: What could I do to fix this error?",https://stackoverflow.com/questions/57206247,11837392.0,1
68441442,Use of tf.while_loop with 1-D tensors as input to produce 2-D tensors,"I need to perform a loop in parallel wit GPUs of a function that computes independently the rows of a matrix. I was using map_fn, but to be able to have the parallel computing enabled with the eager execution, as far as I understand, I've to use the while_loop function. Unfortunately I find not very intuitive how to use this function, so I'm kindly asking to you how to convert map_fn to while_loop in my code. Here a simplified version of the code: The version with while_loop I wrote, following the example in the documentation and other questions here on Stackoverflow is: But in this case what I obtain is: Where is the mistake? Thanks in advance. If needed I can provide a simplified runnable code. EDIT: adding below the runnable code The output image is:",https://stackoverflow.com/questions/68441442,6044435.0,1
54697451,Output TFRecord to Google Cloud Storage from Python,"I know tf.python_io.TFRecordWriter has a concept of GCS, but it doesn't seem to have permissions to write to it. If I do the following: then I get 401s saying ""Anonymous caller does not have storage.objects.create access to my-bucket-name."" However, on the same machine, if I do gsutil rsync -d r gs://my-bucket-name bucket-backup, it properly syncs it, so I've authenticated properly using gcloud. How can I give TFRecordWriter permissions to write to GCS? I'm going to just use Google's GCP python API for now, but I'm sure there's a way to do this using TF alone.",https://stackoverflow.com/questions/54697451,1129436.0,1
51608408,TensorFlow Serving: Pass image to classifier,"I have built a simple classifier in Tensorflow (Python, tensorflow 1.9.0 and tensorflow-serving 1.9.0) which classifies objects into one of 5 classes. Now, I would like to serve that model. I have exported it and given it a classification signature (and only a classification signature): which, further down the line, becomes: And when I start the TF server I can see that the model is being served. My problem is how to pass an image to is from the client. The code is as follows: And this is where I am sort of lost and somewhat confused. For a PredictionRequest the code is: but that does not work for a ClassificationRequest. The error is: Neither does: which gives the error: My question, therefore, is: What do I need to do pass an image to the classifier using a ClassificationRequest?",https://stackoverflow.com/questions/51608408,1938803.0,1
55900270,Attacking Tensorflow model with Cleverhans' CarliniWagnerL2 resulting in NotImplementedError,"I'm trying to get familiar with tensorflow and cleverhans. But it seems that I get functionalities mixed up. I set up a simple model with tensorflow, train it and then want to craft an adversarial image with cleverhans' CarliniWagnerL2-attack. I read through the code of tensorflows and cleverhans' documentation and tried to understand whats happening but I just don't get which function from which library I have to use. This is my simplified example code. As far as I understood I have to turn a callable into a valid function using the CallableModelWrapper. Is that right? Or is my model no callable? Is it actually possible to use tensorflow to train a model and then attack it with cleverhans? The error occurs when I try to generate the adversarial image. I actually want to get the adversarial image but whatever I try it seems that I use a mix of the two libraries and they don't go well together. I get: NotImplementedError: must implement get_logits or must define a logits output in fprop Can anyone help? Basically I just want to understand what models I can use for cleverhans.attacks ! :) Thanks in advance. Rolle Edit This is my Traceback: I replaced my internal directory structure by path_to_project or me respectively.",https://stackoverflow.com/questions/55900270,5138206.0,1
65153063,How can MobileNetV2 have the same number of parameters for different custom input shapes?,"I'm following the tensorflow2 tutorial on fine-tunning and transfer learning using a MobileNetV2 as base architecture. The first thing I noticed is that the biggest input shape available for pre-trained 'imagenet' weights is (224, 224, 3). I tried to use a custom shape (640, 640, 3) and as per the documentation, it gives a warning saying that the weights for the (224, 224, 3) shape were loaded. So if I load a network like this: It gives the warning: If I try to use an input shape like (224, 224, 3) then the warning vanishes, nevertheless, I tried to check the number of trainable parameters in both cases using and found out that the number of trainable parameters is the same even though the number size of the Convolutional filters changes accordingly to the custom input shape. So how can the number of parameters remain the same even when the Convolutional filters have bigger (spatial) sizes?",https://stackoverflow.com/questions/65153063,3562468.0,1
49287202,How to periodically save tensorflow model using saved_model API?,"So for various reasons (such as its language-independence) I want to use tensorflow's saved_model API for saving/loading models. I can save everything (and restore it successfully) with a call to builder.add_meta_graph_and_variables() at the end of training, but I don't see any way to save periodically. Tensorflow docs on this are very sparse, and the template code they provide (here) doesn't help me: Calling builder.save() does not save the new variables into the model. It just updates the model protobuf. What am I missing? How do I save after e.g. the nth epoch using saved_model?",https://stackoverflow.com/questions/49287202,8721926.0,1
45469356,Number of steps doesn't match when using tf.estimator.Estimator,"I am figuring out the TensorFlow estimator framework. I finally have code for a model that trains. I am using a simple MNIST autoencoder for my tests. I have two questions. The first question is why the number of steps reported by training is different from the number of steps I specify in estimator train() method? The second one is how to use training hooks to do things like periodic evaluations, loss output every X steps etc? The docs seem to say to use training hooks, but I cannot seem to find any actual examples of how to use these. Here is my code: And here is the output I get (notice how training stops at 550 steps where the code explicitely calls for a 1000) Update #1 I found the answer to the first question. The reason training stopped at step 550 was because numpy_input_fn() defaults to num_epochs=1. I am still looking for help with training hooks though.",https://stackoverflow.com/questions/45469356,302268.0,1
48552103,"Why does the TensorFlow tf.data.Dataset.shuffle function's reshuffle_each_iteration boolean argument default to None, as opposed to True?","The documentation for the tf.Dataset.data.shuffle function states the following: However, the default value in the function is None, as mentioned on the same page and in the actual code: The function calls the ShuffleDataset class, whose __init__ function also sets the same argument to None by default, and uses the following logic to set the default value of the argument to True: Why isn't the argument just set to True by default in both the function and the class? This would make the above code block redundant and allow replacing it with only self._reshuffle_each_iteration = reshuffle_each_iteration.",https://stackoverflow.com/questions/48552103,6457747.0,1
66422617,Neural network attack foolbox (FGSM),"I am trying to attack a keras neural network model located in a file (model.h5) and per foolbox's documentation, TensorFlowModel supports keras models. However, when I apply this to my keras model, I get an error. I wonder if it is due to the foolbox version I am using? Code: Error:",https://stackoverflow.com/questions/66422617,15307177.0,1
50017241,Converting grayscale to RGB in tfrecord,"I have a dataset of grayscale images, and I'd like to use the sdd-mobilenet checkpoints for training my object detection. What is the proper way to convert grayscale images to RGB that I can convert my dataset to tfrecord? Here is the code that I use (notice that the commented parts didn't work for me)",https://stackoverflow.com/questions/50017241,8130289.0,1
51370733,Running RNN in Tensorflow,"If I have an array of 20 elements of type float. Based on the values of the first ten elements I want a RNN to predict what the value of the last ten elements are. Using various online resources and books I have gotten a RNN built that reads the first 10 elements and processes them. However I don't know how to get it to use the last ten elements as an 'answer key' and train based off that. The data in ""a"" which I'm giving to the feed dict looks something like this: in the step where I sliced the data_np like so : steps = data_np[0:,2:12] I got those first ten numbers successfully but how do I grab the last ten and feed them in so as to train the network? I'm assuming the end of my code needs to look something like below, where the y placeholder holds the 'answer key' for the RNN. However, I cannot make it come together.",https://stackoverflow.com/questions/51370733,3878186.0,1
66748911,Wrapper layer to change kernel weights,"I'm trying to write a custom wrapper layer such as the following one (simplified), where I want to modify the kernel weights of the wrapped layer: However, the code breaks in the first line of the call function with the following output: I've already checked https://www.tensorflow.org/addons/api_docs/python/tfa/layers/WeightNormalization but am not sure whether it helps. While they also seem to redefine the kernel, they redefine it based on separate variables and not the kernel itself (in my understanding). Any help would be greatly appreciated!",https://stackoverflow.com/questions/66748911,2135504.0,1
73496717,"In neural networks, activation is applied by a function or layer?","I am using the Functional API of the TensorFlow/Keras for building a CNN model. In this model, I am trying to apply a custom activation (with constraints) on the output layer. After going through various resources (1, 2), I am confused about whether the activation needs to be applied by a simple python function or layer. I tried implementing it by subclassing the Layer class as follows, and called it in the model as where x is the previous layer instance. My questions are:",https://stackoverflow.com/questions/73496717,11936209.0,1
61389657,How to manually initialize a TF 1.x LSTMCell and dynamic_rnn,"Background info: I need to use TF 1.x to create an LSTM, and save the model. I am using saver = tf.train.Saver(), which IS working in the sense that it saves four files that allow me to restore my graph and use my model to make predictions. However, the predictions are as bad as the initial run of the model, instead of being as good as the final model. I don't know why, because I've used Saver successfully for my last assignment, and I'm using the same lines of code (updated with correct names), in the same order: define graph, declare saver, train model, call save_path = saver.save(sess, ""my_model"") after training but in the same session. Anyway, that's all background. I've given up trying to figure out why Saver isn't working. I did realize that if I manually initialize my weights, for example, using: Then the saved model will use those weights. So I'm trying to train my model, manually save the weights, then run my script again - initializing using those manually saved weights, using Saver this time, which will save the initial model (which is the same as the final model at the end of my last training session). However, I don't know how to manually initialize an LSTMcell or dynamic_rnn. I've tried everything I can think of, based on the Tensorflow manual, other questions on stackoverflow, and some blog posts, but nothing is working. Here's how I add the cells to my graph: My question: How do I manually initialize these layers? I've been trying to use initial_state, but apparently not correctly. Currently I've been using: Where sval_f is the state_val saved from the previous training session. This generates an extremely long error message that I haven't deciphered yet. UPDATE: Ok, I think I've realized that the initial_state is actually a Tensor of size [Batch_size, cell_size] that represents the states of the hidden cells on the first batch, NOT the initial weights. What I need to find out is how to export the weights from the LSTMCell and dynamic_rnn, and how use those to manually initialize them during later sessions. SECOND UPDATE I've learned how to get the weights from the LSTM, using: I can also set the weights of the LSTM to those values during training using: However, I don't know how to INITIALIZE the LSTM with those weights, and it seems like Saver isn't going to save my weights unless the LSTM is initialized with them.",https://stackoverflow.com/questions/61389657,6394617.0,1
62488108,Reformat Tensor in Tensorflow,"I have a tensor of data which is the output of a net in Tensorflow, however, I want to reformat it into a larger batch size composed of elements of the original tensor. That wasn't very clear, so let's say the output of my net is a tensor with shape (10, 1000, 1) - (batch_size, length, features), and I want to reformat it so that I now have (500, 10, 1) which are 500 vectors of length ten from the original data set. I am familiar with numpy, so I was just going to use that but you can only use numpy with EagerTensors. I'm not sure if this is an additional problem, but I am attempting a GAN network so the code looks like: I mention this as I am unsure if reformatting the data in this context would mess up the training.",https://stackoverflow.com/questions/62488108,11132990.0,1
57614436,od_graph_def = tf.GraphDef() AttributeError: module 'tensorflow' has no attribute 'GraphDef',"I have a mac and I am using tensorflow 2.0, python 3.7. I am following the tutorial for creating an object detection model for real-time application. but i am getting the following error: below is the tutorial link: I checked the environment and I already have tensorflow environment in anaconda",https://stackoverflow.com/questions/57614436,11838316.0,1
46648536,Tensorflow initialize certain scope only,"He there, I have a question regarding control over which variable scope is initialized, or at least, which variable scope is used during the run. Take for example this easy piece of code If I would run this as is, I would get the shape of variable z as is defined in variable scope '1'. But how can I specify which variable scope to use during the session? I couldn't find any answer on stackoverflow or in the documentation... Of course I could just rename both z's to z1 and z2... but I want to stay on the situation where both scopes look a lot like each other and use the same names...",https://stackoverflow.com/questions/46648536,6329284.0,1
53963654,Error running Tensorflow Object Detection with custom dataset,"I've been trying to use tensorflow's object detection api for a school project and I've managed to follow their instructions in the documentation, but I'm getting this error I can't find anywhere online. This is the output in the console: This is what I'm running and here is the pipeline.config file",https://stackoverflow.com/questions/53963654,,1
41621333,Tensorflow LSTM character by character sequence prediction,"I am attempting to replicate the character level language modeling demonstrated in the excellent article http://karpathy.github.io/2015/05/21/rnn-effectiveness/ using Tensorflow. So far my attempts have failed. My network typically outputs a single character after processing 800 or so characters. I believe I have fundamentally misunderstood the way tensor flow has implemented LSTMs, and perhaps rnns in general. I am finding the documentation to be difficult to follow. Here is the essence of my code: Graph definition Loss Calculation Training Output, using 1MB Shakespere file to train This is clearly incorrect. I think I am getting confused by the difference between 'batches' and 'sequences', and as to whether or not the state of the LSTM is preserved between what I call 'batches' (ie, sub-sequences) I'm getting the impression that I've trained it using 'batches' of sequences of length 1, and that between each batch, state data is discarded. Consequently it is simply finding the most commonly occurring symbol. Can anyone confirm this, or otherwise correct my mistake, and give some indication of how I should go about the task of character by character prediction using very long training sequences? Many Thanks.",https://stackoverflow.com/questions/41621333,4646735.0,1
42939426,Tensorflow placeholder error,"I have been playing around with tensorflow, I have managed to train the mode and serve it but when i try run the client to send data for classification i get this error I do not quite understand this error, here are my placeholders And i used the builder as in the documentation, writing the prediction_signature as well as classification signatures. If any may know why this is happening i would be extremely grateful",https://stackoverflow.com/questions/42939426,6664161.0,1
45022315,Tensorflow ValueError: Too many vaues to unpack (expected 2),"I have looked this up on Reddit, Stack Overflow, tech forums, documentation, GitHub issues etc etc and still can't solve this issue. For reference, I am using Python 3 TensorFlow on Windows 10, 64 Bit. I am trying to use my own dataset (300 pics of cats, 512x512, .png format) in Tensorflow to train it to know what a cat looks like. If this works I will train it with other animals and eventually objects. I can't seem to figure out why I am getting the error ValueError: too many values to unpack (expected 2). The error appears in the line images,labal = create_batches(10), which points to my function create_batches (see below). I don't know what could be causing this as I am fairly new to TensorFlow. I am trying to make my own Neural Network based on the MNIST Dataset. Code below: And the Error: My GitHub link link if anyone needs it. The project folder is the ""imgpredict"".",https://stackoverflow.com/questions/45022315,,1
74127178,costum loss : check max and min values of variable of type <class 'tensorflow.python.framework.ops.Tensor',"I wrote a costum loss function in tensorflow. But sth is going wrong, because the error is larger 1 which shouldnt be possible. So I want to look up the values of y_predicted and y_true as well as the new calulated loss. but I don't know how to get acces to these values. y_pred and y_true are both of the type &lt;class 'tensorflow.python.framework.ops.Tensor' this is my costum loss fct: and the output is: As you can see I don't get much information out of it. Do you know how tho get the right values. I have batches of size 8 . And I get my input from a generator fct. Thanks in advance! Best regards",https://stackoverflow.com/questions/74127178,19313272.0,1
66894031,CNN using tensorflow from_tensor_slices,"I'm trying to make a classification CNN using image data. I have 10,000 images, which I've divided up into 8,000 for training and 2,000 for validation. They start out as simple numpy arrays with shape (8000, 192, 192) and (2000, 192, 192) respectively. I'm trying to load them into TF following this documentation. It loads correctly and runs fine with a fully-connected network but I run into issues when I try to replace the Flatten layer with a Conv2D layer. I load the images into TF datasets using: The model I'm trying to run is: This fails immediately with the following error: I read that this relates to the shape of the data going into the network, so I tried adding a layer that reshapes the images before going into the convolutional laye: The model builds and compiles when this is added (seemingly no matter numbers I actually put into the reshape layer), but then when I try to fit it, I get the following error: I can't seem to find any examples of datasets created using tensors_from_slices being used with CNNs, only with fully connected networks. In case it's relevant: I'm using a Google Colab notebook that has Python 3.7 and TensorFlow 2",https://stackoverflow.com/questions/66894031,5124723.0,1
45155864,Tensorflow LinearRegressor not converging,"I'm attempting to do a toy linear regression in Python with TensorFlow, using the pre-built estimator tf.contrib.learn.LinearRegressor instead of building my own estimator. The inputs I'm using are real-valued numbers between 0 and 1, and the outputs are just 3*inputs. TensorFlow seems to fit the data (no errors raised), but the outputs have no correlation to what they should be. I'm not sure I'm getting the predictions done correctly- the documentation for the predict() function is pretty sparse. Any ideas for how to improve the fitting? Scatter plot of results",https://stackoverflow.com/questions/45155864,1552018.0,1
46111888,Initializing variables with imported tensors from another graph,"I am using tensorflow (version : v1.1.0-13-g8ddd727 1.1.0) in python3 (Python 3.4.3 (default, Nov 17 2016, 01:08:31) [GCC 4.8.4] on linux), it is installed from source and GPU-based. I would like to know if it is possible to initialize variables with imported tensors from another session, as tensorflow documentations does not mention it and I have found it on stackoverflow. Here the tensors are successfully imported and I want to use them to initialize same generator. Thanks for your help!",https://stackoverflow.com/questions/46111888,8572742.0,1
66477586,Loading Custom Data into TensorFlow with .get_file(),"I'm relatively new to Tensor Flow and Stack overflow, so please be patient. My question is as follows: 'How do I load in a custom dataset spreadsheet into TensorFlow using the .get_file() method and pandas read method?' I have searched the TensorFlow website, stack overflow, and other websites but they all seem to either use publically available data online or do some strange imports with different methods that I do not understand. Here is what I currently have: Thank you so much for reading!",https://stackoverflow.com/questions/66477586,15290446.0,1
63514487,TFLiteConverter Segmentation Fault when running integer quantization,"I'm using tensorflow==1.15.3 and I'm hitting a segmentation fault attempting int8 post-training quantization. The documentation for the 1.15 version of the TFLiteConverter can be found here. I found a similar issue on github, but their solution to provide --add_postprocessing_op=true has not solved the segmentation fault. I've debugged it using PDB and found exactly where it crashes. It never reaches my representative_dataset function. It faults when running CreateWrapperCPPFromBuffer(model_content): Here is my conversion code: FWIW my model conversion works for tf.float16 (not using representative_dataset there, though).",https://stackoverflow.com/questions/63514487,3969602.0,1
40029904,Understanding why tensorflow RNN is not learning toy data,"I am trying to train a Recurrent Neural Network using Tensorflow (r0.10, python 3.5) on a toy classification problem, but I am getting confusing results. I want to feed in a sequence of zeros and ones into an RNN, and have the target class for a given element of the sequence to be the number represented by the current and previous values of the sequence, treated as a binary number. For example: It seems like this is something an RNN should be able to learn quite easily, but instead my model is only able to distinguish classes [0,2] from [1,3]. In other words, it is able to distinguish the classes whose current digit is 0 from those whose current digit is 1. This is leading me to believe that the RNN model is not correctly learning to look at the previous value(s) of the sequence. There are several tutorials and examples ([1], [2], [3]) that demonstrate how to build and use Recurrent Neural Networks (RNNs) in tensorflow, but after studying them I still do not see my problem (it does not help that all the examples use text as their source data). I am inputting my data to tf.nn.rnn() as a list of length T, whose elements are [batch_size x input_size] sequences. Since my sequence is one dimensional, input_size is equal to one, so essentially I believe I am inputting a list of sequences of length batch_size (the documentation is unclear to me about which dimension is being treated as the time dimension). Is that understanding correct? If that is the case, then I don't understand why the RNN model is not learning correctly. It's hard to get a small set of code that can run through my full RNN, this is the best I could do (it is mostly adapted from the PTB model here and the char-rnn model here): The final output here is which indicates that it is only learning to distinguish [0,2] from [1,3]. Why isn't this model learning to use the previous value in the sequence?",https://stackoverflow.com/questions/40029904,2712140.0,1
59427969,Mathematical definition of tensordot operation on TensorFlow tensor,"I'm trying to reverse engineer the behavior of tf.tensordot axes parameter, but having a hard time. Given the following code: I understand how ""d"" is produced, but I don't understand how ""e"" and ""f"" are produced. The TensorFlow Documentation is not sufficient for me to understand.",https://stackoverflow.com/questions/59427969,3656912.0,1
58271820,How to replace Keras' gradients() function with GradientTape in TF2.0?,"With the ""old"" Keras library I created heatmaps for my CNNs using the keras.backend.gradients() function, like this: Now I switched to TF2.0 and it's built-in Keras implementation. Everything works fine, however, using that code I get the following error when calling K.gradients(): I did some research and tried to understand how I can make use of GradientTape, but unfortunately I don't know much about TF nor TF2.0 - I always worked with Keras. Can you guys guide me how I can make this gradient calculation work again with my setup?",https://stackoverflow.com/questions/58271820,514149.0,1
51081570,tf.estimator.inputs.pandas_input_fn label tensor,"Was trying out Tensorflow's built in pandas_input_fn() with a pandas dataframe that I named training_examples It's a very simple dataframe, describing one set of features and labels; this is then passed as argument x in the pandas_input_fn() function as shown below, which, if I understand the docs correctly, should return an input function with the data already parsed into features and labels? However, when I then try and pass this function to the .train() method, I get an error as shown below: Not sure what I'm doing wrong?",https://stackoverflow.com/questions/51081570,9999488.0,1
52177257,Noob stuck Tensor flow adjusting the array shape,"first thank you for any help that you can give. I am absolutely lost on the shape in tensensorflow. I have searched google, StackOverflow, discord, and youtube. I want to run a RNN on a CSV file. #So I have 120 input neurons? Since I have 120 columns? I am getting lost even trying to explain it. AM I on the right track? I know there is a lot of info out there and I did read the documentation. Any help would be greatly appreciated.",https://stackoverflow.com/questions/52177257,10193731.0,1
71909901,Guiding tensorflow keras model training to achieve best Recall At Precision 0.95 for binary classification,"I am hoping to get some help on the titular topic. I have a database of medical data of patients with two similar pathologies, one severe and one much less so. I need flag most of the formers (≥95%) and leave out as many of the latter as possible. Therefore, I want to create a binary classifier that reflects this. Looking around on the web (not an expert) I put together this piece of code, substituting the metric I found with RecallAtPrecision(0.95) in the middle part of the code. Below is an abridged version: However, it simply doesn't work, as it throws the following error: I am at a loss about why that happened, as I can clearly see it in the documentation. The code works if I use Recall(), Precision() or most any other metrics. Looking around some more, I am beginning to think I am missing something fundamental. Do any of you fine ladies and gentlemen have any pointers on how to solve this problem?",https://stackoverflow.com/questions/71909901,18846088.0,1
69230524,merging train and test datasets into one using tensorflow,"I am working with the classic titanic dataset and trying to apply NNs. My data comes already split into train and dev sets. However, I want to merge the datasets together for many things (for example, my own splitting, etc..) Is there a way I can merge both datasets? I have looked around and only found information about how to split a dataset, but I was unable to find how to merge them back together. Any help? A MWE is provided below!",https://stackoverflow.com/questions/69230524,9371999.0,1
62485318,Problems understanding linear regression model tuning in tf.keras,"I am working on the Linear Regression with Synthetic Data Colab exercise, which explores linear regression with a toy dataset. There is a linear regression model built and trained and one can play around with the learning rate, the epoch and the batch size. I have troubles understanding how exactly the iterations are done and how this connects to the ""epoch"" and the ""batch size"". I am basically not getting how the actual model is trained, how data is processed and iterations are done. To understand this I wanted to follow this by calculating each step manually. Therefore I wanted to have the slope and intercept coefficient for each step. So that I can see what kind of data the ""computer"" uses, puts into the model, what kind of model results at each specific iteration and how iterations are done. I tried first to get the slope and intercept for each single step, however failed, because only at the end the slope and intercept is outputted. My modified code (original, just added:) code: In my specific case my output was: Now I tried to replicate this in a simple excel sheet and calculated the rmse manually: However, I get 21.8 and not 23.1? Also my loss is not 535.48, but 476.82 My first question is therefore: Where is my mistake, how is the rmse calculated? Second question(s): How can I get the rmse for each specific iteration? Let's consider epoch is 4 and batch size is 4. That gives 4 epochs and 3 batches with each 4 examples (observations). I don't understand how the model is trained with these iterations. So how can I get the coefficients of each regression model and rmse? Not just for each epoch (so 4), but for each iteration. I think each epoch has 3 iterations. So in total I think 12 linear regression models result? I would like to see these 12 models. What are the initial values used in the starting point when no information is given, what kind of slope and intercept is used? The starting at the really first point. I don't specify this. Then I would like to be able follow how the slope and intercepts are adapted at each step. This will be from the gradient descent algorithm I think. But that would be the super plus. More important for me is first to understand how these iterations are done and how they connect to the epoch and batch. Update: I know that the initial values (for the slope and intercept) are choosen randomly.",https://stackoverflow.com/questions/62485318,2165335.0,1
45097828,Tensorflow: load multiple images to process (Python),"I am working on a Tensorflow project (https://github.com/niektemme/tensorflow-mnist-predict) and I am in front of a problem. In the file named predict_2.py there is a block of code which load an image.. Normally, I execute all the code (not just this one) in CMD so the program works. What I would like to do now is to load multiple images (maybe from a different folder) and not just to pass the argv in the console which load only one image at the time. What I previously thought was to create an array/list of images and then to put it instead of im variable. It doesn't work... Can someone help ? Documentation on Tensorflow (and even the project itself) are very poor (atleast for me). Thank you. EDIT: Here is full code",https://stackoverflow.com/questions/45097828,8193135.0,1
73138108,Tensorflow Batch Normalization results dependent on number of channels in input,"I'm trying to port weights for batch normalization from tensorflow to pytorch and I encountered a strange issue in tensorflow. The below code excerpt computes batchnorm with 10 channels with input of purely ones and default batch norm parameters. You can see that last 2 channels compute to a different value than the rest for 10 channels in an input. We also get different results for different number of channels, I presented example of 5 and 8 channels inputs. And I get a results: for n_channels=10: for n_channels=5: for n_channels=8: The problem is 0.9995004 and 0.9995002 results, even during the same inference. I know it is not big difference, but if we get multiple batch norms in a model it might very easily propagate into much bigger error. I also tried computing it manually with tensorflow and numpy according to tensorflow documentation gamma * (batch - self.moving_mean) / sqrt(self.moving_var + epsilon) + beta, and I get the 0.9995004 result, so it seems 0.9995002 is simply wrong. I also tried this on two different machines and got the same results. Here is the code for manual check: Tensorflow versions checked: 2.4.0 and 2.9.1 Numpy version checked: 1.21.5 So here are the questions:",https://stackoverflow.com/questions/73138108,19631281.0,1
50421555,Argmax function of Tensorflow does not print value when evaluated on a constant tensor,"I'm new at Tensorflow. I am having a litte trouble at understanding its constants. I have this simple code mentioned below: I expect this to return something like [4,7,8], as I understood from the documentation. Instead, I get this: So, i don't know what am I doing wrong.",https://stackoverflow.com/questions/50421555,7070099.0,1
46627032,Truncated Back Propagation (BPTT) for RNN in Tensorflow,"https://www.tensorflow.org/tutorials/recurrent#truncated_backpropagation Here, Official TF document says, and the document entails; These lines implement truncated backpropagation(BPTT) part, but I'm not sure above code part is essentially needed. Does Tensorflow (I'm using 1.3) conduct proper backpropagation automatically, even if hand-written back prop implementation part is absent? Does putting the BPTT implementation code increases prediction accuracy noticeably? The code above uses returned state from RNN Layer from previous timestep to feed RNNCell of next timestep. According to the official document, RNN(GRUCell, LSTMCell...) layer returns tuple of output and state, but I built my model only with output, and didn't touch state. I just passed output to Fully connected layer, and reshaped, then calculated loss with tf.losses.softmax_cross_entropy.",https://stackoverflow.com/questions/46627032,5110804.0,1
56680233,TF gradient returning zero for simple problem,"In TF 2.0, I traced back a bug and isolated to this simple problem: tf.gradient is giving zero gradient, it should be infinity. As you can see, the loss should be infinite cause -log(1-1) in the binary cross entropy. However, I looked up documentation and I noticed that they clip the numbers before applying the log, that's why 15.333 show up instead of infinity. That's great, and help avoiding many troubles during training, BUT, what about the gradient? It is producing zero! According to my math it should be infinite, so, at least it should be producing something very high, rather than zero. As such, my training is stuck! Why is that happening? How did I even arrive at this point? and how come that this doesn't happen when I use Keras high level built classifier models?",https://stackoverflow.com/questions/56680233,10870968.0,1
72973349,how to add text preprocessing tokenization step into Tensorflow model,"I have a TensorFlow model SavedModel which includes saved_model.pb and variables folder. The preprocessing step has not been incorporated into this model that's why I need to do preprocessing(Tokenization etc) before feeding the data to the model for the prediction aspect. I am looking for an approach that I can incorporate the preprocessing step into the model. I have seen examples here and here however they are image data. Just to get an idea how the training part has been done, this is a portion of the code that we did training (if you need the implementation of the function I have used here, please let me know(I did not include it to make my question more understandable )) Training: And this is the preprocessing that I use for the training: and inferencing would be like this: And this is the implementation of model_fn_builder: And this is the implementation of create_intent_model This is the list tensorflow related libraries: There is good documentation here, however, it uses Keras API. Plus, I don't know how can I incorporate preprocessing layer here even with the Keras API. Again, my final goal is to incorporate the preprocessing step into the model building phase so that when I later load the model I directly pass the The movie is ok to the model? I just need the idea on how to incorporate a preprocessing layer into this code which is function based. Thanks in advance~",https://stackoverflow.com/questions/72973349,7934786.0,1
52785019,Specify shape for categorical feature columns?,"I know that I can use a categorical_column_with_identity to turn a categorical feature into a series of one-hot features. For instance, if my vocabulary is [""ON"", ""OFF"", ""UNKNOWN""]: ""OFF"" -&gt; [0, 1, 0] However, I actually have an 1-dimensional array of categorical features. I would like to turn that into a 2-dimensional series of one-hot features: [""OFF"", ""ON"", ""OFF"", ""UNKNOWN"", ""ON""] -&gt; [[0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]] Unlike every other feature column, it doesn't seem like there's a shape attribute on categorical_column_with_identity and I didn't find any help through Google or the docs. Do I have to give up on categorical_column_with_identity and create the 2D array myself through a numerical_column?",https://stackoverflow.com/questions/52785019,2510391.0,1
50590061,Different types of divisions in TensorFlow,"I am very new to TensorFlow. So I came across this different types of division in TensorFlow from here. Code printed below: Since I am a noob in programming languages I could not understand some of their documentation which included things like ""computes division python style"", etc. If someone can explain the differences between all and their practical aspect, I would be grateful.",https://stackoverflow.com/questions/50590061,8560127.0,1
48514123,"Tensorflow: SavedModelBuilder, How to save model with best validation accuracy","I have gone through tensorflow documentation but couldn't find the way of saving model with best validation accuracy, using SavedModelBuilder class. I am using tflearn for model building and below is the work around i have tried but it is taking lot of time, where i am running fit method for each epoch separately and saving model Please suggest if there is a better approach.",https://stackoverflow.com/questions/48514123,2398191.0,1
61257008,How to properly quantize CNN into 4-bit using Tensorflow QAT?,I am trying to make 4-bit quantization and used this example First of all I received the following warnings: Than after reading this doc I found that it is possible to quantize my network into 4 bit but I couldn't understand is it possible for only Dense layer or for all (like Conv2D)? I also don't understand how to work with weights since numpy can work only with float32. UPD: I finally figure out how to perform quantization aware training But I still can't understand how to access the 4-bit quantized weights. I used np.array( quantized_model.get_weights() ) but of course it gave me float32 moreover the number of elements in the quantized array is less than in original model. How this can be explained?,https://stackoverflow.com/questions/61257008,2336778.0,1
46219326,How to use tf.losses.log_loss in tensorflow?,What is the input of tf.losses.log_loss ? Anybody can show me some examples about it ? Official guide has no examples .,https://stackoverflow.com/questions/46219326,6407393.0,1
56000660,Backpropagatable Transformations with Tensorflow,"I want to transform general tensors / vectors in Tensorflow, but to have a concrete example let's say rotate images. For this I would like to have a rotation matrix R, which is learned by my network, i.e. there should be gradients computable. How would you do this? I found tf.contrib.image.transform, but for this it is said no gradients are computed into the transformation parameters. Via py_func also the gradients are not available or would have to be calculated by hand - before writing a long custom solution for this (if even possible), are there maybe any ready-to-use solutions? I cannot be the first one doing this. For the requested code: I just want to feed an image as input, maybe apply some convolutional layer and in the end get a 2x2 matrix representing my transformation: The matrix M then describes how my indices are transformed (imagining each pixel in the image as a vector with endpoint x, y), and I move each pixel then to its new location. In numpy I could for example do this:",https://stackoverflow.com/questions/56000660,4063857.0,1
70054691,"Input to reshape is a tensor with 8434176 values, but the requested shape requires a multiple of 78400","I'm running a convolutional neural network to classify cats and dogs. Here's my code. I'm using the 'Cat and dog' dataset from Kaggle: https://www.kaggle.com/tongpython/cat-and-dog. When I try to fit the model, (that's this part: ), TensorFlow throws this error: I didn't find any similar resources on StackOverflow. I don't know what I'm doing wrong. Can you help?",https://stackoverflow.com/questions/70054691,17112669.0,1
53233633,2 Layer Neural Network Does not Converge,"I am a newbie to TensorFlow and I am trying to understand the basics of deep learning. I started from writing a two-layer neural network from scratch and it achieved 89% accuracy on MNIST dataset and now I am trying to implement the same network in TensorFlow and compare their performance. I am not sure if I miss something basic in the code, but the following implementation seems to be unable to update weights and therefore could not output anything meaningful. I checked many the official docs and many other implementations, but I feel totally confused since they may use different versions and API varies greatly. So could someone help me, thank you in advance.",https://stackoverflow.com/questions/53233633,7784797.0,1
71951333,Prepare data input for tensorflow from numpy and scipy.sparse,"How to prepare data for input into a tensorflow model (say a keras Sequential one) ? I know how to prepare x_train, y_train, x_test and y_test using numpy and scipy (eventually pandas, sklearn style) where train/test datas are train and test datas for training a neural model, and x/y stand for a 2D sparse matrix and a 1D numpy array representing integer labels of the same size as the number of raws in the x data. I'm struggling with the Dataset documentation without many insight so far ... So far, I could only convert the scipy.sparse matrix into a tensorflow.SparseTensor using something like and I can convert the numpy array into a tensorflow.Tensor using something like Examples of x and y are",https://stackoverflow.com/questions/71951333,8844500.0,1
46125018,Use LSTM tutorial code to predict next word in a sentence?,"I've been trying to understand the sample code with https://www.tensorflow.org/tutorials/recurrent which you can find at https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py (Using tensorflow 1.3.0.) I've summarized (what I think are) the key parts, for my question, below: My biggest question is how do I use the produced model to actually generate a next word suggestion, given the first few words of a sentence? Concretely, I imagine the flow is like this, but I cannot get my head around what the code for the commented lines would be: My sub-questions are: (I'm asking them all as one question, as I suspect they are all connected, and connected to some gap in my understanding.) What I was expecting to see here was loading an existing word2vec set of word embeddings (e.g. using gensim's KeyedVectors.load_word2vec_format()), convert each word in the input corpus to that representation when loading in each sentence, and then afterwards the LSTM would spit out a vector of the same dimension, and we would try and find the most similar word (e.g. using gensim's similar_by_vector(y, topn=1)). Is using softmax saving us from the relatively slow similar_by_vector(y, topn=1) call? BTW, for the pre-existing word2vec part of my question Using pre-trained word2vec with LSTM for word generation is similar. However the answers there, currently, are not what I'm looking for. What I'm hoping for is a plain English explanation that switches the light on for me, and plugs whatever the gap in my understanding is. Use pre-trained word2vec in lstm language model? is another similar question. UPDATE: Predicting next word using the language model tensorflow example and Predicting the next word using the LSTM ptb model tensorflow example are similar questions. However, neither shows the code to actually take the first few words of a sentence, and print out its prediction of the next word. I tried pasting in code from the 2nd question, and from https://stackoverflow.com/a/39282697/841830 (which comes with a github branch), but cannot get either to run without errors. I think they may be for an earlier version of TensorFlow? ANOTHER UPDATE: Yet another question asking basically the same thing: Predicting Next Word of LSTM Model from Tensorflow Example It links to Predicting next word using the language model tensorflow example (and, again, the answers there are not quite what I am looking for). In case it still isn't clear, what I am trying to write a high-level function called getNextWord(model, sentencePrefix), where model is a previously built LSTM that I've loaded from disk, and sentencePrefix is a string, such as ""Open the"", and it might return ""pod"". I then might call it with ""Open the pod"" and it will return ""bay"", and so on. An example (with a character RNN, and using mxnet) is the sample() function shown near the end of https://github.com/zackchase/mxnet-the-straight-dope/blob/master/chapter05_recurrent-neural-networks/simple-rnn.ipynb You can call sample() during training, but you can also call it after training, and with any sentence you want.",https://stackoverflow.com/questions/46125018,841830.0,1
45782031,Testing image on Tensorflow Mnist Model using checkpoints,"I am a newbie to TensorFlow.I got the mnist train sample and I want to test an image by generating the checkpoints.I referred to Tensorflow documentation and generated checkpoints and tried to test a sample image by accessing the softmax layer.But given an image number-9 softmax gives me an invalid one-hot-encoded array like 'array([[ 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)',when I tried to access the softmax using softmax = graph.get_tensor_by_name('SOFTMAX:0'). I tried testing with different images,it didn't give proper result for any of them. 1.I asssumed, softmax will give me an array of probabilities.Am I right? 2.Am I saving the model properly? 3.Am I accessing the correct layer for testing an input? 4.Is there anything further to be added in my testing/training code? Sorry for posting everything here. This is my train code: The accuracy was 0.97. This is my test code: So when I tested with an image of number 9 ,it gave me the following output: softmax is [[ 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]] softmax maximum val is 1 I have no idea,where I am going wrong.Any help would be really useful and greatly appreciated.",https://stackoverflow.com/questions/45782031,5830044.0,1
64778081,How to implementing conditional bijectors in Tensorflow (mainly a how to use a kwargs question as that gets me an error),"I'm trying to implement a conditional bijector. That's not important what it is if you don't know, but essentially my code is this: conditional_input = x2 is a kwarg. Essentially I get this error: The problem is the function call(self, x, conditional_input) has this conditional_input that is suppose to be fed in as a **kwargs per TF documentation (at least according to my very bad understanding of kwargs) and I think the **kwargs is not getting fed to conditional input as an argument (as the default value for conditional_input is None which is what I think is raising the error). I don't think a super detailed knowledge of TensorFlow is necessary to answer this question. I think my lack of being able to understand and work with kwargs is what is causing this program not to work. Curious if someone can suggest the way to use kwargs (or another method) so that the call method will accept my conditional_input. Thanks, Cameron",https://stackoverflow.com/questions/64778081,3716368.0,1
58711366,Simple keras dense model freezes while fitting,"I am learning NLP with Keras and I am going through a tutorial. The code is the following: Towards the end of the first epoch the model freezes and makes no further progress: When I dropped the last 1,000 sentences and repeated the process I got the same situation but now at an earlier point: I restarted my PC (Windows 10) but this did not solve the problem. I then uninstalled tensorflow and reinstalled. Then I run the following code found in the official documentation of tensorflow 2.0: But when I rerun the NLP code again the model froze while fitting the data:",https://stackoverflow.com/questions/58711366,8270077.0,1
35148121,Assign op in TensorFlow: what is the return value?,"I was trying to build an autoincrementing graph in TensorFlow. I thought that the assign op might be suitable for that, but found no documentation for it. I assumed that this op returns its value—like in C-like languages—and wrote the following code: and this code works. The question is: is this the expected behavior? Why is the assign op not documented here: https://www.tensorflow.org/versions/0.6.0/api_docs/index.html Is it a non-recommended op?",https://stackoverflow.com/questions/35148121,258483.0,1
42697341,"How to use softmax activation function at the output layer, but relus in the middle layers in TensorFlow?","I have a neural net of 3 hidden layers (so I have 5 layers in total). I want to use Rectified Linear Units at each of the hidden layers, but at the outermost layer I want to apply Softmax on the logits. I want to use the DNNClassifier. I have read the official documentation of the TensorFlow where for setting value of the parameter activation_fn they say: I know I can always write my own model and use any arbitrary combination of the activation functions. But as the DNNClassifier is more concrete, I want to resort to that. So far I have:",https://stackoverflow.com/questions/42697341,4933403.0,1
44472358,Handling large image dataset in tensorflow,"I have a dataset of over 1.5 million images and I have to classify them into 62 classes. I have created two numpy array features (path of png images) and labels (int label). Now I want to load these images using opencv, but handing such large loaded input in RAM is inefficient. So I also tried following using tensorflow input pipeline documentation: But this is getting stuck when I run it ( I tried printing the shape of tensor, which is coming as expected, but its not printing the batch of my features). It will be really helpful if someone can guide me a better way to create batches and load images which can be later fed into the tensorflow model.",https://stackoverflow.com/questions/44472358,3316461.0,1
55615954,"Understanding device allocation, parallelism(tf.while_loop) and tf.function in tensorflow","I'm trying to understand parallelism on GPU in tensorflow as I need to apply it on uglier graphs. In the code above, var is a tensor with length 100000, whose elements are updated as shown above. When I change the parallel_iterations values from 10, 100, 1000, 10000. There's hardly any time difference (all at 9.8s) even though explicitly mentioning the parallel_iterations variable. I want these to happen parallely on GPU. How can I implement it?",https://stackoverflow.com/questions/55615954,7779411.0,1
56685995,Resnet50 image preprocessing,"I am using https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/3 to extract image feature vectors. However, I'm confused when it comes to how to preprocess the images prior to passing them through the module. Based on the related Github explanation, it's said that the following should be done: However, using the aforementioned transformation, the results I am getting suggest that something might be wrong. Moreover, the Resnet paper is saying that the images should be preprocessed by: which I can't quite understand what is means. Can someone point me in the right direction? Looking forward to you answers!",https://stackoverflow.com/questions/56685995,3987085.0,1
62511834,TensorFlow - Tensorflow update_state() missing 1 required positional argument: 'y_pred' when using tfa.metrics.CohenKappa,Looking at the docs for tfa.metrics.CohenKappa I'm trying to figure out how to use it with a simple model. I've written the following code: That produces the following model: If I uncomment the cohenKappa line I get the following error: What am I missing?,https://stackoverflow.com/questions/62511834,1115237.0,1
42012906,Create a custom Tensorflow histogram summary,"There are a couple of SO answers on creating a custom scalar summary in TF (here and here), but I can't find anything on creating a custom histogram summary. The documentation seems to be very lacking for custom summaries. I have a numpy array of that I'd like to make a summary of - any ideas on how? (tf.Summary.Value has a histo field that I tried using, but it requires a tensorflow::HistogramProto; there's no documentation on that class either, so I'm at a loss on how to make it. I've tried creating a minimal failing example below).",https://stackoverflow.com/questions/42012906,4880003.0,1
64941304,Unable to give Keras neural network multiple inputs,"I am trying to get a data pipeline of text based data into a neural network with two heads. Made use of the official documentation that tells you to zip it into a dictionary of values, but it did not work. These are the shapes of the data that will go into each head. Have been converted into sequences of ints using the VectorizeLayer() This is the graph of the neural network enter image description here I am constructing the final dataset using But this is the error it keeps throwing",https://stackoverflow.com/questions/64941304,14680310.0,1
75722924,Shapes for training data and labels,"I am trying to train a convolutional neural network using Conv1D and sparse_categorical_crossentropy as a loss function but I keep having problems related to the shapes of the data. Here is the network: The input data has a shape (1, 1000, 4). It consists of 4 signals made of 1000 floats between which I am trying to discriminate. The training consistently fails with various error messages depending on the shape of the labels. For example, if I use or I obtain whereas, if I use, I obtain I have tried many things based on the documentation or the examples I have found but I don't manage to make it work. Thank you very much! It no longer crashes with some other loss functions such as binary_crossentropy for example. But the minimisation does not work (unless the learning rate is tiny) and the end result does not tally with the training data.",https://stackoverflow.com/questions/75722924,,1
54812292,I try to print in TensorBoard an audio with tf.summary.audio any audio is shown,"I'm using Python 3.6 and TensorFlow 1.8 in a Linux environment. I'm trying to print an audio in TensorBoard with the following code, and even is storing a file, no audio is printed. I have been looking examples or information, but there is no much about tf.summary.audio. This is a example that I found but can't make it work. Thank you",https://stackoverflow.com/questions/54812292,11097109.0,1
42124562,tensorflow attributeerror moddule has no attribute per_image_standardization,"I'm trying to go through the tutorial on convolutional neural nets using cifar10. The cnn is being built (cifar10.py) but when I try to run cifar10_train.py I'm getting the following error: According to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/image.md, there is indeed a per_image_standardization attribute but it looks like my tensorflow doesn't have it. I'm not sure what version I have and not sure where to find it, but I built it from source from the repository so I imagine it's the current one. I can't find anyone else who is having this problem so I'm stymied. Maybe I have to write my own?",https://stackoverflow.com/questions/42124562,7465271.0,1
69595923,How to decrease the learning rate every 10 epochs by a factor of 0.9?,I want to set the learning rate at 10^-3 with a decay every 10 epochs by a factor of 0.9. I am using the Adam optimizer in Tensorflow Keras. I have found this code in the official documentation: I do not know what is this decay_steps=100000. Actually I want to decrease my learning rate after 10 epochs. How can I do it?,https://stackoverflow.com/questions/69595923,14808637.0,1
63235675,Break a tensorflow.while_loop conditionally,"I am trying to modify the GPT-2 sample generating code from nshepperd's fork (https://github.com/nshepperd/gpt-2). Specifically the code below which is part of the sample.py file: Essentially what I am trying to do is make it stop once it has generated a token with a specific value, e.g. !EndText!. However, as I am very new to tensorflow I am very uncertain about how to do this, especially as the official documentation on this is slightly sparse. If I understand correctly, I need to modify the cond function (which I understand to loop over all the outputs of the body function) so that it breaks if enc.decode(output)==""!EndText!"" however I am more or less at a complete loss on where to start.",https://stackoverflow.com/questions/63235675,6845464.0,1
43929037,What is the difference between LSTMBlockCell and BasicLSTMCell in Tensorflow contrib.rnn,"I know that LSTMBlockCell is efficient to initialize at the begining of training. The official API guides of Tensorflow said that LSTMBlockCell add a forgot_bias. Can I just replace the BasicLSTMCell with LSTMBlockCell in my RNN models? And there are too many stuffs in tf.contrib.rnn, I feel that those APIs are really inconsistent.",https://stackoverflow.com/questions/43929037,8000679.0,1
59911740,Custom loss function that skips the NaN input,"I am building an autoencoder, my data has NaN values in it. How do I create a custom (MSE) loss function, that does not compute loss if it encounters a NaN in the validation data? Got a hint from the web: But receive loss of NaN: When I try using the custom loss function in my callback function, after each epoch:",https://stackoverflow.com/questions/59911740,2179152.0,1
47844264,tf.shape() returns a 2-d tensor instead of 1-d,"In the tensorflow API tf.shape, it says However, when I call I get the result of [[59]], which is a 2-D integer tensor. The feature_index can be print as I thought this is a normal [1, 59] tensor. I try the following code: It looks as expected. I want transform feature_index to shape of [59,1]. Would anyone knows why the return type is 2-d and how to convert the tensor?",https://stackoverflow.com/questions/47844264,3528980.0,1
46087294,using tf.nn.dynamic_rnn to make LSTM RNN of multiple hidden layers,I read the documentation of tf.dynamic.rnn in https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn and used it to make a single layer rnn of multiple time-steps. I was wondering if I could use tf.dynamic.rnn to stack multiple hidden layers. Is it possible to do so?,https://stackoverflow.com/questions/46087294,6147251.0,1
45308755,No scalar data in tensorboard,I have been reading tensorboard documentation about scalars and I have a problem with presenting it in tensorboard. I have pip install tensorflow in windows 10 my code looks like this: I see there is a file in my_folder in command prompt: tensorboard --logdir=my_folder --port 6006 out: When I open browser i get:,https://stackoverflow.com/questions/45308755,8053410.0,1
57153123,Remove stdout output from tf.Session due to init in a loop,I've come to stack overflow because no one else seems to have asked this question before. When running my tensorflow model I use it inside a loop to do regression analysis. I use tf.Session inside the lop loop: with tf.Session as sess: ...code rest of code When I run the neural network it spits out all the tensorflow/core information in the loop and makes my actual output (for me to visualize) useless. I'd like to either re-direct the output or find a way to make it less verbose or completely silent. I've gone through most of the documentation from tensorflow and the Session documentation doesn't reveal anything to me. Here is the current output to the terminal.,https://stackoverflow.com/questions/57153123,11821139.0,1
53823287,Keras Xception model input shape confusion,"I'm reading the docs here which says that input shape has to be (299,299,3) if I specify include_top=True. However, if I set input_shape=None (where the input shape is really (32,32,3)) the model trains. So why is it that this is working? Minimal example:",https://stackoverflow.com/questions/53823287,2089899.0,1
69536507,Understand relation between different tensorflow AdagradOptimizer APIs,"I am new to tf, and during reading a model code, I noticed it used 1), but most document I can find are using 2) and 3). So what is the tensorflow.python library used for,seems it is not in official document? And what is the relation between 1 to 2,3?",https://stackoverflow.com/questions/69536507,1269298.0,1
72123555,AssertionError: Some Python objects were not bound to checkpointed values on Jetson Nano with TensorRT,"I am trying to run Inference on my Jetson Nano with TensorRT, but this Error keeps popping up. I dont really work with .pb model rather than .h5 models thats why I am converting my Model to .pb from .h5. I am using this script to convert my model to a tensorrt model, its a modification of the nvidia docs scripts, but more or less the same : Nvidia Docs",https://stackoverflow.com/questions/72123555,11398803.0,1
58628787,What is the intuition behind the Iterator.get_next method?,"The name of the method get_next() is a little bit misleading. The documentation says Python also has a function called next, which needs to be called every time we need the next element of the iterator. However, according to the documentation of get_next() quoted above, get_next() should be called only once and its result should be evaluated by calling the method run of the session, so this is a little bit unintuitive, because I was used to the Python's built-in function next. In this script, get_next() is also called only and the result of the call is evaluated at every step of the computation. What is the intuition behind get_next() and how is it different from next()? I think that the next element of the dataset (or feedable iterator), in the second example I linked above, is retrieved every time the result of the first call to get_next() is evaluated by calling the method run, but this is a little unintuitive. I don't get why we do not need to call get_next at every step of the computation (to get the next element of the feedable iterator), even after reading the note in the documentation In general, it is not clear how the Iterator works.",https://stackoverflow.com/questions/58628787,3924118.0,1
74719668,Somewhat Resolved: Problem with Upsampling for Image Classification,"I have an image dataset of 12 classes. I'm comparing some different techniques of upsampling for image classication and wanted to upsample the classes that are massively imbalanced using SMOTE. I defined by training set as seen below: Output : ""Found 11730 files belonging to 12 classes. Using 9384 files for training."" The problem is, from my understanding, is that in order to upsample with SMOTE, I have to actually have a defined x_train &amp; y_train. I attempted to do so with The shape returns (8,256, 256, 3). This ""8"" feels out of place. I imagined that the shape would be the length of my training set, but maybe I'm misunderstanding. I re-shaped the numpy array to make it 2D to be passed through SMOTE The shape returns (8, 196608) Finally, the above returns the error that n_samples = 1, n_neighbors = 2. My questions are Any help is appreciated! SMOTE initialisation expects n_neighbors &lt;= n_samples, but n_samples &lt; n_neighbors ^This forum was extremely helpful but I still can't explain the shape of my numpy array. My solution: I ended up just duplicating a specified number of images for each of the underrepresented categories. I did the preceding in File Explorer.",https://stackoverflow.com/questions/74719668,16978547.0,1
49280251,How to use tensorflow.feature_column outside of Estimator for prediction?,"I want to use the tensorflow feature_column and feature directly with a session, bypassing the Estimator framework. I read tensorflow's low level introduction on feature column. The problem is that tf.feature_column.input_layer needs the features feed at construction, but the feature feeds are different between training and prediction time. Looking at the tf.Estimator codes, it seems the way is to call the same construction callback function again to get the graph. I came up with the example below, but it fails on table not initialized if I skip the table init after the second construction; or it would complain table already initialized if I do run the table init. According to their research paper, this is by design since they always expect a new model to be reloaded from save point. But this will be very inefficient for situation like reinforcement learning where we want to do updates and inferences at the same time in a training loop. It is also unclear how they want to do dev validation. What's the correct way to construct graph and feed features for prediction?",https://stackoverflow.com/questions/49280251,1293964.0,1
54440859,Eager execution in Tensorflow 2,I am testing code on Google Colab. It seems that Google Colab runs the version 2 of Tensorflow by default: and that this version does not have eager execution: I could not find documentation on TensorFlow 2. Nor could I run an older version of TensorFlow: And this thread from 5 months ago suggests that we cannot downgrade Tensorflow versions. Is it possible to enable eager execution on Google Colab?,https://stackoverflow.com/questions/54440859,9251158.0,1
33932901,What's the purpose of tf.app.flags in TensorFlow?,"I am reading some example codes in Tensorflow, I found following code in tensorflow/tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py But I can't find any docs about this usage of tf.app.flags. And I found the implementation of this flags is in the tensorflow/tensorflow/python/platform/default/_flags.py Obviously, this tf.app.flags is somehow used to configure a network, so why is it not in the API docs? Can anyone explain what is going on here?",https://stackoverflow.com/questions/33932901,5607347.0,1
53998796,IPython Notebook Kernel Crashes when Assessing CNN Accuracy,"I'm relatively new to TensorFlow. I have built a Logistic Regression classifier and a MultiLayer Perceptron in the past that have worked. Now that I have moved on to the Convolutional Neural Network, I am having some problems with testing accuracy. My code is below. The line I am having trouble with is only the very last line where I am attempting to print the test accuracy figure. The print 1, 2, 3 statements are intended to show this. Apologies for the big code dump. I want make sure the issue is reproducible. The result of this code in my notebook is a pop-up window that says, ""The kernel appears to have died. It will restart automatically."" I'm hoping this is some small error in my syntax or something, but I've search all the functional documentation and forums and haven't identified my issue. Any help is appreciated!",https://stackoverflow.com/questions/53998796,4882698.0,1
48767184,Tensorflow running session multiple times in a loop,I'm trying out a simple Tensorflow code to compute the product of two matrices multiple times. My code is as follows: Upon running session.run() in the for loop: I get the following error: I looked at the sample code for MNIST on the Tensorflow website but they run 'session.run()' in a similar manner in a for loop. I'm looking for any insight on why 'session.run()' in my code does not work inside a for loop. Thank you.,https://stackoverflow.com/questions/48767184,5279281.0,1
45959112,Get coefficients of a linear regression in Tensorflow,I've done a simple linear regression in Tensorflow. How can I know what are the coefficients of the regression? I've read the docs but I cannot find it anywhere! (https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) EDIT Code example,https://stackoverflow.com/questions/45959112,3070571.0,1
34141430,Tensorflow Tensor reshape and pad with zeros,"Is there a way to reshape a tensor and pad any overflow with zeros? I know ndarray.reshape does this, but as I understand it, converting a Tensor to an ndarray would require flip-flopping between the GPU and CPU. Tensorflow's reshape() documentation says the TensorShapes need to have the same number of elements, so perhaps the best way would be a pad() and then reshape()? I'm trying to achieve:",https://stackoverflow.com/questions/34141430,4975126.0,1
59364641,Outputting multiple loss components to tensorboard from tensorflow estimators,"I am pretty new to tensorflow and I am struggling to get tensorboard to display some of my custom metrics. The model I am working with is a tf.estimator.Estimator, with an associated EstimatorSpec. The first new metric I am trying to log is from my loss function, which is composed of two components: a loss for an age prediction (tf.float32) and a loss for a class prediction (one-hot/multiclass), which I add together to determine a total loss (my model is predicting both a class and an age). The total loss is output just fine during training and shows up on tensorboard, but I would like to track the individual age and the class prediction loss components as well. I think a solution that is supposed to work is to add a eval_metric_ops argument to the EstimatorSpec as described here (Custom eval_metric_ops in Estimator in Tensorflow). I have not been able to make this approach work, however. I defined a custom metric function that looks like this: The instructions seem to say that I need both the error metric and the update function which should both be returned from the tf.metrics command as in examples like the one I linked. But this command fails for me with the error message: I am probably just misusing the APIs. If someone can guide me on the proper usage I would really appreciate it. Thanks!",https://stackoverflow.com/questions/59364641,2365779.0,1
60786257,How to view samples from ImageDataGenerator(),"I am currently working through a tutorial which is using the cifar10 images. I have written some fully working code which has the line model.fit(x_train, y_train) where x_train as a numpy array of dimension 50000x32x32x3 and dtype ""uint8"". I.e. it contains 50000 32x32 pixel colour images. I can display a sample of these images with calls to imshow() - it all looks and works fine. But now in the next part of the tutorial it suggests that the model will generalise better if we use ImageDataGenerator() to create multiple warped (rotated, zoomed, sheered etc) versions of our training images. I want to better understand ImageDataGenerator() by displaying some of the warped images that are produced in the process. Looking at the documentation, it gives the following example: My current code (without warping) trains the model with the line model.fit(x_train, y_train), so looking at the line in the example model.fit(x_batch, y_batch) I assume that x_batch must be a collection of 32 different warped versions of the current x_train image. I tried to write some code so that I could actually display the 32 images like so: I thought that the first time through the loop I would be shown 32 different warped versions of the zeroth image in x_train. But when I run this it produces almost blank images - I say almost because one or to of them may contain a few garbage looking pixels. I expected x_batch to be of size 32x32x32x3, i.e. a collection of 32 colour images of size 32x32pixels and 3 colours which indeed appears true but the dtype was float32 which confuses me - I thought the warping process would not change the dtype. Have I got a bug in my code or have I misunderstood the documentation?",https://stackoverflow.com/questions/60786257,169774.0,1
61882452,Tensorflow tf.layer.batch_normalization: how to use global moving stats to do normalization during training?,"From the documentation, the arg training It never mentioned that this arg also controls whether to update global moving stats. Even if the update ops is added through they will not be updated is training=False. I am curious if there is a way to have these moving stats keep updating during training, at the same time use them to perform normalization?",https://stackoverflow.com/questions/61882452,11111055.0,1
37668485,Create an int list feature to save as tfrecord in tensorflow?,How can I create a tensorflow record from a list? From the documentation here it seems possible. There's also this example where they convert a numpy array into a byte array using the .tostring() from numpy. However when I try to pass in: I get the error: Which doesn't help me to figure out how to store a list of integers into the tfrecord. I've tried looking through the docs.,https://stackoverflow.com/questions/37668485,6416660.0,1
49868782,How to use tf.argmax,"I want to test the function of tf.argmax(),but when I run the code , I encountered an error. Here is my code My environment is python3 + tf1.3. What's wrong with the code?",https://stackoverflow.com/questions/49868782,9639109.0,1
44264962,how tf.space_to_depth() works in tensorflow?,"I am a pytorch user. I have got a pretrained model in tensorflow and I would like to transfer it into pytorch. In one part of model architecture, I mean in tensorflow-defined model, there is a function tf.space_to_depth which transfers an input size of (None, 38,38,64) to (None, 19,19, 256). (https://www.tensorflow.org/api_docs/python/tf/space_to_depth) is the doc of this function. But I could not understand what this function actually do. Could you please provide some numpy codes to illustrate it for me? Actually I would like to make an exact similar layer in pytorch. Some codes in tensorflow reveals another secret: Here is some codes: And here is the output: As you can see above, In Addition to data reshaping, the tensor values has changed!",https://stackoverflow.com/questions/44264962,3475688.0,1
41909915,tf.train.string_input_producer behavior in a loop,"The following snippet has been taken from the TensorFlow 0.12 API documentation The question I have might be very basic for a regular TensorFlow user, but I am an absolute beginner. The question is the following :",https://stackoverflow.com/questions/41909915,6842947.0,1
50655213,Does input_ parameter matter to tf.Print?,"I read the description for the parameter input_ of tf.Print in this link. I tried a couple of experiments and got the results makes me so confused. I used this following code to experiment Output [[1 2 3]][[4 5 6]] I have replaced the line of code p = tf.Print(A, [a1, a2]) with p = tf.Print(a1, [a1, a2]) or p = tf.Print(a2, [a1, a2]) and got exactly the same output: [[1 2 3]][[4 5 6]]. This makes me feel that ""it does not matter what input_ is, you can pass whatever you want"" My questions are I found a similar question here, but IMO it does not cover the aspect what I wonder in this question.",https://stackoverflow.com/questions/50655213,5657159.0,1
63984268,Need help in understanding Encoder-Decoder code in Tensorflow,"I am reading ""Hands-On Machine Learning with Scikit-Learn and TensorFlow"" by Aurelion Geron. I am currently reading the Encoder-Decoder section of the book and I stumbled upon some code that I don't fully understand, and I find the explanations from the book to be unsatisfactory (at least for someone like me, a beginner). The following picture presents the model we are trying to implement (or to be more precise, we will implement a model that is similar to the following picture, not exactly this model): (picture from Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, chapter 16, page 543, figure 16-3) This is the code that was used (again, the above model is not the exact thing we are going to code. The author explicitly said that the model we will build is just similar to the above picture): There are things in the above code that I don't know what they do, and there are things that I think I know what they do, so I'll try to explain exactly what I am confused about. If I am wrong in anything that I say from this point, please let me know. We import tensorflow_addons. In lines 2-4 we create the input layers for the encoder, for the decoder, and for the raw strings. We could see in the picture where these would go. A first confusion arises here: Why is the shape of encoder_inputs and decoder_inputs a list with the element None in in, while the shape of sequence_lengths is an empty list? What are the meaning of these shapes? Why are they different? Why must we initialize them like this? In lines 5-7 we create the embedding layer and apply it on the encoder inputs and on the decoder imputs. In lines 8-10 we create the LSTM layer for the encoder. We save the hidden state h and the memory cell state C of the LSTM, as this will be the input into the decoder. Line 11 is another confusion for me. We apparently create a so called TrainingSampler, but I have no idea what this is or what it does. In the words of the author: I don't really understand this explanation. What exactly does the TrainingSampler do? Does it tell the decoder that the correct previous output is the previous target? How does it do that? And even more imporantly, would we need to change this sampler during inference (since we wouldn't have the targets during inference)? In lines 12 and 13, we define the decoder cell and the output layer. My question here is why do we define the decoder as LSTMCell, while we declared the encoder as LSTM, not a cell. I read on stackoverflow that LSTM is a recurrent layer, while LSTMCell contains the calculation logic for one step. But I don't understand why we had to use LSTM in the encoder and LSTMCell in the decoder. Why this difference? Is it because in the next line, the BasicDecoder actually expects a cell? In the next few lines, we define the BasicDecoder and apply it on the decoder embeddings (again, I don't know what sequence_lengths does here). We get the final outputs, which we then pass through a softmax function. There's a lot going on in that code and I am really confused about what happens. If someone could clear things up a bit, I would be extremely grateful.",https://stackoverflow.com/questions/63984268,11641316.0,1
74481219,How to get number of values in each row of a sparse tensor?,"I have a Sparse Tensor as follows: I want to convert this sparse tensor to another 1D tensor of shape (5, 1) where the only column represents the number (or size) of values in each of the rows. For example, for the above sparse tensor, desired 1D tensor would be [3, 2, 0, 3, 4]. How can I do it? I tried going through the TensorFlow API docs but couldn't find anything to try.",https://stackoverflow.com/questions/74481219,3243499.0,1
66283913,Error in computing gradients in keras(tensorflow backend),I am trying to compute gradients of one of CNN filters from VGG16 w.r.t an image input using tensorflow-gpu version 2.4.1 and Keras version 2.4.3 with the following code: this results in the following error: Also trying to use tf.GradientTape raised another error: trying to disable eager execution did not work either: since it returns gradients as None. I would appreciate any kind of information about any way to resolve this issue. Thanks in advance.,https://stackoverflow.com/questions/66283913,12654107.0,1
71322383,Tff: define the usage of Tensorflow.take() function,I am trying to mimic the federated learning implementation provided here: Working with tff's clientData in order to understand the code clearly. I reached to this point where I need clarification in.,https://stackoverflow.com/questions/71322383,17534198.0,1
61087933,Inequivalent output from tf.nn.conv2d and keras.layers.Conv2D,"I've been reading the Hands-On Machine Learning textbook (2nd edition) by Aurélien Géron (textbook publisher webpage here). I've gotten into the content that applies CNNs to images. In the section titled Tensorflow Implementation of Chapter 14, they manually create filters that get passed to tf.nn.conv2d and applied to an image to produce a set of feature maps. After these manual filter examples, the book says: The above quote implies to me that given identical inputs (and equivalent initializations), we should be able to derive identical outputs from tf.nn.conv2d and keras.layers.Conv2D. To validate this idea, I looked up whether the two functions were equivalent. According to this previously answered SO post, for convolution, the two functions are the same. I set out to perform a simple test of their equivalence. I created a convolutional layer consisting of one feature map using a 7x7 filter (a.k.a: convolutional kernel) of all zeros that was implemented separately for tf.nn.conv2d and keras.layers.Conv2D. As expected, after summing all the pixel values in the difference of both images, this filter did cause the output images to have a value of zero for each pixel value. This difference of zero implies that the output images are identical. I then decided to create the same 7x7 filter, but with all ones this time. Ideally, both functions should produce the same output, therefore the difference in the two output images should be zero. Unfortunately, when I check the difference in the output images (and sum the differences at each pixel), I get a nonzero sum value. Upon plotting the images and their difference, it is evident that they are not the same image (though they do look very similar at a glance). After reading through the documentation for both functions, I believe that I am giving them equivalent inputs. What could I be doing/assuming incorrectly that is preventing both functions from producing identical outputs? I have attached my code and versionining information below for reference. The code uses the scikit-learn china.jpg sample image as input and matplotlib.pyplot.imshow to help in visualizing the output images and their difference.",https://stackoverflow.com/questions/61087933,3217457.0,1
55040014,How to weight clip in tensorflow?,"I am coding a wgan in tensorflow on mnist dataset and it works well but I am finding it difficult to clip weights of discriminator model [-0.01,0.01] in tensorflow. In keras we can do weight clipping using. I have found a tensorflow doc for weight clipping discrimantor Other than this there is not much is given to how use this function.",https://stackoverflow.com/questions/55040014,996366.0,1
71919267,Trying to achieve same result with Pytorch and Tensorflow MultiheadAttention,"I'm trying to recreate a transformer written in Pytorch and implement it in Tensorflow. The problem is that despite both the documentation for the Pytorch version and Tensorflow version, they still come out pretty differently. I wrote a little code snippet to show the issue: and the result is: The output weights look similar but the base attention outputs are way off. Is there any way to make the Tensorflow model come out more like the Pytorch one? Any help would be greatly appreciated!",https://stackoverflow.com/questions/71919267,9404761.0,1
47141359,How to calculate factorial in tensorflow?,"I am new to tensorflow, I am trying to find a function that calculates the n!. I saw that one can use the gamma function, which was possible with theano, but did not work for tensorflow. I am using a for loop to multiply number from n to 1, but I assume there is an easier and faster way. I saw functions related to gamma distribution, but couldn't figure out how to calculate the factorial. Would appreciate if one can point me to some documentation. Here is the way I do it now Output is",https://stackoverflow.com/questions/47141359,1577800.0,1
45679562,Output from fully connected network in tensorflow,"In this code,the output from fully connected layer is given as 1024 but I cannot understand from which calculation this '1024' is generated and I cannot find any satisfactory answer from tensorflow documentation.And How this ouput size affects the prediction result. Thanks in advance.",https://stackoverflow.com/questions/45679562,7580858.0,1
48323486,Create a tf.contrib.learn Estimator serving that takes JSON input,"I am after some code that I can use to export a model from a tensorflow Estimator that would take JSON as an input. I could make this work with tf.Estimator using tf.estimator.export.ServingInputReceiver, but for models built in tf.contrib.learn I could not find any documentation. There is one example here that creates an export with tf.Example serving, but Example is a bit tricky to construct.",https://stackoverflow.com/questions/48323486,1560163.0,1
45859198,How to define gradient function for this op in tensorflow?,"I'm trying to implement a new op in tensorflow, there are three input tensors and two output tensors, as follows (some codes are ignored due to unrelated to this question): And the gradient registration is as follows: But this gradient function seems wrong from my experiments, it can run OK, but after running the grads = opt.compute_gradients(total_loss) in build training operator, this op will generate wrong results. But this op can run OK and also generate correct results in evaluation status (no training, i.e., no gradient computation). So I realize this gradient function may be wrong. I've read this page in official documents https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/extend/adding_an_op.md#implement-gradient. In fact, in this op, I just want the top errors arrived the two output tensors (output1 and output2) are directly copied(back-propagated) to the first two input tensors (i.e., input1 and input2). How could I implement the correct gradient function for this op? Thanks.",https://stackoverflow.com/questions/45859198,2495287.0,1
75963463,reshaping logits to dim 1,"I am currently working on a T5 model which I am trying to fine-tune. On the training step, I get my outputs, get my loss, and try to update the state of my metric. However, in order to update the state of the metric I am required to use a 1-D array. From the documentation: ""Both prediction and labels must be 1-D arrays of the same shape in order for this function to work."" My question is, is there a recommended way to reshape my outputs.logits variable? it currently has a shape of (8, 2, 32128) and would like to bring it 8. I have tried the argmax function, and softmax but had no luck. Any ideas would be appreciated. Code:",https://stackoverflow.com/questions/75963463,1261440.0,1
66796379,Is tensorflow dataset 'prefetch' method add a dimension for my data? why?,"Here is an example, this func is used to cut time sequence into windows: call &amp;&amp; output: It seemed that the dataset have one more rank after prefetch, is it? I didn't find any doc to describe this phenomenon, i will be appreciate if anybody could offer help. ============================================================ updated at 2021-03-25 12:28:16 UTC+0 I found this to be a little embarrassing misunderstanding, thanks to @ Lescurel for pointing this out. In fact, prefetch does not affect the dimension, and batch will add a dimension. The modification example is as follows: call &amp;&amp; output: It is clear now.",https://stackoverflow.com/questions/66796379,14799935.0,1
48038889,why embedding_lookup only used as encoder but no decoder in ptb_word_ln.py,"I have a question about embedding_lookup while I looking the tensorflow's official sample code ptb_word_ln.py. the embedding_lookup node I found it is only used as an input. the output doesn't use this. so the loss evaluation cannot be benefit from this embedding. so what is the benefit using embedding_lookup here? If I want to use this word-embedding in the optimizer, shouldn't I connect it with loss function explicitly? the source code as following:",https://stackoverflow.com/questions/48038889,3134227.0,1
50163497,error when training single level LSTM in tensorflow,"So I have been trying to train a single layered encoder-decoder network in tensorflow, it is just simply so frustrating given the document is so sparse on explanation, and I have only taken Stanford's CS231n on tensorflow. So here's the straightforward model: now I try to set up the training details: okay then now I get this stupid error",https://stackoverflow.com/questions/50163497,4221715.0,1
64346496,Applying a mask to Conv2D kernel in Keras,"I'm looking to apply a mask to the kernel of a Conv2D layer in Keras. I'm having a bit of difficulty understanding kernel shape. For kernel_size = 3, and filters = 1, the shape of the kernel is (3, 3, 4, 1) =&gt; (kernel_size, kernel_size, ???, filters) What does the 3rd dimension in the kernel represent? How can I take an NxN mask and multiply it to each of the kernel filters? This is the code I have so far. I am not sure if it will work as I expect it to because I don't fully understand the kernel shape.",https://stackoverflow.com/questions/64346496,4257302.0,1
54678961,TF_SessionRun_wrapper: expected all values in input dict to be ndarray,"I don't think I've ever had this error before and I don't really understand what it is saying. Even in a simple test case (shown below), I run into this error. This is specifically on one machine, but not on other computers. So, I think it must be a configuration/setup problem? I am not quite sure how to progress... If there are any hints/If anyone has run into this error before, it would be great to know especially considering there is no information about it online. I am using Tensorflow version 1.13.0-dev20190208 (GPU nightly build) with CUDA 10.",https://stackoverflow.com/questions/54678961,1582331.0,1
66310937,Regard y_true and y_pred as single sample or a batch of samples in Keras.Metric?,"When I want to build a custom metric which can used with model.compile, I got confused about how to understand y_true and y_pred in the callable function. Here is an example given in the Keras documnets. From the codes, I think y_true and y_pred are batch of samples. But it also says that ""Much like loss functions, any callable with signature metric_fn(y_true, y_pred) that returns an array of losses (one of sample in the input batch) can be passed to compile() as a metric"". Does that mean the output return in the callable is the loss for one single sample? Should we regard y_true and y_pred as single sample or batch of samples in metric/loss function?",https://stackoverflow.com/questions/66310937,15024599.0,1
51182162,set device on model trained on GPU and predict on CPU,"I trained a a model on a GPU and saved it like this (export_path is my output directory) Now I'm trying to load this and run predictions. It works fine if I am on a GPU, but w/o a GPU around I get: Now I read about tf.train.import_meta_graph and the clear_device option, but I can't get this work. I'm loading my models like so: at which point is throw the error mentioned above. modelname is the full filename of the pb file. Is there a way to go through the nodes of the graph and manually set the device (or doing something similar)? I'm using tensorflow 1.8.0 I saw Can a model trained on gpu used on cpu for inference and vice versa? which I don't think I'm duplicating. The difference with that question is that I want to know what to do after training",https://stackoverflow.com/questions/51182162,2208967.0,1
44000781,Tensorflow aggregation_method for optimizers,"I could not find documentation regarding the aggregation method in tensorflow optimizer I have the following line of code However, this property can be changed to be Does anyone know what does it do? (I just know that when I used the default with an LSTM it did not have enough memory to run)",https://stackoverflow.com/questions/44000781,6828367.0,1
69932821,Keras preprocessing layer,"I am trying to feed a neural network 50 features (All Yes/No values) to predict the probability of one Yes/No label. I am trying to do this with keras CategoryEncoding, but running into some issues. The start of my code is below: However, I get this error below: I am looking through the documentation, and I don't think I fully understand what a token is in its context here. Also, how would I preprocess my label here? I could use pd.get_dummies, but I don't know if tensorflow has anything that could do that automatically?",https://stackoverflow.com/questions/69932821,16354723.0,1
63780777,To create a custom metrics for regression according to the rule book of Keras' documentation,"I found two main sources about it. I prefer to follow Keras' documentation to avoid memory leak as it's the case for some people who try custom approaches with Keras. But what Keras' is showing in the documentation is about classification. This is not my case. So I tried to look at the source code of Keras. Precisely in the file: /lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py. It does not help me at all because most of metrics (some exception are classification metrics) are all done with a wrapper as the following code: As you can see there's only the constructor method, no good inspiration available for the udpate_state method that I need. Where can I find it ? python 3.7.7 tensorflow 2.1.0 keras-applications 1.0.8 keras-preprocessing 1.1.0",https://stackoverflow.com/questions/63780777,10314460.0,1
63645132,Normalizing difference between x_train /= 255.0 and x_train = x_train/255.0,"I have some simple code, which loads the mnist data and normalizes the images. The code above works, however, if I try to use the shorthand for division, I get an error: The error is as follows: TypeError: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'B') according to the casting rule ''same_kind'' By playing around, I found a fix to it, in that typecasting x_train to float32, would get rid of the error, but I only stumbled upon the fix by accident. I don't understand why the code below fixes the issue Could someone explain what's happening here? Why do the two versions behave differently? Why's an explicit case required in the second instance but not the first? I didn't have much luck finding this behaviour documented anywhere. Edit: I'm not sure what additional 'debugging details' I'm required to provide, since I've basically provided the entire code, the results as well as the details which I did not understand. I've also received no comments explaining why the question was closed, and/or what additional information is expected here. I would like some constructive criticism so as to atleast be able to ask the question in a better manner, if the present form isn't satisfactory by itself.",https://stackoverflow.com/questions/63645132,12279039.0,1
57533942,What exactly is compute_gradients returning and how does it depend on batch_size?,"Please excuse my rookie understanding of TensorFlow, Thanks in advance for the help! I am trying to compute the gradients using compute_gradients() wrt the embedding inputs of my loaded model. My batch_size is 250 and embd_size is 300. I want to compute the gradients of all my inputs for 250 test examples, so predicted_y is a numpy list of the values predicted by the model of shape [250,1] so the x_test that I provide in the feed dict is of shape [250, 300]. I have already tried this similar question What does compute_gradients return in tensorflow but I didn't completely understand the role of batch_size in compute_gradients() After I feed the values in sess.run(gradients, feed), I extract the values of the IndexedSlices object obtained and stored it as a list grads. I expected to get grads with dimentionality [250, 300], corresponding to the gradients for all my inputs for each test example Instead I get [50000, 300] which I cannot explain. I tried varying the batch_size too see what happens but it gives me mismatch between input shapes error. I tried understanding the compute_gradients() code on github but its too obscure for someone with my basic understanding. How do I get the gradients of all inputs for each of my test set examples?",https://stackoverflow.com/questions/57533942,9803875.0,1
38800965,What does the column and rows for images in TensorBoard mean?,"I was trying to use the tensorflow tf. image_summary but it wasn't clear to me how to use it. In the tensorboard readme file they have the following sentence that confuses me: I don't understand the sentence and thus, I am having a hard time figuring out what the columns and rows mean for TensorBoard image visualization. What exactly is a ""tag"" and what exactly is a ""run""? How do I get multiple ""tags"" and multiple ""runs"" to display? Why would I want multiple ""tags"" and ""runs"" to display? Does someone have a very simple but non-trivial example of how to use this? Ideally, what I want to use is compare how my model performs with respect to PCA so in my head it would be nice to compare how the reconstructions compare to PCA reconstruction at each step. Not sure if this is a good idea but I also want to see what the activation images look like and how the templates look like. Curenttly I have a very simple script with the following lines: currently I have managed to discover that the rows are of length 10 so i assume its showing me 10 images that have something to do with the current run/batch. however, if possible I'd like to see reconstruction, filters (currently I am doing fully connected to keep things simple but eventually it would be nice to see a conv net examples), activation units (with any number of units that I choose), etc.",https://stackoverflow.com/questions/38800965,1601580.0,1
60996450,Keras ignores the input_shape provided to the first layer,"I build a simple model like this, specifying an input shape of (32, 32, 1) to the first (and only) layer: Now when I call I get the following error despite the fact that input_shape is indeed specified. The model also happily takes input with non-conforming shapes: Does this mean that despite what the documentation says, input_shape specification to the first layer is simply ignored? How to enforce this value? (My TF version is 2.1.0).",https://stackoverflow.com/questions/60996450,9973879.0,1
50770467,"Custom learning rate decay with tensors, lambdas, and python variable binding","I'm trying to build a custom TensorFlow estimator and train it. I would like to be able to modify its behavior through extra parameters. Specifically, to set the optimizer, and specify a formula for the learning rate that depends on the epoch. So for example, ideally, I would be able to do this: How would I go about it? After some poking around, it became obvious to me that the above approach isn't going to work, because tf.train.global_step() depends on having a session, and I don't have a session at least until I call model.train(). I also know that there might be some kind of witchcraft that lets me defer the call to tf.train.global_step() until model_fn is actually run my tf.Estimator. I'm just at loss at how the whole thing works together, and would appreciate some help for 1. Solving this problem 2. Understanding how variable binding works 3. Understand how tf.train.global_step() fetches the tensor object, and what a tensor really is.",https://stackoverflow.com/questions/50770467,5810747.0,1
59657166,Convert frozen model(.pb) to savedmodel,"Recently I tried to convert the model (tf1.x) to the saved_model, and followed the official migrate document. However in my use case, most of model in my hand or tensorflow model zoo usually is pb file, and according to the official document says that But I still do not understand how to converted to saved_model format.",https://stackoverflow.com/questions/59657166,2469488.0,1
43649591,Serving Keras Models With Tensorflow Serving,"Right now we are successfully able to serve models using Tensorflow Serving. We have used following method to export the model and host it with Tensorflow Serving. However our issue is - we want keras to be integrated with Tensorflow serving. We would like to serve the model through Tensorflow serving using Keras. The reason we would like to have that is because - in our architecture we follow couple of different ways to train our model like deeplearning4j + Keras , Tensorflow + Keras, but for serving we would like to use only one servable engine that's Tensorflow Serving. We don't see any straight forward way to achieve that. Any comments ? Thank you.",https://stackoverflow.com/questions/43649591,7780215.0,1
60593788,Does Tensorflow.unstack() Remove or Rearrange data?,"I've been trying to understand how Tensorflow.Unstack() works. I've read the documentation a few times here: https://www.tensorflow.org/api_docs/python/tf/unstack According to the Tensorflow documentation ""the dimension unpacked along is gone"". It sounds like unstacking a tensor removes data from the original tensor. Is this true? Or does it only rearrange the data? In my code example, in Y, it appears that it has removed the fourth row of X. What confuses me, is why does it leave the row on the side of matrix? Is the function actually removing the row or leaving it there? I'm not quite sure what to make of the output.",https://stackoverflow.com/questions/60593788,5449789.0,1
75338588,Correct way to pass a set of images to a model for training,"I'm trying to create a Keras model to train with a group of images, taken from a list of paths. I know that the method tf.keras.utils.image_dataset_from_directory exists but it doesn't meet my needs because I want to learn the correct way to handle images and because I need to make a regression, not a classification. Every approach I tried failed one way or another, mostly because the type of the x_train variable is wrong. The most promising function I used to load a single image is: This doesn't work because, when I call the .fit() method this way: I receive the following error: This makes me understand that I'm passing the data in a wrong format. Can someone provide me a basic example of creating a (x_train, y_train) pair to feed a model for training using a set of images? Thank you very much",https://stackoverflow.com/questions/75338588,4795403.0,1
49775557,"How can I invoke a SageMaker model, trained with TensorFlow, using a csv file in the body of the call?","I have deployed a TensorFlow model on AWS SageMaker, and I want to be able to invoke it using a csv file as the body of the call. The documentation says about creating a serving_input_function like the one below: In step 2, where it says preprocess input data, how do I get a handle on input data to process them?",https://stackoverflow.com/questions/49775557,4537553.0,1
65321954,Tensorflow custom preprocessing with tf.py_function losing shape,"Im writing a model and doing the preprocessing part: I have a method which preprocesses my tensorflow dataset by calling: ds = ds.map(process_path, num_parallel_calls=AUTOTUNE) I followed the tensorflow documentation and got this code for process_path: Then I want to add my own preprocessing, such as rotating the image so I created a rotate method wrapped with py_function as the documentation suggests: However when I add this to my process_path the model seems to break and freezes... I added print statements with image.shape after each adjustment and it shows that after the rotate method the image shape becomes &lt;unknown&gt; so I believe this to be the error: Output: Any help is greatly appreciated.",https://stackoverflow.com/questions/65321954,9209390.0,1
52992821,Tensorflow graph fetch all consts in a scope,"I create a graph and now I want to fetch their ops, how can I do this? Can you show me document links about this?",https://stackoverflow.com/questions/52992821,6935676.0,1
39732460,How to use evaluation_loop with train_loop in tf-slim,"I'm trying to implement a few different models and train them on CIFAR-10, and I want to use TF-slim to do this. It looks like TF-slim has two main loops that are useful during training: train_loop and evaluation_loop. My question is: what is the canonical way to use these loops? As a followup: is it possible to use early stopping with train_loop? Currently I have a model and my training file train.py looks like this Which is awesome so far - my models all train and converge nicely. I can see this from the events in train_log_dir where all the metrics are going in the right direction. And going in the right direction makes me happy. But I'd like to check that the metrics are improving on the validation set, too. I don't know of any way to do with TF-slim in a way that plays nicely with the training loop, so I created a second file called eval.py which contains my evaluation loop. Questions: 1) I currently have this model for the evaluation_loop hogging up an entire GPU, but it's rarely being used. I assume there's a better way to allocate resources. It would be pretty nice if I could use the same evaluation_loop to monitor the progress of multiple different models (checkpoints in multiple directories). Is something like this possible? 2) There's no feedback between the evaluation and training. I'm training a ton of models and would love to use early stopping to halt the models which aren't learning or are not converging. Is there a way to do this? Ideally using information from the validation set, but if it has to be just based on the training data that's okay, too. 3) Is my workflow all wrong and I should be structuring it differently? It's not clear from the documentation how to use evaluation in conjunction with training. Update ~~It seems that as of TF r0.11 I'm also getting a segfault when calling slim.evaluation.evaluation_loop. It only happens sometimes (for me when I dispatch my jobs to a cluster). It happens in sv.managed_session--specifically prepare_or_wait_for_session.~~ This was just due to evaluation loop (a second instance of tensorflow) trying to use the GPU, which was already requisitioned by the first instance.",https://stackoverflow.com/questions/39732460,5565980.0,1
70926446,How to optimise an arbitrary function with TensorFlow/Keras?,"I have some black box simulation code that runs some physics, possibly in other languages, possibly using NumPy. All of it is wrapped and is callable as a Python method: Additionally, I have some code that computes the partial derivatives out the output w.r.t. the input x: I would like to optimise the first function using some of the algorithms in Keras/TensorFlow (e.g. ADAM, SGD, etc.). I tried working with the TensorFlow documentation, but I can't seem to do the appropriate approach. However, this just gives me: Would anyone have any helpful pointers?",https://stackoverflow.com/questions/70926446,6848887.0,1
60444486,Use tf.distribute strategies with tf.keras model subclassing,"I am currently have a tf.keras model subclass, but cannot use GPU distribute strategies although it is stated on the Tensorflow website that it is possible I recieve an error telling me the contrary. One solution I found was to wrap the model in tf.keras.models.Model but this resulted in ValueError: We currently do not support distribution strategy with a `Sequential` model that is created without `input_shape`/`input_dim` set in its first layer or a subclassed model. This is not solvable for me because my input shape is (None, None) due to the fact that the input is a group of sequences that are not the same shape and I am not defining them to be the same shape. Is there any way around this or to use tf.distribute with a Model subclass?",https://stackoverflow.com/questions/60444486,6919063.0,1
57811162,TransformedTransitionKernel fails to apply inverse bijector in sample_chain,"I am trying to run a fairly simple MCMC sample for some time series data. I believe I am including all the required args, but I'm still getting an error. The library versions: I tried rolling back to tfp 0.6.0 and got a matmul error. I tried pushing forward to tf nightly and got the same error as below. The code This returns an error.",https://stackoverflow.com/questions/57811162,11335842.0,1
70187502,How to sample from a normal distribution random values inside a range using Tensorflow?,"I have two variables mean and stddev which are tensors of shape (1,) and they represent many normal distributions with mean lets say mean[i] and stardard deviation stddev[i]. From these distributions I want to sample one value within a range in [low,up,] for everyones and then I want to get the log probabilities of the sampled values. From the docs I found that the experimental_sample_and_log_prob method is almost for me because it does not sample elements within a range of values (low, up) that I would like to have. So I coded few lines but it doesn't work very well naturally ad it is so computationally expensive. Any tips to solve it?",https://stackoverflow.com/questions/70187502,8810638.0,1
70937339,tfa.metrics.F1Score calculated wrong?,"I train a Keras model from scratch for image classification and print the F1 score during training. I use the following metrics in the metrics property in model.compile(): When I check my logs I have a precision of 0.98956, a recall of 0.9875 and a F1 score of 0.98113. According to the formula in the documentation the F1 score should be 0.9885. Is the formula or my setup wrong?",https://stackoverflow.com/questions/70937339,14836138.0,1
60876340,How can I save a trained TensorFlow Federated model as a .h5 model?,"I want to save a TensorFlow federated model which was trained with the FedAvg Algorithm as a Keras/.h5 model. I couldn't find the documents on this and would like to know how it may be done. Also if possible, I'd like to have access to both the aggregated server model and the models of the clients. The code I use to train the federated model is below:",https://stackoverflow.com/questions/60876340,12992742.0,1
72418200,how to make custom list classification in tensorflow with python 3?,"how to make custom list classification in tensorflow with python 3? I was trying to make a custom dataset with this code after that, I was try to make the model with this code after that, I was try to compile the model with this code after that, I was try to train the model with this code after that, I was try to predict the data with this code after that, I got an error message like this what should I do? and why do I get this error? my environment Thanks for help",https://stackoverflow.com/questions/72418200,6592692.0,1
70086613,"Why do I get the ""Failed to convert a NumPy array to a Tensor"" error?","I am trying to fit a neural network with training data, but keep getting errors like this when reaching the fit function: I don't understand why I get this error when fitting. Because as you can see from the official Keras documentation here, the fit function accepts lists and arrays. I have tried to pass both but always get errors. Passing lists: prints: I have tried converting the data like this as well: But this leads to the following error: Lastly I have tried giving all my input training vectors the same length. Because the vectors are a series of integers and have varying lengths: But this again leads to issues: At this point I am not quite sure anymore of how I have to structure my vectors in order to not have issues any more. What do I have to do at this point?",https://stackoverflow.com/questions/70086613,17491372.0,1
44764887,How to restore trained LinearClassifier from tensorflow high level API and make predictions,"I have trained a logistic regression model model using tensorflow's LinearClassifier() class, and set the model_dir parameter, which specifies the location where to save metagrahps of checkpoints during model training: I've been reading about restoring models from metagraphs, but have found nothing about how to do so for models created using the high level api. LinearClassifier() has a predict() function, but I can't find any documentation on how to run prediction using an instance of the model that has been restored via checkpoint metagraph. How would I go about doing this? Once the model is restored, my understanding is that I am working with a tf.Sess object, which lacks all of the built in functionality of the LinearClassifier class, like this: How do I run the same prediction algorithm used by the high-level api to make predictions on a restored model? Is there a better way to approach this? Thanks for your input.",https://stackoverflow.com/questions/44764887,5540936.0,1
53404301,How to compute Spearman correlation in Tensorflow,"I need to compute the Pearson and Spearman correlations, and use it as metrics in tensorflow. For Pearson, it's trivial : But for Spearman, I am clueless ! From this answer : But this return NaN... Following the definition of Wikipedia : I tried : But running this I got the following error :",https://stackoverflow.com/questions/53404301,9494790.0,1
46851689,Python-Tensorflow running on GPU instead of CPU,"I have the sample tensorflow code below explicitly i have given tf.device('/cpu:0') but it is giving the following error : Tensorflow version : 1.3.0, python version : 3.6.1 with Anaconda Distribution",https://stackoverflow.com/questions/46851689,6490241.0,1
51795791,Input tensors to a Model must come from `tf.layers.Input` when I concatenate two models with Keras API on Tensorflow,"I'm creating a wide and deep model using Keras functional API on tensorflow. When I try to merge the two models, the below error occurred. Here is the code for concatenating the two. For each model's inputs, I tried using tf.layers.Inputwith to make them tf.layers.Input as this page mentions. But I'm still facing the same issue. I'm using tensorflow==1.10.0 Could someone help me solving this issue? Thanks!",https://stackoverflow.com/questions/51795791,3368526.0,1
33727935,How to use stop_gradient in Tensorflow,"I'm wondering how to use stop_gradient in tensorflow, and the documentation is not clear to me. I'm currently using stop_gradient to produce the gradient of the loss function w.r.t. the word embeddings in a CBOW word2vec model. I want to just get the value, and not do backpropagation (as I'm generating adversarial examples). Currently, I'm using the code: But when I run this, it does the backpropogation anyway! What am I doing wrong, and just as importantly, how can I fix this? CLARIFICATION: To clarify by ""backpropagation"" I mean ""calculating values and updating model parameters"". If I run the two lines above after the first training step, the I get a different loss after 100 training steps than when I don't run those two lines. I might be fundamentally misunderstanding something about Tensorflow. I've tried setting using set_random_seed both in the beginning of the graph declaration and before each training step. The total loss is consistent between multiple runs, but not between including/excluding those two lines. So if it's not the RNG causing the disparity, and it's not unanticipated updating of the model parameters between training steps, do you have any idea what would cause this behavior? Welp, it's a bit late but here's how I solved it. I only wanted to optimize over some, but not all, variables. I thought that the way to prevent optimizing some variables would be to use stop_grad - but I never found a way to make that work. Maybe there is a way, but what worked for me was to adjust my optimizer to only optimize over a list of variables. So instead of: I used: This prevented opt from updating the variables not in var_list. Hopefully it works for you, too!",https://stackoverflow.com/questions/33727935,5565980.0,1
34236252,What is the difference between np.mean and tf.reduce_mean?,"In the MNIST beginner tutorial, there is the statement tf.cast basically changes the type of tensor the object is, but what is the difference between tf.reduce_mean and np.mean? Here is the doc on tf.reduce_mean: For a 1D vector, it looks like np.mean == tf.reduce_mean, but I don't understand what's happening in tf.reduce_mean(x, 1) ==&gt; [1., 2.]. tf.reduce_mean(x, 0) ==&gt; [1.5, 1.5] kind of makes sense, since mean of [1, 2] and [1, 2] is [1.5, 1.5], but what's going on with tf.reduce_mean(x, 1)?",https://stackoverflow.com/questions/34236252,678572.0,1
45523380,why the tf.nn.dynamic_rnn returns different result regarding sequence_length,"while i studied RNN in the book called Hands-On Machine Learning with Scikit-Learn and TensorFlow, i encountered different result which must be the same. Tensorflow document says 'If sequence_length not provided, all batch entries are assumed to be full sequences; and time reversal is applied from time 0 to max_time for each sequence. ' So must the result be the same?",https://stackoverflow.com/questions/45523380,4571281.0,1
52210472,"Error when checking input: expected dense_input to have shape (21,) but got array with shape (1,)","How to fix the input array to meet the input shape? I tried to transpose the input array, as described here, but an error is the same. ValueError: Error when checking input: expected dense_input to have shape (21,) but got array with shape (1,)",https://stackoverflow.com/questions/52210472,6531629.0,1
73897736,"Argument must be a string or a number, not 'ExponentialDecay'","I am on Tensorflow 2.4.0, and tried to perform Exponential decay on the learning rate as follows: and start the learning rate of my optimizer with such decay method: the model is compiled as follows The train goes well until the third epoch, where the following error is showed: I checked this issue was even raised in the official keras Forum, but no success even there. Plus, the documentation clearly states that: What could be the issue?",https://stackoverflow.com/questions/73897736,2163392.0,1
75698781,Keras Migration issues ImageDataGenerator to image_dataset_from_directory,"It appears that ImageDataGenerator has been deprecated after TF 2.10. Thus, I wanted to change my code to avoid using this class and use pre-processing layers to do the augmentation. The recommendation on TF Documentation is to use image_dataset_from_directory. But I'm having problems with this class as now I get a lot of errors about the type of file. I'm using the Kaggle Cats-vs-Dogs dataset to test this. Here is the code using the ImageDataGenerator: For the approach using image_dataset_from_directory, I create the preprocessing layers like: I add them to my model using: And then I create the datasets using: Same thing goes for the validation set. However with image_dataset_from_directory I get: ImageDataGenerator works without any issue. Is this a bug?",https://stackoverflow.com/questions/75698781,7056614.0,1
43752099,Predictions for tf.contrib.metrics.streaming_auc distributed uniformly?,"The TensorFlow documentation for tf.contrib.metrics.streaming_auc mentions the following: I am a bit confused because I feel like a common paradigm is to have predictions be compared against a target 1-hot encoding: In those cases, the predictions tensor contains all 0s or 1s. Should we avoid using tf.contrib.metrics.streaming_auc in those cases? I am not sure in what cases we would use tf.contrib.metrics.streaming_auc then.",https://stackoverflow.com/questions/43752099,1276460.0,1
52542342,Keras: Derivatives of output with respect to time with LSTM,"I have been trying to model nonlinear dynamic systems with LSTM networks using Keras. I have had success by simply using the Keras LSTM networks, where I define my input/output relationship something like the following pseudo-code: x[t] = NN(y[t-200:t],x[t-200-1:t-1]) Where y would be my forcing function and x is the variable I'm after. So I use the past 200 points to estimate the next point. I do this recursively by adding the newly predicted point to my ""past outputs"" vector. Now I would like to add some information about the PDE that I'm solving to the loss function, so I need to compute derivatives with respect to time. I have read this answer and the related answers to get started but I can't seem to get that workflow to work with LSTMs. First of all, time is not an explicit variable in my workflow, so I would need to add it as an input to accommodate the workflow in that answer. So I could add the time vector to the list of inputs, and then try to compute derivatives of the output with respect to the input: For reference, my input dimension is (?,200,3) and my output dimension is simply (?,1). The code above works and I get a (?,200,3) tensor. But when I try to compute the second derivative like so: Then I get the error: TypeError: Second-order gradient for while loops not supported. Since I only need the derivatives at the current timestep (t), I have tried slicing the tensor, but that doesn't work either. Even if I could do something like that, I am not too comfortable adding the time vector as an explicit input. I have considered computing the derivative numerically with diff() (given a constant dt), but I am not sure how to do that here when dealing with tensors. So I'd appreciate any suggestions or ideas to help me solve this problem. Ultimately, I'd like to add the homogeneous portion of the PDE to the loss function. At this point, my equation only has derivatives with respect to time. Thanks.",https://stackoverflow.com/questions/52542342,10425539.0,1
36521908,How to Iteratively Create Tensorflow Graphs On The Fly Without Accumulating Memory?,"What is the idiomatic way to construct a new neural network during each iteration of the training loop? It is an unusual thing to do, but I am working on an unusual project. The tensorflow API documentation says ""A session may own resources, such as variables, queues, and readers. It is important to release these resources when they are no longer required. To do this, either invoke the close() method on the session, or use the session as a context manager."", so my first attempt involved declaring all my tensorflow variables within a session context manager, so that they can be freed at the next iteration of the training loop: The first iteration of the training loop executes correctly, but on the second iteration the call to tf.initialize_all_variables() leads to a memory error ""ValueError: GraphDef cannot be larger than 2GB."" Does exiting the session context not in fact free memory in the graph? Each iteration of the loop involves the same amount of data and the same number of parameters in the neural network, so I don't think it's my construction that leads to the memory error. The documentation is not very detailed on what exactly tf.reset_default_graph does, but I've tried freeing memory by calling at the end of the session, leading to the error: How can I iteratively create tensorflow graphs without accumulating memory?",https://stackoverflow.com/questions/36521908,1483516.0,1
62801832,Rewrite tf.contrib.layers.batch_norm in Tensorflow 2.0,Could somebody help me rewrite the following block of code in Tf2.0? I'm aware batch_norm is equivalent to keras.layers.BatchNormalization but the documentation doesn't give clear solution as to what 'decay' and 'epsilon' correspond to. Thanks!,https://stackoverflow.com/questions/62801832,13636839.0,1
56834934,How to replace tensorflow softmax with max for generating one hot vector at the output layer of Neural Network?,"For a classification problem, softmax function is used in the last layer of the Neural Network. I want to replace the softmax layer with the max layer that generates one hot vector with one set to the index where maximum value occurred and set all other entries to zero. I can do it with tf.argmax as suggested in TensorFlow - dense vector to one-hot and Tensorflow: Convert output tensor to one-hot, but these are not a differentiable way of doing it and gradients cannot be calculated. If not exact 0's and 1's can be obtained then values should be close enough. I was thinking to apply softmax multiple times but it is not recommended and I do not understand the reason behind it. Please suggest a differentiable solution.",https://stackoverflow.com/questions/56834934,7930290.0,1
71590479,GradientTape returning None when run in a loop,"The following gradient descent is failing 'coz the gradients returned by tape.gradient() are none when the loop runs second time. I checked the documentation which explains the possibilities of the gradients becoming None, but none of them are helping.",https://stackoverflow.com/questions/71590479,3151330.0,1
72967055,"LSTM forecasting tensorflow use of batch, repeat and shuffle","I came across these two pages - page 1 and page 2 which use LSTM for forecasting. the second link uses below code: while the first link doesn't use similar code at all. I have relatively small dataset. Please guide me regarding when I should use above code and when I shouldn't. I saw stackoverflow posts regarding batch, repeat, shuffle but I am not clear. Please keep in mind I am building a forecasting model",https://stackoverflow.com/questions/72967055,2543622.0,1
76402835,ValueError: tf.function only supports singleton tf.Variables created on the first call,"I have the following code: I get the error in the title, I read the documentation but I still don't know how to solve it. I tried model.build() but I'm not sure where to call it.",https://stackoverflow.com/questions/76402835,14114819.0,1
51849347,Keras and input shape to Conv1D issues,"First off, I am very new to Neural Nets and Keras. I am trying to create a simple Neural Network using Keras where the input is a time series and the output is another time series of same length (1 dimensional vectors). I made dummy code to create random input and output time series using a Conv1D layer. The Conv1D layer then outputs 6 different time series (because I have 6 filters) and the next layer I define to add all 6 of those outputs into one which is the output to the entire network. The error I get is: Looking at the Keras documentation for Conv1D, the input shape is supposed to be a 3D tensor of shape (batch, steps, channels) which I don't understand if we are working with 1 dimensional data. Can you explain the meaning of each of the items: batch, steps, and channels? And how should I shape my 1D vectors to allow my network to run?",https://stackoverflow.com/questions/51849347,10226515.0,1
56426598,Input several images in tensorflow session.run(),"I have a code that uses tensorflow to analyse some images with a GPU, I use the tf.session and introduce the frames in the session.run for the model as As I am running this on a GPU it has spare space so I would want to introduce several images. I have tried what was said in Bach several images in tensorflow, but I obtain the error: ""The name 'image_tensor:0' refers to a Tensor which does not exist. The operation, 'image_tensor', does not exist in the graph."" I have introduce the images in a bach as:",https://stackoverflow.com/questions/56426598,11016252.0,1
44433438,What is the purpose of tf.global_variables_initializer?,"I would like to understand what tf.global_variables_initializer does in a bit more detail. A sparse description is given here: But that doesn't really help me. I know that the op is necessary to initialize the graph, but what does that actually mean? Is this the step where the graph is complied?",https://stackoverflow.com/questions/44433438,3747801.0,1
36339059,Exporter classification_signature,"I'm trying to modify the serving tutorial to work with my model, which is basically the CIFAR example modified to work with a CSV file and JPEGs. I can't seem to find the documentation for the Exporter class, but here is what I have so far. It's in the train() function in the cifar10_train.py file: Here is the code I use to train the model: Any ideas how I can set up Exporter correctly?",https://stackoverflow.com/questions/36339059,563762.0,1
46288154,"In tensorflow, why do the predictions are two dimensional?","As I'm learning Tensorflow, I have a confusion about the dimensions of the output layer tensor. I am learning how to build a multilayer_perceptron model in Tensorflow. The code I'm starting from is this one. In short, it's basically as the below frame: I understand the concepts of argmax and equal methods. But why in tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1)) the axis argument is 1? Or to say, why the pred is more than 1 dimension? To me, the pred shall be just similar to a 1D array. E.g. [0,1,1,1,1] means except the first prediction, all others are right. And why we need a argmax before the equal method? Thank you!",https://stackoverflow.com/questions/46288154,7521737.0,1
50433094,What do the return values of tf.metrics mean?,"I've been trying to add some hopefully useful intermediate calculations used to derive my loss function to the eval_metric_ops dictionary for my evaluation EstimatorSpec. I have wrapped these in a call to tf.metrics.mean as it seemed to fit my needs. The return type of this function is a tuple of (mean, update_op), where mean is ostensibly the current mean and update_op is an operation that computes the new mean and returns it. However, when I try to evaluate it I see that the value and update_op fields seem to be different. The documentation doesn't provide an explanation for this as far as I can see. For example, take the following snippet of code: This returns the following: The second value of the tuple is obviously an overall average of the input value, but the left hand side values seem to be asymptoting towards 3.5, while the taking the zero-index of test_mean and evaluating it results in 3.5 directly, as opposed to the value that I get by evaluating the whole operation and then taking the index. What is happening here?",https://stackoverflow.com/questions/50433094,1613983.0,1
37980518,meaning of `grad` parameter in tensorflow gradient functions (python),"What does the grad parameter in tensorflow gradient functions in python (like the example below from the docs) represent? The docs say it represents ""the gradients with respect to each output of the op."" Which gradients? The gradients of Each output of the op, with respect to each output of the op? The op here is x - y. Does that mean the grad parameter in this function refers to ? This would be consistent with the output of the function, which is , but I wanted to make sure. Thanks in advance for your clarification!",https://stackoverflow.com/questions/37980518,1387992.0,1
41113004,What is the effect of calling TensorArray.close()?,"(tensorflow version: '0.12.head') The documentation of TensorArray.close says that it close the current TensorArray. What does it mean for the status of TensorArray? I try the following code And there are no errors. What is the usage of close? Learning-to-learn includes TensorArray.close in the reset operations of the network. I can't figure out what the comment Empty array as part of the reset process means. Update For examples, Why arr.close() doesn't make the while loop fail? What are the advantages of calling arr.close() at the beginning of each epoch?",https://stackoverflow.com/questions/41113004,6770703.0,1
46636288,tensorflow - saving and restoring operations,"I have simple goal of training model in tensorflow saving and restoring it later either in order to continue training or to use some functions/operations. Here is simple example of the model Now we restore it here: In restored operation one could not even find predict or train_step from original code. Do I need to name this operations before saving? How can I get predict back and run something like this P.S. I read many tutorials on saving and restoring in tensorflow, but still have poor understanding how it all works.",https://stackoverflow.com/questions/46636288,1700890.0,1
38326578,TensorFlow custom model optimizer returning NaN. Why?,I want to learn optimal weights and exponents for a custom model I've created: The problem is that whenever there is a negative value zero in x the optimizer returns the weight as NaN. If I simply add 0.0001 when x = 0 then everything works as expected. But should I really have to do this? Shouldn't the TensorFlow optimizer have a way to handle this? I've noticed Wikipedia shows no activation functions where x is taken to an exponent. Why isn't there an activation function that looks as below Image? For the above image I'd like my program to learn that the correct exponent is 0.5.,https://stackoverflow.com/questions/38326578,1676118.0,1
55345384,Load (or combine) several pretrained checkpoints with tf.estimator.WarmStartSettings,"I want to use pretrained weights for 2 parts of my model. I have 2 checkpoints from different models, from which I can load only one into my main model with tf.estimator.WarmStart as I'm using the estimator architecture. from the doc: I can't see how I can add an additional checkpoint. Maybe there is a way to load the weights from both checkpoint into one and load that one?",https://stackoverflow.com/questions/55345384,2368505.0,1
43697539,Eigenvalue problems in TensorFlow,"I want to solve an eigenvalue problem using TensorFlow. In particular, I have so I don't want to compute all eigenvectors. In Matlab, I would use eigs(laplacian,4,'sm') Looking at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/linalg_ops.py, I see that tf.self_adjoint_eig calls gen_linalg_ops._self_adjoint_eig_v2. However, I can't find gen_linalg_ops on Github or elsewhere. Any advice on doing such linear algebra in TensorFlow, or is it best to go with other libraries in Python?",https://stackoverflow.com/questions/43697539,3498821.0,1
41604616,Save and load Tensorflow model,"I want to save a Tensorflow (0.12.0) model, including graph and variable values, then later load and execute it. I have the read the docs and other posts on this but cannot get the basics to work. I am using the technique from this page in the Tensorflow docs. Code: Save a simple model: Later, load and execute the model: Question 1: The saving code seems to work but the loading code produces this error: How to fix this?. Question 2: I included this line to follow the pattern in the TF docs... ... but why is that line necessary? Doesn't expert_meta_graphexport the entire graph by default? If not then does one need to add every variable in the graph to the collection before saving? Or do we just add to the collection those variables that will be accessed after the restore? ---------------------- Update January 12 2017 ----------------------------- Partial success based on Kashyap's suggestion below but a mystery still exists. The code below works but only if I include the lines containing tf.add_to_collection and tf.get_collection. Without those lines, 'load' mode throws an error in the last line: NameError: name 'myVar' is not defined. My understanding was that by default Saver.save saves and restores all variables in the graph, so why is it necessary to specify the name of variables that will be used in the collection? I assume this has to do with mapping Tensorflow's variable names to Python names, but what are the rules of the game here? For which variables does this need to be done?",https://stackoverflow.com/questions/41604616,3444294.0,1
56917051,Set flags within python,"I would like to run the TensorFlow Object Detection API within a Jupyter Notebook and not from the terminal. In particular, I would like to start the training by calling train.py, which has a main function that gets called when running the file with python train.py &lt;additional flags&gt; because of this part in the file: I found out that this invokes the main function to start running after it sets the global variables from the flags passed in the terminal: Is there a way to set the global variable flags without changing the script train.py and then calling the main function by importing the file. Unfortunately, I couldn't find any documentation on tf.app.flags.",https://stackoverflow.com/questions/56917051,1902610.0,1
53754540,Tensorflow Access CsvDataset values,"Eager execution I have been digging through the API for 2 days and I cant seem to find a way to use the data from a CsvDataset object. I have the following sample from a dataset: 70,1,4,130,322,0,2,109,0,24,2,3,3,2 67,0,3,115,564,0,2,160,0,16,2,0,7,1 57,1,2,124,261,0,0,141,0,3,1,0,7,2 64,1,4,128,263,0,0,105,1,2,2,1,7,1 74,0,2,120,269,0,2,121,1,2,1,1,3,1 65,1,4,120,177,0,0,140,0,4,1,0,7,1 56,1,3,130,256,1,2,142,1,6,2,1,6,2 59,1,4,110,239,0,2,142,1,12,2,1,7,2 60,1,4,140,293,0,2,170,0,12,2,2,7,2 63,0,4,150,407,0,2,154,0,4,2,3,7,2 I read the csv as said in their high-level APIs video: But from here on i cant acess any data like, getting the values of a column. Converting the dataset to a list using: list(dataset) is not an option, as it takes a very long time with normal size csv's (~190k samples). So, is there any way to get column or row values from this object? Or is there really no point in using TF to read data instead of using scikit/pandas? Edit 1: Tried doing col1 = dataset.map(lambda *row: row[0]) as said by @kvish, this return a &lt;MapDataset shapes: (), types: tf.float64&gt; which is iterable. Problem is that having to loop over every column and then iterating over every MapDataset would make the complexity O(n^2). The idea output would be a list of tensors, each tensor containing all values from a column, similar to this:",https://stackoverflow.com/questions/53754540,3497258.0,1
38961547,Unicode in the standard TensorFlow format,"Following the documentation here, I am trying to create features from unicode strings. Here is what the feature creation method looks like, This will raise an exception, Naturally if I wrap the value in a str, it fails on the first actual unicode character it encounters.",https://stackoverflow.com/questions/38961547,4068846.0,1
54843448,"How to ""zip"" Tensorflow Dataset and train in Keras correctly?","I have a train_x.csv and a train_y.csv, and I'd like to train a model using Dataset API and Keras interface. This what I'm trying to do: What's the right way to implement this dataset? I tried Dataset.zip API like dataset = tf.data.Dataset.zip((train_x, train_y)) but it seems not working(code here and error here). I also read this answer, it's working but I'd like a non-functional model declaration way.",https://stackoverflow.com/questions/54843448,2666624.0,1
62008061,TypeError when fitting keras model,"I am a new to tensorflow, I am trying to build a simple neural network. But every time I get close, there are a list of errors stopping me. I followed tutorials and documentations and kept most of the code and changed only things I need to. Here is my code: Console Output: Any help, tips, and advice is greatly appreciated.",https://stackoverflow.com/questions/62008061,8620607.0,1
37921781,What does opt.apply_gradients() do in TensorFlow?,"The documentation is not quite clear about this. I suppose the gradients one can obtain by opt.compute_gradients(E, [v]) contain the ∂E/∂x = g(x) for each element x of the tensor that v stores. Does opt.apply_gradients(grads_and_vars) essentially execute x ← -η·g(x), where η is the learning rate? That would imply that if I want to add a positive additive change p to the variable, I would need to need to change g(x) ← g(x) - (1/η)p, e.g. like this: Is there a better way to do this?",https://stackoverflow.com/questions/37921781,852592.0,1
67533628,Why does tfa.layers.GroupNormalization(groups=1) produce different output than LayerNormalization?,"From the group normalization documentation in tensorflow addons, it states that the group norm layer should become layer normalization if the number of groups is set to one. However when I try this by calling the layers one a test tensor the results differ. It appears that the group norm layer computes the mean and variance across the time as well as the channel axis, whereas the layer norm computes it for each channel's vector independently. Is this a bug or am I missing something? The current behavior of layer norm is actually desirable for what I am doing. Here is the documentation for GroupNormalization:",https://stackoverflow.com/questions/67533628,2876799.0,1
49544410,Switching from tf.contrib.layers.conv2d to tf.nn.conv2d,"I am using tf.contrib.layers.conv2d so far, but (e.g. to allow for weight decay filters as discussed here) I want to switch to the tf.nn.conv2d implementation. However I am confused regarding the parameters, since apparently I need to specify things that before I haven't. With doc and SO entries I gave it a try. For 4D-Tensors with [batch_size, x, y, channels], are these two versions identical? I.e. am I correct in assuming that input_layer.shape[-1] represents the input_channels as required in filter and that I have to explicitly set strides to the number of dims of my input tensor: with tf.contrib.layers.conv2d (original) with tf.nn.conv2d",https://stackoverflow.com/questions/49544410,6409572.0,1
57133866,"How to fix:""Expected shapes TensorShape([Dimension(None), Dimension(785)]) got dataset with shapes TensorShape([Dimension(785)])""",So I am trying to build Fashion-MNIST CNN classifier using tensorflow. and I am getting this dimensionality error.I am a newbie to tensorflow. I read tensorflow documentation but i didnt get solution to my problem. I am sharing the code which i find related to the error. Following is the entire traceback my model.build() my getdata() I was expecting to find a way to reshape but I couldnt do it.Any help will be appreciated,https://stackoverflow.com/questions/57133866,6873425.0,1
55063120,can anyone give a tiny example to explain the params of tf.random.categorical?,"tensorflow's site gives this example produces a tensor that ""has shape [1, 5], where each value is either 0 or 1 with equal probability"" I have already known, the basic demo, the meaning of tf.log([[10., 10.]]). what I want to know is what does [batch_size, num_classes] do, can anyone give a tiny example to explain the params?",https://stackoverflow.com/questions/55063120,,1
62008235,Tensorflow Reinforcement Learning RNN returning NaN's after Optimization with GradientTape,"I am working on a reinforcement learning project with Tensorflow 2.0; the format of the code comes from an online MIT course of which I am attempting to adapt to my own project. I am new to Tensorflow 2.0 and I can't glean from the documentation why this problem is occurring. The issue is that when I run the reinforcement learning process, Some debugging info I have found that should be helpful: If I comment out the optimization lines 'grads = tape.gradient(...)' and 'optimizer.apply_gradients(...)' the script will run to completion error free (though it is obviously not doing anything useful without optimization). This indicates to me the optimization process is changing the model in a way that is causing the problem. I've tried to include only the necessary functions for debugging; if there is any further information one might need for debugging, I'd be happy to add additional info in an edit.",https://stackoverflow.com/questions/62008235,12757857.0,1
55165126,"Tensorflow's Estimator.evaluate(): Is the accuracy ""global"" or specific to the batch it saw?","I've checked through stack overflow as best I can and the Tensorflow API's section on Estimator.evaluate() but haven't been able to find anything addressing this question. I'm a student working on a research project with Tensorflow, I've been tracking accuracy with evaluate() and storing that value that's returned in a text file. My advising professor (who works with ML/NNs but not specifically python and Tensorflow) wants to know if that accuracy value is specific to the batch of data it saw in the moment, or if it's the overall accuracy of that network from inception to that moment in time. Can someone please clarify whether 'accuracy' is a measure of the accuracy for that given batch of data at the moment of evaluation OR is it a measure of all batches/data that it has seen up to and including that moment? If it is NOT a measure of all batches, is there any way to find that from the network or do I need to be manually calculating it? On how I've been building/training my network (in case it matters): I build the model at a slightly lower level than Keras (as in, I define the architecture in a method using tf.layers), I also have never explicitly run the network with tf.session() (I've only run into trouble when I've tried and past networks have functioned fine without it).",https://stackoverflow.com/questions/55165126,7655593.0,1
49715867,keras trainable attribute not compatible with tensorflow?,"It seems that keras trainable attribute is ignored by tensorflow, which makes it very inconvenient to use keras as a syntactical shortcut in tensorflow. For example: OutPut: It simply means the loss is decreasing and the weights are trainable. I read the blog ''Keras as a simplified interface to TensorFlow'', but it mentioned nothing about the trainable problem. Any suggestion is appreciated.",https://stackoverflow.com/questions/49715867,8144379.0,1
51297190,"Understanding shape=(1,) tensor","I have a tensor “idx” that is returned as the result of the code below. The code uses three other tensors called “result”, “theta”, and “user” which are all described by the output below. I’m very new to tensorflow and I’m trying to understand what idx is, the documentation is a little unclear on what shape=(1,) would be. Is it a vector, or a matrix? Is there a way to access the elements of idx? I tried idx[1], or idx[1,] but I get out of bound errors. Any tips are greatly appreciated.",https://stackoverflow.com/questions/51297190,3476463.0,1
48682703,How to set parameter weights in tf.losses.sigmoid_cross_entropy?,"I'm now trying to use tf.losses.sigmoid_cross_entropy on an unbalanced dataset. However, I'm a little confused on the parameter weights. Here are the comments in the documentation: I know in tf.losses.softmax_cross_entropy the parameter weights can be a rank 1 tensor with weight for each sample. Why must the weights in tf.losses.sigmoid_cross_entropy have the same rank as labels? Can anybody answer me? Better with an example.",https://stackoverflow.com/questions/48682703,2066987.0,1
55491752,Workaround for using tf.matmul with two non-constant inputs,"We are currently trying to convert a transformer model to a tensorflow-lite graph but it seems that the problem is the self-attention mechanism. We're not able to process the graph. Looking into tf-lite code we narrowed it down to the tf.matmul lite-version. The docs state: However, this is the case in self-attention: (source: Attention is all you need) Is there a known workaround for such a situation?",https://stackoverflow.com/questions/55491752,826983.0,1
67858077,UnidentifiedImageError in imageclassification using tensorflow,I'm new to tensorflow. I'm following the official tensorflow documentation where they have a sample project. which I'm executing. documentation link everything seem to be working fine but when I try to execute the last block where we are giving our model to identify what kind of flower it is. here is the code the error is how to resolve this error or another way to give my model images to predict??,https://stackoverflow.com/questions/67858077,10861852.0,1
71114690,Tensorflow keras BatchNormalization for higher than 4-dimension Tensor (video input),"I'm trying to implement S3D[https://arxiv.org/pdf/1712.04851.pdf] for video classification and I encountered a problem with BatchNormalization. Since the implementation that I'm dealing with is video classification, I need an additional temporal dimension for my input tensor. (i.e. [Batch, Time, Height, Width, Channel]) Here's my error situation. And the error message is like this. I read about the meaning of axis in BatchNormalization from this stackoverflow question here But I still don't understand why my BatchNormalization code gives an error depending on what axis I give as an argument. Also, I've searched a lot of questions and read tensorflow BatchNormalization document. [link] I think this error message is telling me that it's expecting 4-dimensional input like we usually do for image processing([Batch, Height, Width, Channel]) Can anyone know what is happening here? and how to use BatchNormalization for a 5-dimension Tensor?",https://stackoverflow.com/questions/71114690,13102945.0,1
58644349,Can the bias of a dense layer be set to zero in Tensorflow?,I'm trying to implement a neural network in which I need the kernel multiplication with the input only. The dense layer in Tensorflow also adds bias which I am trying to set to zero. From the documentation the only variable that is available to play with is bias_regularizer. So I tried doing the following: But I still see the bias values are not zero. Is there any other method to achieve this?,https://stackoverflow.com/questions/58644349,6997665.0,1
38517533,How to permutate tranposition in tensorflow?,"From the docs: But it's still a little unclear to me how should I be slicing the input tensor. E.g. from the docs too: Why is it that perm=[0,2,1] produces a 1x3x2 tensor? After some trial and error: [out]: And if I transpose it: I get a 4x3x2 to a 2x3x4 and that sounds logical. [out]: But when I use the perm parameter the output, I'm not sure what I'm really getting: [out]: Why does perm=[0,2,1] returns a 2x4x3 matrix from a 2x3x4 ? Trying it again with perm=[1,0,2]: [out]: Why does perm=[1,0,2] return a 3x2x4 from a 2x3x4? Does it mean that the perm parameter is taking my np.shape and transposing the tensor based on the elements based on my array shape? I.e. : [out]:",https://stackoverflow.com/questions/38517533,610569.0,1
57168631,"Does Keras convolution option ""channels_first"" work with Tensorflow?","Keras documentation for a Conv2D layer implies that a value of ""channels_first"" can be used for the parameter data_format, supporting data that is in ""NCHW"" format, rather than the default ""NHWC"" format. But this doesn't seem to work in the code below. For the ""channels_first"" case, I get the message: Am I making some silly error here?",https://stackoverflow.com/questions/57168631,11825822.0,1
40304005,tf.gradients applied to pooling wrong result?,"I have a problem in tensorflow with tf.gradients applied to pooling: [edit]: I was able to reproduce my expectation by changing the equation to: Anyway, I am not sure why I have to do it this way and people answered below do not seem to understand my problem. I don't understand the tf result for tf.gradients pool test backward. (Looks like tensorflow only returns the store matrix for the locations??). Any idea why tf does not return the actual upsampling result? Here is my code:",https://stackoverflow.com/questions/40304005,4132112.0,1
52879126,How are tensors immutable in TensorFlow?,"I read the following sentence in the TensorFlow documentation: Can someone elaborate a little bit on the ""immutable"" aspect of a Tensor?",https://stackoverflow.com/questions/52879126,3926152.0,1
56367068,"Custom Loss Function: logits and targets must have the same shape ((?, 1) vs (45000,))","My model predicts everything as 0 in a binary classifier. In total we have 4000 true's and 41000 false's. Therefore we're trying to make a custom loss function. The error I receive is: (logits.get_shape(), targets.get_shape())) ValueError: logits and targets must have the same shape ((?, 1) vs (45000,)) The code looks like this: the shape of the initial arrays are: The problem was partly solved with the code in the comments. I now receive an error that I didn't had before. It says:",https://stackoverflow.com/questions/56367068,11192771.0,1
43340217,how the tensorflow call the device?,"how the tensorflow call the device? And how the tesorflow assign the task to the device for automatically? Are there interface source code in tensorflow? But I can't find the source code in details. just like : with tf.device('/gpu:2'): a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a') b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b') c = tf.matmul(a, b) why when we run the with tf.device('/gpu:2'):,the ops(a,b,c) can assign to the gpu:2 for automatically,how can I find the detailed descriptions in the source code of tensorflow? Thanks in advance.",https://stackoverflow.com/questions/43340217,7791266.0,1
44906870,"What is ""Const:0"" in Tensor Object","In a python environment, I'm following along with ""Getting Started With TensorFlow"". I am wondering what the meaning and purpose is of "":0"" as the visualization of these nodes will be just ""Const"" and ""Const_1"". Is there "":1"" for tf.constant()? I searched in the source tensorflow/python/framework/constant_op.py, but it doesn't seem to have my answer. Edit for duplicate questions on How does TensorFlow name tensors? My bad for not concerning tf.Variable and having forgotten constant is also a case of variables.",https://stackoverflow.com/questions/44906870,8253997.0,1
46828171,"In tensorflow, I get the error info ""try: return fn(*args) except errors.OpError as e:""",~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ returns 1.2.1 and I use python 3.5.3 in anaconda I run my code in jupyter notebook. When run the cell(second one)，I come across a error. The detailed information is shown in the picture.,https://stackoverflow.com/questions/46828171,7931705.0,1
49505986,How do i get the VALUES of trainable variables from a restored graph & checkpoint in tensorflow,"I want to get the values of the variables from a trained model. I have a check point file and I can restore graphs and checkpoints and do inference with them just fine. However, I'm finding it extremely difficult to figure out how to get the trainable variable values (like the weight and bias values, not names...i want the VALUES) after I restore the checkpoint and graph. I've read through Tensorflow documentation and there's lots of suggestions regarding ""with variable_scope"", ""reuse = True"", and ""tf.get_variable(""myvar"") within the scope...etc, but I get errors stating either the variable already exists or it hasn't been initialized. tf.graphkeys only returns names...not values.",https://stackoverflow.com/questions/49505986,3496060.0,1
61665285,Problem with input to tf.keras.layers.GRU,"I am trying to make a seq2seq model using tfa.seq2seq.BaseDecoder in TensorFlow 2.1. I have where inputs has shape (batch_size, 1, embedding_dimension) and comes from and states are the encoder hidden states for the batch. I am implementing tfa.seq2seq.BaseDecoder's initialize, step and some properties and the error is happening in step which contains the line that I have copied out here. However, it gives me the following error message (some function names are changed to make explaining the question easier and are slightly different in the code). I didn't manage to figure out from the documentation where the error might be comming from nor did I find any advice on the internet. Any ideas on where the problem might be?",https://stackoverflow.com/questions/61665285,13045395.0,1
73796471,using tf.keras.layers.Embedding for categorical variables in regression problem,Using the iris dataset as a hypothetical hello world example: Let us say I want to use tf.keras.layers.Embedding instead of one-hot/dummy encoding as part of ANN for regression. e.g.: iris_class_name + sepalwidthcm + petallengthcm -&gt; sepallengthcm where sepallengthcm is the dependent variable. I came across this: but am not sure how to exactly use it in my use case. Any pointers very much welcome. Thanks!,https://stackoverflow.com/questions/73796471,283538.0,1
42981493,Weights and biases in tf.layers module in TensorFlow 1.0,How do you access the weights and biases when using tf.layers module in TensorFlow 1.0? The advantage of tf.layers module is that you don't have to separately create the variables when making a fully connected layer or convolution layer. I couldn't not find anything in the documentation regarding accessing them or adding them in summaries after they are created.,https://stackoverflow.com/questions/42981493,7656080.0,1
60690923,How to map input image with neurons in first conv layer in CNN?,"I just completed ANN course and started learning CNN. I have basic understanding of padding and stride operation works in CNN. But have difficultly in mapping input image with neurons in first conv layer but i have basic understanding of how input features are mapped to first hidden layer in ANN. What is best way of understanding mapping between input image with neurons in first conv layer? How can I clarify my doubts about the below code example? Code is taken from DL course in Coursera. How is this input image of size 64*64*3 is processed by 8 filter of each size 4*4*3? stride = 1, padding = same and batch_size = 1. What I have understood till now is each neuron in first conv layer will have 8 filters and each of them having size 4*4*3. Each neuron in first convolution layer will take portion of the input image which is same as filter size (which is here 4*4*3) and apply the convolution operation and produces eight 64*64 features mapping. If my understanding is correct then: 1&gt; Why we need striding operation since kernel size and portion input image proceed by each neuron is same, If we apply stride = 1(or 2) then boundary of portion of input image is cross which is something we don't need right ? 2&gt; How do we know which portion of input image (same as kernel size) is mapped which neuron in first conv layer? If not then: 3&gt; How input image is passed on neurons in first convolution layer, Is is complete input image is passed on to each neuron (Like in fully connected ANN, where all the input features are mapped to each neuron in first hidden layer)? Or portion of input image ? How do we know which portion of input image is mapped which neuron in first conv layer? 4&gt; Number of kernel specified above example (W1= [4, 4, 3, 8]) is per neuron or total number of kernel in fist conv layer ? 5&gt; how do we know how may neurons used by above example in first convolution layer. 6&gt; Is there any relationship between number of neurons and number of kernel first conv layer.",https://stackoverflow.com/questions/60690923,2552740.0,1
41195121,Tensorflow.strided_slice missing argument 'strides'?,"I am trying to run cifar10_train.py according to tutorials, but I got The document says that strides is optional, and it did work properly on Ubuntu before. My tensorflow version is 0.12.0rc1-cp35-cp35m-win_amd64. I have already installed the newest release. May I have to pass this argument? I have no idea about it... UPDATE: I replaced strided_slice with slice, and it works. According to issue#754, strides will be optional at 1.0 release. (maybe?)",https://stackoverflow.com/questions/41195121,7244589.0,1
37890394,Tensorflow GradientDescentOptimizer - how does it connect to tf.Variables?,"Documentation I'm just curious how you tell it to minimize which variables. For example in this linear regression code, TF does fine optimizing weights/bias without being told the names of the variables: How does tensorflow know I want it to update W and b? Does it just see that those are the only Variables in the session?",https://stackoverflow.com/questions/37890394,712997.0,1
57769065,TensorFlow Serving Error: 'StatelessIf has '_lower_using_switch_merge' attr set but it does not support lowering.',"When attempting to serve a new model coded using TensorFlow 2.0 with TensorFlow serving, I get the following error from my Docker container logs: Using the saved_model_cli, the model works fine and can make predictions. Initially I was getting this error: ""TensorFlow Serving crossed columns strange error"" I found that this error might be fixed by swapping to tf-nightly-2.0-preview==2.0.0.dev20190819 But instead I am now I can't even get my model to be served. The only changes I made to the code to compile my model in TF2 are: Like the previous problem, the goal is to have a prediction output from my served model, an output similar to when I use saved_model_cli. Something like this:",https://stackoverflow.com/questions/57769065,11765356.0,1
43504906,How do I read variable length 1D inputs in Tensorflow?,"I'm trying to read variable length 1-D inputs into a Tensorflow CNN. I have previously implemented reading fixed length inputs by first constructing a CSV file (where the first column is the label and the remaining columns are the input values - flattened spectrogram data all padded/truncated to the same length) using tf.TextLineReader(). This time I have a directory full of files each one containing a line of data I want to use as input (flattened spectrogram data again but I do not want to force them to the same dimensions), and the line lengths are not fixed. I'm getting an error trying to use the previous approach of compiling a CSV first. I looked into the documentation of tf.TextLineReader() and it specifies that all CSV rows must be the same shape, so I am stuck! Any help would be much appreciated, thanks :)",https://stackoverflow.com/questions/43504906,3296050.0,1
55619070,GraphKeys.TRAINABLE_VARIABLES vs tf.trainable_variables(),Is GraphKeys.TRAINABLE_VARIABLES is the same as tf.trainable_variables() ? Is GraphKeys.TRAINABLE_VARIABLES actually tf.GraphKeys.TRAINABLE_VARIABLES? Looks like networks successfully trains with: but not with According to documentation: Also as I can see in batch normalization example code var_list is omited:,https://stackoverflow.com/questions/55619070,1179925.0,1
38241758,What do I pass as the x and y parameters in tf.contrib.learn.LinearClassifier.fit,"I've set up a toy example of the TensorFlow linear classifier tutorial. In this example, the fit method is called with a parameter input_fn in which I pass train_input_fn. This is how TensorFlow likes to pass the data. However, I really want to run mini batches. Fortunately, fit has a batch_size parameter, but I need to forgo the use of input_fn and pass x and y instead. I've tried passing ndarrays and DataFrames as well as the output from the train_input_fn function. Nothing works. I need a working example of using the batch_size parameter. Here is the setup code split into stuff I have no problem with followed by the problem portion. Below is the error I get but I get a different error depending on what I try. The documentation says a matrix. I tried that too.",https://stackoverflow.com/questions/38241758,2336654.0,1
49890477,Log accuracy metric while training a tf.estimator,"What's the simplest way to print accuracy metrics along with the loss when training a pre-canned estimator? Most tutorials and documentations seem to address the issue of when you're creating a custom estimator -- which seems overkill if the intention is to use one of the available ones. tf.contrib.learn had a few (now deprecated) Monitor hooks. TF now suggests using the hook API, but it appears that it doesn't actually come with anything that can utilize the labels and predictions to generate an accuracy number.",https://stackoverflow.com/questions/49890477,98975.0,1
59725112,How to automatically assign free GPUs in TensorFlow,"I have 4 Tesla K80 GPUs in my system. I would like to automatically allocate free GPUs based on an integer input in the code. I am aware of tf.config.experimental.set_visible_devices() to assign specific GPUs but currently do not know how to identify which of the GPUs are in-use (expect manually using nvidia-smi). I am currently changing the code below for every run. The above code lets me set the GPUs I want to allocate (GPU 2,3 in above example) for the run. Is there anyway to obtain a list of free (unused) devices to automate the allocation process instead manually having to identify which of the devices should be set? I am currently using TensorFlow version 1.15",https://stackoverflow.com/questions/59725112,7537870.0,1
73004772,Is it possible to set a 1d array to a tensorflow 2 model with tflite?,"I am trying to use a Keras model saved in tflite in C#. For preformance constraints, I would like to have a 1D array as an input to my model. But Keras always seems to add a dimension before for the batch size: I then export it to tflite using the following: When I upen my tflite model, the dimension is (1, 128) I haven't found a way to make it 128 Here it is None, I can set it to 1 but the first dimension remains, I am not sure how to discard it, there seems to be no way to do this in the tensorflow documentation. I use: tensorflow-2.6.5 and python 3.7.5",https://stackoverflow.com/questions/73004772,6651736.0,1
56639621,how to use tensorflow tf.losses.softmax_cross_entropy?,"I am doing some semantic segmentation problem and need to define loss function. Does any one know how to use tensorflow ""tf.losses.softmax_cross_entropy""? It is said in the documentation that the first input of the function is onehot_labels, so do we need to first transfer the pixel-wise class label into one hot encode format and input one hot encode into this function? Or we can directly input the pixel class label like tf.losses.sigmoid_cross_entropy in this post sigmoid_cross_entropy loss function from tensorflow for image segmentation? Thank you so much!",https://stackoverflow.com/questions/56639621,9357193.0,1
54194053,"AttributeError: Layer has no inbound nodes, or AttributeError: The layer has never been called","I need a way to get the shape of output tensor for any type of layer (i.e. Dense, Conv2D, etc) in TensorFlow. According to documentation, there is output_shape property which solves the problem. However every time I access it I get AttributedError. Here is code sample showing the problem: The print(dense.output_shape) statement will produce error message: or print(dense.output) will produce: Is there any way to fix the error? P.S.: I know that in example above I can get shape of output tensor via out.get_shape(). However I want to know why output_shape property doesn't work and how I can fix it?",https://stackoverflow.com/questions/54194053,9565342.0,1
43126116,Range of size of tensor's dimension - tf.range,"I'm trying to define an operation for a NN I'm implementing, but to do so I need to iterate over the dimension of a tensor. I have a small working example below. This produces an error stating When using the same code but using tf.shape instead, resulting in the code being Gives the following error The way that I'm implementing this NN, the batch_size isn't defined until the training function, which is at the end of the code. This is just where I'm building the graph itself, so the batch_size isn't known by this point, and it can't be fixed as the training batch_size and the test set batch_sizes are different. What is the best way to fix this? This is the last thing keeping my code from running, as I got it to run with a fixed batch_size, though those results aren't useful. I've been pouring over the TensorFlow API Documentation and stack overflow for weeks to no avail. I've also tried to feed in a placeholder into the range, so when I'm running the test/training set the code would be the following However, this gives the same error as above",https://stackoverflow.com/questions/43126116,1560300.0,1
42001566,TensorFlow: How to merge multiple 'collections'?,"I have some collections that I would like to track with TensorBoard using a supervisor. In the Supervisor initializer I would like something to the effect But I get the error TypeError: unhashable type: 'list', because the key must be a string (see documentation). Edit: This doesn't work either:",https://stackoverflow.com/questions/42001566,3747801.0,1
67676763,How to read an array (list of dictionaries) into Python Tensorflow?,"As a result of dealing with a gigantic dataset that takes up too much memory, I need to tap into Tensorflow's generator functions (e.g. map, apply) I have the following array that I'd like to load into Tensorflow: From reading the documentation, I've tried the following: However it returns the following error: I've also tried the following based on this documentation that generates the same error: I've also tried this as well, which generates a different error: Error:",https://stackoverflow.com/questions/67676763,2850808.0,1
39555745,How to define a weighted loss function in TensorFlow?,"I have a training dataset of train_data and train_labels which is train_data_node and train_labels_node in the graph of tensorflow. As you know, I can use the loss function of tensorflow as bellows: However, this loss function processes all the training data equally. But in our situation, we want to process the data discriminately. For example, we have a csv file corresponding to the training data to indicate the train data is original or augmented. Then we want to define a custom loss function which makes the loss of original data play more important role and the loss of augmented data play less important role, such as: I have defined a loss function as bellow, but it didn't work: I think we should write the loss function using tensor operations, however, I am not familiar with them. So could anyone give me some advice on how to define the loss function. Thank you for your kind answers or suggestions.",https://stackoverflow.com/questions/39555745,4049614.0,1
70365874,Validation_split with BatchDataset,"I am trying to split my dataset into validation and training. I was unable to call a validation subset in model.fit() as y data is not accepted for datasets, and the validation_split works only for tensors or numpy arrays. I checked the documentation for tensorflow, and there is no documentation of casting of BatchDataset to tensor, unless the neural network is altered itself, which I am unable to do as I am using the resnet architecture using keras. The following errors showed up respectively: Here is the code I am currently working on: Thank you for your time",https://stackoverflow.com/questions/70365874,17280417.0,1
40957286,AttributeError: module 'tensorflow.contrib.slim' has no attribute 'nets',I want to use the built in resnet in tf-slim for a quick experiment. I did according to the README in github: But got such an error:AttributeError: module 'tensorflow.contrib.slim' has no attribute 'nets'. I have already installed the latest version of tensorflow-0.12.0. How can I fix this issue?,https://stackoverflow.com/questions/40957286,5785319.0,1
49865446,Understanding next step after saving TensorFlow model,"I've a simple MNIST which I've successfully saved, being the code the next: Then, the next files are generated: Now, in order to use it in production (and so, for example, pass it a number image), I want to be able to execute the trained model by passing it any number image to make the prediction (I mean, not deploying yet a server but making this prediction ""locally"", having in the same directory that ""fixed"" number image, so using the model would be like when you run an executable). But, considering the (mid-low?) API level of my code, I'm confused about what would be the easiest correct next step (if restoring, using an Estimator, etc...), and how to do it. Although I've read the official documentation, I insist that they seem to be many ways, but some are a bit complex and ""noisy"" for a simple model like this. Edit: I've edit and re-run the mnist file, whose code is the same as above except for those lines: Then, I try to run this another .py code (in the same directory as the above code) in order to pass a local handwritten number image (""mnist-input-image.png"") located in the same directory: Now, if I correctly understand, I've to pass the image as numpy array. Then, my questions are: 1) Which is the exact file reference of those lines (since I've no .meta folder in my User folder)? I mean, to which exact files refer those lines (from my generated files list above)? 2) Translasted to my case, is correct this line to pass my numpy array into the feed dict?",https://stackoverflow.com/questions/49865446,9499989.0,1
55091348,How do I restore subset of weights in fully connected layer?,"My goal is to train a network sequentially by first training a subset of the weights and then training all weights. Consider the two architectures given here first starting with ""Network 1"" which consists of one input scalar z_1, 2 nodes with weights (w_11, w_21) and biases (b_1, b_2) respectively. ""Network 2"" extends ""Network 1"" by adding an input node (z_2) and thus also adding one scalar weight to each node (w_12, w_22). In ""Network 2"", (w_11, w_21) and (b_1, b_2) are initialized by the training result from ""Network 1"" while (w_12, w_22) are initialized in some other way. I know how to save and restore subsets of weights (see here and here). The approach described in the links does, however, not work when using fully connected layers like tf.layers.dense(...), it only works when restoring subsets of variables instantiated by tf.Variable(...). I might have to write a custom layer for this, but I am not sure. How can my goal be achieved? To give some context, the script below saves ""Network 1"" This gives the output The script below restores the graph from the script above and extends it with two weights. NOTE: When z_dim = 1, the code runs fine (it just restores the same graph as before), but when z_dim = 2 it obviously fails because it doesn't know what weights to restore in layer ""h1"". I highly appreciate your input. Thank you.",https://stackoverflow.com/questions/55091348,11180209.0,1
48956407,TensorFlow to Keras Tensor,I'm tyring to mix TensorFlow tensor and Keras tensor using this blog's info: But the problems occurs at the last layer when output needs to be Keras tensor not TensorFlow tensor. Is there a simple way to just convert? Or is there a Keras function that does bilinear resize? Error msg:,https://stackoverflow.com/questions/48956407,9200689.0,1
42560998,Tensorflow classification labels datatype,"I am using Tensorflow DNN model to do some classification. I have a numerical (float32) data input but string type output. When I try to define the loss and optimizer as below: I encounter an error that I looked up the document from here, it said that Do I need to convert the class into a floating number(hashing string to number)?",https://stackoverflow.com/questions/42560998,6343552.0,1
44313202,What are the 'from' and 'to' dimensions of transition_params in tf.contrib.crf.crf_log_likelihood?,"On TensorFlow, I want to pass a transition_params matrix as argument to tf.contrib.crf.crf_log_likelihood (https://www.tensorflow.org/api_docs/python/tf/contrib/crf/crf_log_likelihood), in order to initialize the transitions matrix of the CRF. Although, in the documentation, it is not clear which dimension of this matrix corresponds to the first tag of the transition and which dimension corresponds to the second. So, let T be the transitions matrix, does T[i,j] represent the score of the transition from tag i to tag j, or is it the other way around?",https://stackoverflow.com/questions/44313202,1868775.0,1
45446236,Tensorflow slower when using multiple threads during preprocessing on CPU,"I have a dataset that is generated on the fly on the CPU. Samples are computed in python by a function make_sample that is pretty complex and cannot be translated into tensorflow ops. Because sample generation is time consuming, I want to call the function from multiple threads to fill an input queue. I started from the example given in the documentation and arrived at the following toy example: What surprises me is that, when increasing read_threads, the CPU usage never goes above 50%. What's worse, the computation time plummets: on my computer, Is there an explanation, and above all, a solution to get efficient multithreaded data generation with custom python function on tensorflow?",https://stackoverflow.com/questions/45446236,1735003.0,1
48349099,Questions about tensorflow GetStarted tutorial,"So I was reading the tensorflow getstarted tutorial and I found it very hard to follow. There were a lot of explanations missing about each function and why they are necesary (or not). num_epochs=None, shuffle=True num_epochs=1000, shuffle=False but I don't understand what ""input_fn"" or ""train_input_fn"" are/do, or what's the difference between the two, or if both are necesary. 3.In the estimator.train(input_fn=input_fn, steps=1000) piece of code, I don't understand the difference between ""steps"" and ""num_epochs"". What's the meaning of each one? Can you have num_epochs=1000 and steps=1000 too? These are just some of the questions that bugged me while reading the ""getStarted"" tutorial. I personally think it leaves a lot to desire, since it's very unclear what each thing does and you can at best guess.",https://stackoverflow.com/questions/48349099,8250385.0,1
53970858,Cropping A Detected Object On A Video With Tensorflow Api And Opencv,"-Python 3.6 -Tensorflow 1.11 with GPU support. -Opencv 3.4.2 I am working on Tensorflow Api, and I have already trained my dataset. It works fine. But I have to crop the detected object and make some preprocess on it. It seems easy, because Tensroflow draws the detected object with green box as well. When I try to find the coordinates of the object it gives me numbers of range 0 to 1. When I put the coordinates on Opencv Crop Image I have to multply the image with pictures height and width, but it works wrong. Tensorflow.org says that I can use ""tf.image.crop_and_resize"" function. But I can't run it on my own code. This is my run_inference_for_single_image function and returns output_dict: This is my video capture funtion. It Crops the wrong coordinates. It might be about output_dict. class_name = category_index[output_dict['detection_classes'][i]]['name'] =&gt; This codes give me the name of the class. It works well.",https://stackoverflow.com/questions/53970858,8987216.0,1
46221420,How to use TensorFlow Dataset API in combination with dense layers,"I am trying out the Dataset API for my input pipeline shown in the TensorFlow documentation and use almost the same code: This should be faster since it avoids using the slow feed_dicts. But I can't make it work with my model, which is a simplified LeNet architecture. The problem is the tf.layers.dense in my model_function() which expects an known input shape (I guess because it has to know the number of weights beforehand). But next_example and next_label only get their shape by running them in the session. Before evaluating them their shape is just undefined ? Declaring the model_function() throws this error: Right now, I don't know if I am using this Dataset API in the intended way or if there is a workaround. Thanks in advance! Edit 1: Below is my model and it throws the error at the first dense layer Edit 2: Here you see the print of the tensors. Notice that next_example does not have a shape",https://stackoverflow.com/questions/46221420,6661139.0,1
40435329,TensorFlow:What should be the first parameter for prediction using sess.run() in TensorFlow after loading a saved model.ckpt file?,I am new to TensorFlow and machine learning. I am trying to classify two objects a cup and a pendrive (jpeg images). I have trained and exported a model.ckpt successfully. Now I am trying to restore the saved model.ckpt for prediction of an image. Here is the script: In the above script what should I use as the first parameter in sess.run() ? I have read many stackoverflow and github posts but havent found a solution that works for my case. The TensorFlow Documentation is also not very clear. Thank you in advance,https://stackoverflow.com/questions/40435329,6438307.0,1
61761477,What's the use for converter.build() in TensorRT?,"The official documentation on TensorRT lists two ways to convert a TensorFlow SavedModel into a TensorRT SavedModel: the first is and the second is Stripping out all of the boilerplate code for imports, inference etc the difference seems to lie in the call to converter.build(). The documentation explains this function as such: ""This method optimizes the converted function (returned by convert()) by building TensorRT engines. This is useful in case the user wants to perform the optimizations before runtime. The optimization is done by running inference on the converted function using the input data received from the argument input_fn. This argument is a generator function that yields input data as a list or tuple. "" What does ""before runtime"" mean in this context? Will the ""optimizations"" be performed upon model loading, upon the first inference, or upon every single inference using the converted model? What are those optimizations, even? Isn't converting the model to TensorRT an optimization in itself? I am asking because if I call converter.build() the conversion seems to fail in unpredictable ways after taking a LOT of time (more than two hours) to run without producing any sensible output, so I was wondering how much am I losing by not calling it and whether there is more comprehensive documentation on using TF2.x SavedModels with TensorRT. Thanks in advance to whoever can answer!!",https://stackoverflow.com/questions/61761477,5623016.0,1
56092824,TF 2.0: Where can I find the upgrade of tf.contrib.training?,"I want to use the HParams class from tf.contrib.training in tensorflow 2.0 version, but I can't find the replacement for this class neither in tensorflow alpha documentation nor in tensorflow_addons",https://stackoverflow.com/questions/56092824,6396977.0,1
58527671,Finding the input Tensors of a Tensorflow Operation,"I am trying to generate some kind of textual representation for the TensorFlow Computational Graph. I know that Tensorboard can provide me with the visualization. However, I need some kind of representation (adjacency matrix or adjacency list) from where I can parse information associated with graphs. So far, I have tried the following: After this, I decided to keep the graph object in a separate variable and tried to parse information from there: I found out how to get the list of all operations from this documentation. This part actually provides me with the information of the nodes of the computation graph. However, I cannot seem to find any method that can provide me with information regarding the edges of the computation graph. I cannot find any method that can give me the input tensors associated with each operation. I would like to know that the operation named addition_1 has input tensors produced by the operations addition and multiplication; or something that can be used to derive this information. From the documentation, it seems that the Operation object has a property named inputs which may be the thing I am looking for. Nonetheless, I don't see a method that can be called to return this property.",https://stackoverflow.com/questions/58527671,6868602.0,1
40819321,Understanding the conceptual basics of Distributed TensorFlow,Let me describe the cluster setup first : I have gone through the Distributed TensorFlow documentation but there are some functional basics I could not understand properly and hence this question. Consider the following situation : If I want to use Distributed TensorFlow to train a model :,https://stackoverflow.com/questions/40819321,6842947.0,1
48225315,Reading data into tensorflow and creating Dataset with TF-slim,"I need to read in many 'images' from .txt files and want to generate a tensorflow dataset with them. Currently, I read in every single matrix with numpy.loadtxt and create an array of shape [N_matrices, height, width, N_channels], and a similar array with the label for every matrix. I create a tensorflow dataset from these two arrays by using I now want to make use of the following function to create batches from this dataset (as done here): However, this gives me the following error: Why am I getting this error, and how can I fix it? I also suppose there are much better ways for handling input from txt files to tensorflow (or tensorflow-slim) but I've found very little information on this. How could I generate my Datasets in a better way?",https://stackoverflow.com/questions/48225315,9208637.0,1
61302405,"TensorFlow2 beginner, recalculating after assigning new value","I'm new to TensorFlow (using TensorFlow2). Trying to understand how to re-calculate a simple calculation, after re-assigning a value to variable. It sounds simple, but I'm having a hard time finding it in the new TF2 documentation. Simple example: define a tensor which is a sum two variables (3+4). Then, if I re-assign one of the variables, I'd like to re-use this ""sum tensor"" - making it re-calculate (without having to create a new ""sum tensor""). Is there a way to achieve this please? thank!",https://stackoverflow.com/questions/61302405,13353258.0,1
70608765,ValueError in user code because of custom definition train_step function,"I am trying to build my custom graph neural network, however I do not fully understand the Keras API. Is there anyone who has experience in how to build custom neural networks in the Keras API? I have looked at this documentation. But my application doesn't seem to work due to a ValueError in user code. The problem lies in the input training data and the input of the first layer. In the MNIST data set, the data points is a vector composed of pixel values. And you plug these vectors in the first layer as input layer. However, in my case my data points are matrices. The input of the first layer is a row from this matrix. Per row the loss is calculated and added to the previously calculated loss. Eventually obtaining a cumulative loss per row. Then we backpropagate using the cumulative loss of the entire matrix. Then the next matrix in the dataset is called, etc.... I tried to define a custom train_step function, but failed miserably at it: The error Im getting: Code to reproduce:",https://stackoverflow.com/questions/70608765,17825323.0,1
56992725,Is the shard operation on Tensorflow Datasets deterministic?,"Tensorflow Datasets have a shard operation that creates a unique subset of a given Dataset. We can use it to partition a Dataset, as follows: Is this partitioning deterministic? i.e. the 3 subsets above would always be given the same elements? The documentation states the following about shard:",https://stackoverflow.com/questions/56992725,11726832.0,1
71241340,How can I combine two outputs to form a custom metric in TensorFlow?,"I would like to implement a metric in TensorFlow based on the combined results of two outputs. My model takes in a 100-character string and returns two outputs (called flavour and form) based on this string. These outputs are both softmax probabilities that are compared with a one-hot encoded vectors (standard classification). The code for the model is: Here is a flow diagram of the model's architecture: Currently, I am compiling and fitting as follows: Each of the individual outputs (flavour and form) reach score around 96% accuracy on the test set. However, I would like to create a metric that combines these two predictions and assess them together. Something that might look a little bit like: I've looked at the Keras documentation (https://keras.io/api/metrics/#creating-custom-metrics), but it seems as if the custom metric is applied to each output individually. What can I try next?",https://stackoverflow.com/questions/71241340,13498838.0,1
45357661,Tensor returned by tf.tranpose() different when stored?,"I am writing an application using TensorFlow and I'm using the tf.transpose() function. The API states that the function returns a transposed tensor, which is what you'd expect. However, I noticed the following phenomenon: Does anyone know why this happens or how it should be used?",https://stackoverflow.com/questions/45357661,4699762.0,1
67533336,Implementing Cosine similarity loss gives different answer than Tensorflow's,"I was implementing cosine similarity loss with my custom python script but it gives me a very different answer than TensorFlow. First see TensorFlow's answer:- Output: According to the TensorFlow documentation, the formula to compute the loss is this:- I implemented the same with plain python as this:- Output: I don't why I am getting -2.45 and TensorFlow is outputting -0.85. Any solution so my answer can match with TensorFlow's?",https://stackoverflow.com/questions/67533336,,1
70870188,How to use legacy_seq2seq for TensorFlow 2?,"I am new to TensorFlow and I am wanting to use tensorflow.config.legacy_seq2se, specifically embedding_rnn_seq2seq() and I can't figure out how to use it (or if there is an equivalent method) for TensorFlow 2. I know that in TensorFlow 2, TensorFlow removed contrib and according to this document tf.contrib.legacy_seq2seq has been deleted and replaced with tf.seq2seq in TensorFlow 2, but I can't find embedding_rnn_seq2seq() in the tf.seq2seq documentation I have seen. The reason I want to use it is I am trying to implement something similar to what is done with embedding_rnn_seq2seq() in this article. So is there an equivalent in tensorflow 2, or is there a different way to achieve the same goal?",https://stackoverflow.com/questions/70870188,17499704.0,1
47399201,How to store a dictionary and map words to ints when using Tensorflow Serving?,"I have trained an LSTM RNN classification model on Tensorflow. I was saving and restoring checkpoints to retrain and use the model for testing. Now I want to use Tensorflow serving so that I can use the model in production. Initially, I would parse through a corpus to create my dictionary which is then used to map words in a string to integers. I would then store this dictionary in a pickle file which could be reloaded when restoring a checkpoint and retraining on a data set or just for using the model so that the mapping is consistent. How do I store this dictionary when saving the model using SavedModelBuilder? My code for the neural network is as follows. The code for saving the model is towards the end (I am including an overview of the whole structure for context): I am not entirely sure if this is the correct way to save a model such as this but this is the only implementation I have found in the documentation and online tutorials. I haven't found any example or any explicit guide to saving the dictionary or how to use it when restoring a savedModel in the documentation. When using checkpoints, I would just load the pickle file before running the session. How do I restore this savedModel so that I can use the same word to int mapping using the dictionary? Is there any specific way I should be saving the model or loading it? I have also added inputs_ as the input for the input signature. This is a sequence of integeres 'after' the words have been mapped. I can't specify a string as input because I get an AttributeError: 'str' object has no attribute 'dtype' . In such cases, how exactly are words mapped to integers in models that are in production?",https://stackoverflow.com/questions/47399201,6021490.0,1
44177817,Calling reshape on an LSTMStateTuple turns it into a tensor,"I was using dynamic_rnn with an LSTMCell, which put out an LSTMStateTuple containing the inner state. Calling reshape on this object (by my mistake) results in a tensor without causing any error at graph creation. I didn't get any error at runtime when feeding input through the graph, either. Code: Is this a bug (I ask because it's not documented anywhere)? What is the reshaped tensor holding?",https://stackoverflow.com/questions/44177817,4204963.0,1
75635596,How to create a new Tensor to support batching from the input tensor in a custom layer in tensorflow functional API model,"I am working on a problem in which I have to create a custom layer in keras, which takes, output of a conv layer of a pre-trained model as an input. This custom layer work is to select K best feature maps based on shannon entropy for each images in that input tensor and then outputs the final tensor with k feature maps or each images. So that this output tensor is passed to other conv layer in the model. Let input tensor from a conv layer has shape = (None, 224,224, 128) and I want to take 64 best feature maps out of 128 based on shannon entropy . So the output tensor shape should be = (None, 224,224, 64). Below is the code snippet : But when I ran this code I got error : enter image description here I have tried many solutions available on the internet. But nothing worked. I think this error is due to the shape of input tensor having None as first value in its shape (None, 224,224, 128). But I am unable to resolve this error. And also I don't want to fix batch size during defining Input(shape, batch_size). I want dynamic batch. It would be a great help for me if anyone of you could assist me. Thanks in advance.",https://stackoverflow.com/questions/75635596,21331261.0,1
44569219,Tensorflow: can one prevent one branch of tf.where from executing?,"I'm working on an encoder-decoder setup. I want to be able to run the encoder once and then perform multiple decoder runs. The solution I've come up with is to feed the decoder with a TF conditional node (using tf.where) which contains either the final hidden state of the encoder (in which case TF will run the encoder when I ask for the decoder output), or a placeholder with the stored results of the encoder (in which case in theory TF does not need to run the encoder). Here is the relevant part of the code: As I don't get a speedup from this method, I'm pretty sure it doesn't work and both branches of the tf.where are run by TF everytime, even when it only needs to read from the placeholder. Is there any way to use tf.where such that it does not run the encoder? I've looked at the description of the method and I'm not sure whether both branches are always computed or not, I've seen contradictory information on this issue. Thanks!",https://stackoverflow.com/questions/44569219,8166504.0,1
45403180,TensorFlow: Restoring a model,I'm trying to save my model at the end of triaining and restore it every time the training begins. I just followed what this link did. But it gives error below: Can anyone help me please? Many thanks!,https://stackoverflow.com/questions/45403180,6166590.0,1
41439254,What are the differences between tf.initialize_all_variables() and tf.global_variables_initializer(),"On Tensorflow official website, it gives explantions of the tf.initialize_all_variables() and tf.global_variables_initializer() functions as follow It seems like both can be used to initialize all variables in graphs. Can we use these two functions exchangbly? If not, what would be the differences?",https://stackoverflow.com/questions/41439254,6733064.0,1
66171799,Tensorflow incompatible matrix size when using GradientTape,"I am trying to run code that previously worked on tensorflow 2.2.0 on version 2.4.0-rc0 for apple silicon (using python 3.8), but it is now generating the following error regarding the matrix dimensions: tensorflow.python.framework.errors_impl.InvalidArgumentError: GetOutputShape: Matrix size-incompatible: In[0]: [256,4], In[1]: [4,400] I am using nested gradient tapes to compute the gradient of my MLP model wrt the inputs (which form part of the loss), after which I compute the gradient of the loss wrt the trainable variables as below: In words I am computing the MSE and trying to force the sign of the gradient to be positive (as a soft constraint). I have read through the documentation on gradient tape and as I understand it, setting persistent=True should allow me to recompute gradients freely. As a side note my code works fine if I omit the nested gradient tape and simply use the MSE metric, so I don't think the issue lies anywhere else in the code. Any pointers would be much appreciated, thanks in advance :)",https://stackoverflow.com/questions/66171799,12860541.0,1
53122714,TensorFlow Probability MCMC with Bernoulli distribution,"I need to use TensorFlow Probability to implement Markov Chain Monte Carlo with sampling from a Bernoulli distribution. However, my attempts are showing results not consistent with what I would expect from a Bernoulli distribution. I modified the example given in the documentation of tfp.mcmc.sample_chain (sampling from a diagonal-variance Gaussian) example here to draw from a Bernoulli distribution. Since the Bernoulli distribution is discrete, I used the RandomWalkMetropolis transition kernel instead of the Hamiltonian Monte Carlo kernel, which I expect would not work since it computes a gradient. Here is the code: I expected to see values for the states of the Markov chain in the interval [0,1]. The result for the Markov chain values does not look like what is expected for a Bernoulli distribution, nor does the KDE plot, as shown in this figure: Do I have a conceptual flaw with my example, or mistake in using the TensorFlow Probability API ? Or is there possibly an issue with the TF.Probability implementation of Markov Chain Monte Carlo using a discrete distribution such as the Bernoulli distribution?",https://stackoverflow.com/questions/53122714,3697273.0,1
44314992,Are valid `tf.matmul` arguments described correctly in the TensorFlow documentation?,"Maybe I'm confused about what ""inner"" and ""outer"" tensor dimensions are, but the documentation for tf.matmul puzzles me: Isn't it the case that R-rank arguments need to have matching (or no) R-2 outer dimensions, and that (as in normal matrix multiplication) the Rth, inner dimension of the first argument must match the R-1st dimension of the second. That is, in The outer dimensions a, ..., z must be identical to a', ..., z' (or not exist), and x and x' must match (while p and q can be anything). Or put another way, shouldn't the docs say:",https://stackoverflow.com/questions/44314992,656912.0,1
63068695,Getting error when trying to load data using keras.utils.get_file(),I am getting an error when trying to load a dataset using TensorFlow Keras. Here is the code: I have changed the URL to 'sample_file.zip' for security reasons. This is the error that I am getting: What is causing this error? How can I fix it? This is the first block of code run after imports so I don't know why 'FileExistsError' happens. I have tried changing the name of the file. I have checked TensorFlow documentation and it uses code like this: I have run this above code and it is working. But I cannot figure out why the same code is showing error for my data. Please advice.,https://stackoverflow.com/questions/63068695,12424846.0,1
62729593,Fitting Keras Sequential Model gives ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray),"I have the following array of lists (actors per movie): Since I want to use that as an input to a Keras model I have to convert the array of lists to an array of arrays. To do this I am running the following code, taken from this SO question So now I get this: But neither this is sufficient to get away from the type of the input Tensor, since I get this error: My model fit process [EDIT] - 04.07.2020 I would like to add that I have done the padding on sequences for another experiment and the actor's list that presented above is transformed to list below However, when I apply this list in the .fit() of the neural network I get the following error (39192, 17) is the shape of the actors array [EDIT 2] - 05.07.2020 Trial 1 (failed) Based on some proposals on the answers provided I tried to change input shape of the hub.Keraslayer: I made it equal to my training_input length #39192 data per actor, plot, features, reviews. Error produced: From the error, I can guess that the input_shape should be []? Trial 2 (failed) Error again: I transformed the input list of actors to tensor. Note that only the actor's list has problems because they are stored as names in a list [[name1, name2, name3]]. I had no problem neither with plot, features, or reviews inputs because they are saved as a list of corpus. Trial 3 (failed) Based on the comments I used the data API likewise: Again I got an error: So I searched about it, and I figured out this question and the documentation, I did the following change, (added tf.constant): Moreover, it seems that I cannot convert a NumPy array of strings to a Tensor of floats. Probably here is where the padding of sequences plays an important role. However, if you follow this link of a tensorflow article from which I got the idea, you will notice that the user gives as input only byte strings and not padded sequences. Please note that a solution to all of this, is just to flatten the list of actors by using the "" "".join() command. However, the actors would be just a text of names and not a separate name. Even though it works, I think that for better results the actors should be given as separate names because a Neural Network cannot distinguish names on its own. [INPUT DATA FOR DEBUGGING - ISSUE REPLICATION] In case someone wants to replicate and debug the problem, below I represents my 4 input layers (sample of data) and the article from Tensorflow that I have followed. Here is the Issue's GitHub link with the question posted. As it seems when I run the code locally everything looks fine apart from the EarlyStopping error presented in the GitHub issue attached. I will re-check the data that I use, because the data provided in the GitHub link are the proper data to be used.",https://stackoverflow.com/questions/62729593,10623444.0,1
38937984,"distributed tensorflow on localhosts failed by ""socket error, connection refused""","I am experimenting distributed tensorflow using a slight modification of an official example. My experiment code is (you can skip this for now and scroll down to the problem), Then I run the following commands as instructed by the official document (the script is named hello_distributed.py), The first two lines for running ""ps"" are good. The last two lines get the following ""connection refused"" error. Thank you!",https://stackoverflow.com/questions/38937984,4089301.0,1
40350849,Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2),"I'm building DNN to predict if the object is present in the image or not. My network has two hidden layers and the last layer looks like this: Then I have placeholder for labels: I run training in batches (therefore first argument in Output layer shape is None). I use the following loss function: But in runtime I got the following error: I guess I should reshape labels layer, but not sure what it expects. I looked up in documentation and it says: If I have just single class, what my labels should look like (now it is just 0 or 1)? Any help appreciated",https://stackoverflow.com/questions/40350849,76590.0,1
56409515,What does reset actually mean in Tensorflow 2 dataset?,"I'm following tensorflow 2 Keras documentation. My model looks like this: The documentation says What does the reset actually mean? Will tensorflow read data from tensor slices after every epoch? or it only reshuffles and runs map function? I want tensorflow to read data from numpy after epoch and run _my_cus_func. I can rather pass _my_cus_func on dataset map or apply api, but I'm more comfortable in doing this on python list or numpy array.",https://stackoverflow.com/questions/56409515,2204131.0,1
37146272,How do I get TensorFlow's 'import_graph_def' to return Tensors,"If I attempt to import a saved TensorFlow graph definition with the returned values are not Tensors as expected, but something else: instead, for example, of getting x as I get That is, instead of getting the expected tensor x I get, x.op. This confuses me because the documentation seems to say I should get a Tensor (though there are a bunch of ors there that make it hard to understand). How do I get tf.import_graph_def to return specific Tensors that I can then use (e.g. in feeding the loaded model, or running analyses)?",https://stackoverflow.com/questions/37146272,656912.0,1
63239226,usage of tf.keras.layers.DenseFeatures,"Here is the official doc. This is used in TF example and usually put in keras.Sequential(...) model construction. Like below: In my case, I want to use it to transfer my dictionary data type into Tensor format and pass it into model. So I used code like below: And input is the training data I would feed into model. The question is whether my usage of this DenseFeatures() layer is reasonable. Or this feature_layer has to be in keras.Model class?",https://stackoverflow.com/questions/63239226,2189731.0,1
48368096,TensorFlow Python warning in PyCharm - Cannot find reference __version__ in __init__.py,"I'm using the statement within PyCharm, which is found in many of the TensorFlow GitHub examples, like so: This works great, I'm at TensorFlow 1.4.0 currently, if I run this script as above, the error message does not show, and if I change the if statement to, for example, 2.4.0 (which is not out yet of course) then the error shows as expected and the program exits. The problem I'm encountering is PyCharm shows the following warning on the if statement: Here is a screenshot: If I choose the PyCharm light bulb icon, I get these options: none of which are especially appealing. For the moment, I'm choosing the last option ""Suppress for statement"", which adds this line above the if statement My concern here is I'm in the process of writing documentation that many other people will use, some of whom will be using PyCharm and some of whom will inevitably be using a different editor. For this reason, I can't alter any of the TensorFlow __init__.py files, because that would then create a custom install on my computer and anybody following my documentation would see different results on their screen if they are using PyCharm. Further, I'm using pip to install packages so I'm not even sure if this is possible, but even if it is it's still not an acceptable choice. Similarly, I'd prefer not to include a comment line specific to PyCharm since that would cause confusion for those not using PyCharm. I'd really prefer to not disable this inspection entirely since I find PyCharm's warnings very helpful in many circumstances and therefore I'd rather not disable them. Upon Googling on this concern, I found this post. The suggested answers were to either edit an init.py file which I'd rather not do for the reasons mentioned above, or to change the import statement to be to the effect of which does not seem to be applicable in my case since I'm importing TensorFlow entirely with the statement Even if modifying the import statement to prevent this warning is somehow possible I'd still rather not do this as this would cause confusion for non-PyCharm users and would make my examples different than all the other TensorFlow documentation and examples available. At the moment it seems this is the best I can do: Is there something I'm missing here? Any suggestions as to a better way to do this?",https://stackoverflow.com/questions/48368096,4835204.0,1
48346409,Importing own dataset in TensorFlow,"I am making a neural network using TensorFlow. I now want to import my own images as dataset, to train the neural network on these images. For this, I at first get a list of filenames and their corresponding label. I am doing this with the following code: locations is here a dictionary with the label as key and their folder as value. This works fine: I get a list of the file locations, a list of the labels and a list of which turns the output neuron number in a monkey type. I am then trying to makes from this a TensorFlow dataset. I at first convert the list of the filenames and the labelnames in a TensorFlow constant: I first tried the code on the Tensorflow website. However, I get the error that image contains no shape after decoding an image. How to correctly import images? Further, after making an dataset, I want to loop through it in batches. The MNIST dataset contains a very handy function for it, but is it also possible for custom datasets? Searching for this problems doesn't give me a lot of useful tips.",https://stackoverflow.com/questions/48346409,9198145.0,1
54041135,Multiclass U-Net segmentation in TensorFlow,"I've seen variations of this question all over, but am still struggling to implement it correctly. I have brain MRI images with ground-truth segmented masks with 4 classes (0- background, 1-tissue type1, 2-tissue type2, 3-inexplicably skipped, and 4-tissue type 4...BrATs dataset) I have a basic U-Net architecture implemented, but am having trouble extending it to non-binary classification. Particularly, the loss function. This is what I have implemented, but I'm obviously overlooking important details: I thought 5 filters for the (0,1,2,3,4) possible mask values would be correct. I then used the following loss function: Where the logits would get passed the output from above, and the labels would be my stacked mask images [n_batch, x_dim, y_dim, 1]. Looking at the documentation, I know I am not passing labels the correct tensor. Am I even going about this correctly? How do I implement the loss with multi-class labels contained within the 1 mask image?",https://stackoverflow.com/questions/54041135,6749743.0,1
57191517,About Output of the Keras LSTM,"I have a built a LSTM architecture using Keras. My goal is to map length 29 time series input sequences of floats to length 29 output sequences of floats. I am trying to implement a ""many-to-many"" approach. I followed this post for implementing such a model. I start by reshaping each data point into an np.array of shape `(1, 29, 1). I have multiple data points and train the model on each one separately. The following code is how I build my model: I am confused because when I call model.predict(test_point, steps = 1, verbose = 1) the model returns 29 length 29 sequences! I don't understand why this is happening, based on my understanding from the linked post. When I try return_state=True instead of return_sequences=True then my code raises this error: ValueError: All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API. How do I solve the problem?",https://stackoverflow.com/questions/57191517,8322075.0,1
64422727,What is tensorflow concrete function outputs correspond to structured_outputs?,"I trained my customized ssd_mobilenet_v2 using TensorFlow2 Object Detection API. After training completed, I used exporter_main_v2.py to export a saved_model of my customized model. If I load saved_model by TensorFlow2, it seem there are two kind of output format. Then, I try to convert this saved_model to onnx format using tf2onnx. However, the outputs of onnxruntime was a list. By the shape of result in the list, I think that the sequence is same as detect_fn.outputs Because there is some shape of result which is same as others, so it become hard to recognized. Is there any document talk about this relationship that I can refer?",https://stackoverflow.com/questions/64422727,14148018.0,1
65792565,Preserving training/validation split after restarting training from a checkpoint with TensorFlow,"I have written a TensorFlow training loop which does validation at the end of each epoch. At the start of the training I split my dataset into training and validation subsets (about 85%-15% split). My dataset actually consists of audio samples stored in small chunks on disk, and I randomly shuffle the entire dataset before splitting, so I get a completely even distribution over the training and validation subsets. Problem is, if I restart the training from a given checkpoint the random shuffle occurs again, and I suspect this can lead to data contamination - the validation phase is potentially going to be processing bits of the dataset that the network has aleady been trained on. I think I'm seeing this affecting the loss and accuracy of the training after retsrating, but it's hard to tell. I can't find any info on this specific issue on the web, but my proposed solution is to cache the names of the files in the validation split to a file, and if restarting load them from there. Is there a better solution? For clarity, I am using the tf.data.Dataset API, building both training and validation datasets with a simple dataset pipeline which begins by reading samples from the files on disk.",https://stackoverflow.com/questions/65792565,795131.0,1
60934251,How to send REST API request to Tensorflow Serving model with Sparse tensors?,"I am trying to serve my TF model with TF Serving. Here's the model's input I have: Then I'm exporting my model with: So when I serve exported model by this code using TFS image from Docker Hub, sending HTTP GET request to /model/metadata I'm getting: But when I send HTTP POST request to /model:predict with body: I'm getting an error So how should I re-organize JSON for getting correct Response from the API? TF version: 2.1, TF Serving latest and TF Transform - 0.21.0.",https://stackoverflow.com/questions/60934251,12768873.0,1
39215149,Unable to create correct batches using tf.train.batch(),"I have bunch of data with length of 5000 (though even inner list has different length) and type as numpy array: Then I have converted and created a list of tensors which each tensor represents one example of the original data: Now I have tried using both tf.train.batch() and tf.train.batch_join() to generate batched data: The resulting batched data is wrong, and it simply creates a list (with the same length as inputs) of tensors and each tensor has a shape of (50, length of one input) I suspect it is just 50 replications of that input.. Can someone please enlighten me on how to create correct batched data with the correct length and each batch is dynamically padded. Thanks so much!! Update: Having read LINK, it seems the issue is it tries tf.pack() the tensors which fails because they don't have the same length.. Tried a few things but haven't been successful.",https://stackoverflow.com/questions/39215149,3319713.0,1
39677168,"Tensorflow documentation's example code on ""Logging Device Placement"" doesn't print out anything","Tensorflow documentation has the following example code on finding out the device placement of nodes. That is, on which device a particular computation takes place. For me, the code does not print out the locations of the devices like it is supposed to. I'm using the Jupyter notebook running on Ubuntu. How might I fix this or find out the information some other way?",https://stackoverflow.com/questions/39677168,4700482.0,1
58666537,Error while feeding tf.Dataset to fit(): KeyError: 'embedding_input',"I'm using TensorFlow 2.0 Datasets to feed my model's fit function. Here is the code: But I receive the following error: I've seen this thread, however it doesn't clarify things up for me. As far as I understood there is a problem with the loaded data, but according to documentation for Datasets it should work out of the box, so I couldn't figure out how to fix it. Any help is appreciated. Thanks!",https://stackoverflow.com/questions/58666537,4541899.0,1
39638468,What is the right way to make a barrier in distributed tensorflow?,"During distributed training I want to sync after each epoch, do some calculations on chief worker and proceed or stop training depending on these calculations. I need a barrier to do so. I don't see anything similar in documentation, so I implemented solution based on queues (similar to how gradients are stored and applied in distributed training): The idea is to create a queue per worker. For 'signal' I push a token in each queue and for 'join' I dequeue so many tokens from corresponding queue how many tasks I want to synchronize. The question is: is it the right way to do or there is a better way?",https://stackoverflow.com/questions/39638468,2570037.0,1
48495814,Tensorflow: Error while restoring model,"I am not sure how to use this model to obtain predictions. The code for the model is below: To restore the model and access the variable layer_2, I am using this code: The error I get is: In the Documents folder, the following files are present: model.ckpt.meta, checkpoint, model.ckpt.data-00000-of-00001, model.ckpt.index In general, can you comment on if this approach of evaluation is correct or not.",https://stackoverflow.com/questions/48495814,1262953.0,1
66698823,How to modify output in keras for back propagation,I have a U-Net model written in tensorflow for a segmentation problem. I want to improve my segmentation with the same amount of training data and I was thinking of adding a level set method module to the output and then calculate the loss. Something like this https://arxiv.org/pdf/1705.06260.pdf But I don't know how to modify the output of the last layer in tensorflow How do you apply a transformation to conv1 before forwarding to tf.keras.Model? Thanks you,https://stackoverflow.com/questions/66698823,,1
53144832,Tensorflow CNN 'tuple' object has no attribute 'initializer',"Seems like I am messing up a step in preparing the dataset. Couldn't find a proper answer or look up the correct solution in documentation. I have pointed out the problem line with ###, bottom part. (Model goes here, irrelevant.)",https://stackoverflow.com/questions/53144832,10520111.0,1
59585574,Autograph in TensorFlow 1.15 gives TypeError in conditional statement with value assignment in one branch,"System information Current behavior If a constant value is assigned to variable in one branch of conditional statement, then data type of that value is inferred for the variable, which need not align with the intended data type of the variable leading to TypeError. The issue is that one is expected to know about any assignment in python source code (and its type) before using autograph to create the graph and assign placeholder dtype, which is not always practical. See example minimal code below. Code to reproduce the issue Modification of square_if_positive method from TensorFlow documentation The error message is: See detailed traceback below. How can we modify code or autograph behavior for the code to work successfully? One (undesirable) workaround is to define x as: x = tf.placeholder(tf.float32, name='x') However, this assignment will now fail to work, if foo was: and new error is: Is there a more suitable workaround? Other info / logs Error log:",https://stackoverflow.com/questions/59585574,2376170.0,1
62691100,How to use model input in loss function?,"I am trying to use a custom loss-function which depends on some arguments that the model does not have. The model has two inputs (mel_specs and pred_inp) and expects a labels tensor for training: In my loss function I need to calculate the lengths of mel_specs and pred_inp. This means my loss looks like this: However, no matter which approach I choose, I am facing some issue. If I actually wrap the loss function s.t. it returns a function which takes y_true and y_pred like this: Here I get a _SymbolicException after calling model.fit(): The documentation of add_loss() states: So I tried to do the following: However, calling model.fit() throws a ValueError: Is any of the above options supposed to work?",https://stackoverflow.com/questions/62691100,826983.0,1
48266862,Trouble Displaying an Image with Bounding Boxes,"I have some code which is meant to simply draw a bounding box on an image, and save it out as a new image. However, when I run it I get a TypeError: Cannot handle this data type from pillow. The code is test_no_bb.jpg gets created fine, but when I reach Image.fromarray(bb_image_np).save(""test.jpg""), I get the aforementioned type error. I have searched the web all over to no avail, and TensorFlow's documentation on this is lacking. The shape of the bb_image is correct, and the output of bb (the coordinates of the bounding box) is also correct so I am at a loss. Any help is greatly appreciated.",https://stackoverflow.com/questions/48266862,5280140.0,1
52323297,TypeError when using tf.keras.layers.Reshape,"when building a model in Keras, I run into this error: The error occurs when initially building the model (as opposed to during execution), more specifically on the last line of this snippet: Obviously the dense layer will pass along a tensor of floats because, well, it's a machine learning operation. The issue seems to be that Reshape requires a tensor of integers. I read the documentation but there is no information there. Here are some things I've tried: The weird part is that it works just fine when using eager execution. I don't want to have eager execution enabled though because I want to use tensorboard.",https://stackoverflow.com/questions/52323297,4293998.0,1
55645953,Shape of tensorflow dataset data in keras (tensorflow 2.0) is wrong after conversion from np array,"When setting up a simple tensorflow 2.0 test following this guide, the input to the keras input layer is wrong, but only after converting to a dataset (that pretends to have the right shape). Running the colab notebook from the documentation works of course, but I cannot figure out what might be wrong with my setup. Any hints are appreciated! Setting up some fake data in jupyter lab: Build a simplified model with the functional keras API (sequential doesn't make a difference): Running the model fit on the numpy arrays works as expected: What does not work is fitting with the dataset (while the docs/colab example does): Which throws a ValueError on the input shape which is apparently (1,): This is the simplest, condensed version after encountering the error with more complicated models, and the new tensorflow-datasets package in the first place - it is so simple now that I am out of ideas why it does not just work (and do the (almost) same thing as the numpy array version does).",https://stackoverflow.com/questions/55645953,3084689.0,1
57510115,cifar100 with MobiletNetV2,"I am trying to train MobileNetV2 on CIFAR100 using keras.applications Here is my code: The issue is with the validation accuracy, after 200 epochs the acc is almost 40%. I tried to fine_tune the optimizer/loss params but still the same. My guess is the dim of the input is too small for the model as the default is 224*224, however according to the documentation you could use whatever you want! Any advice? (I do not want to change the dim of cifar100 to 224*224 because of some assumptions related to this experiment)!",https://stackoverflow.com/questions/57510115,458105.0,1
65734836,"Numpy Equivalent to ""tf.tensor_scatter_nd_add"" method","Question is in the title really, I am looking for a method in scipy/numpy/etc. (not TensorFlow) which encapsulates the behaviour described in the tf.tensor_scatter_nd_add but on Numpy arrays rather than tensors. I have come across the scipy.ndimage.sum method, but couldn't get this to reproduce the example I've given below. Whichever method you think fits has to be able to reproduce the rank-3 example that is provided in the TF Documentation: Hopefully someone has solved a similar problem before and can help here - Thanks in advance!",https://stackoverflow.com/questions/65734836,7861160.0,1
47762625,TensorFlow.jl output shape of dynamic_rnn,"I am setting up an LSTM for time series prediction. I need the outputs for every time-step, as I want to calculate loss not only for the last time-step. According to the documentation of tensorflow (Python API), the outputs of dynamic_rnn should have shape [batch_size, max_time, cell.output_size] (if time_major == False). In python, this works fine: outputs has shape [3, 10, 7], which agrees with [batch_size, series_length, hidden_size]. Now, I can use a dense layer to output a single value y at every time-step. When I use TensorFlow.jl, outputs has shape [3, 7] which corresponds to [batch_size, hidden_size]. This seems to be only the last time-step. Does someone understand if this is intentionally, a bug or am I missing the point?",https://stackoverflow.com/questions/47762625,4146880.0,1
69354179,How to get the classes from a Binary Image Classification model with Keras?,"Currently I am working on a binary classification model using Keras(version '2.6.0'). And I build simple model with three Blocks of 2D Convolution (Conv2D + ReLU + Pooling), then a finale blocks contain a Flatten, Dropout and two Dense layers. I have a small dataset of images in my disk and they are organized in a main directory like this: After the training step i have the following learning curves: Even with the noisy behave, they seems great for me (correct me if I am wrong). No overfitting the training and the validation curves have the same behavior, and after 15 epochs I get 1 of accuracy and less than 0.2 as losses. When I test the model, I want to display to which classes the image belong A or B ? I tried the following : but i get the same score (0) for two different images belong to two different classes. I appreciate any suggestions or written documents, because the documentations at Keras didn't specified the details of this step. Thanks in advance.",https://stackoverflow.com/questions/69354179,13906448.0,1
58336039,Loading ModelCheckpoint in tensorflow 2,"In keras using tensorflow 1 I could ModelCheckpoint(filepath) and the saved file was a called filepath and then I could call model = load_model(filepath) to load the saved model. Now the equivalent in tensorflow 2 the ModelCheckpoint creates a directory called filepath and when I follow the documentation here to load the saved model I have to create an empty model then call model.load_weights(filepath). Here is my callback and fit: Doing model.load_weights(filepath) in another script I get the following error: OSError: Unable to open file (unable to open file: name = 'filepath', errno = 13, error message = 'Permission denied', flags = 0, o_flags = 0) I would like to get some help on why I would be getting a permission denied error for a model that I created.",https://stackoverflow.com/questions/58336039,10882883.0,1
59697286,Creating SequenceExample(s) using TensorFlow Transform,"With TensorFlow Transform, we can pre-process data using Apache Beam. One of the requirements when setting up such a pipeline is to define a DatasetMetadata object, which contains the schema that has the information needed to parse the data from its on-disk or in-memory format, into tensors. In the official documentation, we are given an example of the form: This is all fine if your raw data is a dictionary of the form: However, I am somewhat lost when it comes to defining a schema for a SequenceExample. More specifically, consider that my data has the following format: Above I have a sentence with 2 sequences: How can I create a TFT data schema for such examples? The documentation is a bit absent for this one. Any help much appreciated!",https://stackoverflow.com/questions/59697286,5923976.0,1
40859416,Confusion about rank and shape in TensorFlow,"I am confused about rank and shape concept of TensorFlow. I have read the details from here and did run some code to clear my concept about them. But I am still confused and need help to understand. I thought x is like a 2d matrix where 2 is number of rows and 12 is number of columns. Then why I am getting shape for x[120, :] as (12, )? How even x[120, :] is possible with the given shape? Besides, since I thought x is a 2D tensor, its rank is also 2 because dimension and rank is the same thing for tensors (according to my understanding). But when I run: I am getting this error: It means my understanding is wrong about rank and dimension. What I am missing about rank and dimensions? Is rank and dimension two different things? How the rank of tensor x in the above example is 1? How can I set the rank of a tensor? Can anyone explain in details with some comprehensive examples?",https://stackoverflow.com/questions/40859416,5352399.0,1
51482730,TensorFlow: how to export estimator using TensorHub module?,"I have an estimator using a TensorHub text_embedding column, like so: How can I export and serve the model so that it accepts strings as input to predictions? I have a serving_input_receiver_fn as follows, and tried quite a few more, but I'm quite confused as to what it needs to look like so that I can serve it (with saved_model_cli, say) and call it with title strings (or a simple JSON structure) as input.",https://stackoverflow.com/questions/51482730,10122928.0,1
62309757,"tf.data.Dataset.from_generator - TypeError: If shallow structure is a sequence, input must also be a sequence",I am trying to build a generator function that will take multiple inputs and outputs to pass to a model using a series of memory mapped numpy arrays (larger than available RAM). All preprocessing has already been performed and I just need to access these arrays in batches. When I attempt to fit the model: I get the following error: I've tried referring the official documentation and other SO posts but haven't been able to find a solution that used both multiple inputs and multiple labels.,https://stackoverflow.com/questions/62309757,4613042.0,1
73359572,normalize trained data with tensorflow,"this is the code from the TensorFlow website, but doesn't explain well, i know what is the goal of this code which is to normalize data and make it between 0 and 1 instead of 0 to 255, but I need to understand what does lambda means here.",https://stackoverflow.com/questions/73359572,4399890.0,1
59626966,Using tensors are dictionary keys in tensorflow,i have seen the answer here. It is not what i am looking for. I am running this on tensorflow2.0 I read the following sentence in the TensorFlow documentation: I tried using tensors as a dictionary key and i get the following error:,https://stackoverflow.com/questions/59626966,6546694.0,1
38543850,How to Display Custom Images in Tensorboard (e.g. Matplotlib Plots)?,"The Image Dashboard section of the Tensorboard ReadMe says: I see how a pyplot image could be written to file, read back in as a tensor, and then used with tf.image_summary() to write it to TensorBoard, but this statement from the readme suggests there is a more direct way. Is there? If so, is there any further documentation and/or examples of how to do this efficiently?",https://stackoverflow.com/questions/38543850,5587428.0,1
44908968,Tensorflow multiple export strategies,I am training a model with the Experiment class and although the documentation seems to suggest you can have more than one export strategy: When I include two I get an error while training with ml engine: When using the make_export_strategy function there is no option to specify the export directory. Am I approaching this in the wrong way? Ultimately I want people to be able to make prediction requests to the same model with CSV and JSON inputs.,https://stackoverflow.com/questions/44908968,6520820.0,1
60106449,How to create a TensorFlow 2 SavedModel with more than 1 signatures?,"I used tf.saved_model.save and tf.saved_model.load to save and load TF2 SavedModel. According to this link, I created a signature and this signature is serving_default. Then I try to add a new function with signature decorator in class Adder. But after I loaded the model according to this, I find that the signatures disappear in the model, i.e., print(adder1.signatures) prints no signature names. I don't find any information about how to use multiple signatures while saving models. So can anyone provide me with some information? Thank you very much. Tensorflow 2.1.0, on Google Colab. The code looks like this:",https://stackoverflow.com/questions/60106449,12375578.0,1
44219077,label_keys type error on DNNCLassifier Tensorflow,"I want to embed labels into a DNNClassifier model in Tensorflow. Unlike the documentation example, here , I get the following error message: &lt; dtype: 'string'&gt;, got &lt; dtype: 'int64'&gt; On the other hand, if I make the label_key_values column a numpy.array, I will get the following error:",https://stackoverflow.com/questions/44219077,5279947.0,1
43917456,Matrix norm in TensorFlow,"I need to compute the Frobenius norm in order to achieve this formula using the TensorFlow framework: where w is a matrix with 50 rows and 100 columns. I tried to write something, but I don't understand how to fill out the axis argument. According to the TensorFlow docs I have to use a 2-tuple (or a 2-list) because it determines the axies in tensor over which to compute a matrix norm, but I simply need a plain Frobenius norm. In SciPy, for example, I can do it without specify any axis. So, what should I use as axis to emulate the SciPy function?",https://stackoverflow.com/questions/43917456,4735866.0,1
42209854,The node 'Merge/MergeSummary' has inputs from different frames: what does it mean?,"trying to merge all my summaries, I have an error saying that the inputs of Merge/MergeSummary comes from different frames. So, first of all: what is a frame? Could you please point me somewhere in the TF documentation about such stuff? -- of course, I googled a bit but could find almost nothing. How can I fix this issue? Below the code to reproduce the error. Thanks in advance.",https://stackoverflow.com/questions/42209854,1861627.0,1
72386951,"Tensorflow custom training step fails with ""Unexpected result of train_function""","I've subclassed the tensorflow.keras.models.Model class and written a custom train_step, following the process described here. The model takes in two 2d-arrays as input (it is a multi-input model) and produces a single float value as output. I'm passing a TFRecord dataset to the model using the following, where parse_element_func returns a tuple of 4 items: (2d array, 2d array, float, float). The first and second items are input data, the third is the target value, and the last is a number used in a custom loss function that varies by training example. Each of these items is expanded by 1 dimension during training because they are batched. The class looks like this: The model builds and compiles just fine, and I've checked that all the shapes are correct using plot_model. When I test loading the data, everything is there in the correct shape and value. No matter what, I get the same ValueError: This is the only message I get. It doesn't tell me anything about what is wrong besides it has something to do with the training function, and it happens during model.fit. When I call it, it looks like this in my script: Whether I run it eagerly or not does not make a difference. I thought maybe my dataset passing in a tuple of 4 values might be the issue, but as far as I can through the documentation it should be fine, and even I modify the TFRecord dataset element parser to just provide inputs and outputs and no other values (so 2 values instead of 4), I still get the same error. I've spent hours on this and just have no idea why I'm getting this error and what is wrong with this function or my process. Can anyone help figure out how to get past this error?",https://stackoverflow.com/questions/72386951,5744252.0,1
47117498,Does `tf.data.Dataset.repeat()` buffer the entire dataset in memory?,Looking at this code example from the TF documentation: Does the dataset.repeat(num_epochs) require that the entire dataset be loaded into memory? Or is it re-initializing the dataset(s) that came before it when it receives an end-of-dataset exception? The documentation is ambiguous about this point.,https://stackoverflow.com/questions/47117498,4790871.0,1
41515716,Tensorflow tf.contrib.learn.DNNClassifer estimation accuracy does not align to DNNClassifier prediction accuracy,"In general, what alignment should we expect between the accuracy achieved during estimation, and the accuracy achieved during prediction? Simply put, if we achieved an 85% accuracy during estimation, should we expect a similar result during prediction? There are a few other posts discussion prediction accuracy issues, but none appear to ask this question directly. To be more specific, I am using a DNNClassifier to learn against 1000 rows of feature data, each with 53 characteristics (i.e. columns). This is then tested against 100 samples. The model is configured to classify against two labels: 0 and 1, and achieves the prediction accuracy below. INFO:tensorflow:Saving evaluation summary for step 45300: accuracy: 0.846154 accuracy/baseline_label_mean: 0.197802 accuracy/threshold_0.500000_mean: 0.846154 auc: 0.743912 global_step: 45300 labels/actual_label_mean: 0.197802 labels/prediction_mean: 0.283492 loss: 0.398202 precision/positive_threshold_0.500000_mean: 1.0 recall/positive_threshold_0.500000_mean: 0.222222 However, when 15 examples are then used during the prediction step, and where 50% should be classified with a label of 1, they are generally all returned as 0s. Occasionally, a single example will be correctly classified as a 1. For example: Predictions: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] My DNNClassifier is configured as follows: and the predict function is called as below: I have two questions. (1) Am I correct to assume that there should be a direct correlation between estimation and prediction accuracy, and therefore that an 85% estimation accuracy should result in a similar prediction accuracy? (2) Do the other results provided when training completes (i.e. ""labels/prediction_mean: 0.283492"") provide information that is relevant to the low level of prediction accuracy being achieved? I have not been able to find a definition of these result labels in the TensorFlow documentation, and my apologies if I have missed something. Many thanks for any thoughts on this.",https://stackoverflow.com/questions/41515716,7382474.0,1
63821290,"ValueError: Value tf.Tensor.. shape=(), dtype=float64) has insufficient rank for batching.?",I'm trying to take a dataframe and convert them to tensors to train a model in keras. I think it's being triggered when I am converting my Y label to a tensor: I'm getting the following error when casting y_train to tensor from slices: In the tutorials this seems to work but I think those tutorials are doing multiclass classifications whereas I'm doing a regression so y_train is a series not multiple columns. Any suggestions of what I can do?,https://stackoverflow.com/questions/63821290,640558.0,1
44335033,Does 'tf.assign' return its argument?,"The Tensorflow documentation says that tf.assign(ref, ...) returns ref, but it appears instead (not surprisingly) to return a Tensor (attached to the assign op): produces demonstrating that the argument Q and what's returned qop behave differently (and that Q is unchanged until qop is executed). Is the return value of tf.assign described correctly in the documentation?",https://stackoverflow.com/questions/44335033,656912.0,1
74031314,AttributeError: module 'tensorflow_federated.python.learning' has no attribute 'algorithms',"I am trying to run the code given by Tensorflow in their official documentation, pertaining to Tensorflow-Federated. The code is as follows: However, I am getting the following error: Could someone please help me out?",https://stackoverflow.com/questions/74031314,12661027.0,1
34706950,How many processes does TensorFlow open?,"I am using torque to run some CNN-based learning using tensorflow library. (1 CPU per task) When I run top on my server, I noticed that: load average: 677.29, 668.59, 470. I create a session like this: sess = tf.Session() So my question is there some place in documentation where I can read when and how many processes TensorFlow uses.",https://stackoverflow.com/questions/34706950,1886138.0,1
48431870,What does DNN mean in a TensorFlow Estimator.DNNClassifier?,"I'm guessing that DNN in the sense used in TensorFlow means ""deep neural network"". But I find this deeply confusing since the notion of a ""deep"" neural network seems to be in wide use elsewhere to mean a network with typically several convolutional and/or associated layers (ReLU, pooling, dropout, etc). In contrast, the first instance many people will encounter this term (in the tfEstimator Quickstart example code) we find: This sounds suspiciously shallow, and even more suspiciously like an old-style multilayer perceptron (MLP) network. However, there is no mention of DNN as an alternative term on that close-to-definitive source. So is a DNN in the TensorFlow tf.estimator context actually an MLP? Documentation on the hidden_units parameter suggests this is the case: That has MLP written all over it. Is this understanding correct? Is DNN therefore a misnomer, and if so should DNNClassifier ideally be deprecated in favour of MLPClassifier? Or does DNN stand for something other than deep neural network?",https://stackoverflow.com/questions/48431870,1099237.0,1
53845742,How to construct a multi-tower tensorflow graph from predefined models,"I have a model that has been trained and stored to file in Tensorflow. It was a pretrained model that had some parameter tweaking done to produce the required results. Now I am looking to take that model and run it in parallel across multiple GPUs for inference. I can only find resources showing how to produce multi-GPU towers when the graph is initially defined by using tf.device when defining the operations, but since I am reading in a GraphDef from file I don't have that option. For reference, the model loading code (identical to what is on the tensorflow hub's label_image.py):",https://stackoverflow.com/questions/53845742,3773546.0,1
44401495,Tensorflow program results in type conversion error,"Tring to master Tensorflow, following documentation of TensorFlow. Below program results in 'Incompatible type conversion error' Above program results in this error I tried to solve the problem by defining the 'linear_model' variable as float (linear_model = 1.0) or tf.to_float(linear_model = W * x + b) but nothing works Im a TensorFlow newbie, please help me out. Thanks in advance.",https://stackoverflow.com/questions/44401495,557806.0,1
51142984,how to calculate the weights for deconvolution layer based on the trained value weights of the corresponding convolution layer,"Is this possible? The correspoding layer for deconvolution layer is tf.conv2d_transpose(), but the document states it is just a transpose conv layer, not a real deconv. So how can I calculate the weights for deconv layers? Like in the following codes, how can I make y == x(by calculating W2 from W)? Is this possible? Or the only way is to train the deconv layer? But in Visualizing and Understanding Convolutional Networks, Matthew D. Zeiler and Rob Fergus, they proposed a way to do deconv with the""transposed versions of the same filters*, does this mean the shape is transposed or it includes the weight?",https://stackoverflow.com/questions/51142984,10022303.0,1
47406652,How to correctly implement Keras's fit_generator on multiple datasets?,"I am having a problem implementing Keras's fit_generator function. I have followed the Keras documentation and numerous other documentation online. But I can't seem to get this thing to work. When I run the fit_generator, it is not throwing an error. I could tell that something is running in the background since my GPU usage on my task manager skyrockets to 70% processing. However, there is no text/verbose that says that the batches are being processed for my convolutional neural network. I have six hdf5 files that I want to loop through that each contain 40,000 images. They are already formatted as Numpy arrays. I am yielding a batch size of 20 each time. When fitting my model with my generator, I know that my GPU is processing the data; I've got an NVIDIA GTX 1070. But there is no verbose/text displayed when running this code below. I also tried running without GPU, but still no luck. Is there something I'm doing wrong here?",https://stackoverflow.com/questions/47406652,5187714.0,1
58871822,How to combine multiple output in tensorflow to create a metric?,"I am working on a multi-task neural net which has two outputs, a segmentation ""mask"" and a classification ""label"": From this model I obtain one prediction ""mask"" and one prediction ""label"". The question is: I want to create a metric such that it only evaluates the dice coefficient of ""mask"" when the corresponding ""label"" &gt; 0.5. I have been searching this for quite a while and from tensorflow official site I can only find how to calculate metrics for each output, but no documentation on how to access all the predictions and combine them. here each metric only accept two arguments (y_true, y_pred). Update: I have figured out a work around myself, instead of combining results in the metrics, I added one lambda layer in the network and added one more output And the metrics now is set to be: This works but seems like will cost additional memory. Still looking for a neat solution...",https://stackoverflow.com/questions/58871822,12376581.0,1
67803574,Weights were not updated using Gradient Tape and apply_gradients(),"I am building a DNN with a custom loss function and I am training this DNN using Gradient Tape in TensorFlow.kerasenter code here. The code runs without any errors, however, as far as I can check the weights of the DNN, the weights were not being updated at all. I followed exactly what recommends from the TensorFlow website and search for the answers but still don't understand what is the reason. Here is my code: I have checked the weights of the model using model.get_weights() and they look exactly the same before and after running the loop. So what is the problem here? And one more question, how can I print out the loss for every epoch?",https://stackoverflow.com/questions/67803574,16104905.0,1
50204609,Is there a way to partition a tf.Dataset with TensorFlow’s Dataset API?,"I checked the doc but I could not find a method for it. I want to de cross validation, so I kind of need it. Note that I'm not asking how to split a tensor, as I know that TensorFlow provides an API for that an has been answered in another question. I'm asking on how to partition a tf.Dataset (which is an abstraction).",https://stackoverflow.com/questions/50204609,1120410.0,1
70007364,tf.print gives TypeSpec TypeError,"What does this error message mean? I'm printing the shape of a tensor. My code ""works"" without the print, so I'm sure it is this statement, and the tensor is valid. I can print the shape of a tensor in a test colab. I'm clueless how to narrow this down and debug this. My failure is in a big hairy program. I can't find any information on the web about what might be causing this error. What does it mean when I get a TypeSpec error from a tf.print? -- Malcolm (TF 2.7.0)",https://stackoverflow.com/questions/70007364,5662360.0,1
56146885,How can I inspect the contents of my tensor using TensorFlow’s eager execution?,"I use TensorFlow 1.12 using eager execution, and I have the following (incomplete) function in which I want to inspect some intermediate tensor: However, print(mask) merely returns Tensor(""mask:0"", shape=(?, 1000, 1200), dtype=uint8), while I would like to see the actual values. This should be possible, as demonstrated in TensorFlow’s eager execution guide. I also tried tf.print(mask, output_stream=sys.stdout), but only a blank line is being printed. mask.dtype is uint8, so I guess it should contain integers, given that is has a shape. What I also find strange is that mask.device is the empty string. It should be stored on some device, right? How can I print the contents of the mask tensor?",https://stackoverflow.com/questions/56146885,,1
48531039,Create variable of weights from array,"I have an array : [1, 4, -10, 3, 5]. I'm trying to create a Variable of weights using that array. After doing training, I print the weight as: the result is just the array in the format [1, 4, -10, 3, 5]. How I tried to create a Variable from the array: Obviously, this weight result is wrong, and I've spent hours looking at documentation and SO posts. How do I create a Variable using that array?",https://stackoverflow.com/questions/48531039,7933838.0,1
54271159,Variable size mismatch between x.shape and tf.shape(x)?,"I am trying to understand tf code and for this I am printing out shapes of tensors. For the following code I get output It does not make a lot of sense. Based on what I found online tf.shape(x) can be used to dynamically get the size for the batch. But it gives rather wrong output - 4. I am not sure where this (4,) is coming from and how to get the right value for my tensor.",https://stackoverflow.com/questions/54271159,3849781.0,1
71803405,Tensorflow - post training integer quantization,"I am trying to perform post training integer quantization to a model trained in Tensorflow 2.8.0, following the instructions mentioned here with some adaptations. I have all my images in a directory called ""customTF2/data/images"". I can't figute out though how to generate a representative dataset needed for the quantization. The official documentation, as well as the majority of examples found online, use either Tensorflow datasets or datasets where the images are already labelled and split into relevent subfolders (which is not the case for my project). Below is my code which fails with the error : Given shapes, [1,20,20,128] and [1,19,19,128], are not broadcastable.Node number 68 (ADD) failed to prepare. Not sure how I should perform the quantization for that dataset or how the previous code needs to be updated. Any help would be appreciated.",https://stackoverflow.com/questions/71803405,7127572.0,1
42201565,Using Tensorflow.slim to apply convolution2d_transpose,"I am trying to apply 2 convolutional layers with the tf.slim.conv2d function, they basically reduce the size of my input image by half each time. Then I want to apply the convolution2d_transpose to get my original image shape back. The problem is I don't exactly know how to use the transpose convolution function, and the documentation is not much help. I am using a custom wrapper, but here is what I have so far: How can I apply the convolution_transpose function to reverse the effect of these two layers now ?",https://stackoverflow.com/questions/42201565,5016028.0,1
49223976,Default Initialization for Tensorflow LSTM states and weights?,I am using the LSTM cell in Tensorflow. I was wondering how the weights and states are initialized or rather what the default initializer is for LSTM cells (states and weights) in Tensorflow? And is there an easy way to manually set an Initializer? Note: For tf.get_variable() the glorot_uniform_initializer is used as far as I could find out from the documentation.,https://stackoverflow.com/questions/49223976,5763590.0,1
65851897,subclassing of Model class and model functional API give different results in tensorflow,"According to the documentation for a model, there are two equivalent ways to create a model: by subclassing the Model class or using the functional API. When I run the following code below, I get an error. Please tell me why this is so. Shouldn't the two models be identical?",https://stackoverflow.com/questions/65851897,9680031.0,1
54703473,TensorFlow why we still use tf.name_scope when we already have the function tf.variable_scope,"I do not understand why we also need the function tf.name_scope when we already have tf.variable_scope. From the Tensorflow official API, I see that the tf.variable_scope is more powerful because it can have an effect on tf.get_variable. When we create layers and want to share variables, we always use tf.variable_scope and tf.name_scope. However, I try to learn something new from code released by Nvidia on GitHub. I found that it is frequent for coders to use tf.name_scope. Why do we still need this function?",https://stackoverflow.com/questions/54703473,9881203.0,1
71889649,(Conv1D) Tensorflow and Jax Resulting Different Outputs for The Same Input,I am trying to use conv1d functions to make a transposed convlotion repectively at jax and tensorflow. I read the documentation of both of jax and tensorflow for the con1d_transposed operation but they are resulting with different outputs for the same input. I can not find out what the problem is. And I don't know which one produces the correct results. Help me please. My Jax Implementation (Jax Code) My TensorFlow Implementation (TensorFlow Code) Output from the Jax Output from the TensorFlow,https://stackoverflow.com/questions/71889649,17030468.0,1
54516938,Weights decay on evaluation step - Tensorflow,"My weights are defined as I want to use the weights decay so I add, for example, the argument to the tf.get_variable. Now I'm wondering if during the evaluation phase this is still correct or maybe I have to set the regularizer factor to 0. There is also another argument trainable. The documentation says If True also add the variable to the graph collection GraphKeys.TRAINABLE_VARIABLES. which is not clear to me. Should I use it? Can someone explain to me if the weights decay effects in a sort of wrong way the evaluation step? How can I solve in that case?",https://stackoverflow.com/questions/54516938,9540764.0,1
49820105,Tensorflow Mean Absolute Error (MAE) for evaluation,"Looking at tensorflow docs for MAE, I saw that tf.metrics.mean_absolute_error will return: How to implement this for evaluation purpose? As stated here: I don't know how to deal with returned value from mean_absolute_error function. Can someone write a simple example with this function? Thanks a lot.",https://stackoverflow.com/questions/49820105,3280050.0,1
42909692,"Tensorflow error using while_loop: ""List of Tensors when single Tensor expected""","I'm getting a TypeError(""List of Tensors when single Tensor expected"") when I run a Tensorflow while_loop. The error is from the third parameter, which should be a list of Tensors, according to the documentation. x, W, Win, Y, temp, and Wout are all previously declared as floats and arrays of floats. cond2 and test2 are functions I've written to be the condition and body. I use an almost identical call earlier in the program with no issues.",https://stackoverflow.com/questions/42909692,7643546.0,1
74248433,Keras slicing index out of range beginner question,I am using Keras and Tensorflow for the first time. I am trying to get vgg16 to train on the imagenette dataset. Im not sure why I am getting an index out of range error. Maybe I am doing something obviously wrong. Ive been messing with this for awhile now so any help would be great! Attached is the error and source code I resized my images to the correct size based on the vgg16 documentation: https://keras.io/api/applications/vgg/#vgg16-function ` ` Error:,https://stackoverflow.com/questions/74248433,6632577.0,1
53562518,How to create ClassificationRequest with structured data to send to TensorFlow Serving with gRPC,"I trained &amp; exported the Iris Classifier from this guide. I exported it by adding the following to premade_estimator.py: I'm able to get inferences using the REST API like so: I've also been able to successfully get inferences with other models using gRPC, like this object detection model which takes as input an image as an array: But I can't figure out how I'm supposed to specify the inputs for a ClassificationRequest. My best guess is something along these lines: But I can't find any information about how to set the input, and everything I've tried so far throws some kind of TypeError.",https://stackoverflow.com/questions/53562518,5870145.0,1
58525480,Padded_batch with pre- or post-padding option,"I have a dataset of variable-length sequences (a tensorflow TFRecord dataset) to feed an LSTM network and I want to try and compare pre- and post-padding in the batches, but current padded_batch function only pads at the sequences end. I know that we have tf.keras.preprocessing.sequence.pad_sequences function in API but I don't know how to apply this function to dataset batch processor. The padded_batch function in tensorflow does both padding and batching, and it will find the required paddding size per batch dynamically. How can I implement this myself? My code right now is like this, and I am reading multiple TFRecord files and interleave them to make my mixed dataset:",https://stackoverflow.com/questions/58525480,6450489.0,1
61678924,Can you explain difference between tensorflow loading and hdf5 loading in keras model,I was trying to load the keras model which I saved during my training.So I went to keras documentation where I saw this. Could you please explain the above one?,https://stackoverflow.com/questions/61678924,9999035.0,1
68984195,Converting tensorflow 1.0 code to tensorflow 2.0,"I have the following code: Since ""session"" are no longer supported in tensorflow 2.0, how do i modify it so that it is in tensorflow 2.0 syntax? I would prefer not using the compat function as I want to learn the new tensorflow 2.0 syntax alternative for session. I read the doc, https://www.tensorflow.org/guide/effective_tf2 but I'm having a hard time understanding it on the doc mentioning to use a function instead. How do i modify the session code above so that i can get the same output in tensorflow 2.0?",https://stackoverflow.com/questions/68984195,7661005.0,1
57376829,"How can I filter and balance a Windowed Tensorflow dataset with a binary classification label, based on the label?","I have an unbalanced tensorflow windowed dataset with labels (over 90% negative examples) which I am trying to balance by filtering. I am having trouble filtering as my windowed dataset with labels does not fall under the cases I have come across in my searches, or the tensorflow documentation. I'm working on a model to predict a binary classification based on time series data. I start with a time series dataframe with a number of columns (price, volume, etc.) where each row is one minute. Currently I am still stuck on filtering the different labels. My next step after filtering would be to get the size of both filtered datasets, find the smaller size (n), and then concatenate the smaller dataset with (n) elements from the bigger dataset, after shuffling the bigger dataset. This way I would have a balanced dataset with an equal number of 1 and 0 labels. If you have a better Idea I would be happy to hear it. EXPLAINING MY CODE: DFrame is a pandas dataframe with columns such as price, volume, etc., and each row is a different minute, with the first row being the earliest/oldest time period. The last column of DFrame is the classifier 0 or 1. I then create a tensorflow dataset from slices with the first input being all the DFrame columns except for the label which is in the last column, and the second input (the label) being the last column which is the classifier. I then use the window function to create windows of size (hindsight) which is currently 512, meaning (If i'm not mistaken) it takes the previous 511 minutes as well as the current minute and uses this as a rolling window to associate with the label of the current minute. So my understanding is that x is then an array of 512 arrays, from the row of the current minute to the row of 511 minutes ago, and the y is the label of the current minute. So x is an array of 512 arrays (rows for each minute, from the dataframe), and y is just one integer, 1 or 0. Ideally I would like to be able to apply the same balancing logic to a multiclass classification problem, where I essentially add additional labels for additional price movement ranges. The error comes from the filter. The model seems to run without that, and even trains my keras model. as explained I would actually want to add more code after the filter once I get it working to balance the dataset but I need to filter it first.",https://stackoverflow.com/questions/57376829,11743037.0,1
76262758,TF2.3 - More model outputs than targets,"I am trying to write a model in which there are three outputs, the latter two of which are to be trained with respect to targets present in the dataset, the former should just be a non-trainable output. First, defining a dataset: In the above, the dataset has two targets, corresponding to the last two outputs of the model defined below. From reading the Keras documentation, to handle this case where there are a greater number of model outputs than there are targets in the dataset (with the surplus outputs considered to be non-trainable), it appears that the Model.compile arg loss_weights should handle the matching between targets and losses. More concretely, given the following. I would expect that Keras would disregard the first model output when computing the loss, given the None loss provided and the 0 loss weight, however I am seeing the following error. Which seems to indicate that this is not the case when run as follows. If I provide an additional target in data_fn and gen, combined with a dummy loss (lambda x, y: 0.0. for example), then training commences. However, this will not scale to a non toy problem with potentially large outputs and targets (images, for example). If I instead return a dict from the model call method and provide dict for losses and loss_weights (both with keys matching that returned from call), there is no change (I thought that the explicit output naming might allow Keras to match outputs, losses and targets). Am I misunderstanding the intended purpose of lists as losses (in which None is allowed) and loss_weights?",https://stackoverflow.com/questions/76262758,588959.0,1
34265768,What is a tensorflow float ref?,Trying to run the following basic example to run a conditional calculation I got the following error message: what is a tensorflow float_ref and how does the code have to be modified?,https://stackoverflow.com/questions/34265768,2505295.0,1
63656333,'Reduction' parameter in tf.keras.losses,"According to the docs, the Reduction parameter takes on 3 values - SUM_OVER_BATCH_SIZE, SUM and NONE. What I could infer about the calculation after various trials, is this:- As a result, SUM_OVER_BATCH_SIZE is nothing but SUM/batch_size. Then, why is it called SUM_OVER_BATCH_SIZE when SUM actually adds up the losses over the entire batch, while SUM_OVER_BATCH_SIZE calculates the average loss of the batch. Is my assumption regarding the workings of SUM_OVER_BATCH_SIZE and SUM at all correct?",https://stackoverflow.com/questions/63656333,9895768.0,1
52920476,Tensor - define function while evaluating other one,"I need to define an error function looking like this: e = (y(0) - 1)^2. My y function/tensor looks like this: I have read, that all the variables have to be declared before the session start. I'd define the error function/tensor like this: But, I'm not able to use eval() method outside the session block. So, how should I define the tensor containing y_1(0)?",https://stackoverflow.com/questions/52920476,3801449.0,1
64908920,Can't use color_mode = 'grayscale' with grayscale JPEGs,"I'm using tensorflow v 2.3.1 This is my code: Errors out with : I thought, documentation says, grayscale is how jpeg will be preprocessed. Any ideas about the cause?",https://stackoverflow.com/questions/64908920,14665728.0,1
46820500,How to handle large amouts of data in tensorflow?,"For my project I have large amounts of data, about 60GB spread into npy files, each holding about 1GB, each containing about 750k records and labels. Each record is a 345 float32 and the labels are 5 float32. I read the tensorflow dataset documentation and the queues / threads documentation as well but I can't figure out how to best handle the input for training and then how save the model and weights for future predicting. My model is pretty straight forward, it looks like this: The way I was training my neural net was reading the files one at a time in a random order then using a shuffled numpy array to index each file and manually creating each batch to feed the train_op using feed_dict. From everything I read this is very inefficient and I should somehow replace it with datasets or queue and threads but as I said the documentation was of no help. So, what is the best way to handle large amounts of data in tensorflow? Also, for reference, my data was saved to a numpy file in a 2 operation step:",https://stackoverflow.com/questions/46820500,686572.0,1
55688621,How to apply mask to a tensor and keep its original shape,"I have two tensors: one containing data and the other mask of boolean values. I would like to set all values in data tensor to zero, if boolean values are False, while keeping the original shape of data tensor. So far I can achieve it only while mask is a numpy array. Since https://www.tensorflow.org/api_docs/python/tf/boolean_mask influences shape of the tensor, I cannot use it. How to do that?",https://stackoverflow.com/questions/55688621,1435046.0,1
60665006,Conceptual understanding of GradientTape.gradient,"In Tensorflow 2, there exists a class called GradientTape which is used to record operations on tensors, the result of which can then be differentiated and fed to some minimization algorithm. For example, from the documentation we have this example: The docstring for the gradient method implies that the first argument can be not just a tensor, but a list of tensors: In the above example, it is easy to see that y, the target, is the function to be differentiated, and x is the dependent variable the ""gradient"" is taken with respect to. From my limited experience, it appears that the gradient method returns a list of tensors, one per each element of sources, and each of these gradients is a tensor that is the same shape as the corresponding member of sources. The above description of the behavior of gradients makes sense if target contains a single 1x1 ""tensor"" to be differentiated, because mathematically a gradient vector should be the same dimension as the domain of the function. However, if target is a list of tensors, the output of gradients is still the same shape. Why is this the case? If target is thought of as a list of functions, shouldn't the output resemble something like a Jacobian? How am I to interpret this behavior conceptually?",https://stackoverflow.com/questions/60665006,6204891.0,1
46135499,How to Properly Combine TensorFlow's Dataset API and Keras?,"Keras' fit_generator() model method expects a generator which produces tuples of the shape (input, targets), where both elements are NumPy arrays. The documentation seems to imply that if I simply wrap a Dataset iterator in a generator, and make sure to convert the Tensors to NumPy arrays, I should be good to go. This code, however, gives me an error: Here's the error I get: Strangely enough, adding a line containing next(datagen) directly after where I initialize datagen causes the code to run just fine, with no errors. Why does my original code not work? Why does it begin to work when I add that line to my code? Is there a more efficient way to use TensorFlow's Dataset API with Keras that doesn't involve converting Tensors to NumPy arrays and back again?",https://stackoverflow.com/questions/46135499,4444582.0,1
61830841,"Why am I getting ""ValueError: No gradients provided for any variable: ['Variable:0']."" error?","I'm extremely new to tensorflow, and I'm trying to build a style transfer model, I understand the concept of how the model is but am having difficulty at actually implementing it, since I don't fully understand what is going on in tensorflow, yet. When I try to run the optimization for the generated image I get the ""No gradients provided"" error, which I don't understand since my code has:",https://stackoverflow.com/questions/61830841,13552520.0,1
64438467,"Multi Input Modeling in TensorFlow, with Generator",I do not understand why at the 2nd time the model is not receiving any input from the generator (it is supposed to be a generator which is basically producing the same data). The input is intentionally random. Is there any problem with my generator? I know it is not good practice but logically I was thinking it should work for creating an example purpose. But I am stuck. I have intentionally added some print statements to understand and explanation purposes.,https://stackoverflow.com/questions/64438467,7096813.0,1
63587813,Tensorflow - Conv2D batch_input_shape array shape error,"I am trying to create a basic CNN in tensor flow using some custom dataset from 2D np arrays. I cant seem to get the input data to line up with the input_shape or batch_input_shape parameter for the convolutional layer. I have tried every order of variables and the same as the documentation, but am unsure why it still produces an error. Any help would be greatly appreciated! It always says that either the input data is not in the expected format or that the ndims is wrong as it adds None to some of the values. I just can't make it run!!",https://stackoverflow.com/questions/63587813,9807578.0,1
44462550,Keras + Tensorflow : Debug NaNs,"Here is a great question on how to find the first occurence of Nan in a tensorflow graph: Debugging nans in the backward pass The answer is quite helpful, here is the code from it: Apparently, running the training and the numerical check at the same time will result in an error report as soon as Nan is encountered for the first time. How do I integrate this into Keras ? In the documentation, I can't find anything that looks like this. I checked the code, too. The update step is executed here: https://github.com/fchollet/keras/blob/master/keras/engine/training.py There is a function called _make_train_function where an operation to compute the loss and apply updates is created. This is later called to train the network. I could change the code like this (always assuming that we're running on a tf backend): I'm currently trying to set this up properly and not sure whether the code above actually works. Maybe there is an easier way ?",https://stackoverflow.com/questions/44462550,497600.0,1
68134087,Why does the loss spike up after compiling for a second time?,"I'm currently working on a project that requires me to change the model architecture half way during training using Tensorflow. There are new weights added and others removed. The model needs to be recompiled so that the Optimizer recognizes the new weights and calculates gradients for them. However i noticed, that after compiling the network, the loss spikes up only to after drop down again (see here) In the first steps after compiling the loss is still as low as before, but it increases quick. This Question is similar to mine but only says that you should But I can't find any resources on how to do this. My attempts include: I recreated the problem with a modified example from https://www.tensorflow.org/datasets/keras_example and increased the network complexity as the height of the spike seems to increase with the network size: This is the resulting plot. In this example I didn't change the Network but compiled with a different Optimizer, from my testing the loss spikes regardless of which combination you choose. (if you compile with model.optimizer without changing the model, the loss doesn't increase which makes me think I have to change the optimizer. But SGD also doesn't work which confuses me) This is the same Problem as if you resume model training after restoring with another model.fit() call. I'm using Tensorflow version 2.5.0 Any ideas on how to fix or work around this problem?",https://stackoverflow.com/questions/68134087,16314415.0,1
47103249,How to use tf.data.Dataset.padded_batch with a nested shape?,"I am building a dataset with two tensors of shape [batch,width,heigh,3] and [batch,class] for each element. For simplicity lets say class = 5. What shape do you feed to dataset.padded_batch(1000,shape) such that image is padded along the width/height/3 axis? I have tried the following: Each raising TypeError The docs state: The relevant code:",https://stackoverflow.com/questions/47103249,7067514.0,1
64063954,How do I multiply each vector in tensor by each element of vector,Hi so what I exactly want is if we have matrix W and vector V such as: we should got the result: I found this method on the website: which is exactly what I want but when I implement this on my model it also include the batch size of the vector in which result in error such which I assume is the same error which this can produce I wanted to know what is the standard procedure to get each element from the softmax output vector and multiply them as weight for each vector in the feature tensor,https://stackoverflow.com/questions/64063954,11344228.0,1
59751851,I get an error when I load a tensorflow2.0 model,I am learning a simple model to perform a linear regression and then I save the model and then I am trying to load the model with the following lines following tensorflow documentation: However I get the following error message: What is wrong ? Why serving_default is not defined ?,https://stackoverflow.com/questions/59751851,9427880.0,1
42173255,How does batching interact with the loss function in TensorFlow?,"I'm training a multi-objective neural net in TensorFlow with my own loss function and can't find documentation regarding how batching interacts with that functionality. For example, I have snippet of my loss function below, which takes the tensor/list of predictions and makes sure that their absolute value sums to no more than one: But when I'm passing in a batch of estimates I feel like this loss function is normalising the whole set of inputs to sum to 1 at this point, rather than each individual set summing to 1. I.e. [[.8,.8],[.8,.8]] -&gt; [[.25,.25],[.25,25]] rather than the desired [[.8,.8],[.8,.8]] -&gt; [[.5,.5],[.5,.5]] Can anybody clarify or put to rest my suspicions? If this is how my function is currently working, how do I change that?",https://stackoverflow.com/questions/42173255,4910036.0,1
49560420,Deep Learning implementation in Tensorflow or Keras give drastic different results,"Context: I'm using a fully convolutional network to perform image segmentation. Typically, the input is an RGB image shape = [512, 256] and the target is a 2 channels binary mask defining the annotated regions (2nd channel is the opposite of the fist channel). Question: I have the same CNN implementation using Tensorflow and Keras. But the Tensorflow model doesn't start learning. Actually, the loss even grows with the number of epochs! What is wrong in this Tensorflow implementation that prevents it from learning? Setup: The dataset is split into 3 subsets: training (78%), testing (8%) and validation (14%) sets which are fed to the network by batches of 8 images. The graphs show the evolution of the loss for each subsets. The images show the prediction after 10 epoch for two different images. Tensorflow implementation and results Keras implementation and reslults There must be a difference between the two but my understanding of the documentation lead me nowhere. I would be really interested to know where the difference lies. Thanks in advance!",https://stackoverflow.com/questions/49560420,1782553.0,1
64181490,Having problems while doing multiclass classification with tensorflow,"https://colab.research.google.com/drive/1EdCL6YXCAvKqpEzgX8zCqWv51Yum2PLO?usp=sharing Hello, Above, I'm trying to identify 5 different type of restorations on dental x-rays with tensorflow. i'm using the official documentation to follow the steps but now i'm kind of stucked and i need help. here are my questions: 1-i have my data on my local disk. TF example on the link above downloads the data from a different repository. when i want to test my images, do i have any other way than to use the code below ?: i'm asking this because the official documentation just shows the way to test images one-by-one, like this: 2- i'm using ""image_dataset_from_directory"" method, so i don't have a separate validation directory. is that ok ? or should i use ImageDataGenerator ? For testing my data, i picked some data randomly from all 5 categories by hand and put them in my test folder which has 5 subfolders as i have that number of categories. is this what i am supposed to do for prediction, also separating the test data into different folders ? if yes, how can i load all these 5 folders simultaneously at test time ? 3- i'm also supposed to create the confusion matrix. but i couldn't understand how i can apply this to my code ? some others say, use scikit-learn's confusion matrix, but this time i have to define y-true, y_pred values, which i cannot fit into this code. am i supposed to evaluate 5 different confusion matrices for 5 different predictions and how ? 4-sometimes, i observe that the validation accuracy starts much higher than the training accuracy. is this unusual ? after 3-4 epochs, train accuracy cathces the validation accuracy and continues in a more balanced way. i thought this should not be happening. is everything alright ? 5- final question, why the first epoch takes much much longer time than other epochs? in my setup, it's about 30-40 minutes to complete the first epoch, and then only about a minute or so to complete every other epoch. is there a way to fix it or does it always happen the same way ? thanks.",https://stackoverflow.com/questions/64181490,6244386.0,1
60091461,What does seq_lengths mean in tensorflow.reverse arguments?,I'm new to the tensorflow world. With tensorflow.reverse_sequence we need to pass sequential_length but what are its exact requirements? I played with the values provided in the docs. I cant grasp the concept. I'm curious about its properties and exact usage. This is my code:,https://stackoverflow.com/questions/60091461,7291498.0,1
63665112,Can anyone explain how the function of shuffle in tf.dataset work?,"I can't find out how the function of shuffle in tf.dataset work. I try to see output to guess what happen inside. Output: ===&gt; As you see, the shuffle doesn't work when buffer_size =1 But when I change buffer_size = 2 the list change the order but the first item only in 0 or 1 although I run 100 time again. Anyone in group can explain the role of buffer_size. I read the document of tensorflow at https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle In my thought, when set buffer_size = 1, as document said, maybe i can replace element in buffer_size. But the output I get make me confused. can anyone run into the same problem ?",https://stackoverflow.com/questions/63665112,1755017.0,1
73825623,Stream data using tf.data from cloud object store other than Google Storage possible?,"I've found this nice article on how to directly stream data from Google Storage to tf.data. This is super handy if your compute tier has limited storage (like on KNative in my case) and network bandwidth is sufficient (and free of charge anyway). Unfortunately, my data resides in a non Google bucket and it isn't documented for other Cloud Object Store systems. Does anybody know if it also works in non GS environments?",https://stackoverflow.com/questions/73825623,3656912.0,1
48309707,When to use tf.resource and tf.variant?,TensorFlow DType has tf.resource and tf.variant with pretty vague description. Can someone please explain to me what those two types are for? It'd be great if there are examples. Thanks a lot!,https://stackoverflow.com/questions/48309707,5029595.0,1
49698567,How to Save TensorFlow model using estimator.export_savemodel(),"How can i Save the TensorFlow model using estimator.export_savedmode() ? Especially, what should i put inside the serving_input_receiver_fn()? I have created a Custom Estimator based on VGGNet Architecture, i am using my own images and doing some transformation (you can see them in _parse_function()) on the images. I have read the documentation here, but i am exactly not sure what to write for my code (please see below). Ultimately i want to save the model and use TensorFlow Serving.",https://stackoverflow.com/questions/49698567,8549932.0,1
65918888,Mixture parameters from a TensorFlow Probability mixture density network,"How do you get the mixture parameters from a mixture density network created using TensorFlow Probability? I'm trying to learn a bit about mixture density networks and came across an example in the TensorFlow Probability documentation here. By the way, I'm a beginner with this stuff. See below for my complete code using the above example as a starting point. I had to make a change to the original concerning the AdamOptimizer, and I added a model.predict() at the end. Calling predict(X) seems to draw samples from the conditional distribution P(Y|X), but instead I want to get to the parameters of the mixture model for supplied values of X i.e., the weight, mean, and std deviation for each of the num_components mixture components. Any ideas? I have seen the convert_to_tensor_fn argument for the MixtureNormal layer, and tried adding: convert_to_tensor_fn=tfp.distributions.Distribution.sample - to confirm that predict() draws samples and convert_to_tensor_fn=tfp.distributions.Distribution.mean - looks like predict() returns the conditional expectation so I was then hoping that there would be some other option to get the mixture components, but I haven't been able to find it so far. Now that we have an answer, the complete code is as follows:",https://stackoverflow.com/questions/65918888,15091026.0,1
43972949,TFlearn to categorical,"I`m using DNN of tflearn, and I want to change my features and lables to be categorical and not numeric. here is my net: I know about tflearn.data_utils.to_categorical but I dont know how to inject this method. thanks EDIT: I tried few things, like: and also change the loss: but I got loss more than 1: where is the problem?",https://stackoverflow.com/questions/43972949,6925731.0,1
64052842,Keras/TensorFlow equivalent of PyTorch Conv1d,"I am currently in the process of converting a PyTorch code to TensorFlow (Keras). One of the layers used is Conv1d and the description of how to use it in PyTorch is given as where as in Keras (TF1.15) the description is given as I have not been able to reproduce the same output I get in PyTorch in TensorFlow. i.e. for the sample code in PyTorch In TensorFlow to get similar dimensions for the output the code can be found below Comparing the dimensions of the weights in either case the Conv1d operation is clearly different than TensorFlow (Keras), how should the TF code be changed to reflect the same operation?",https://stackoverflow.com/questions/64052842,7537870.0,1
44064753,Multiply all elements of Tensor in Tensorflow,"I have tensor with 3 elements which I want to multiply with each others. My code currently looks like this: Which imho is very unflexible, of course I could put a loop and iterate over the elements, but I was wondering if there is such functionallity already provded in tf ? I could not find anything in the docs",https://stackoverflow.com/questions/44064753,6786718.0,1
67971878,Random Seed for Tensorflow federated?,"I want to get reproducible results with my Tensorflow Federated code. For that I have implemented some seeds (random, numpy and tensorflow), but they aren't affecting Tensorflow Federated. The data processing steps are all reproducible, it has to be in the code snippet below. I have read that Tensorflow Federated doesn't provide a global seed function and that my only possibility is to save the state. But I don't understand this argumentation. Is anyone aware of a method/function that can help me out or explain to me why I can't use seeds with Tensorflow Federated? Appreciate every comment :) Thanks for your help.",https://stackoverflow.com/questions/67971878,16223516.0,1
74741897,Tensorflow: Data dependent loss function,"I am trying to implement a loss function that computes a loss depending on the (unaugmented) data. So far I found an example detailing the process using the model.add_loss() method of a tf.keras.models.Model() here, but I struggle to implement it. I have a tf.Dataset object containing my data, labels, and the data dependent variable for every sample calculated before augmentation (let's call it z). The data dependent variable is what I want to pass to my custom loss function. I am dropping the ball in trying to pass the predictions, label and z to my loss function when calling it with model.add_loss. Given a simple model like: Trying to run this, I get: ValueError: Layer ""model_17"" expects 3 input(s), but it received 1 input tensors. Is there a way to use an input array [data, label, z] with a tf.dataset object? Or how do I access the three different values inside the model, if I just pass the dataset object as one input value?",https://stackoverflow.com/questions/74741897,14787559.0,1
43662094,im2txt: Load input images from memory (instead of read from disk),"I'm interested in modifying the tensorflow implementation of Show and Tell, in particular this v0.12 snapshot, in order to accept an image in numpy form instead of read it from disk. Loading a filename using the upstream code results in a python string after in run_inference.py which is then turned into an ndarray of no shape. However, I can't replicate that. I've tried the following: I wrote this function to load a pillow image from a filename, convert the image to a numpy array and feed it to the beam_search function in run_inference.py In this case, there is a size mismatch later, resulting in the following stack trace: Can I somehow trick numpy into thinking the array has no shape? Here I used the following function This didn't work either: The last line in this stacktrace seems helpful, however there is no documentation as to what kind of structure is expected So, what should a valid input look like? The internals of preprocessing are not particularly clear to me. Thanks for your time! EDIT: Attached gist of the modified inference script for the big picture EDIT 2: The path to sess.run goes like this: 1: run_inference.py 2: caption_generator.py 3: inference_wrapper.py EDIT 3: I forgot to mention that I'm restricted to TensorFlow v0.12 and therefore I'm using this snapshot of the im2txt repo.",https://stackoverflow.com/questions/43662094,7932035.0,1
39507405,"TensorFlow, Python, Sharing Variables, initialize at top","I'm having an issue in TensorFlow with Sharing Variables with the Python API. I've read the official documentation (https://www.tensorflow.org/versions/r0.10/how_tos/variable_scope/index.html), but I still can't figure out what is going on. I've written below a minimal working example to illustrate the issue. In a nutshell, I'd like the code below do to the following: 1) Initialize one variable ""fc1/w"" immediately after I create the session, 2) Create a npy array ""x_npy"" to feed into a placeholder ""x"", 3) Run an operation ""y"", which should realize that the variable ""fc1/w"" is already created, and then use that variable values (rather than initialize new ones) to compute its output. 4) Please note that I added the flag "", reuse=True"" in the variable scope in the function ""linear"", but that doesn't seem to help, since I keep getting the error: This is quite confusing since if I were to remove the flag "", reuse=True"", then TensorFlow would tell me that the variable does exist: 5) Please note that I'm working with a larger code base, and I'd really like to be able to use the Sharing Variables capability, rather than come up with a hack without using Sharing Variables that might solve the particular example code I wrote below, but might not generalize well. 6) Finally, please note also that I'd really like to keep separated the creation of the graph from it's evaluation. In particular, I would not like to use ""tf.InteractiveSession()"" or create ""y"" in the session scope, i.e., below: ""with tf.Session() as sess:"". This is my first post on Stack Overflow, and I'm quite new to TensorFlow, so please accept my apologies if the question is not completely clear. In any case, I'd be happy to provide more details or clarify any aspect further. Thank you in advance.",https://stackoverflow.com/questions/39507405,6834455.0,1
42364283,Tensorflow: calculate gradient for tf.multiply,"I'm building a neural network that has the following two layers I then want to multiply them using tf.multiply (which, unlike tf.matmul multiplies corresponding indices, i.e. c_ij = a_ij * b_ij) My goal is to learn weights. So I run But it doesn't work. The network doesn't change at all. Looking at tensorboard, I could see that 'input' has no gradient, so I'm assuming that's the problem. Any ideas how to solve this? From reading tensorflow docs it seems like I might have to write a gradient op for tf.multiply, but I find it hard to believe no one needed to do this before.",https://stackoverflow.com/questions/42364283,1660762.0,1
56588353,How to use Tensorflow BatchNormalization with GradientTape?,"Suppose we have a simple Keras model that uses BatchNormalization: How to actually use it with GradientTape? The following doesn't seem to work as it doesn't update the moving averages? In particular, if you inspect the moving averages, they remain the same (inspect model.variables, averages are always 0 and 1). I know one can use .fit() and .predict(), but I would like to use the GradientTape and I'm not sure how to do this. Some version of the documentation suggests to update update_ops, but that doesn't seem to work in eager mode. In particular, the following code will not output anything close to 150 after the above training.",https://stackoverflow.com/questions/56588353,1048214.0,1
57438856,tf.constant_initializer() vs tf.global_variables_initializer(),"In the following code from this website, what's the role of tf.constant_initializer(0.) and tf.global_variables_initializer()? Why do we need two initializers? The original post I link has an explanation that goes: ... which still seems confusing as, in that case, why do we need the tf.constant_initializer(0.) at all? We might as well just leave our m and b uninitialized until we run tf.global_variables_initializer()...",https://stackoverflow.com/questions/57438856,3736306.0,1
67652872,InvalidArgumentError: Inner dimensions of output shape must match inner dimensions of updates shape,"I'm trying to implement an SPL loss in keras. All I need to do is pretty simple, I'll write it in numpy to explain what I need: I'm trying to implement it following this tutorial but I'm having troubles with the step needed to set values to zero. Currently I have the following code: According to the docs, tensor_scatter_nd_update operation should perform the assignment operation, but it fails with the following error: I'm running it in colab, here you can try it. I tried several re-shapes, because I understand it is a matter of shapes expected vs obtained, but I don't find the way. What's going on here? Thanks in advance",https://stackoverflow.com/questions/67652872,4913143.0,1
53116036,Tensorflow prefetching to multiple GPUs,"When having a Tensorflow dataset and multiple GPUs it is beneficial to preload data to the multiple GPUs. The only example I could find is in this issue What I am wondering is: - is it really necessary to have multiple calls to sess.run (one for each GPU?) - Can this work with a configurable number of GPUs? (splits = multi_device_iterator.get_next()) - It seems like this MultiDeviceIterator is implemented, but can not be found in the documentation. Is it still under development? Also when I try to implement this I get a lot of errors which seem not really helpful",https://stackoverflow.com/questions/53116036,987397.0,1
65013199,StopIteration error while trying to build data input for a model,"Gives an error I saw the documentation for next() and found that you can no longer use at as .next but after correction, it still gives me StopIteration error I checked the value of classes on my local Python and it gives me a list ['Class0', 'Class1', 'Class2', 'Class3', 'Class4', 'Class5', 'Class6']",https://stackoverflow.com/questions/65013199,14709369.0,1
50164572,BatchNormalization in Keras,"How do I update moving mean and moving variance in keras BatchNormalization? I found this in tensorflow documentation, but I don't know where to put train_op or how to work it with keras models: No posts I found say what to do with train_op and whether you can use it in model.compile.",https://stackoverflow.com/questions/50164572,8748308.0,1
60472754,Keras LearningRateScheduler callback on batches instead of epochs,"I am using Tensorflow 2.x, The below is the custom learning rate scheduler which i have written and i am calling it like this But instead of calling it on epochs, i want to call it on each batch. I couldn't find anything below documentation regarding batches https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler Is it possible to call it on batches, if yes how to do that?",https://stackoverflow.com/questions/60472754,6490241.0,1
41865218,Interleaving slim.dropout and slim.fully_connected in slim.stack?,"In tf.slim, I'd like to create a stack of fully-connected layers with dropout. To the example from documentation: slim.stack(x, slim.fully_connected, [32, 64, 128], scope='fc'), I'd like to add dropout. Is it possible to use slim.stack or do I have to go back to the verbose approach?",https://stackoverflow.com/questions/41865218,314710.0,1
63506296,Saving and Loading Tensorflow Model Results in Keras Error,"For a project that I'm working on, I have created a simple model in TensorFlow that consists of a dense features layer followed by three dense layers. I am unable to go into more detail about the parameter arguments, but the above model function works perfectly fine and can train and save a .h5 file perfectly fine using the code below. However, when I try to load the model back from the .h5 file, I get the following error message. Looking around, I suspect it has something to do with the custom_objects tag for the load_model function, but I am not 100% sure of how to implement it. The only custom objects that I could be using are my loss, which I declare below, and the accuracy metric that I use. loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)",https://stackoverflow.com/questions/63506296,13079914.0,1
56759226,How to access Feature dictionaries of Datasets in TensorFlow,With tensorflow-datasets I integrated the MNIST dataset into Tensorflow and now want to visualize single images with Matplotlib. I did it according to this guide: https://www.tensorflow.org/datasets/overview Unfortunately I get an error message during execution. But it works great in the Guide. According to the guide you have to create a new dataset with only one image using the take() function. Then the features are accessed in the guide. During my attempts I always get an error message. This is the error message: Does anyone know how I can fix this? After a lot of research I still haven't found the solution.,https://stackoverflow.com/questions/56759226,11699024.0,1
47798492,Using Datasets to consume Numpy arrays,"I'm trying to use Numpy arrays within a graph, feeding in the data using a Dataset. I've read through this, but can't quite make sense of how I should feed placeholder arrays within a Dataset. If we take a simple example, I start with: Then I attempt to modify it to use a Dataset as follows: If I run this I get 'InvalidArgumentError: You must feed a value for placeholder tensor ...' The code until the for loop mimics the example here, but I don't get how I can then employ the placeholders a &amp; b without supplying a feed_dict to every call to sess3.run(c) [which would be expensive]. I suspect I have to somehow use the iterator, but I don't understand how. Update It appears I oversimplified too much when picking the example. What I am really trying to do is use Datasets when training a neural network, or similar. For a more sensible question, how would I go about using Datasets to feed placeholders in the below (though imagine X and Y_true are much longer...). The documentation takes me to the point where the loop starts and then I'm not sure. Trying the following only gets me a InvalidArgumentError",https://stackoverflow.com/questions/47798492,9094969.0,1
60598858,"tensorflow.keras.optimizers.Adam optimizer object not giving error when using ""minimize"" function","I'm working on linear regression problem using 'keras' but when I try to use the function ""minimize"" for the ""Adam optimizer"" object,I get the following error. This function can be found in the official documentation at : https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam#minimize and the code can also be found at https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L289-L318 my code is given below why cant I use the minimize function for the above Adam object? Note : linear_regression and loss_function are two functions already defined as below.",https://stackoverflow.com/questions/60598858,5587971.0,1
49303136,tensorflow tfrecords for batch with variable length data in each example?,"I am trying to use tfrecords to read batches that have a field that is a variable length list in each example. The data might be I have been using to store each of the above, that is I'll make 3 different tfrecords, where x is [1,2,3] then [10,11] then [100,200,300,400] Those three records got their SerializeToString() method called, and each appended to a file via the TFRecordWriter Reading back was tricky, I couldn't use tf.FixedLenFeature, so then I found tf.VarLenFeature. It seemed to be very nice, when I read the data batch in a batch size of 3, it looked like I was getting a tf.SparseVectorValue back where column 0 of the indices was the example number in the batch, and column 1 was the value within the list, that is, it looked like I was getting (suppose the batch size is 3): but now that I'm working with more data, I don't think this is what I'm getting. My question is, what does VarLenFeature return when you batch up variable length lists like this? Should it do what I explained? Then maybe I have a bug to find. But if it does something different, then what should I do to read back a batch of data with variable length lists? I need to know the example number in the batch for each list, I could add another field to the tfrecord with the length of each of these lists. -- EDIT -- I've done more testing, and I think it works like I think. I must have a problem in my bigger program. It would be nice if there was documentation saying exactly what tf.VarLenFeature is supposed to return for batched datasets, so I could be sure my above interpretation is correct. Below is some test code I'm trying:",https://stackoverflow.com/questions/49303136,2280020.0,1
69344366,TensorFlow/Keras: How to resume training using model.checkpoint()?,"I'm saving my best model using model.checkpoint(): This is how I'm loading my model: Now, I want to resume training from where I last left off. In this ipynb, it's mentioned: However, it doesn't exactly tell me how to do that. Please guide me.",https://stackoverflow.com/questions/69344366,,1
49285664,training a custom estimator in tensorflow,"I am new to tensorflow and trying to train a custom CNN estimator with inputs being provided from TFRecord files. The Load_input() function is supposed to look into DATA_DIR for TFRecords file and decode it through a call to read_and_decode function(which is supposed to do the actual decoding of the records), store the information into an instance of _image_object and return it. cnn_model is where I have defined the CNN architecture. And generate_input_fn is supposed to create the batches and feed it to the estimator.train while training. I just have an abstract understanding of the codes, no idea of the internal mechanics which is the primary reason why I am not able to debug. Here is my code : it gives me the following error : also the layers shapes are as follows : I don't understand why is the batch size 9 even if I try to explicitly set it to 3 in the code. Note : If anyone has a better/easier solution please post it. The aim is to use tfrecords to train a custom CNN",https://stackoverflow.com/questions/49285664,7713497.0,1
60683848,What is the need to return a function object while creating a data set using tensorflow,I am new to Machine Learning and I am trying to create a Machine Learning Model using the Tensorflow API from the tutorial in the Tensorflow documentation from here But I am having trouble understanding this part of the code Then storing the output of the function in a variable And at last training the model with the data set I failed to realize what we are trying to do when by just returning the function name of the inner-function in make_input_function instead of just returning our data set and passing it to train the model. I am a beginner in Python and just started to learn Machine Learning and I am unable to find a proper answer to my question so if anyone can kindly explain it in a beginner friendly way I would be very much obliged.,https://stackoverflow.com/questions/60683848,11743459.0,1
46455648,Tensorflow seq2seq Decoder problems?,I try to write a seq2seq decoder with the tensorflow tf.contrib.seq2seq package. I am wondering if my code is correct and if there is better way to rewrite it. The documentation is not easy to read. Or my question can be: how can I easily debug this kind of code? How can I inspect some intermediate results in tensorflow? I got the following error when running the code,https://stackoverflow.com/questions/46455648,5942350.0,1
47379766,Replacing a node in a frozen Tensorflow model,"I have a frozen inference graph stored in a .pb file, which was obtained from a trained Tensorflow model by the freeze_graph function. Suppose, for simplicity, that I would like to change some of the sigmoid activations in the model to tanh activations (and let's not discuss whether this is a good idea). How can this be done with access only to the frozen graph in the .pb file, and without the possibility to retrain the model? I am aware of the Graph Editor library in tf.contrib, which should be able to do this kind of job, but I wasn't able to figure out a simple way to do this in the documentation.",https://stackoverflow.com/questions/47379766,7869068.0,1
33720645,Why is this TensorFlow implementation vastly less successful than Matlab's NN?,"As a toy example I'm trying to fit a function f(x) = 1/x from 100 no-noise data points. The matlab default implementation is phenomenally successful with mean square difference ~10^-10, and interpolates perfectly. I implement a neural network with one hidden layer of 10 sigmoid neurons. I'm a beginner at neural networks so be on your guard against dumb code. Mean square difference ends at ~2*10^-3, so about 7 orders of magnitude worse than matlab. Visualising with we can see the fit is systematically imperfect: while the matlab one looks perfect to the naked eye with the differences uniformly &lt; 10^-5: I have tried to replicate with TensorFlow the diagram of the Matlab network: Incidentally, the diagram seems to imply a tanh rather than sigmoid activation function. I cannot find it anywhere in documentation to be sure. However, when I try to use a tanh neuron in TensorFlow the fitting quickly fails with nan for variables. I do not know why. Matlab uses Levenberg–Marquardt training algorithm. Bayesian regularization is even more successful with mean squares at 10^-12 (we are probably in the area of vapours of float arithmetic). Why is TensorFlow implementation so much worse, and what can I do to make it better?",https://stackoverflow.com/questions/33720645,1715157.0,1
46846708,Keras vs. TensorFlow. Hyperparamters not identical?,"I'm converting a Keras script to my own pure TensorFlow script. Unfortunately, there is something wrong. The training on my script is a lot faster (so fast it got to be an error somewhere), and loss is not improving. I think it has something to do with my hyperparamters... but I can't figure it out. I was a bit confused of the terminology, samples_pr_epoch etc., but I thought I had it. Is the second for-loop right? Anyone have an idea whats different? Is it something under the hood of Keras?",https://stackoverflow.com/questions/46846708,8770778.0,1
56899105,How to use regularizer argument in tf.get_variable?,"The syntax of the usage is clear: However, in the documentation only the following is stated: The above does not imply that the regularization loss is automatically minimized. So do we need to manually get the variable from the collection tf.GraphKeys.REGULARIZATION_LOSSES and add it to our main loss in order for it to be applied?",https://stackoverflow.com/questions/56899105,4958717.0,1
73018686,How can I convert NHWC to NCHW in python for deepstream,"I have a TensorFlow Keras model which is stored in .pb format and from .pb format I am converting the model to .onnx format using the tf2onnx model now after converting I see that my input layer is in NHWC format and I need to convert the same to NCHW, to achieve that I am using which is still giving me the same output as NHWC I have to consume the above model in NVIDIA Deepstream which only accepts NCHW format. I found this link which talks about the transpose of the input layer, but unfortunately, that is also not working. Convert between NHWC and NCHW in TensorFlow It would be really helpful if some experts can share their thoughts on how to convert NHWC to NCHW",https://stackoverflow.com/questions/73018686,7877016.0,1
48914953,Tensorflow custom Estimator with Dataset API: embedding lookup (feature_column) NMT task,"my question is close in nature to Feature Columns Embedding lookup, however I was unable to comment on the answer given there (not enough rep), and I think the answerer either did not fully understand the question, or the answer was not exactly what was asked. To serve a custom Estimator which uses Dataset API to feed in data. The task is NMT (seq2seq). Estimator requires feature_columns as input for serving. My NMT task has only one feature, the input sentence to translate (or possibly each word in the sentence is a feature?). And so I am unsure how to build a feature_column (and thus an embedding_column and finally an input_layer) using my input sentences as a feature that can be fed into an RNN (which expects an embedding_lookup [batch_size, max_seqence_len, embedding_dim]) which will finally allow me to serve the Estimator. I am attempting to utilize a custom estimator to feed a seq2seq style NMT implementation. I need to be able to serve the model via tf-serving, which estimators seem to make relatively easy. However I hit a road block with 'how' to serve the model. From what I can tell I need 'feature_columns' that will serve as the input into the model. https://github.com/MtDersvan/tf_playground/blob/master/wide_and_deep_tutorial/wide_and_deep_basic_serving.md Shows that you need to have an export_input_fn which uses a feature_spec which needs a feature_column(s) as input. This makes sense, however, for my use case I do not have a bunch of (different) features, instead I have input sentences (where each word is a feature) that need to be looked up via embeddings and used as features... So I know I need the input into my model to be feature column(s). My input for NMT is simply a tensor of [batch_size, max_sequence_len] which is filled with the indices of the words from the sentences (e.g., for batch_size=1 [3, 17, 132, 2, 1, 0, ...] where each index should map to an embedding vector). Typically I would feed this into a embedding_lookup via and I would be good to go, I could feed this to an RNN as inputs and the rest is history, not a problem. BUT, this is where I hit the issue, I need to use feature_columns (so I can serve the model). The answer given to the question I mentioned at the beginning of this shows how to use embedding_column, but instead he is suggesting that embedding should look up an entire sentence as one single feature, but traditionally you would look up each word in the sentence and get its embedding. Similarly, https://www.damienpontifex.com/2018/01/02/using-tensorflow-feature-columns-in-your-custom-estimator-model/ Shows 'how to implement a feature-column in a custom estimator' and indeed his 'Before' code is exactly right (as I wrote out), a tf.get_variable into a tf.nn.embedding_lookup, but his 'after' code, again, only takes in 1 feature (the entire sentence?). I have verified this by using their code and feeding my data in [batch_size, max_seq_len] to the tf.feature_column.categorical_column_with_identity, and the output tensor is [batch_size, embedding_dim] the sequence information is lost? Or does it simply get flattened? when I print the output its size (?, embedding_dim) where ? is typically my batch_size. EDIT: I have verified the shape is [batch_size, embedding_dim], it is not just flattened... So the sequence info is lost I'm guessing it must be treating the input as 1 single input feature (thus the batch_size=1 ex [3, 17, 132, 2, 1, 0, ...] where each index maps to an embedding vector) would map to a single feature which is not what is wanted, we want each index to map to an embedding and the needed output is [batch_size, max_seq_len, embedding_dim]. It sounds like what I instead need, is not one categorical_column_with_*, but a max_seq_len amount of them (1 for each word in my sequence), does this sound right? Each word would be a feature for my model so I am leaning toward this being the correct approach, but this also has issues. I am using the Dataset API, so in my input_train_fn() I load my data from a file, and then use tf.data.Dataset.from_tensor_slices(data, labels) to split the data into tensors which I can then dataset.batch(batch_size).make_one_shot_iterator().get_next() to feed into my Estimator. I cannot iterator over each batch (Tesors are not iterable) so I cannot simply make 100 feature_columns for each input batch... Does anyone have any idea how to do this? This embedding lookup is a very straightforward thing to do with simple placeholders or variables (and a common approach in NLP tasks). But when I venture into Dataset API and Estimators I run into a wall with very little in the way of information (that is not a basic example). I admit I may have gaps in my understanding, custom estimators and dataset API are new to me and finding information on them can be difficult at times. So feel free to fire off information at me. Thanks for reading my wall of text and hopefully helping me (and the others I've seen ask a question similar to this but get no answer https://groups.google.com/a/tensorflow.org/forum/#!searchin/discuss/embeddings$20in$20custom$20estimator/discuss/U3vFQF_jeaY/EjgwRQ3RDQAJ I feel bad for this guy, his question was not really answered (for the same reason outlined here, and his thread got hijacked...).",https://stackoverflow.com/questions/48914953,6110624.0,1
68021455,How to use tfa.image.sparse_image_warp?,"I have the log mel spectrograms of a few audio clips and I am trying to augment the spectrograms using tfa.image.sparse_image_warp so that time warping can be achieved as done in Google's SpecAugment. But I am confused on how to do achieve time warping as the documentation does not specify how to initialize arguments to sparse_image_warp. The method declaration is like this: Can someone point out how to initialize source_control_point_locations, dest_control_point_locations and num_boundary_points?",https://stackoverflow.com/questions/68021455,11142738.0,1
38400360,Working with tensorflow's shuffle_batch method,"I'm experimenting with tensorflow and I'm trying to read from a csv file and print out a batch of its data via shuffle_batch. I've gone throw the decode_csv docs and the shuffle_batch docs, but I'm still unable to get it working. Here's what I have: import tensorflow as tf Running this will generate this exception: I'm not sure what the issue is. I have a feeling it's due to the session and the way I'm handling it; I'm probably not doing it properly.",https://stackoverflow.com/questions/38400360,409865.0,1
52253378,"Convert a tensor of shape (?,32,24,24) into a 3D numpy array","I have a tensor with a batch of 32 grayscale images, each of size 24x24. The tensor is produced after a Conv2D layer in a CNN built using Keras with tensorflow backend. The data is provided to the model as a numpy array. Now, I wish to covert the output tensor into a numpy array, and again back into a tensor. I have referred to this page and wrote this simple piece of code that doesn't seem to work here, x is my tensor and ip is the intended numpy array. This throws as InvalidArgumentError(). Is there any way I can get rid of the unkown (?) dimension? Here's the stack trace:",https://stackoverflow.com/questions/52253378,5116406.0,1
69526670,"TypeError: ('Keyword argument not understood:', 'pool1') when trying to load model with custom layer","I'm trying to load a model with a custom layer with the code below: but I get the error: My custom layer: I'm using google colab, which upgraded to tensorflow 2.6. In tensorflow 2.5 I had no such problem. I was forced to make many changes to the layer to try to get it to work. In 2.5, I didn't need to assign filters_1, filters_2 and the other args in __init__ (because I don't use them elsewhere), pass **kwargs and write the get_config function. I even tried installing tensorflow 2.5 and keras again, but I would get an error when training. I tried so many things, searched the docs and read almost all the similar questions, but can't find something.",https://stackoverflow.com/questions/69526670,17126599.0,1
71361898,GAN with tensorflow: model syntax is not clear,"I am very new with tensorfflow and am trying to implement the example from the documentation: I don't understand the syntax that consist in creating the generator with generator = make_generator_model() and then creating an image with generated_image = generator(noise, training=False). How come the generator doesnt use .fit() in that case?",https://stackoverflow.com/questions/71361898,4961888.0,1
70776552,Incompatibility between input and final Dense Layer (Value Error),"I'm following this tutorial from Nabeel Ahmed to create your own emotion detector using Keras (I'm a noob) and I've found a strange behaviour that I'd like to understand. The input data is a bunch of 48x48 images, each one with an integer value between 0 and 6 (each number stands for an emotion label), which represents the emotion present in the image. In order to feed the data into the model, train_X and val_X are reshaped (as the tutorial explains) The model, as it is in the tutorial, is this one: However, when I try to use it, using the tutorial snippet, I get an error in the line of the validation_data like this After reviewing the code and the documentation about the fit method, my only idea was to change the 7 in the last Dense layer of the model to 1, which mysteriously works. I'd like to know what is happening here if anyone could give me a hint.",https://stackoverflow.com/questions/70776552,5457202.0,1
42818842,Transitioning to Tensorflow 1.0.0,"I am trying to translate this pix2pix GAN code to Tensorflow 1.0.0 using the following script as described in Tensorflow Documentation, but I keep getting the following error: This is the Adam optimizer part: Where d_vars is: And the discriminator code:",https://stackoverflow.com/questions/42818842,7671750.0,1
48449847,Calculating output_shape when using 3d transpose convolutions in Tensorflow,"I have a 4D tensor h0 from a previous layer with shape [10, 1, 1, 1, 10] and I want to upsample using conv3d_transpose to a tensor h1 with shape, lets say, [10, 4, 4, 4, 20]. I do not understand how my choice of filter, strides and padding effect output_shape, given h0, and hence whether [10, 4, 4, 4, 20] is possible for h1? Is there a rule of thumb or formula? For example, if I run the following: I get the error: But if I change padding = 'SAME' then I get no error. I have read about convolutional arithmetic but do not understand how the formulas apply to Tensorflow specifically.",https://stackoverflow.com/questions/48449847,6379902.0,1
41651034,input pipeline in tensorflow,"While practicing on the official tensorflow mnist dataset tutorial for beginners, I'm trying to change the mnist data to my own images collected from search engines. That strFilePaths is a standard python list containing all my image paths , iLabels is a list of lists representing labels. And I have only 2 classes in this case. This program runs without error output but tensorflow just keeps on running and not giving me any output. I've read the ""reading files"" session in tensorflow website for like a thousand times but I still don't have a clue on whether I did things right or not. Q1: What's wrong with this code? Q2: Is there any complete example on how to read jpeg files into tensorflow and perform some training tasks on them?",https://stackoverflow.com/questions/41651034,3205742.0,1
59464570,"tf.reduce_sum(lastconv,axis=2) / tf.reduce_sum(tf.cast(tf.greater(lastconv, 0), tf.float32), axis=2) used in place of Mean Pooling?","I am working with eye trajectories data and convolution neural networks. I was asked to use tf.reduce_max(lastconv, axis=2) in place of MaxPooling layer and tf.reduce_sum(lastconv,axis=2) / tf.reduce_sum(tf.cast(tf.greater(lastconv, 0), tf.float32), axis=2) in place of MeanPooling layer. I have following questions, for which I am not able to get clarity. It would be great it you can make me understand. I am sure you can tell that i don't quiet understand what reduce_max/min/mean/sum are doing to input tensors and what is the learning the model takes away from these functions? About data: the shape of data is (24,4,15,2,87236), where 24 are subjects, 4 temperature variations and 15 trails, 2x87236 is continuous eye gaze (2 because of x-axis and y-axis). I am using LeaveOneOut CV where I train on 22 subjects and test and validate on 1 subject each. After I create train, validation and test sets, the final input that goes in the model is (22,60[4x15],2,87236) , (1,60,2,87236) and (1,60,2,87236) respectively. I hope I have provided enough information about the dilemma I am in, for you to help me out. Thanks in advance.",https://stackoverflow.com/questions/59464570,9457610.0,1
49692842,Tensorflow: Importing GraphDef with Placeholder,"How do I replace a placeholder in a GraphDef loaded from a file to connect the imported graph to a dataset provider? This script borrows heavily from the eval_image_classifier.py script as part of the slim API. First I open a graph Then I set up a dataset provider and preprocessing function using the slim API Then I import a graph from a GraphDef from a file and load it into the current graph using import_graph_def Then I set up the metrics and call slim.evaluation.evaluate_once to process the batches When I run this I get the following error: The GraphDef that I am loading has a Placeholder op with the name batch, with the same shape and dtype as the tensor images. For reference, running print(images) returns: Note that I have supplied the argument input_map to the import_graph_def function that should replace the batch placeholder with the tensor images. I have also tried using batch:0 and batch_1 as the key to the input_map but neither works. According to the documentation for tf.import_graph_def: As I understand it, the input_map argument should connect the two graphs, but that doesn't seem to be working. See related article ""Connecting Two Graphs Together using import_graph_def"". I believe that I am doing the same thing as in the article. Also, evaluate_once is a function that runs a batch of images in a single function call, so I cannot simply call images.eval() and pass the result to evaluate_once because it would only run the first batch. So the two graphs must be connected and able to be run with a single invocation.",https://stackoverflow.com/questions/49692842,129814.0,1
57346191,Tensorflow pad sequence feature column,"How to pad sequences in the feature column and also what is a dimension in the feature_column. I am using Tensorflow 2.0 and implementing an example of text summarization. Pretty new to machine learning, deep learning, and TensorFlow. I came across feature_column and found them useful as I think they can be embedded in the processing pipeline of the model. In a classic scenario where not using feature_column, I can pre-process the text, tokenize it, convert it into a sequence of numbers and then pad them to a maxlen of say 100 words. I am not able to get this done when using the feature_column. Below is what I have written sofar. I am also confused as to what to use here, sequence_categorical_column_with_vocabulary_list or categorical_column_with_vocabulary_list. In the documentation, SequenceFeatures is also not explained, all though I know it is an experimental feature. I am also not able to understand what does dimension param do?",https://stackoverflow.com/questions/57346191,1561188.0,1
53965422,Training loss and accuracy don't change - stuck around a value -- Tensorflow,"My LSTM model below in tensorflow works without any error, but the values of the loss and accuracy seem to swarm around specific values, leading to a misleading conclusion after all the epochs. My thoughts were/are: As there is not a lot of documentation (and due to my little experience) about linking the dataset API, together with RNNs, different batches and different datasets, I may have done something wrongly. Please, I would appreciate any review or knowdledge that could add some light to this. Many thanks for your time. CODE: This is the output in tensorboard for accuracy and loss (stopped at around 250 epochs):",https://stackoverflow.com/questions/53965422,9273596.0,1
40258943,"Using height, width information stored in a TFRecords file to set shape of a Tensor","I have converted a directory of images and their labels into a TFRecords file, the feature maps include image_raw, label, height, width and depth. The function is as follows: Now, I would like to read this TFRecords file to feed a input pipeline. However, since image_raw has been flattened, we need to reshape it into the original [height, width, depth] size. So how can I get the values of height, width and depth from the TFRecords file? It seems the following code cannot work because height is a Tensor without values. When I read the Tensorflow's official documents, I found they usually pass into a known size, saying [224,224,3]. However, I don't like it, because this information has been stored into the TFRecords file, and manually passing into fixed size cannot ensure the size is consistent with the data stored in the file. So any ideas?",https://stackoverflow.com/questions/40258943,1659534.0,1
74310782,OSError: SavedModel file does not exist. What is .pb format?,I'm trying to convert my TF model into TFLite. I found this code online But it seems to not work. In this path I have my model.h5 and also model.data-00000-of-00001 + model.index I created the model in h5 format and also the one that was created when model.save_weights Any help will be appreciated! The full error is this: What is a .pb format?,https://stackoverflow.com/questions/74310782,20035360.0,1
42956766,3D tensors with tensorflow tf.matmul,"I want to do a multiplication with two 3-D tensors, as defined: but I can't get the right answer as described in the tf.matmul function https://www.tensorflow.org/api_docs/python/tf/matmul",https://stackoverflow.com/questions/42956766,7752274.0,1
57838412,How do I create a layer from a function that does not accept Tensors/NumPy arrays as arguments?,"I have two Python functions that take strings as inputs and return NumPy arrays. I am trying to use these functions to create Lambda layers that are then fed into another Keras model. I can vectorize the function, and then create a TensorFlow operation via tf.py_func, like so (full code is further down below): I want my Lambda function calls to produce Lambda layers, and Keras's documentation appears to suggest they should. Instead, per my indicated logging statements, they are creating Tensors. What should I do to create working layers?",https://stackoverflow.com/questions/57838412,10083113.0,1
60096831,Tensorflow text generation not returning valid index,"I am trying to train a Tensorflow model to generate text. I'm using mostly code from the Tensorflow website but when I try to generate text the model returns indices that are not in the word_index. Text generation function: Error The word index as well as the training text only contains upper and lower case letters. EDIT For more context this is my data prep and structure Structure [['SENTENCE'], ['SENTENCE2']...] Data Prep",https://stackoverflow.com/questions/60096831,10654785.0,1
55852943,How can i use tf.image.draw_bounding_boxes to draw bounding boxes on my original image to show where my object was detected?,Im new to Tensorflow and so far I've been able to build a classifier using data i got from Kaggle for a flower dataset and I have been able to train a CNN to identify a sunflower vs a daisy and plot the results with labels using the matplotlib.pyplot.figure() call. Now I want to actually draw a bounding box on the original image itself to show where it detected the flower. I read about tf.image.draw_bounding_boxes but im a bit confused how to use it because technically the CNN has already drawn a bounding box over objects to be able to classify it. Is there a way to tap into that operation and draw abounding box the moment it frames an object in the source file? Here is an example of what I want to do. I want to train my model on identifying sunflowers and then when I present a picture with sunflowers I want it to find where the sunflowers are and draw a bounding box around each sunflower. and here is my code i'm using for this tutorial (assume the first three lines are just basic functions that create the labels and irrelevant for this question) What i would like to find is an example of how i can use this library on this kind of tutorial code and then take an arbitrary image and determine if there are sunflowers in that image and draw a box around them. Thank you!,https://stackoverflow.com/questions/55852943,3530309.0,1
47932738,TensorFlow: restoring model in a MonitoredSession,"I have a model that contains multiple variables including a global step. I've been able to successfully use a MonitoredSession to save checkpoints and summaries every 100 steps. I was expecting the MonitoredSession to automatically restore all my variables when the session is run in multiple passes (based on this documentation), however this does not happen. If I take a look at the global step after running the training session again, I find that it starts back from zero. This is a simplified version of my code without the actual model. Let me know if more code is needed to solve this problem When I run this code the first time, I get this output The checkpoint folder at this point has checkpoints for every hundredth step up to 500. If I run the program again I would expect to see the counter start at 500 and the increase up to 900, but instead I just get the same thing and all of my checkpoints get overwritten. Any ideas?",https://stackoverflow.com/questions/47932738,6642285.0,1
44345863,"What is a ""reference edge"" in TensorBoard?","The TensorBoard UI shows something called a ""Reference edge"" as distinct from a data flow (Tensor) edge: What distinguishes the former from the latter? The documentation says that ""the outgoing operation node can mutate the incoming tensor"", but indicates different symbols that don't match the UI, so it's hard to tell what's meant by ""incoming"" and ""outgoing"": For example how does this definition apply to or to In both cases it just seems that the reference edge indicates that the value its tail fills the Tensor represented by the edge.",https://stackoverflow.com/questions/44345863,656912.0,1
38892976,Tensorflow serving retrained inception,"I am trying to serve my retrained inception model following this guide (you may also see this guide, which explains how to retrain inception). I've modified retrain.py to export my model as follows: After exporting my model I start running the server: Server log file (inception_log) contains: Finally, I run the client and I get the following error: Any advice or guidance in this matter would be greatly appreciated.",https://stackoverflow.com/questions/38892976,5140223.0,1
56285229,How to properly use tf.metrics.mean_iou in Tensorflow to show confusion matrix on Tensorboard?,"I found evaluation script in Tensorflow official implementation of DeeplabV3+ (eval.py) uses tf.metrics.mean_iou to update mean IOU, and adds it to Tensorboard for record. tf.metrics.mean_iou actually returns 2 tensors, one is calculated mean IOU, the other is an opdate_op, and according to official doc (doc), confusion matrix. It seems every time if you want to get calculated mean_iou, you have to call that update_op first. I am trying to add this update_op into summary as a tensor, but it does not work. My question is how to add this confusion matrix into Tensorboard? I saw some other threads on how to calculate confusion matrix and add it to Tensorboard, with extra operations. I just would like to know if one can do this without those extra operations. Any help would be appreciated.",https://stackoverflow.com/questions/56285229,7555390.0,1
41725214,Does queue enqueue_many block unitll all items are on the queue?,"I'm working on a problem where I need to guarantee the order of items on the queue, however, I would also like to use multiple threads to do this. Thus I'm wondering if a call to enqueue_many will ensure that those items are placed in order? One solution to this is to only use one thread to enqueue items, however that is not optimal. The documentation only mentions blocking in the case where the queue is full. https://www.tensorflow.org/versions/r0.10/api_docs/python/io_ops/queues#QueueBase",https://stackoverflow.com/questions/41725214,5038048.0,1
45316382,tensorflow: initialization of variables inside function,Newbee to tensorflow. I'm trying to write some simple net with following code: but got error: for the last line checked official api of tensorflow but still don't know what's wrong with the code. ================================UPDATE========================== found 2 ways to fix it 1.if replace by then whole code works. OR 2.run again it also works. BUT don't understand why,https://stackoverflow.com/questions/45316382,5155829.0,1
65475110,Are Keras custom layer parameters non-trainable by default?,I built a simple custom layer in Keras and was surprised to find that the parameters were not set to trainable by default. I can get it to work by explicitly setting the trainable attribute. I can't explain why this is by looking at documentation or code. Is this how it is supposed to be or I am doing something wrong which is making the parameters non-trainable by default? Code: Output: If I change the custom layer creation like this: the output is what I expect (all parameters are trainable): then it works as expected and makes all the parameters trainable. I don't understand why that is needed though.,https://stackoverflow.com/questions/65475110,14890777.0,1
46089839,Creating a session in a graph that uses another graph and its session,"Versions : I am using tensorflow (version : v1.1.0-13-g8ddd727 1.1.0) in python3 (Python 3.4.3 (default, Nov 17 2016, 01:08:31) [GCC 4.8.4] on linux), it is installed from source and GPU-based (name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate (GHz) 1.076). Context : Generative adversarial networks (GANs) learn to synthesise new samples from a high-dimensional distribution by passing samples drawn from a latent space through a generative network. When the high-dimensional distribution describes images of a particular data set, the network should learn to generate visually similar image samples for latent variables that are close to each other in the latent space. For tasks such as image retrieval and image classification, it may be useful to exploit the arrangement of the latent space by projecting images into it, and using this as a representation for discriminative tasks. Context Problem : I am trying to invert a generator (compute L2 norm between an input image in cifar10 and a image g(z) of the generator, where z is a parameter to be trained with stochastic gradient descent in order to minimize this norm and find an approximation of the preimage of the input image). Technical Issue : Therefore, I am building a new graph in a new session in tensorflow but I need to use a trained gan that was trained in another session, which I cannot import because the two graphs are not the same. That is to say, when I use sess.run(), the variables are not found and therefore there is a Error Message. The code is I understood what is the problem, it is actually that I am trying to run a session which is saved in gan/train_logs but the graph does not have those variables I am trying to run. Therefore, I tried to implement this instead : This script runs, but I have checked on tensorboard, the generator that is used here does not have the trained weights and it only produces noise. I think I am trying to run a session in a graph that uses another graph and its trained session. I have read thoroughly the Graphs and Session documentation on tensorflow website https://www.tensorflow.org/versions/r1.3/programmers_guide/graphs, I have found an interesting tf.import_graph_def function : But I don't know how to use this function, no example is given, and also I only found those two links that may help me : https://github.com/tensorflow/tensorflow/issues/7508 Tensorflow: How to use a trained model in a application? It would be really nice to have your help on this topic. This should be straightforward for someone who has already used the tf.import_graph_def function... What I really need is to get the trained generator to apply it to a new variable z which is to be trained in another session. Thanks",https://stackoverflow.com/questions/46089839,8572742.0,1
75020232,Get input shape with Keras custom layer,"I am writing a custom layer using Keras that returns a tensors of zeros the first three times it is invoked and does nothing the other times. The code is the following Unfortunately if I try to build a model using this layer like this I get the following error message Where it seems that, despite using the build function as suggested in the documentation I am not able to retrieve the correct shape of the input. How can I fix this problem? EDIT: I was complicating the problem without thinking, the best solution is to just multiply the inputs per zero like this",https://stackoverflow.com/questions/75020232,7286547.0,1
72146421,AttributeError: 'MapDataset' object has no attribute 'client_ids' in tensorflow_federated TFF,"I'm trying to test a compression technique in federated learning with non-IID using this API tff.simulation.datasets.build_single_label_dataset(), following these posts: But after defining the model and training it, I got this error : The code: What does that mean? Appreciate any help!",https://stackoverflow.com/questions/72146421,18969005.0,1
49182351,How to print SparseTensor contents in TensorFlow?,"For quick debugging purposes, I'm trying to print out the SparseTensor I've just initialized. The built-in print function just says it's a SparseTensor object, and tf.Print() gives an error. The error statement does print the contents of the object, but not in a way that shows the actual entries (unless it's telling me it's empty, there's some :0s I don't know the significance of).",https://stackoverflow.com/questions/49182351,2430134.0,1
60269407,Simpler way to avoid the UserWarning: Converting sparse IndexedSlices,"I have a rnn network structure that looks like following Here while I am running the code, I am getting the following warning. Now I understand why this error is coming. I tried out several ideas and the most common one is the following How to deal with UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape But the problem is this requires too many variable like max_length time_steps seq_length n_dim partitions this make the code very unreadable. I wanted to know if there is a simpler way I can avoid the problem. Also if the sequence length remain same across all the batches, can I assume max_length == time_steps == seq_length ? Please help, documentation is very less.",https://stackoverflow.com/questions/60269407,4037927.0,1
56967648,Need help in writing the tf.estimator.export.ServingInputReceiver in Tensorflow 2.0.beta1,"I am trying to serve my Keras model, but my model is trained on image of shape (125,125,3) and it expect an input as numpy array. But as I was learning the tf.estimator.export.ServingInputReceiver to pre-process my b64_enoded image to a numpy array and feed my model with it, I am stuck here. All my model building and pre-processing is done in tensorflow 2.0. So I am looking for a help to write the tf.estimator.export.ServingInputReceiver function for it. Model Summary: Here is my code : I want to export my model with the ServingInput Receiver as a pre-processing funtion to convert a b64_encoded image to numpy and feed it to the Model.",https://stackoverflow.com/questions/56967648,9887738.0,1
46911972,"ValueError: Cannot feed value of shape (165,) for Tensor 'Placeholder_11:0', which has shape '(?, 2)'","I'm just learning TensorFlow. The goal of this program is to detect Mines and rocks. But I have a problem when I feed the placeholders. I read many questions about this problem in this website but impossible to find a solution. In the feed_dict the shape of train_y is (165,) and y (the placeholder) is (?, 2)... Here is the problem I think. But I don't know how to solve it. I tried to reshape train_y but it doesn't work. I have this error: Here is the data and my program: import pandas as pd import tensorflow as tf import matplotlib.pyplot as plt import numpy as np from sklearn.preprocessing import LabelEncoder from sklearn.utils import shuffle from sklearn.model_selection import train_test_split #traitement des données df = pd.read_csv('sonar.all-data.csv') X = df[df.columns[:60]].values y = df[df.columns[60]] encoder = LabelEncoder() encoder.fit(y) y = encoder.transform(y) #mix data X,y = shuffle(X, y, random_state = 1) #separate date for training train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 415) # Parameters learning_rate = 0.1 num_steps = 500 display_step = 100 # Network Parameters n_hidden_1 = 60 # 1st layer number of neurons 60 n_hidden_2 = 60 # 2nd layer number of neurons 60 num_input = X.shape[1] num_classes = 2 # tf Graph input X = tf.placeholder(""float"", [None, num_input]) Y = tf.placeholder(""float"", [None, num_classes]) # Store layers weight &amp; bias weights = { 'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])), 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])), 'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes])) } biases = { 'b1': tf.Variable(tf.random_normal([n_hidden_1])), 'b2': tf.Variable(tf.random_normal([n_hidden_2])), 'out': tf.Variable(tf.random_normal([num_classes])) } # Create model def neural_net(x): # Hidden fully connected layer with 50 neurons layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1']) layer_1 = tf.nn.relu(layer_1) # Hidden fully connected layer with 50 neurons layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']) layer_2 = tf.nn.relu(layer_2) # Output fully connected layer with a neuron for each class out_layer = tf.matmul(layer_2, weights['out']) + biases['out'] out_layer = tf.nn.relu(out_layer) return out_layer # Construct model logits = neural_net(X) prediction = tf.nn.softmax(logits) # Define loss and optimizer loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( logits=logits, labels=Y)) optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) train_op = optimizer.minimize(loss_op) # Evaluate model correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1)) accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) # Initialize the variables (i.e. assign their default value) init = tf.global_variables_initializer() # Start training with tf.Session() as sess: # Run the initializer sess.run(init) for step in range(1, num_steps+1): sess.run(train_op, feed_dict={X: train_x, Y: train_y}) if step % display_step == 0 or step == 1: # Calculate loss and accuracy loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_x, Y: train_y}) print(""Step "" + str(step) + "", Minibatch Loss= "" + \ ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \ ""{:.3f}"".format(acc)) Thank you for your help!",https://stackoverflow.com/questions/46911972,8803778.0,1
49165112,How to use the old value and the new value of a Variable in Tensorflow?,"I want to use the old value and the new value of a Variable. But I am confused about when the Assign Op is applied. Here is a simple example. The outputs of output and output2 are different. The result is Please advise me what is the proper way to use the old value and the new value of a Variable. Thanks. According to chrisz's answer, I tried tf.control_dependencies to get the old value of v. But the result is not what I expected. I still need to add 0 to v to get the old value. Here is the test code. And I add a 0 to get the same result as above. Otherwise, the result of output_old will be 10",https://stackoverflow.com/questions/49165112,8904948.0,1
72311927,How to train mnist data with tensorflow ParameterServerStrategy distributed training?,"I'm trying to train the mnist dataset using the ParameterServerStrategy. As a beginner, I find the documentations to be confusing specially when it comes to the section ""Clusters in the real world"". This is the docs that I'm following:https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/parameter_server_training.ipynb#scrollTo=zyby6M2Jqg6J&amp;uniqifier=1 So far I have this: I copy these files to the worker and ps VM, change the index and run ""main.py"" on all of them at the same time. I get the message saying that the server was started at ip_address but that's about it. Would anyone please show me what I need to do in order to get this working?",https://stackoverflow.com/questions/72311927,11909464.0,1
46338074,Tensorflow seq2seq,"The api doc of tensorflow's tf.contrib.legacy_seq2seq.basic_rnn_seq2seq says: where, encoder_inputs: A list of 2D Tensors [batch_size x input_size]. decoder_inputs: A list of 2D Tensors [batch_size x input_size]. Question 1: Why are the sequence sizes (input_size) same for both the encoder_inputs and decoder_inputs. In my case, there are seq - to - seq mappings for unequal lengthts. For instance, ""What are you doing"" (length 4) -&gt; ""wie gehts (length 2)"". Is it necessary to pad and make the sequences of equal lengths while using this tensorflow module? Question 2: If I use the The outputs come out to be of the size (batch_size x 128 [num of hidden units in lstm]) which really confuses me. Shouldn't it be equal to (batch_size x output_size)? What am I missing here? I am really confused how the decoder works here.",https://stackoverflow.com/questions/46338074,4341842.0,1
48027341,Getting iterator handle in MonitoredTrainingSession,"I want to try out MonitoredTrainingSession, but I also use several Dataset objects for train and validation sets. And to select the correct one, as the manual suggests I use string handles. But to pass the handle into a feed_dict while training, I need to evaluate it first. Like this: But when I do this in context of MonitoredTrainingSession, I get an error: The way out, as I thought, was to create an init_fn for a Scaffold object which I pass into the session. But this didn't work out. If I try to run aforementioned code in the context init_fn is still get the same error. As the documentation says about init_fn: This makes me think that I'm radically wrong with the intended purpose of this callback, or Tensorflow misbehaves. Could you help me to resolve this confusion. My tensorflow version is 1.4.0. UPDATE Adding a minimal example. The first block works, the second doesn't.",https://stackoverflow.com/questions/48027341,1201416.0,1
42535815,How to add more layers to Convolutional Neural Network text classification TensorFlow example?,"According to the documentation, the model presented in this example is similar to the following paper: ""Character-level Convolutional Networks for Text Classification"" I found that the original model (presented in the paper) contains 9 layers deep with 6 convolutional layers and 3 fully-connected layers, but the implemented example contains only two convolutional layers: If anybody can help me to extend this model for more layers?",https://stackoverflow.com/questions/42535815,3052875.0,1
36585071,"Cannot feed value of shape (500,) for Tensor 'x_17:0', which has shape '(?, 500)'","I'm just learning TensorFlow, so sorry if this is obvious. I've checked the documentation and experimented quite a bit and I just can't seem to get this to work. yield_financials() outputs an numpy array of 500 numbers and the number that I want it to guess. I've tried shuffling OUT_DIMS and FIN_SIZE around, I tried accumulating them into batches to more closely match what the tutorial looked like, I tried setting OUT_DIMS to 0, removing it entirely, and I tried replacing None with other numbers, but have not made any progress.",https://stackoverflow.com/questions/36585071,3471004.0,1
49482390,"Tensorflow, replacing feed_dict with Dataset.from_generator","I have an existing model which reads through a text file in a loop, the resulting input and output looks like this: But now i want to convert to using the Dataset.from_generator method, to get started i created a wrapper class around my text reader that implemted the generator function, this all works well, and returns the input data as expected: However i am getting an error And i assume this is because i have declared X/Y inputs as placeholders, the documentation states the values must be fed via feed_dict. So i got a couple of questions:",https://stackoverflow.com/questions/49482390,1371314.0,1
43315068,Tensorflow: has no attribute 'numpy_input_fn',"I am using Eclipse's PyDev for tensorflow version:0.12.1 I directly copy the sample code from tensorflow documentation, but a attribute is not found and it returned Tried to re-download pydev and tensorflow but none of them work The source code:",https://stackoverflow.com/questions/43315068,3026820.0,1
71734880,Any example workflow from TensorFlow to OpenMV?,"I have trained an image multi classification model based on MobileNet-V2(Only the Dense layer has been added), and have carried out full integer quantization(INT8), and then exported model.tflite file, using TF Class () to call this model. Here is my code to quantify it: The accuracy of this model is quite good in the test while training. However, when tested on openmv, the same label is output for all objects (although the probability is slightly different). I looked up some materials, one of them mentioned TF Classify() has offset and scale parameters, which is related to compressing RGB values to [- 1,0] or [0,1] during training, but this parameter is not available in the official API document. So are there any examples of workflow from tensorflow training model to deployment to openmv?",https://stackoverflow.com/questions/71734880,17221142.0,1
71273332,tff.simulation.datasets.ClientData to build federated learning model from CSV files,"I am building a federated learning model using my own dataset. I aim to build a multi classification model. The data are presented in separate 8 CSV files. I followed the instructions in this post As shown in the code below. but it gave me this error I was reading this documentation and found that .datasets methods would work, so I replaced with .from_clients_and_fn and the error disappeared but I dont know if it is right and what is next? My questions are: and thanks in advance",https://stackoverflow.com/questions/71273332,17534198.0,1
71245237,tensorflow : @ symbol,"I saw a code snippet in the tensorflow documentation and couldn't find any info about it So, what is the role/purpose of the @ symbol at the code below :",https://stackoverflow.com/questions/71245237,14118985.0,1
42608245,How to use tf.contrib.seq2seq.simple_decoder_fn_inference API,"I did not understand the parameters that needed to be passed into the API call to tf.contrib.seq2seq.simple_decoder_fn_inference in Tensorflow 1.0 for building the inference block for a Seq2Seq Attention mechanism RNN. Can someone explain, in detail, what each parameter of this function call means and is supposed to do? The link to the documentation is here : tf.contrib.seq2seq.attention_decoder_fn_inference()",https://stackoverflow.com/questions/42608245,7661539.0,1
42598841,using validation monitor in tflearn.regression to create confusion matrix,So I have been trying to create a confusion metrics in my autoencoder I have gone through the documantation but they were not very useful to me. How would I configure to get the confusion matrix?,https://stackoverflow.com/questions/42598841,5540592.0,1
52484694,TF Eager mode: Load a complete model from disk if possible,"Update: ""AttributeError: 'AdamOptimizer' object has no attribute 'name'"" might be an alternative title for this question. If this can be solved then the whole thing might work right. Have a new jupyter notebook that has NO model saving code. The trained model was already saved using another notebook like this. The iris dataset was used here and the model is all trained up: I grabbed the output path from the above and then tried to load the model in a new notebook using tf.contrib.eager code but it fails: So what is an actually WORKING use case code to load a previously developed model with the tf.contrib.eager api (not the session api) WHEN THE CODE IN THE MODEL-LOADING NOTEBOOK DOES NOT SAVE THE MODEL AND DOES NOT HAVE THE MODEL'S PARTS IN MEMORY ALREADY like optimizer, graph definition, and global_state? The TF docs always choose to demo a pointless example of loading a model we already have in memory. I can't tell if ""With the TF.contrib.eager API you have to have explicit model creation code and optimizer creation code and global step code right in your notebook because TFE cannot load this stuff from disk"" or ""its a new API and some features are missing"", or ""you have to also use session and graph coding api along with tf.contrib.eager api"" or ""just use Microsoft cntk which actually works with imperative code and they didnt forget critical parts of the API"". Thanks if you know something. If speculating, please state. I suspect it's some superset and subset combination of the following if it's going to work. (Scraped from SO posts on the subject.) Update - I added code to first manually recreate the model, optimizer, etc into memory, and then ran the restore() code. Error - optimizer does not have a name. But, oddly, it actually does have a name attribute according to the documentation: INFO:tensorflow:Restoring parameters from /tmp/iris-1 AttributeError: 'AdamOptimizer' object has no attribute 'name' The documentation says: It sure looks like Adam optimizer has a name! That's funny. What's the problem then? Maybe the TF error is really saying that an optimizer and a model and a global_state variable cannot be restored. So then what would be restored from a checkpoint -- specifically what variables would go in the save and corresponding restore? Thanks if you know anything.",https://stackoverflow.com/questions/52484694,39123.0,1
42838796,"Value error: Cannot feed value of shape (5, 15) for Tensor 'one_hot:0', which has shape '(5, 15, 2)'",this is the code genreating data{...} some optimization code{....} and then creating the graph and this the error: i looked the docs but that does not helpful at all if there is any other easy way that also will be helpful,https://stackoverflow.com/questions/42838796,7018732.0,1
49500495,TensorFlow InternalError: Unable to get element as bytes,"I am trying to run a DNNClassifier with TensorFlow on some log data that contains a mix of categorical and numeric data. I have created feature columns to specify and bucketize/hash the data for tensorflow. When I run the code I receive the 'Unable to get element as bytes' internal error. Note: I did not want to drop the Nan values as stated in this article so I converted them to 0 using this code train = train.fillna(0, axis=0) so I am not sure why I am still gettting this error. If I dropna then it works but I do not want to drop the Nan's as I feel they are needed for the model to train. Then I receive this error:",https://stackoverflow.com/questions/49500495,8160293.0,1
75552310,How to use my pretrained LSTM saved model to make new classifications,"I have a simple pretrained LSTM model builded with Keras and Tensorflow, I trained, compiled and fitted it, and make a test prediction with a simple sentence, and it works, then I saved my model using model.save(sentanalysis.h5 and everything OK. Then, I loaded this model with model.load_model(), and it loads without error, but when I tried model.predict() I got an array with floats that doesn't shows anything related to the classes: How can I use my pretrained model to make new classifications? The dataset I use to train it is very simple, a csv with text and sentiment columns, nothing else. Can you help me? This is the code of the model: And this is how I save and load my model withouth loading previous code: And I get this: I've reading some doc, but nothing helped me.",https://stackoverflow.com/questions/75552310,19156897.0,1
73853604,how to include image input to a transformer model?,"i am using this transformer architecture: https://github.com/JanSchm/CapMarket/blob/master/bot_experiments/IBM_Transformer%2BTimeEmbedding.ipynb to make some binary clasification, i am adding some pictures as input, but i was wondering, how is the right way to do this? my modified architecture is: here i am doing the concatenation of the time embedding beforethe first lstm(not sure is i should add this lstm layer and concatenate here) then i use the dense layer to make it have a common shape, then i put a convolutional 2d to start working whit the images, then it goes to the dense in order to make it have the desired shape having this two outputs whit the same shape, i concatenate them and then pass it over a dense, then i reshape it, in order to do the time embedding concatenation again before sending all this mess up to the transformer's layers here it is the the model's plot i really feel like im doing this wrong but i can't find too much documentation over this topic, also i am using a tensorflow dataset to feed the network here i put the time2vec, attention, multihead and transformer classes (almost identical to the github code)",https://stackoverflow.com/questions/73853604,11579387.0,1
58798502,how to find similarity between image patches/windows,"I want to compare the similarity between one reference window(patch) and all other windows(patches) taken from an image. My code is given below. Can anyone please help me evaluate the similarity between 'ref' (reference window) and all other 10000 windows given by variable 'test'? thank you Detailed explanation: I tried doing using for loop. it is time-consuming. I tried to use the built-in function ""ssim"" but it says the dimension of tensors do not match. please suggest any method to do this batch processing I expect the distance between each of these windows and the reference to be printed.",https://stackoverflow.com/questions/58798502,12354419.0,1
49116343,Dataset API 'flat_map' method producing error for same code which works with 'map' method,"I am trying to create a create a pipeline to read multiple CSV files using TensorFlow Dataset API and Pandas. However, using the flat_map method is producing errors. However, if I am using map method I am able to build the code and run it in session. This is the code I am using. I already opened #17415 issue in TensorFlow Github repository. But apparently, it is not an error and they asked me to post here. I get the following error: map_func must return a Dataset object. The pipeline works without error when I use map but it doesn't give the output I want. For example, if Pandas is reading N rows from each of my CSV files I want the pipeline to concatenate data from B files and give me an array with shape (N*B, 2). Instead, it is giving me (B, N,2) where B is the Batch size. map is adding another axis instead of concatenating on the existing axis. From what I understood in the documentation flat_map is supposed to give a flatted output. In the documentation, both map and flat_map returns type Dataset. So how is my code working with map and not with flat_map? It would also great if you could point me towards code where Dataset API has been used with Pandas module.",https://stackoverflow.com/questions/49116343,7656080.0,1
38992445,Tensorflow: Py_func returns unknown shape,"I have a simple question re the tf.py_func function. I have an image tensor my_img of shape (1,224,224,3). To test py_func, I feed the tensor to a python function return_tf that should give back the same tensor (after being converted to a numpy array as per docs). Here's the code: But when I checked the shape of the returned tensor called test, I get: I am also unable to run eval() on the tensor, since I get the error: Anyone knows how could I fix the tensor shape of the tensor returned by tf.py_func?",https://stackoverflow.com/questions/38992445,6720221.0,1
67267305,How should Exponential Moving Average be used in custom TF2.4 training loop,"I have a custom training loop that can be simplified as follow The TensorFlow documentation of ExponentialMovingAverage is not clear on how it should be used in from-scratch training loop. As anyone worked with this? Additionally, how should the shadow variable be restored into the model if both are still in memory, and how can I check that that training variables were correctly updated?",https://stackoverflow.com/questions/67267305,1782553.0,1
51050053,Investigating into Float16 training in TensorFlow,"TensorFlow slim pre-trained models are saved with their weights in tf.float32. For the purpose of memory efficiency, I would like to load a pre-trained model in tf.float16 and then run some training operations after attaching a few other modules in tf.float16. I am aware that doing this normally is not possible due to the tensor data type mismatch. However, is there a good resource dedicated to this issue ? Has anyone tried something like this before ? For records, following is a snippet which I used just to verify if pretrained models can be restored in tf.float16 and it did not work. The output is",https://stackoverflow.com/questions/51050053,8530591.0,1
54942875,"How could I get part of a tensor with indices coming from another tensor? (Keras, tf backend)","I am working with RNN and attention mechanisms. Different from soft attention (which weights time steps of RNN by attention tensor and sum up them), I want to select the most k important time steps and using other methods to combine them. Thus, I have three tensors: Ideally, I can get KRNNMatrix shaped (None, k, cell_num) through RNNMatrix and IdxMatrix. The straightforward method to get IdxMatrix is using tf.nn.top_k. My code below: The model complies well and throws an error when I train it: ValueError: An operation has None for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval. I'm pretty sure this error blame to my Lambda layer, most probably blame to the variable indices of tf.nn.top_k. But I don't know how to fix it. Or, is the operation 'select tensor by index' theoretically nondifferentiable? If so, is there any workaround? In the worst case, could reinforcement learning hold this? I also search a lot on the internet and find a very similar question asked by Daniel Möller. However, Daniel does not show more details about how he solves this problem.",https://stackoverflow.com/questions/54942875,9997549.0,1
52636943,"What is a ""stateful object"" in tensorflow?","In several parts of the documentation (e.g. Dataset Iterators here) there are references to Stateful Objects. What exactly are they and what role do they play in the graph? To clarify, in the Dataset documentation there's an example with the one_shot_iterator that works because it's stateless: what makes the iterator stateless?",https://stackoverflow.com/questions/52636943,1047543.0,1
57114360,"TypeError: float() argument must be a string or a number, not 'builtin_function_or_method'","I am running a CNN that check for images but does not classify. In fact, the output layer is a dense layer that have as argument the size of the images in the labels in 1d. As shown below in the code, I am using model.fit_generator() instead of model.fit and when it comes to start training the model the following error comes up: TypeError: float() argument must be a string or a number, not 'builtin_function_or_method' I am not really getting why this is happening. Here attached is the summary of the model: conv2d_4 (Conv2D) (None, 26, 877, 32) 544 activation_5 (Activation) (None, 26, 877, 32) 0 max_pooling2d_4 (MaxPooling2 (None, 13, 438, 32) 0 conv2d_5 (Conv2D) (None, 12, 437, 16) 2064 activation_6 (Activation) (None, 12, 437, 16) 0 max_pooling2d_5 (MaxPooling2 (None, 6, 218, 16) 0 conv2d_6 (Conv2D) (None, 5, 217, 8) 520 activation_7 (Activation) (None, 5, 217, 8) 0 max_pooling2d_6 (MaxPooling2 (None, 2, 108, 8) 0 activation_8 (Activation) (None, 2, 108, 8) 0 flatten_2 (Flatten) (None, 1728) 0 dropout_2 (Dropout) (None, 1728) 0 dense_2 (Dense) (None, 19316) 33397364 ================================================================= Total params: 33,400,492 Trainable params: 33,400,492 Non-trainable params: 0 Any suggestions ? Thanks a lot in advance! I have already looked up many of the online forums/websites but I don't seem to find one that suits my case.",https://stackoverflow.com/questions/57114360,11782908.0,1
44141986,Clarification on Tensorflow tensor shapes and matmul,"I need some clarification on how Tensorflow treats the shape of its tensors. This is taken from the MNIST example: I define a placeholder that will at some later point be fed with some of my training data: x = tf.placeholder(tf.float32, shape=[None, 784]) During runtime I feed it in batches of 100, so its shape during runtime is (100, 784). I also define weights and biases: Wis of shape (784, 10) and bis of shape (10). Now I compute And this is where I am stuck. The matrix product of x and W is of shape (None, 10) or (100, 10) during runtime. However I can without error add vector b to it. This confuses me. How can this work? And is there some better documentation for this?",https://stackoverflow.com/questions/44141986,578640.0,1
54521572,How to transform keras model to tpu model,"I am trying to transform my Keras model in the Google cloud console into a TPU model. Unfortunatelly I am getting an error as shown below. My minimal example is the following: My output is: The keras_to_tpu_model method seems experimental as indicated on the tensorflow website. Has it recently been removed? If so, how can I proceed to make use of TPUs to estimate my Keras model? If the keras_to_tpu_model method would be still available, why can I not invoke it?",https://stackoverflow.com/questions/54521572,6493472.0,1
43736089,How to use tf.contrib.seq2seq.BahdanauAttention,"I am trying to produce a simple code for a seq2seq model with attention in tf 1.1. I am not sure what is the parameter ""depth of query mechanism "". I am getting an error on creation of Attention Mechanisms saying that: Here is my code. Am I on a right track? I could not find any detailed documentation.",https://stackoverflow.com/questions/43736089,5579493.0,1
42497521,Use of softmax with tf.nn.weighted_cross_entropy_with_logits,"Is it necessary to use tf.nn.softmax() to get the softmax of logits before using tf.nn.weighted_cross_entropy_with_logits()? I am doing binary classification on an imbalanced set, and have my pos_weight value set to [1.0, 15.0] to compensate for the latter class being underrepresented in the data. The other similar op tf.nn.softmax_cross_entropy_with_logits() explicitly says not to use softmax beforehand, but the weighted version does not specify. I have tried it both with and without, and when I use the softmax before the model does not learn (e.g. AUC converges to 0.500). The last layer in my model is using elu activation on a [batch_size, 2] tensor. My labels are coded as [1, 0] for the first class, and [0, 1] for the second.",https://stackoverflow.com/questions/42497521,7542570.0,1
41796965,Tensorflow: How to use a trained model in a application?,"I have trained a Tensorflow Model, and now I want to export the ""function"" to use it in my python program. Is that possible, and if yes, how? Any help would be nice, could not find much in the documentation. (I dont want to save a session!) I have now stored the session as you suggested. I am loading it now like this: However, I get the error ""no Variables to save"" when I try to initialize the saver. What I want to do is this: I am writing a bot for a board game, and the input is the situation on the board formatted into a tensor. Now I want to return a tensor which gives me the best position to play next, i.e. a tensor with 0 everywhere and a 1 at one position.",https://stackoverflow.com/questions/41796965,6480160.0,1
63310748,How to code keras to read my own picture using my trained model?,"I used minst to train my own model of number reading, but when I tried to upload my own picture for predicting, it told me an error said ""ValueError: Input 0 of layer dense_3 is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape [None, 84]""(My model was trained correctly, predicting picture in minst was successful. Here is my code: This is my error: Minst is a 28x28 picture so this code is using 28x28 picture. My environment of develop is: ""Google Colab"" and ""Juypter Notebook"", and this error I have tried both environment and still getting this error. Can somebody help? import tensorflow as tf # deep learning library. Tensors are just multi-dimensional arrays",https://stackoverflow.com/questions/63310748,13992843.0,1
43848414,How is memory managed during tensor transformations?,"Even if the question involves TensorFlow, I will use normal math terminology to describe my question. Let's say that After reading some code examples, the way I do it now is as it follows (n = self.nNodes, k=self.inputShape): It seems to be - but I am not sure - that, after a while, TensorFlow has some difficulties in managing the memory (especially on the GPU) since the expand_dims and tile operations return new tensors. Is there any way to allocate a tensor for X_MM (as I do for W) and copy the input value x into each element of X_MM. In this way the memory for X_MM would be allocated only once. Is there an ""atomic"" instructions for copying a vector, line by line, into another (a sort of tiling without allocating new memory)? Should I use a TensorFlow iterator for obtaining this? More in general, should I worry about memory management with TensorFlow? It seems to me it is an important topic, but cannot find any relevant info on the documentation and all of the examples I see use operators that allocate new memory.",https://stackoverflow.com/questions/43848414,774133.0,1
66538337,How to get Tensorflow Embedding Projector to work with images,"After reading the documentation [here] and [here] 1 2, I have been unable to get my embedding to populate the Tensorflow Embedding Projector. I am working with image data and want to visualize the embeddings, but after saving the weights and the labels to /log_dir Tensorboard still says no data was found. Any help would be appreciated. This is copy pasted from a notebook so I apologize for any formatting errors.",https://stackoverflow.com/questions/66538337,10413628.0,1
43147428,MNIST Tensorflow example,"This is the code from the Deep MNIST for experts tutorial on Tensorflow website. I have two questions: 1) The documentation k-size is an integer list of length greater than 4 that refers to the size of the max-pool window. Shouldn't that be just [2,2] considering that it's a 2X2 window? I mean why is it [1, 2, 2, 1] instead of [2,2] ? 2) If we are taking a stride step on size one. Why do we need a vector of 4 values, wouldn't one value suffice? 3) If padding = 'SAME' why does the image size decrease by half? ( from 28 X 28 to 14 X 14 in the first convolutional process )",https://stackoverflow.com/questions/43147428,6203717.0,1
37822097,Using TensorArrays in the context of a while_loop to accumulate values,"Below I have an implementation of a Tensorflow RNN Cell, designed to emulate Alex Graves' algorithm ACT in this paper: http://arxiv.org/abs/1603.08983. At a single timestep in the sequence called via rnn.rnn(with a static sequence_length parameter, so the rnn is unrolled dynamically - I am using a fixed batch size of 20), we recursively call ACTStep, producing outputs of size(1,200) where the hidden dimension of the RNN cell is 200 and we have a batch size of 1. Using the while loop in Tensorflow, we iterate until the accumulated halting probability is high enough. All of this works reasonably smoothly, but I am having problems accumulating states, probabilities and outputs within the while loop, which we need to do in order to create weighted combinations of these as the final cell output/state. I have tried using a simple list, as below, but this fails when the graph is compiled as the outputs are not in the same frame(is it possible to use the ""switch"" function in control_flow_ops to forward the tensors to the point at which they are required, ie the add_n function just before we return the values?). I have also tried using the TensorArray structure, but I am finding this difficult to use as it seems to destroy shape information and replacing it manually hasn't worked. I also haven't been able to find much documentation on TensorArrays, presumably as they are, I imagine, mainly for internal TF use. Any advice on how it might be possible to correctly accumulate the variables produced by ACTStep would be much appreciated.",https://stackoverflow.com/questions/37822097,6466534.0,1
53409455,"How do I find the output of a tensor and/or op in tensorflow? (or ""tensorflow op.outputs only pointing to itself"")","First things first - this might be a very basic and dumb question, but I've tried many things and searched all over to no avail, so here I am. The problem is the following: I have a tensor, and I'd like to find ""where it leads"" for various reasons. The way to theoretically do this would be to just look at my_tensor.op.outputs, as per documentation and such, but this always seems to point back to my_tensor itself! I've easily gone the other way before, meaning I can get the input tensor by using my_tensor.op.inputs, but for some reason ""outputs"" isn't doing the expected. Here's a simple example: If you tried the above, you'll see you got back to 'a'... Again, running my_sum.op.inputs gives the 'add' op, and running even further back get's us to 'a' and 'b' as expected: But the other way round? No such luck: So what am I doing wrong? I've also tried using the (deprecated) op.values() with no success, and I'm confused because the documentation explicitly states that this should give me the outputs of the op (from https://www.tensorflow.org/api_docs/python/tf/Operation): (I checked that a.op.__class__ is the right class and that I'm reading the correct documentation). (Just to wrap things up, the node_def of the ops also shows no signs of an output field...). Thanks in advance for any advice! Edit (due to Yuxin's answer): Just to clarify, taking the output of the output of the etc. stays put on the same tensor. I'm trying to reach the next tensor/op. P.S: This is my first stackoverflow question, so if I did anything ""wrong"" let me know and I'll try fix it.",https://stackoverflow.com/questions/53409455,5024514.0,1
41161815,Implementing an accuracy metric in TensorFlow,"I am following the examples in the TensorFlow documentation, specifically example 1, where the metric is assigned as follows: I was wondering: how do I implement a different accuracy metric. For example MAP(mean average precision). Assuming that I have a function: A way to go through is to make the predictions and pass it the mean_precision_scorce function: where both y_true and y_predicted are converted to numpy arrays.But is there a way to do it similar with the example of Tensorflow? Any tip?",https://stackoverflow.com/questions/41161815,4157666.0,1
37661063,Variable initialization in the variable_scope in the Tensorflow,"I've been trying to understand how variables are initialized in Tensorflow. Below, I created a simple example which defines a variable in some variable_scope and the process is wrapped in the subfunction. In my understanding, this code creates a variable 'x' inside the 'test_scope' at tf.initialize_all_variables() stage and it can always be accessed after that using tf.get_variable(). But this code ended up with the Attempting to use uninitialized value error at print(x.eval()) line. I don't have any idea about how Tensorflow initializes variables. Can I get any help? Thank you.",https://stackoverflow.com/questions/37661063,6424552.0,1
50371333,usage of tf.app.run() and argparse,"I have understood what a parser does, but I do not get its use when it is mingled with tf.app.run() in the following code: the main function in the program does not have any arguments as it is defined as def main(_). So what is the argv argument in tf.app.run() supposed to mean or do? Thanks",https://stackoverflow.com/questions/50371333,7415247.0,1
59796343,Transformer model not able to be saved,"I'm trying to follow this tutrial https://colab.research.google.com/github/tensorflow/examples/blob/master/community/en/transformer_chatbot.ipynb, However, when I tried to save the model in order to load it again without training I got an error mentioned here NotImplementedError: Layers with arguments in `__init__` must override `get_config` I understood from the answer that I need to make the encoder and decoder as classes and customise it(instead of leaving it as functions like the colab tutrial) so I went back to tensor flow documentation of this model here: https://www.tensorflow.org/tutorials/text/transformer#encoder_layer and tried to edit in it. I made the encoder layer as: and same for the decoder layer class. Then the same encoder in the documentation of tf the function of the model as: and calling the model: However, I got that error: TypeError: __init__() missing 2 required positional arguments: 'dff' and 'maximum_position_encoding' I am really confused and I don't understand what dff and maximum position encoding mean in the documentation and when I removed them from the encoder and decoder classes, I got anther error as positional_encoding function takes maximum position as input and also dff is passed as input inside the class. I am not so sure what I should do as I am not sure whether I am following the right steps or not",https://stackoverflow.com/questions/59796343,10291435.0,1
67600983,How can I prevent TextVectorization in Tensorflow creating values for Unknown and blank strings?,"I am looking to one hot encode string tensor as part of my dataset pipeline. It seems to me this can be achieved using TextVectorization to get an integer representation of the string tensor and then one_hot to convert to achieve the encoded 2d tensor. When i use TextVectorization it seems to automatically try to map """" to 0 and strings out of vocabulary strings to 1. See below using Tensorflow 2.3: I can see why it would be useful as it would handle the last 2 values in the below tensor without throwing an error and creating a feature for them in the process. In my application though I want to switch this behaviour off as I don't need it. The documentation doesn't seem to provide an option to disable it and for now I am just going to -2 from the output but that doesn't feel right. Are there any cleaner, tensorflow native, solutions for generating integer representations of string tensors?",https://stackoverflow.com/questions/67600983,5799799.0,1
73942265,How do I explicitly split a Dataset tuple in Tensorflow's functional API into two separate layers from just one input layer?,"Context The input to my model is a BatchDataset object called dataset_train, and it is batched to yield (training_data, label). For some of the machinery in my model, I need to be able to split the Dataset tuple inside the model and independently access both the data and the label. This is a single input model with multiple outputs, so I am using Tensorflow's Functional API. For the sake of reproducibility, I am working with timeseries, so a toy dataset would look like this: Note: Sequence Length and batch_size are additional semi-arbitrary hyperparameters that are not important for the purposes of this question. Question How do I split apart the Dataset in Tensorflow's Functional API into the training data element and the label element? Here is pseudocode of what I am looking for: After that point, my model can perform it's actions on training_data and label independently. First Solution I tried: I first started by trying to define two input layers and pass each element of the dataset tuple to each input layer, and the act on each input layer independently. The first problem I had with this is that I got the following error: This is a problem, because if I actually pass the model a dictionary of datasets (nevermind that this isn't supported) then I introduce a circular dependency where in order to use model.predict, it expects labels for the inputs to model.predict. In other words, I need the answers to get the answers. Because I need to pass it only a single Dataset to prevent introducing this circular dependency (tensorflow implicitly assumes that the second element in a Dataset is the label, and doesn't require Datasets with labels for model.predict), I decided to abandon this strategy for unpacking the Input layer directly within the functional API for the model. Second Solution I tried: I thought maybe I could unpack the Dataset using the .get_single_element() method in the following code excerpt This gave the following error: I then thought the problem was that because the symbolic tensor wasn't of type Dataset, I needed to define the input layer to expect a Dataset. After reading through the documentation and spending ~9 hours messing around, I realized that tf.keras.Input takes an argument called type_spec, which allows the user to specify exactly the type of symbolic tensor to create (I think - I'm still a little shaky on understanding exactly what's going on and I'm more than a little sleep deprived, which isn't helping). As it turns out there's a way to generate the type_spec from the dataset itself, so I did that to make sure that I wasn't making a mistake in generating it. Which gives the following error: I'm not really sure why I get this error, but I tried to circumvent it by explicitly defining the type_spec in the Input layer Which gives the following error: I also had tried to make the DatasetSpec manually instead of generating it using .from_value earlier and had gotten the same error. I thought then it was just because I was messing it up, but now that I've gotten this error from .from_value, I'm beginning to suspect that this line of solutions won't work because DatasetSpec implicitly is missing a shape. I might also be confused, because performing dataset_train.element_spec clearly reveals that the dataset does have a shape, so I'm not sure why Tensorflow can't infer from it. Any help in furthering either of those non-functional solutions so that I can explicitly access the training_data and label separately from an input Dataset inside the Functional API would be much appreciated!",https://stackoverflow.com/questions/73942265,19272719.0,1
49017930,Errors implementing Sampled Softmax Tensorflow,"I have been trying for a while to implement sampled softmax because I have half a million output classes. I have tried to follow the official documentation exactly, but I always get an error. This is my code: This is the cost computation function: For the purpose of just testing this out, I am using 1144 output classes, which would otherwise scale to 500,000. There are 3144 training examples. I get this error: I am unable to debug this or make any sense out of it. Any help would be really appreciated.",https://stackoverflow.com/questions/49017930,5054785.0,1
48768206,How to use dataset.shard in tensorflow?,"Recently I am looking into the dataset API in Tensorflow, and there is a method dataset.shard() which is for distributed computations. This is what's stated in Tensorflow's documentation: This method is said to return a portion of the original dataset. If I have two workers, am I supposed to do: Because the documentation did not specify how to make subsequent calls, I am a bit confused here. Thanks!",https://stackoverflow.com/questions/48768206,8736709.0,1
58276774,How do you write a fixed len feature to tfrecord,"I'm struggling with the basics of writing a tensorflow tfrecord file. I'm writing a simple example with an ndarray in python, but for some reason when I read it it's required to be variable-length and reads it as a SparseTensor. Here's the example Can anybody explain to me why this writes a variable-length record? It is fixed in code, but I can't seem to write it in a way tensorflow knows its fixed. The tensorflow documentation is pretty horrific here. Can anybody clarify the API for me?",https://stackoverflow.com/questions/58276774,1196033.0,1
36286594,Predicting the next word using the LSTM ptb model tensorflow example,"I am trying to use the tensorflow LSTM model to make next word predictions. As described in this related question (which has no accepted answer) the example contains pseudocode to extract next word probabilities: I am confused about how to interpret the probabilities vector. I modified the __init__ function of the PTBModel in ptb_word_lm.py to store the probabilities and logits: Then printed some info about them in the run_epoch function: This produces output like this: I was expecting the probs vector to be an array of probabilities, with one for each word in the vocabulary (eg with shape (1, vocab_size)), meaning that I could get the predicted word using np.argmax(probs, 1) as suggested in the other question. However, the first dimension of the vector is actually equal to the number of steps in the unrolled LSTM (20 if the small config settings are used), which I'm not sure what to do with. To access to the predicted word, do I just need to use the last value (because it's the output of the final step)? Or is there something else that I'm missing? I tried to understand how the predictions are made and evaluated by looking at the implementation of seq2seq.sequence_loss_by_example, which must perform this evaluation, but this ends up calling gen_nn_ops._sparse_softmax_cross_entropy_with_logits, which doesn't seem to be included in the github repo, so I'm not sure where else to look. I'm quite new to both tensorflow and LSTMs, so any help is appreciated!",https://stackoverflow.com/questions/36286594,4034105.0,1
60104249,Missing modules and attributes for training in TensorFlow's Object Detection API,"I'm currently attempting to train an object detection model. I'm following Gilbert Tanner's tutorial on YouTube. I am running TF version 1.9.0. It seems as though I'm missing the necessary modules. When I run the following command: I get the following error: For some reason, I've had to fix other problems with certain modules not being in the correct place (for instance, the nets module wasn't placed under the models/research/object_detection directory upon installation, it was instead placed under models/research/slim). I'm not sure exactly how to fix this issue. I've tried bouncing between different 1.x versions of TensorFlow but each time I am met with similar errors, such as not having the 'v2' attribute. I suspect I could be lacking a package that should be installed in my environment, but I'm not sure what it could be. I'm also unsure about why the necessary modules aren't properly installed. Here are all of the packages that are installed in my environment: Am I missing any necessary packages? Any help on this issue is appreciated. Please let me know if I have not included information that would be helpful. EDIT: Line 375 in C:\Users\Admin\Desktop\ObjectDetection\models\research\object_detection\nets\inception_resnet_v2.py is bolded below: Here is the link to the video I'm referring to. My problem is occurring when I run the command at 18:01. https://www.youtube.com/watch?v=HjiBbChYRDw I realize the command I provided above is slightly different than the one shown in the video. However, in the written version of the tutorial, Gilbert Tanner has updated the command to the one I provided above. Changing all references on tf.compat.v1.GraphKeys to tf.GraphKeys works, but more errors arise: on this function signature: When I change it to this: I get this error: There is no documentation for avg_pool2d for TensorFlow 1.x and there is for TensorFlow 2.x, so I'm not sure why it's in this file if I have TensorFlow 1.9. I notice tf.nn has attributes avg_pool and avg_pool3d, however, changing it to these causes a TypeError: Here is line 98 in tensors_to_item: I'm not sure how to handle this issue and it seems like I shouldn't have changed the function signature. Is having to make this many changes to the modules normal?",https://stackoverflow.com/questions/60104249,11477760.0,1
60797147,Embedding layer output shape is 2D,"I'm encountering some issue with the output shape of my embedding layer, as per the keras documentation, the embedding layer should have an output shape of 3D tensor, but my embedding layer is only outputting 2D tensor. It outputs the shape of the embedding layer out as a 2D (300,300) tensor. which causes error on the bidirectional lstm: ValueError: Input 0 of layer bidirectional is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [300, 300]",https://stackoverflow.com/questions/60797147,11000852.0,1
38855807,Tensorflow Grid3LSTMCell visualization,"I'm having a difficult time visualizing what this Tensorflow class creates. I want to implement a LSTM RNN that handles 3D data. This is difficult to explain, so I've provided a drawing. Here is what I want it to do... However the comment sounds like it isn't doing this. The comment makes it sound like the RNN is still a flat RNN, where the first dimension is outputting to, what is commonly called, the outputs variable (see below). The second dimension is outputting to the next step in the RNN, and the third dimension is outputting to the next hidden layer. outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32) If this is the case, what is the point in having the first and second dimensions? Aren't they essentially the same thing? The BasicLSTMCell sends the output to the next step into outputs -- in other words they are one in the same. Clarity? For reference, here is my example code...",https://stackoverflow.com/questions/38855807,5449456.0,1
58174470,What does the `order` argument mean in `tf.keras.utils.normalize()`?,"Consider the following code: which returns I understand how B1 is computed via order=1 such that each entry in A is divided by the sum of the elements in its column. For example, 0.8 becomes 0.8/(0.8+0.1) = 0.888. However, I just can't figure out how order=2 produces B2 nor can I find any documentation about it.",https://stackoverflow.com/questions/58174470,5640161.0,1
67583469,How to run inference from a frozen-graph (efficentdet-dX.pb) file in tensorflow 2.x?,"I have trained an efficentdet-d4 model using the automl pipeline which has generated .ckpt files, which I have converted to a .pb (frozen-graph) file using the command given in the automl repository. Now, I wants to run this frozen-graph (efficentdet-d4.pb) file on a given image. For that, I have followed the tensorflow object-detection-api docs and official Guides to run the model and make inferences but it throws me 'AutoTrackable' object is not callable error. Please Note : This same code runs fine if I use a pre-trained network given in the TF2 Model Zoo. I have tried to debug in how automl create the frozen-graph, here are some of the key paths that may be helpful: export_saved_model &gt; build &amp; export",https://stackoverflow.com/questions/67583469,9850713.0,1
46938530,Produce balanced mini batch with Dataset API,"I've a question about the new dataset API (tensorflow 1.4rc1). I've a unbalanced dataset wrt to labels 0 and 1. My goal is to create balanced mini batches during the preprocessing. Assume I've two filtered datasets: Is there a way to combine these two datasets such that the resulting dataset looks like ds = [0, 1, 0, 1, 0, 1]: Something like this: My current approach is: But I've the feeling there is a more elegant way. Thanks in advance!",https://stackoverflow.com/questions/46938530,863543.0,1
49286590,tf.while_loop only makes only one loop,"After days of trying to apply a tf.while_loop, I still fail to understand how it works (or rather why it does not). The documentations and various questions here on StackOverflow haven't helped so far. The main idea is to train the different columns of a tensor trueY separately using a while_loop. The problem is that when I trace this code, I see that the while_loop gets called only once. I'd like to dynamically assign names to variables created in the while_loop so as to be able to access them outside the while_loop after they have been created (thus the ""gen_name"" function trying to dynamically generate names for the dense layers created in each loop), and make tf.while_loop run n times this way. Here is a sample of my code with the issue (not the full code and modified to demonstrate this problem)",https://stackoverflow.com/questions/49286590,1971741.0,1
57216896,Understanding Nested Function in python,"I have the following nested function code: the output is like: I understood this but I have a piece or code in an pretrained model called BERT Algorithm calls this function model_fn_builder as following: here I don't under how the parameters namely features, labels, mode, params of function model_fn are being passed. Could anyone help me in understanding it ??",https://stackoverflow.com/questions/57216896,4732694.0,1
69709010,"Keras/Conv2D: Strange, I use padding=SAME, but the size is still reduced","I set padding to SAME or same, but the output is still being reduced, what's wrong then? 😅, as I understand according to the official doc, the output size shall be the same to the input one, do I forget what is important? Output",https://stackoverflow.com/questions/69709010,1835650.0,1
47320379,"use GAN to generator mnist,but study nothing","Recently,I am studying the GAN network,I'm using it to generator a mnisit image,the environment in my computer is ubuntu16.04,tensorflow,python3. The code can run without any error.But the result shows the network study nothing,through training,the output image is still noisy image. Firstly I design a generator network:the input is 784 dimension's noisy data,through a hidden layer and rule it,generate a 784 dimension's image. Then I design a discriminator network:the input is real image and fake image,through a hidden layer and rule it,the output is 1 dimension's logits. Then I defined the generator_loss and discriminator_loss, then train generator and discriminator.It can run,but the result show the network study nothing, the loss can not convergence. the result is:",https://stackoverflow.com/questions/47320379,8920592.0,1
54613474,Tensorflow Keras Input layer does not add _keras_shape,"According to the keras documentation, Input adds the _keras_shape attribute to the input tensor. However, as shown below, this is not the case. Have I misunderstood something, or is this a bug I should report? The lack of this attribute makes further Keras functions go haywire: I'm using tensorflow version '1.11.0-rc2'",https://stackoverflow.com/questions/54613474,2110869.0,1
54060667,Continue training of a custom tf.Estimator with AdamOptimizer,"I created a custom tf.Estimator whose weights I'm training using the tf.train.AdamOptimizer. When I continue training of an existing model, I observe a steep change in the metrics at the start of the continued training in Tensorboard. After a few steps, the metrics stabilise. The behaviour looks similar to the initial transients when training a model. The behaviour is the same if I continue training on the same Estimator instance, or if I recreate the estimator from a checkpoint. I suspect that the moving averages and/or the bias correction factor are reset when restarting the training. The model weights themselves seem to be properly restored, as the metrics do continue from where they settled before, only the effective learning rate seems to be too high. Previous Stack-Overflow answers seem to suggest that these auxiliary learning parameters should be stored with the checkpoints together with the model weights. So what am I doing wrong here? How can I control restoring of these auxiliary variables? I would like to be able to continue training as if it had never been stopped. However, other people sometimes seem look for the opposite control, to completely reset the optimizer without resetting the model weights. An answer that shows how both effects can be achieved would probably most helpful. Here is a sketch of my model_fn: The training step is called as follows: EDIT: The documentation of the warm_start_from argument of tf.estimator.Estimator and tf.estimator.WarmStartSettings are not entirely clear what exactly will happen in the default case, as I am using in the example above. However, the documentation of [tf.train.warm_start] (https://www.tensorflow.org/api_docs/python/tf/train/warm_start) seems to suggest that in the default case, all TRAINABLE_VARIABLES will be warm-started, which Indeed, I find Adam's accumulator variables in VARIABLES, but not in TRAINABLE_VARIABLES. These documentation pages also state how to change the list of warm-started variables, to either a list of tf.Variable instances, or a list of their names. However, one question remains: How do I create one of those lists in advance, given that with tf.Estimator, I have no graph to collect those variables/their names from? EDIT2: The source-code of warm_start highlights an undocumented feature: The list of variable names is in fact a list of regexes, to be matched against GLOBAL_VARIABLES. Thus, one may use to load all variables. However, even with that, the spikes in the summary stats remain. With that, I'm completely at a loss now what is going on.",https://stackoverflow.com/questions/54060667,4112821.0,1
70400987,TypeError: tf__normalize_img() missing 1 required positional argument: 'label',I'm new to deep learning and I was working with the Tensorflow Oxford Flowers dataset when I ran into an error while normalizing the images. I followed the guide on how to normalize images on the Tensorflow website but the error remains. Followed by I referred to https://www.tensorflow.org/datasets/keras_example. My Code:,https://stackoverflow.com/questions/70400987,17706343.0,1
48483980,why explain logit as 'unscaled log probabililty' in sotfmax_cross_entropy_with_logits?,"In the tensorflow documentation (softmax_cross_entropy_with_logits), they said ""logits : unscaled log probablilty"". What is 'log probability'? First, I understand that 'logits' is an 'output before normalization' or a 'score for class'. If I got [1.5, 2.4, 0,7] by tf.matmul(X,W) + b, then [1.5, 2.4, 0,7] is logits(score) and this was unscaled. I can understand it up to this stage. But, I can't understand why [1.5, 2.4, 0.7] is 'log probability'.",https://stackoverflow.com/questions/48483980,6333512.0,1
44518790,"Are tensor names always prepended with ""import/"" when loaded from protobuf?","When I load a (frozen) Tensorflow model from disk using: It seems that all tensor names are prepended with import/ . This is the code I use to print the names: Why? Is this some kind of default option that can be overriden? Or can I rely on this in my code? I could not find this documented anyhwere, can anybody point me to references regarding this?",https://stackoverflow.com/questions/44518790,7264906.0,1
39068703,"Tensorflow: Using weights trained in one model inside another, different model","I'm trying to train an LSTM in Tensorflow using minibatches, but after training is complete I would like to use the model by submitting one example at a time to it. I can set up the graph within Tensorflow to train my LSTM network, but I can't use the trained result afterward in the way I want. The setup code looks something like this: ...Note the two placeholders, input_data and target_data. I haven't bothered including the optimizer setup. After training is complete and the training session closed, I would like to set up a new session that uses the trained LSTM network whose input is provided by a completely different placeholder, something like: This second part returns the following error: ...Presumably because the graph I'm using still has the old training placeholders attached to the trained LSTM nodes. What's the right way to 'extract' the trained LSTM and put it into a new, different graph that has a different style of inputs? The Varible scoping features that Tensorflow has seem to address something like this, but the examples in the documentation all talk about using variable scope as a way of managing variable names so that the same piece of code will generate similar subgraphs within the same graph. The 'reuse' feature seems to be close to what I want, but I don't find the Tensorflow documentation linked above to be clear at all on what it does. The cells themselves cannot be given a name (in other words, is not valid), and while I can give a name to a seq2seq.rnn_decoder(), I presumably wouldn't be able to remove the rnn_cell.DropoutWrapper() if I used that node unchanged. Questions: What is the proper way to move trained LSTM weights from one graph to another? Is it correct to say that starting a new session ""releases resources"", but doesn't erase the graph built in memory? It seems to me like the 'reuse' feature allows Tensorflow to search outside of the current variable scope for variables with the same name (existing in a different scope), and use them in the current scope. Is this correct? If it is, what happens to all of the graph edges from the non-current scope that link to that variable? If it isn't, why does Tensorflow throw an error if you try to have the same variable name within two different scopes? It seems perfectly reasonable to define two variables with identical names in two different scopes, e.g. conv1/sum1 and conv2/sum1. In my code I'm working within a new scope but the graph won't run without data to be fed into a placeholder from the initial, default scope. Is the default scope always 'in-scope' for some reason? If graph edges can span different scopes, and names in different scopes can't be shared unless they refer to the exact same node, then that would seem to defeat the purpose of having different scopes in the first place. What am I misunderstanding here? Thanks!",https://stackoverflow.com/questions/39068703,3280780.0,1
58856160,Why do TensorFlow and PyTorch gradients of the eigenvalue decomposition differ from each other and the analytic solution?,"The following code computes the eigenvalue decomposition of a real symmetric matrix. Then, the gradient of the first eigenvalue with respect to the matrix is computed. This is done three times: 1) using the analytic formula, 2) using TensorFlow, 3) using PyTorch. This yields three different results. Can someone explain this behavior to me? Prints The main diagonals of the three results are identical. The off-diagonal elements of TensorFlow and PyTorch are twice as large as the analytic elements or equal to zero. Is this intended behavior? Why is it not documented? Are the gradients wrong? Version infos: TensorFlow 1.14.0, PyTorch 1.0.1",https://stackoverflow.com/questions/58856160,5555176.0,1
44124376,TensorFlow Dataset Shuffle Each Epoch,"In the manual on the Dataset class in Tensorflow, it shows how to shuffle the data and how to batch it. However, it's not apparent how one can shuffle the data each epoch. I've tried the below, but the data is given in exactly the same order the second epoch as in the first. Does anybody know how to shuffle between epochs using a Dataset?",https://stackoverflow.com/questions/44124376,4880003.0,1
48335842,Tensorflow: Exogenous feature key raises KeyError on StructuralEnsembleRegressor predict call,"I have a tensorflow implementation for timeseries forecasting. My data contains exogeneous features, I provide them in my train input and evaluate inputs. In the prediction step predict_continuation_input_fn raises KeyError for my exogenous feature column. Here is the simplified version of my code: At this point I get error KeyError: 'ex_0'. Error is obvious, since resulting evaluation variable does not contain my exogenous features. predict_continuation_input_fn has argument to get exogenous_features however I could not find any documentation on how to feed exogenous data from evaluation to that argument. How should I provide those features to prediction? Is there a flaw in my implementation? Advises are very welcome.",https://stackoverflow.com/questions/48335842,65071.0,1
47521759,tf.metrics.accuracy not working as intended,"I have linear regression model that seems to be working fine, but I want to display the accuracy of the model. First, I initialize the variables and placeholders... X_train has shape (6702, 89) and Y_train has shape (6702, 1). Next I run the session and I display the cost per epoch as well as the total MSE... This all seems to work correctly. However, now I want to see the accuracy of my model, so I want to implement tf.metrics.accuracy. The documentation says it has 2 arguments, labels and predictions. I added the following next... Apparently I need to initialize local variales, however I think I am doing something wrong because the accuracy result that gets printed out is 0.0. I searched everywhere for a working example but I cannot get it to work for my model, what is the proper way to implement it?",https://stackoverflow.com/questions/47521759,4333347.0,1
51508075,"Tensorflow: seq2seq with attention, dimension mismatch","Trying to implement an encoder-decoder model with bidirectional RNN encoding, beam search inference, and attention in Tensorflow. While the first two are working, I'm having trouble with the AttentionWrapper. I'm currently running into the following bug: This is my encoding layer: This is my decoding training: Finally, here is the decoding inference: This code is partially based on the Tensorflow NMT documentation. Here is the full stack trace:",https://stackoverflow.com/questions/51508075,6480948.0,1
42870727,Can one only implement gradient descent like optimizers with the code example from processing gradients in TensorFlow?,"I was looking at the example code for processing gradients that TensorFlow has: however, I noticed that the apply_gradients function was derived from the GradientDescentOptimizer. Does that mean that using the example code from above, one can only implement gradient like descent rules (notice we could change the opt = GradientDescentOptimizer or Adam or any of the the other optimizers)? In particular, what does apply_gradients do? I definitively check the code in the tf github page but it was a bunch of python that had nothing to do with mathematical expressions, so it was hard to tell what that was doing and how it changed from optimizer to optimizer. For example, if I wanted to implement my own custom optimizer that might use gradients (or might not e.g. just change the weights directly with some rule, maybe more biologically plausible rule), its not possible with the above example code? In particular I wanted to implement a gradient descent version that is artificially restricted in a compact domain. In particular I wanted to implement the following equation: in TensorFlow. I realized that the following is true: so I thought that I could just implement it by doing: and then just having: however, I realized that that wasn't good enough because I don't actually have access to w so I can't implement: at least not the way I tried. Is there a way to do this? i.e. to actually directly change the update rule? At least the way I tried? I know its sort of a hacky update rule, but my point is more to change the update equation than actually caring to much about that update rule (so don't get hung up on it if its a bit weird). I came up with super hacky solution: not sure if it works but something like that should work in general. The idea is to just write down the equation one wants to use (in TensorFlow) for the learning rate and then update the weights manually using a session. Unfortunately, such a solution means we have to take care of the annealing (decaying learning rate manually which seems annoying). This solution probably has many other problems, feel free to point them out (and give solutions if you can). For this very simple problem I realized one can just do the normal optimizer update rule and then just take the mod of the weights and re-assign them to their value: but in this case its a coincidence that such a simple solution exists (unfortunately, bypasses the whole point of my question). Actually, this solutions slows down the code a lot. For the moment is the best that I've got. As a reference, I have seen this question: How to create an optimizer in Tensorflow , but didn't find it responded directly to my question.",https://stackoverflow.com/questions/42870727,1601580.0,1
35644264,How to read data into Tensorflow?,"I'm trying to read data from CSV files to tensorflow, https://www.tensorflow.org/versions/r0.7/how_tos/reading_data/index.html#filenames-shuffling-and-epoch-limits The sample code in official document is like this: To read the file, I need to know how many columns and lines in the file beforehand, and if there are 1000 columns, I need to define 1000 variables like col1, col2, col3, col4, col5,..., col1000 , this doesn't look like an efficient way to read data. My questions",https://stackoverflow.com/questions/35644264,3723683.0,1
69607117,tensorflow - Invalid argument: Input size should match but they differ by 2,"I am trying to train a dl model with tf.keras. I have 67 classes of images inside the image directory like airports, bookstore, casino. And for each classes i have at least 100 images. The data is from mit indoor scene dataset But when I am trying to train the model, I am constantly getting this error. I tried to resolve the problem by resizing the image with the resizing layer, also included the labels='inferred' and label_mode='categorical' in the image_dataset_from_directory method and included loss='categorical_crossentropy' in the model compile method. Previously labels and label_model were not set and loss was sparse_categorical_crossentropy which i think is not right. so I changed them as described above.But I am still having problems. There is one question related to this in stackoverflow but the person did not mentioned how he solved the problem just updated that - My suggestion is to check the metadata of the dataset. It helped to fix my problem. But did not mentioned what metadata to look for or what he did to solve the problem. The code that I am using to train the model - Note - I just modified the code to make it as simple as possible to reduce the error. The model run for few batches than again got the above error. Modified code -",https://stackoverflow.com/questions/69607117,12195048.0,1
61859883,how to load large datasets of numpy arrays in order to train a CNN model in tensorflow2.1.0,"I'm training a convolutional neural network (CNN) model for a binary classification task in tensorflow2.1.0. The feature of each instance is a 4-dimensional numpy array with shape of (50, 50, 50, 2), in which the type of each element is float32. The label of each instance is 1 or 0 My largest training dataset can contain up to ~100 millions of instances. To efficiently train the model, is it best to serialize my training data and store it in a set of files with TFrecord format, and then load them with tf.data.TFRecordDataset() and parse them with tf.data.map()? If so, could you show me an example of how to serialize the pairs of feature-label and store them into TFrecord files, then how to load and parse them? I did not find appropriate example in the website of Tensorflow. Or is there any better way to store and load the huge datasets? Thanks very much.",https://stackoverflow.com/questions/61859883,13456421.0,1
46359843,Parameters in tf.contrib.seq2seq.sequence_loss,"I'm trying to use the tf.contrib.seq2seq.sequence_loss function in a RNN model to calculate the loss. According to the API document, this function requires at least three parameters: logits, targets and weights My understand is logits is my prediction after using Xw+b, so the shape of it should be [batch_size, sequence_length, output size]. Then target should be my label, but the shape required in is [batch_size, sequence_length]. I suppose my label should have the same shape as the logits. So how to convert the 3d labels to 2d? Thanks in advance",https://stackoverflow.com/questions/46359843,1779012.0,1
61131730,Tensorflow Datasets with string inputs do not preserve data type,"All reproducible code below is run at Google Colab with TF 2.2.0-rc2. Adapting the simple example from the documentation for creating a dataset from a simple Python list: we get the result where all data types are int32, as expected. But changing this simple example to feed a list of strings instead of integers: gives the result where, surprisingly, and despite the tensors themselves being of dtype=string, their evaluations are of type bytes. This behavior is not confined to the .from_tensor_slices method; here is the situation with .list_files (the following snippet runs straightforward in a fresh Colab notebook): the result being: where again, the file names in the evaluated tensors are returned as bytes, instead of string, despite that the tensors themselves are of dtype=string. Similar behavior is observed also with the .from_generator method (not shown here). A final demonstration: as shown in the .as_numpy_iterator method documentation, the following equality condition is evaluated as True: but if we change the elements of b to be strings, the equality condition is now surprisingly evaluated as False! probably due to the different data types, since the values themselves are evidently identical. I didn't stumble upon this behavior by academic experimentation; I am trying to pass my data to TF Datasets using custom functions that read pairs of files from the disk of the form which custom functions work perfectly well on their own, but mapped through TF Datasets give which, after this digging, seems at least not unexplained, if the returned data types are indeed bytes and not string. So, is this a bug (as it seems), or am I missing something here?",https://stackoverflow.com/questions/61131730,4685471.0,1
58044469,Gaussian Process Regression in Tensorflow 2.0 leads to no gradients?,"The following code is basically from the documentation, slightly converted to run in tensorflow 2.0. The gradients are all None. I'm not sure if this is a bug or just something I am missing: (corrected code) UPDATE: The following example now works. Am wondering if there is a better pattern for organizing this flow in tf 2.0?",https://stackoverflow.com/questions/58044469,287238.0,1
51170644,How to correctly restore a OOP tensorflow model?,"For the sake of a current project, I decided to define a tensorflow model within a class instance. This all worked well until I wanted to restore it to continue training from the latest checkpoint. It is a simple linear regression model which is built upon initialization of the instance. It tries to approximate the function f(x) = 3x + 1. The logic is: if there's no checkpoint yet, create a new model, train it for 20 epochs, save it. If there is already a checkpoint, load it, and continue training from it for 20 epochs. Now, initially training the network works. But when trying to train it after loading it, it throws the following error: The question is: how do restore it and proceed the training properly? I have found an interesting article about OOP here, but it does not deal with saving and restoring models. My code is below. Thank you for helping me out! EDIT1: When instantiating the model before checking whether there is an checkpoint or not, it results in an precondition error of an optimizer variable:",https://stackoverflow.com/questions/51170644,8334261.0,1
38527096,Run a tensorflow with a list of fetches does not work,"I'm playing around with Tensorflow and implemented a k means clustering algorithm. Everything works well, but if I want to run the session with a couple of fetches in a list I always get the error, that a list can not be converted to a Tensor or Operation. The documentation explicitly says, that I can call Session.run() with a list. Am I doing anything wrong? Here is the source code: Here is the error message:",https://stackoverflow.com/questions/38527096,1264252.0,1
67497418,TensorFlow accuracy metrics,"The following is a very simple TensorFlow 2 image classification model. Note that the loss function is not the usual SparseCategoricalCrossentropy. Also, the last layer has only 1 output, so this is not the usual classification setting. The accuracy here does not have meaning, but I am just curious. So this code does not work well as we expected, but still produces outputs with an accuracy of around 10%, which seems reasonable. My question is how this accuracy is calculated? The prediction from this model is a continuous value and the y_true is an integer value. It is not impossible to have an x.0 for the prediction, then the accuracy is too high. So, I have searched the TensorFlow API document to find the following example. And it makes sense. So I have tried the following code and get the 0.0 accuracy. Is there any explanation for this?",https://stackoverflow.com/questions/67497418,11381722.0,1
44762631,How to use tf.nn.ctc_loss in cnn+ctc network,"Recently, I try to use tensorflow to implement a cnn+ctc network base on the article Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks. I try to feed batch spectrogram data (shape:(10,120,155,3),batch_size is 10) into 10 convolution layer and 3 fully connected layer. So the output before connecting the ctc layer is 2d data(shape:(10,1024)). Here is my problem: I want to use tf.nn.ctc_loss function in tensorflow library,but it generate the ValueError: Dimension must be 2 but is 3 for 'transpose'(op:'Transpose') with input shapes:[?,1024],[3]. I guess the error is related to the dimension of my 2d input data. The discription of the ctc_loss function in tensorflow official site is require a 3d input with the shape (batch_size x max_time x num_classes). So, what is the extra dimension of 'num_classes' ? what should I change the shape of my cnn+fc output data?",https://stackoverflow.com/questions/44762631,3732470.0,1
66094207,TensorFlow Hidden Markov Model with more complex structure,"Using the great TensorFlow Hidden Markov Model library, it is straightforward to model the following Dynamic Bayesian Network: where Hi is the probability variable that represents the HMM and Si is the probability variable that represents observations. What if I'd like to make H depend on yet another HMM (Hierarchical HMM) or simply other probability variable like this: The HiddenMarkovModel definition in TensorFlow looks like the following: It only accepts initial, transition and observation distributions. How could I model the above and pass additional probability variable distribution to the HiddenMarkovModel? Is that possible by somehow incorporating C into the transition_distribution parameter? Maybe C should be treated as observation as well? (I'm not sure though, if that would be a full equivalent of the structure I'd like to model) A simple example / explanation would be great to have. UPDATE I've tried building a simple joint distribution of two dependent variables and feed as transition_distribution into the HMM: This gives an error: The HMM manual mentions: And that transition_distribution must be which tfd.JointDistributionSequential is probably not. Still looking for a ways of building hierarchical HMMs with TensorFlow.",https://stackoverflow.com/questions/66094207,716720.0,1
57721804,"setting sample_weight_mode=""temporal"" doesn't seem to work","I am working with LSTM in tensorflow 2.0 and I am trying to assign a weight to the training samples (I've already tried with class_weights dictionary but it complains that 3-d arrays are not supported for it. my array shape is (26000, 7, 1)). As suggested in the documentation, I am setting sample_weight_mode to ""temporal"" in compile, but after that when I try to fit the model I still get the error below: I have already tried changing the shape of the sample_weights passed in fit (also tried to flatten it), setting shuffle to False and removing the validation split without success. Here's the code I am using",https://stackoverflow.com/questions/57721804,9961790.0,1
63656778,How to load a trained TF1 protobuf model into TF2?,"Update: This is a bug in tensorflow. Track progress here. I have created and trained a model using stable-baselines, which uses Tensorflow 1. Now I need to use this trained model in an environment where I only have access to Tensorflow 2 or PyTorch. I figured I would go with Tensorflow 2 as the documentation says I should be able to load models created with Tensorflow 1. I can load the pb file without a problem in Tensorflow 1: However in Tensorflow 2 I get the following error: Model definition: Model saving in TF1: Fully reproducible code can be found in the following 2 google colab notebooks: Tensorflow 1 saving and loading Tensorflow 2 loading Direct link to the saved model: model",https://stackoverflow.com/questions/63656778,1564252.0,1
72794777,Received incompatible tensor at flattened index 4 from table 'uniform_table',"I'm trying to adapt the TensorFlow Agents tutorial to a custom environment. It's not very complicated and meant to teach me how this works. The game is basically a 21x21 grid with tokens the agent can collect for a reward by walking around. I can validate the environment, the agent, and the replay buffer, but when I try to train the model, i get an error message (see bottom). Any advice would be welcome ! The agent class is: The class I want to use for training the model is: It produces this error message: InvalidArgumentError: Received incompatible tensor at flattened index 4 from table 'uniform_table'. Specification has (dtype, shape): (int32, [?]). Tensor has (dtype, shape): (int32, [2,1]). Table signature: 0: Tensor&lt;name: 'key', dtype: uint64, shape: []&gt;, 1: Tensor&lt;name: 'probability', dtype: double, shape: []&gt;, 2: Tensor&lt;name: 'table_size', dtype: int64, shape: []&gt;, 3: Tensor&lt;name: 'priority', dtype: double, shape: []&gt;, 4: Tensor&lt;name: 'step_type/step_type', dtype: int32, shape: [?]&gt;, 5: Tensor&lt;name: 'observation/observation', dtype: int32, shape: [?,441]&gt;, 6: Tensor&lt;name: 'action/action', dtype: int32, shape: [?]&gt;, 7: Tensor&lt;name: 'next_step_type/step_type', dtype: int32, shape: [?]&gt;, 8: Tensor&lt;name: 'reward/reward', dtype: float, shape: [?]&gt;, 9: Tensor&lt;name: 'discount/discount', dtype: float, shape: [?]&gt; [Op:IteratorGetNext]",https://stackoverflow.com/questions/72794777,19437595.0,1
44874973,How to pass images through TensorFlow-Slim VGG Pre-Trained Net in Batches?,I want to pass the images through the network for a transfer learning task. In the following code I'm building the graph and then getting the outputs of a fully connected layer. I wanted to get the outputs in batches because I have an array with more than 20k images. The vgg.vgg_16(images) required images to be an array of images. I tried feeding an input placeholder (after looking at the docs) but when loading the checkpoint I got an error There are no variables to save. I can feed vgg.vgg_16(images) a few images at a time but I would need to load the checkpoint for each batch. I'm pretty sure there is a better way to do that. Is there any examples or references I can look at? I also tried this and this references but I didn't find the answers.,https://stackoverflow.com/questions/44874973,2069120.0,1
64880392,How to use Google Cloud Platform TPU v3?,I found a tutorial on How to Set up an Instance to Run a Jupyter Notebook in GCP? This tutorial is about how to run Jupyter Notebook in Google Cloud Platform. I would like to use also TPU v3. I also read the documentation https://cloud.google.com/tpu/docs/quickstart. But unfortunately it doesn't help me. My questions now are: In Google Colab I do the following in order to use the TPU: How do I use a TPU v3 with Google Cloud Platform?,https://stackoverflow.com/questions/64880392,,1
53488870,SageMaker fails when using Multi-GPU with keras.utils.multi_gpu_model,"Running AWS SageMaker with a custom model, the TrainingJob fails with an Algorithm Error when using Keras plus a Tensorflow backend in multi-gpu configuration: This simple parallel model loading will fail. There is no further error or exception from CloudWatch logging. This configuration works properly on local machine with 2x NVIDIA GTX 1080, same Keras Tensorflow backend. According to SageMaker documentation and tutorials the multi_gpu_model utility will work ok when Keras backend is MXNet, but I did not find any mention when the backend is Tensorflow with the same multi gpu configuration. [UPDATE] I have updated the code with the suggested answer below, and I'm adding some logging before the TrainingJob hangs This logging repeats twice Before there is some logging info about each GPU, that repeats 4 times According to the logging all the 4 GPUs are visible and loaded in the Tensorflow Keras backend. After that no application logging follows, the TrainingJob status is inProgress for a while, after that it becomes Failed with the same Algorithm Error. Looking at CloudWatch logging I can see some metrics at work. Specifically GPU Memory Utilization, CPU Utilization are ok, while GPU utilization is 0%. [UPDATE] Due to a known bug on Keras that is about saving a multi gpu model, I'm using this override of the multi_gpu_model utility in keras.utils This works ok on local 2x NVIDIA GTX 1080 / Intel Xeon / Ubuntu 16.04. It will fails on SageMaker Training Job. I have posted this issue on AWS Sagemaker forum in [UPDATE] I have slightly modified the tf.session code adding some initializers and now at least I can see that one GPU (I assume device gpu:0) is used from the instance metrics. The multi-gpu does not work anyways.",https://stackoverflow.com/questions/53488870,758836.0,1
47007997,keras custom loss function Value error on convert to tensor,"I'm trying to implement a custom loss function for keras using tensorflow backend. The idea i'm working with is to provide the ""Cost"" of a ""Signal"" as the y_true and handle the signals as the y_pred. This is basically a complicated classification situation. As an example lets say I have 3 possible output signals and N samples then I would have a cost matrix that is Nx3 and my predictions would also be Nx3 (So as to not run into problems with y_true and y_pred needing to be the same size. The way I am selecting my actual signal is by taking the max of the three output values and then the cost for this signal is the value in the cost matrix at the corresponding index. Total cost is the sum of these individual costs. I have implemented this in tensorflow (I needed to use gather_nd so I couldn't use keras.backend but all the examples I have read online don't seem to care about this fact). The code for my implementation is: I have confirmed this function to be working as expected by comparing it to the numpy equivalent. I am passing this loss function to my model when compiling: All of this seems to work fine until I try to fit the model with: model.fit(TrainX, TrainY, epochs=100) At which point the console spits out the following unhelpful message I tried to track down where this message was coming from in keras and tensorflow but while I found the functions it did not yield much insight for me as to what I am doing wrong. I have out of desperation also completely implemented to calculation manually using tf.convert_to_tensor() on my input X and Y which had no issues so I'm pretty stumped at this point what is going wrong. I'm new to Keras and tensorflow and while I have looked at basically every example I could find its very likely I am missing something pretty simple. So any help is greatly appreciated. Thanks in advance Also if there are pre-made solutions to this type of cost set up I would be happy to know about them. I came up with this idea after tinkering with a few different standard options without much success so I decided to try something that would give me more direct control over incentivizing the various output signals which better capture the underlying problem (Mis classification of some samples is not as important as misclassifying other samples)",https://stackoverflow.com/questions/47007997,3199524.0,1
71771353,Add reserved tokens to `tft.vocabulary`,I would like to append words to the vocabulary created by tft.vocabulary that are not a part of the training samples (i.e. &lt;mask&gt; and &lt;pad&gt; tokens). I see in the docs that the tft.vocabulary function can take an argument key_fn which the docs says: but with the key_fn below it still does not append the &lt;mask&gt; and &lt;pad&gt; tokens to the vocabulary.,https://stackoverflow.com/questions/71771353,18727781.0,1
37388604,How can I use intersphinx with Tensorflow and numpydoc?,"The main question here is where (if) there is an objects.inv for TensorFlow, but an example how to actually use it would be nice. For example, I currently have the following docstring: How do I use intersphinx to automatically link the object to the TensorFlow documentation?",https://stackoverflow.com/questions/37388604,562769.0,1
54657542,How to get subset of 10K MNIST images from Dataset class in tensorflow?,I found the following way to get mnist dataset in tensorflow: data variable is Dataset object. This approach is quite unclear to me and I cannot figure out how to convert 60K dataset into 10K dataset. When I do the following: I get error: But docs provide this method: Thank you for help!,https://stackoverflow.com/questions/54657542,3849781.0,1
70294847,Low accuracy using functional API + CNN and CIFAR10; incorrect initialization?,I'm new to using CNNs but I'm trying to make one using the functional API with the CIFAR10 dataset. The only thing is I'm getting very very low accuracy. I've looked over my textbook examples and documentation but can't figure out why it's so low when it should be starting way higher. This is my setup using DenseNet201 and tf version 2.7: I feel like all the examples I've seen start way higher and that's even without additional layers. Am I misunderstanding something in the initialization?,https://stackoverflow.com/questions/70294847,12379067.0,1
52785827,Run 1-D Conv using tensorflow,"I'm a beginner in TensorFlow. I want to train a 1-D conv model. I have one-rowed csv files for each row of my original data. csv files look like this The last column(containing 1 &amp; 0) are the labels for the single-row csv files Following the link I wrote the following pieces of code. I converted the csv files to TFRecord using the following code I want to now read the files and this is the code I'm using. From here the problem starts, From the documentation I understand what session does but failing to put it into code. Assuming I'll later figure out how to use I wrote the below code but don't know how to actually include it into my main script and further use it to train my model. Any help regarding how to proceed further will help. PS: Assuming my data was loaded into an np.array the dimension would be, (6571, 65281). Since it's astronomical data, each star has 65781 points.",https://stackoverflow.com/questions/52785827,8115171.0,1
69901254,model.fit() never calls custom metric specified,"Following the documentation I'm trying to implement a custom metric, however the metric never gets called. I added sanity checks that should produce errors when the metric is called. You can find the full example in this notebook. However, the code runs without a problem after passing the metric to model.compile() What I actually get:",https://stackoverflow.com/questions/69901254,20280771.0,1
70979815,How to crop an image using TensorFlow?,"I'm trying to crop an image where I have a detected object. From TensorFlow's documentation there is a function. I'm trying to work out how to get the given arguments but not sure what information to use. Here's the code I'm working with. With this being the result, I'm trying to crop out everything but the bounding box - Identified object",https://stackoverflow.com/questions/70979815,18114544.0,1
60450394,Understanding target data for softmax output layer,"I found some example code for a MNIST hand written character classification problem. The start of the code is as follows: Looking at the code it appears that the output layer of the network consists of ten nodes. If the network was working perfectly after training then (the appropriate) one of the ten outputs would have an activation very close to one and the rest should have activations very close to zero. I knew that the training set contained 60000 example patterns. I assumed that the target output data (y_train) would therefore be a 2D numpy array with a shape of 60000x10. I decided to double check and executed print(y_train.shape) and was very surprised to see it say (60000,)... Normally you would expect to see the size of the target patterns would be the same as the number of nodes in the output layer. I thought to myself, ""OK, well obviously softmax is an unusual special case were we only need one target""... My next thought was - how could I have known this from any documentation?... so far I have failed to find anything.",https://stackoverflow.com/questions/60450394,169774.0,1
49920153,tensorflow serving client does not work(grpc.framework.interfaces.face.face.AbortionError: AbortionError),"I'm deploying a text matching tensorflow program on docker referring to the official website, the installation steps and the test steps are all OK, including the server running status as well as OK, but client has a problem. Let me explain it in detail. This is my model graph with four inputs: This is my model server: And this is my client: And this is the error: I have printed the shape of features: (1,4), why does it still say I have fed the wrong tensor 'features'? I can not get it. Thanks for your any suggestion in advance.",https://stackoverflow.com/questions/49920153,7022048.0,1
65725030,How can I manage Queues in Tensorflow 2.0?,"Well, I'm trying to understand the Threading and Queues. I saw many documents on the web, but surprisingly there is not even a single example of this topic in tensorflow 2.0. What I want my queues to do is to, What I have in mind is, I have no idea what I'm doing. I also learned that how to manage multiple threads using tf.train.Coordinator() but I don't know where to use this.. While asking this, I have a suspicion that many APIs in the tf.data.Dataset replace all of these and multiple threads can be replaced with the tf.data.experimental.AUTOTUNE. Sorry for all the mess here. I can't arrange this properly even during asking. Any comments will be appreciated. Thanks in advance.",https://stackoverflow.com/questions/65725030,7820717.0,1
53367063,"tensorflow python expected dense_input to have 2 dimensions, but got array with shape (5, 28, 5)","I am a complete newbie to tensorflow, trying to learn about it and solve a problem. I tried a lot of tutorials but they all talked about the same classify image or mnist stuff, so I followed the documentation and tried to figure something out. The goal is to find a pattern to predict the result when the input is [[1000,10, 5, 3, 1744...etc. There are only 5 cases when the value is 300 400, 500, 600, 700, with shape 28,5 and the result for each is 28,2 list. The data is loaded from file and assigned to tf.tensor. Here's my code: newData: newResult: Getting this error when I run it: I know my model definitely has something wrong with it, but I can't quite figure out what. I have trouble finding information other than the afore mentioned examples.",https://stackoverflow.com/questions/53367063,10672298.0,1
54703128,"No gradients provided for any variable, check your graph for ops that do not support gradients, between variables and loss","I am trying to build a Bayesian Softmax Regression model using the TensorFlow Probabilities Dense Flip-Out layer. This model is being trained on the MNIST dataset. TensorFlow is returning an error: I presume this is due to the fact that random variables are not differential, thus no gradient exists. However, Tensorflow provides a clear demonstration of this code on their website - here. Does anyone have a comprehensive answer as to why this is happening? My code is as below:",https://stackoverflow.com/questions/54703128,11055886.0,1
43284047,What is the default kernel initializer in tf.layers.conv2d and tf.layers.dense?,"The official Tensorflow API doc claims that the parameter kernel_initializer defaults to None for tf.layers.conv2d and tf.layers.dense. However, reading the layers tutorial (https://www.tensorflow.org/tutorials/layers), I noted that this parameter is not set in the code. For example: The example code from the tutorial runs without any errors, so I think the default kernel_initializer is not None. So, which initializer is used? In another code, I did not set the kernel_initializer of the conv2d and dense layers, and everything was fine. However, when I tried to set the kernel_initializer to tf.truncated_normal_initializer(stddev=0.1, dtype=tf.float32), I got NaN errors. What is going on here? Can anyone help?",https://stackoverflow.com/questions/43284047,7833924.0,1
58947679,No gradients provided for any variable in tensorflow2.0,I met a problem when I tried to use tensorflow2.0 to create a transformer based on the official guidelines posted by the TensorFlow and when I add a full connected net it seems that both the classification loss and the translate loss as gradients on some of the variables. But once I try to add the two loss the gradients to all variables disappear. I have no idea and I tried to figure to solved the problem for weeks. Could anyone give me some suggestions? below is my error infomation,https://stackoverflow.com/questions/58947679,10796214.0,1
48495699,How to understand the effect of local_step in tf.ConditionalAccumulator(),"I want to implement the function which conducts backward() after multiple forward() operations in order to increase the actual batch_size with limited GPU memory. So I came to tf.ConditionalAccumulator. In the arguments of tf.ConditionalAccumulator().apply_grad(), there is an argument local_step which I do not understand how to appoint. The document explains as follow: I tried to search the implementation of tf.CondionalAccumentor().apply_grad(), but didn't find the member variable refers to global_time_step. In my understanding, there should be ten gradient slots, if we want to accumulate 10 times before one gradient update. The global_time_step is applied as an indicator to point out which slot should be used. if the local_step is less than the global_time_step, which means the corresponding slot has been used, so the gradient is stale and should be discarded. In my implementation, I assign it with global_step variable, which is used to record the number of gradient update in training procedure, and it increases one in every batch_size iterations, thus it increases one after batch_size examples forward. I am not sure about the correctness of my implementation. I hope someone can help to explain the mechanism of tf.ConditionalAccumulator.",https://stackoverflow.com/questions/48495699,4202137.0,1
